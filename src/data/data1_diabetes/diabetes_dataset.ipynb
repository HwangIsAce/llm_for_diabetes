{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) raw dataset\n",
    "2) keywords based extraction\n",
    "3) train/test split\n",
    "4) sample a specific number of samples (high cardinality)\n",
    "5) paste the instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8c35691f2347309e1cc7b08e9c4a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import logout, notebook_login\n",
    "# logout()\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset load\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# qa datasets\n",
    "medqa = load_dataset(\"GBaker/MedQA-USMLE-4-options\")\n",
    "# medqa = load_dataset(\"bigbio/med_qa\")\n",
    "medmcqa = load_dataset(\"openlifescienceai/medmcqa\")\n",
    "pubmedqa = load_dataset(\"bigbio/pubmed_qa\", trust_remote_code=True)\n",
    "# pubmedqa = load_dataset(\"qiaojin/PubMedQA\", \"pqa_artificial\")\n",
    "# bioasq = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"question-answer-passages\")\n",
    "# mednli = load_dataset(\"bigbio/mednli\")\n",
    "\n",
    "# nli datasets\n",
    "# mednli = load_dataset(\"cnut1648/mnli_resampled_as_mednli\")\n",
    "bionli = load_dataset(\"clinicalnlplab/BioNLI_test\")\n",
    "\n",
    "# information extraction datasets\n",
    "# cie_mse = load_dataset(\"mitclinicalml/clinical-ie\", \"medication_status\", trust_remote_code=True) # medication status extraction\n",
    "# cie_ccr = load_dataset(\"mitclinicalml/clinical-ie\", \"coreference\", trust_remote_code=True) # clinical coreference resolution\n",
    "\n",
    "# medmentions = load_dataset(\"bigbio/medmentions\", trust_remote_code=True)\n",
    "# bc5cdr = load_dataset(\"bigbio/bc5cdr\", trust_remote_code=True)\n",
    "\n",
    "# chemdisgene = load_dataset(\"bigbio/chem_dis_gene\", trust_remote_code=True)\n",
    "# biored = load_dataset(\"bigbio/biored\", trust_remote_code=True)\n",
    "# biorelex = load_dataset(\"bigbio/biorelex\", trust_remote_code=True)\n",
    "biorel = load_dataset(\"DFKI-SLT/BioRel\")\n",
    "# biorex = load_dataset(\"bigbio/biorelex\", trust_remote_code=True)\n",
    "\n",
    "# generation task about clinical skills datasets\n",
    "# medichat = load_dataset(\"Mostafijur/medichat_conversation\", \"medichat_subset1\") # ~ medichat_subset15 # conv2note\n",
    "icliniq = load_dataset(\"lavita/ChatDoctor-iCliniq\")\n",
    "# mediqa = load_dataset(\"jonathankang/EN-MEDIQA\")\n",
    "pubmed = load_dataset(\"ccdv/pubmed-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "icliniq = icliniq['train'].train_test_split(test_size=0.3, seed=42)\n",
    "# pubmedqa = pubmedqa['train'].train_test_split(test_size=0.3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medqa\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer', 'options', 'meta_info', 'answer_idx', 'metamap_phrases'],\n",
      "        num_rows: 10178\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer', 'options', 'meta_info', 'answer_idx', 'metamap_phrases'],\n",
      "        num_rows: 1273\n",
      "    })\n",
      "})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "medmcqa\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n",
      "        num_rows: 182822\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n",
      "        num_rows: 6150\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n",
      "        num_rows: 4183\n",
      "    })\n",
      "})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "pubmedqa\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['QUESTION', 'CONTEXTS', 'LABELS', 'MESHES', 'YEAR', 'reasoning_required_pred', 'reasoning_free_pred', 'final_decision', 'LONG_ANSWER'],\n",
      "        num_rows: 200000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['QUESTION', 'CONTEXTS', 'LABELS', 'MESHES', 'YEAR', 'reasoning_required_pred', 'reasoning_free_pred', 'final_decision', 'LONG_ANSWER'],\n",
      "        num_rows: 11269\n",
      "    })\n",
      "})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "bionli\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'query', 'answer', 'choices', 'gold'],\n",
      "        num_rows: 5544\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'query', 'answer', 'choices', 'gold'],\n",
      "        num_rows: 12806\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'query', 'answer', 'choices', 'gold'],\n",
      "        num_rows: 6308\n",
      "    })\n",
      "})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "biorel\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'relation', 'h', 't'],\n",
      "        num_rows: 534277\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'relation', 'h', 't'],\n",
      "        num_rows: 114506\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'relation', 'h', 't'],\n",
      "        num_rows: 114565\n",
      "    })\n",
      "})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "icliniq\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input', 'answer_icliniq', 'answer_chatgpt', 'answer_chatdoctor'],\n",
      "        num_rows: 5124\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input', 'answer_icliniq', 'answer_chatgpt', 'answer_chatdoctor'],\n",
      "        num_rows: 2197\n",
      "    })\n",
      "})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "pubmed\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'abstract'],\n",
      "        num_rows: 119924\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'abstract'],\n",
      "        num_rows: 6633\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'abstract'],\n",
      "        num_rows: 6658\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"medqa\")\n",
    "print(medqa)\n",
    "print('------------------------------------------------------------------------------'* 2) \n",
    "print(\"medmcqa\")\n",
    "print(medmcqa)\n",
    "print('------------------------------------------------------------------------------'* 2) \n",
    "print(\"pubmedqa\")\n",
    "print(pubmedqa)\n",
    "print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"mednli\")\n",
    "# print(mednli)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "print(\"bionli\")\n",
    "print(bionli)\n",
    "print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"cie_mse\")\n",
    "# print(cie_mse)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"cie_ccr\")\n",
    "# print(cie_ccr)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"medmentions\")\n",
    "# print(medmentions)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"bc5cdr\")\n",
    "# print(bc5cdr)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"chem-dis-gene\")\n",
    "# print(chemdisgene)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"biored\")\n",
    "# print(biored)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"biorelex\")\n",
    "# print(biorelex)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "print(\"biorel\")\n",
    "print(biorel)\n",
    "print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"biorex\")\n",
    "# print(biorex)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"medichat\")\n",
    "# print(medichat)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "print(\"icliniq\")\n",
    "print(icliniq)\n",
    "print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"mediqa\")\n",
    "# print(mediqa)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "print(\"pubmed\")\n",
    "print(pubmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medqa (train): 10178 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "medqa (test): 1273 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "medmcqa (train): 182822 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "medmcqa (test): 6150 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "medmcqa (validation): 4183 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "pubmedqa (train): 200000 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "pubmedqa (validation): 11269 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "bionli (train): 11088 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "bionli (validation): 25612 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "bionli (test): 12616 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "biorel (train): 534277 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "biorel (validation): 114506 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "biorel (test): 114565 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "icliniq (train): 10248 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "icliniq (test): 4394 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "pubmed (train): 119924 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "pubmed (validation): 6633 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "pubmed (test): 6658 rows processed and appended to all_data_filtered_by_keywords.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    " \n",
    "keywords = [\n",
    "    # 질환 관련\n",
    "    \"diabetes\", \"HbA1c\", \"blood sugar\", \n",
    "    \"glucose\", \"ketoacidosis\",\n",
    "    \n",
    "    # 약물 및 치료\n",
    "    \"insuline\",\n",
    "    \"metformin\", \"SGLT2 inhibitors\", \"GLP-1 receptor agonist\",\n",
    "\n",
    "    # 합병증\n",
    "    \"neuropathy\", \"retinopathy\", \"nephropathy\",\n",
    "]\n",
    "\n",
    "def contains_keywords(text, keywords):\n",
    "    if not text or not isinstance(text, str): \n",
    "        return False\n",
    "    return any(keyword in text.lower() for keyword in keywords)\n",
    "\n",
    "def process_dataset_split(dataset_name, split_name, dataset, text_columns, output_file, keywords=[\"diabetes\", \"insulin\"]):\n",
    "    rows = []\n",
    "    for i in range(len(dataset)):\n",
    "        row = dataset[i]\n",
    "\n",
    "        for col in text_columns:\n",
    "            if col in row:\n",
    "                text = row[col]\n",
    "\n",
    "            elif col == \"abstract\" and \"passages\" in row:\n",
    "                if isinstance(row[\"passages\"], list):\n",
    "                    text = \" \".join([p[\"text\"] for p in row[\"passages\"] if p.get(\"type\") == \"abstract\"])\n",
    "                else:\n",
    "                    text = \"\"\n",
    "            else:\n",
    "                text = \"\"\n",
    "\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            is_related = 1 if contains_keywords(text, keywords) else 0\n",
    "\n",
    "            rows.append({\n",
    "                \"dataset\": dataset_name,\n",
    "                \"split_data\": split_name,\n",
    "                \"features\": row,  \n",
    "                \"input\": text,\n",
    "                \"output\": is_related\n",
    "            })\n",
    "\n",
    "    if rows:  \n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(output_file, mode=\"a\", header=not os.path.exists(output_file), index=False)\n",
    "        print(f\"{dataset_name} ({split_name}): {len(rows)} rows processed and appended to {output_file}\")\n",
    "    else:\n",
    "        print(f\"{dataset_name} ({split_name}): No rows processed.\")\n",
    "\n",
    "datasets = {\n",
    "    \"medqa\": {\"splits\": medqa, \"columns\": [\"question\"]},\n",
    "    \"medmcqa\": {\"splits\": medmcqa, \"columns\": [\"question\"]},\n",
    "    \"pubmedqa\": {\"splits\": pubmedqa, \"columns\": [\"QUESTION\"]},\n",
    "    # \"mednli\": {\"splits\": mednli, \"columns\": [\"premise\", \"hypothesis\"]},\n",
    "    \"bionli\": {\"splits\": bionli, \"columns\": [\"query\", \"answer\"]},\n",
    "    # \"cie_mse\": {\"splits\": cie_mse, \"columns\": [\"snippet\"]},\n",
    "    # \"cie_ccr\": {\"splits\": cie_ccr, \"columns\": [\"snippet\"]},\n",
    "    # \"medmentions: {\"splits\": medmentions, \"columns\": [\"passages\"]},\n",
    "    # \"bc5cdr\": {\"splits\": bc5cdr, \"columns\": [\"passages\"]},\n",
    "    # \"chemdisgene\": {\"splits\": chemdisgene, \"columns\": [\"passages\"]},\n",
    "    # \"biored\": {\"splits\": biored, \"columns\": [\"passages\"]},\n",
    "    # \"biorelex\": {\"splits\": biorelex, \"columns\": [\"text\"]},\n",
    "    \"biorel\": {\"splits\": biorel, \"columns\": [\"text\"]},\n",
    "    # \"biorex\": {\"splits\": biorex, \"columns\": [\"text\"]},\n",
    "    # \"medichat\": {\"splits\": medichat, \"columns\": [\"conversation\"]},\n",
    "    \"icliniq\": {\"splits\": icliniq, \"columns\": [\"input\", \"answer_icliniq\"]},\n",
    "    \"pubmed\": {\"splits\": pubmed, \"columns\": [\"abstract\"]},\n",
    "}\n",
    "\n",
    "output_file = os.path.join(\"all_data_filtered_by_keywords.csv\")\n",
    "\n",
    "for dataset_name, details in datasets.items():\n",
    "    splits = details[\"splits\"]\n",
    "    text_columns = details[\"columns\"] \n",
    "\n",
    "    for split_name, split_data in splits.items():\n",
    "        process_dataset_split(dataset_name, split_name, split_data, text_columns, output_file, keywords=keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_df = pd.read_csv(\"/data/jaesung/llm_for_diabetes/src/data/data1_diabetes/all_data_filtered_by_keywords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_filtered_by_keyword\n",
    "diabetes = all_df[all_df['output'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split_data</th>\n",
       "      <th>features</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>medqa</td>\n",
       "      <td>train</td>\n",
       "      <td>{'question': 'A 68-year-old man presents to th...</td>\n",
       "      <td>A 68-year-old man presents to the emergency de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>medqa</td>\n",
       "      <td>train</td>\n",
       "      <td>{'question': 'A 68-year-old man comes to the p...</td>\n",
       "      <td>A 68-year-old man comes to the physician becau...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset split_data                                           features  \\\n",
       "15   medqa      train  {'question': 'A 68-year-old man presents to th...   \n",
       "17   medqa      train  {'question': 'A 68-year-old man comes to the p...   \n",
       "\n",
       "                                                input  output  \n",
       "15  A 68-year-old man presents to the emergency de...       1  \n",
       "17  A 68-year-old man comes to the physician becau...       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset   split_data\n",
       "bionli    test           3906\n",
       "          train          3690\n",
       "          validation     8280\n",
       "biorel    test          15618\n",
       "          train         69864\n",
       "          validation    15396\n",
       "biorelex  train             1\n",
       "biorex    train             1\n",
       "icliniq   test            972\n",
       "          train          2238\n",
       "medmcqa   test            414\n",
       "          train         11952\n",
       "          validation      270\n",
       "medqa     test           1122\n",
       "          train          9564\n",
       "pubmed    test           3264\n",
       "          train         54714\n",
       "          validation     3222\n",
       "pubmedqa  train         21744\n",
       "          validation     1227\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.groupby(['dataset', 'split_data'])['output'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def re_train_test_split_unique(dataframe, train_ratio=0.8):\n",
    "    new_rows = []\n",
    "\n",
    "    grouped = dataframe.groupby('dataset')\n",
    "\n",
    "    for dataset_name, group in grouped:\n",
    "        if dataset_name not in ['bionli', 'biorel', 'icliniq', 'medmcqa', 'medqa', 'pubmed', 'pubmedqa']:\n",
    "            continue\n",
    "\n",
    "        # 중복 제거\n",
    "        group = group.drop_duplicates(subset='features')\n",
    "\n",
    "        train_data, test_data = train_test_split(\n",
    "            group,\n",
    "            test_size=1-train_ratio,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        train_data = train_data.copy()\n",
    "        train_data['split_data'] = 'train'\n",
    "\n",
    "        test_data = test_data.copy()\n",
    "        test_data['split_data'] = 'test'\n",
    "\n",
    "        new_rows.append(train_data)\n",
    "        new_rows.append(test_data)\n",
    "\n",
    "    result_df = pd.concat(new_rows, ignore_index=True)\n",
    "    return result_df\n",
    "\n",
    "diabetes2 = re_train_test_split_unique(diabetes, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset   split_data\n",
       "bionli    test            426\n",
       "          train          1701\n",
       "biorel    test           3359\n",
       "          train         13434\n",
       "icliniq   test             89\n",
       "          train           356\n",
       "medmcqa   test            422\n",
       "          train          1684\n",
       "medqa     test            357\n",
       "          train          1424\n",
       "pubmed    test           2039\n",
       "          train          8154\n",
       "pubmedqa  test           1532\n",
       "          train          6125\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes2.groupby(['dataset', 'split_data'])['output'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "def add_input_to_for_sampling(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    \n",
    "    # INPUT 값을 추출하여 새로운 컬럼에 추가\n",
    "    def extract_for_sampling(row):\n",
    "        if row['dataset'] == 'bionli':\n",
    "            features = ast.literal_eval(row['features']) \n",
    "            query = features.get('query', '') \n",
    "            input_text = query.split(\"INPUT: \")[1].split(\"[HYP]\")[0].strip() if \"INPUT: \" in query else None\n",
    "            answer = features.get('answer', None)\n",
    "            return {'input': input_text, 'output': answer}\n",
    "        elif row['dataset'] == 'biorel':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            text = features.get('text', None)\n",
    "            relation = features.get('relation', None)\n",
    "            return {'input': text, 'output': relation}\n",
    "        elif row['dataset'] == 'icliniq':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            input_text = features.get('input', None)\n",
    "            answer_iclinq = features.get('answer_iclinq', None)\n",
    "            return {'input': input_text, 'output': answer_iclinq}\n",
    "        elif row['dataset'] == 'medmcqa':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            input_text = features.get('question', None)\n",
    "            answer = \", \".join([\n",
    "                features.get('opa', ''),\n",
    "                features.get('opb', ''),\n",
    "                features.get('opc', ''),\n",
    "                features.get('opd', ''),\n",
    "            ]).strip()\n",
    "            return {'input': input_text, 'output': answer}\n",
    "        elif row['dataset'] == 'medqa':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            input_text = features.get('question', None)\n",
    "            answer = features.get('answer', None)\n",
    "            return {'input': input_text, 'output': answer}\n",
    "        elif row['dataset'] == 'pubmed':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            input_text = features.get('article', None)\n",
    "            abstract = features.get('abstract', None)\n",
    "            return {'input': input_text, 'output': abstract}\n",
    "        elif row['dataset'] == 'pubmedqa':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            question = features.get('QUESTION', None)\n",
    "            answer = features.get('LONG_ANSWER', None)\n",
    "            return {'input': question, 'output': answer}\n",
    "\n",
    "    dataframe['for_sampling'] = dataframe.apply(extract_for_sampling, axis=1)\n",
    "    return dataframe\n",
    "\n",
    "diabetes3 = add_input_to_for_sampling(diabetes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split_data</th>\n",
       "      <th>features</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>for_sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bionli</td>\n",
       "      <td>train</td>\n",
       "      <td>{'id': 'BioNLI16787330', 'query': '\\nTASK: Ple...</td>\n",
       "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input': '[PRE] An increased oxidative stress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bionli</td>\n",
       "      <td>train</td>\n",
       "      <td>{'id': 'BioNLI22643846', 'query': '\\nTASK: Ple...</td>\n",
       "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input': '[PRE] Previously we demonstrated th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset split_data                                           features  \\\n",
       "0  bionli      train  {'id': 'BioNLI16787330', 'query': '\\nTASK: Ple...   \n",
       "1  bionli      train  {'id': 'BioNLI22643846', 'query': '\\nTASK: Ple...   \n",
       "\n",
       "                                               input  output  \\\n",
       "0  \\nTASK: Please classify the relationship betwe...       1   \n",
       "1  \\nTASK: Please classify the relationship betwe...       1   \n",
       "\n",
       "                                        for_sampling  \n",
       "0  {'input': '[PRE] An increased oxidative stress...  \n",
       "1  {'input': '[PRE] Previously we demonstrated th...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split_data</th>\n",
       "      <th>features</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>for_sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>biorel</td>\n",
       "      <td>train</td>\n",
       "      <td>{'text': 'hla antigens , complement allotypes ...</td>\n",
       "      <td>hla antigens , complement allotypes , insulin ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input': 'hla antigens , complement allotypes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>biorel</td>\n",
       "      <td>train</td>\n",
       "      <td>{'text': \"glucosamine and n-acetylglucosamine ...</td>\n",
       "      <td>glucosamine and n-acetylglucosamine supported ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'input': 'glucosamine and n-acetylglucosamine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset split_data                                           features  \\\n",
       "2127  biorel      train  {'text': 'hla antigens , complement allotypes ...   \n",
       "2128  biorel      train  {'text': \"glucosamine and n-acetylglucosamine ...   \n",
       "\n",
       "                                                  input  output  \\\n",
       "2127  hla antigens , complement allotypes , insulin ...       1   \n",
       "2128  glucosamine and n-acetylglucosamine supported ...       1   \n",
       "\n",
       "                                           for_sampling  \n",
       "2127  {'input': 'hla antigens , complement allotypes...  \n",
       "2128  {'input': 'glucosamine and n-acetylglucosamine...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes3[diabetes3['dataset']=='biorel'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16793"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diabetes3[diabetes3['dataset']=='biorel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41102"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diabetes3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast \n",
    "\n",
    "def filter_na_relations(dataframe):\n",
    "    def is_valid_relation(features_str):\n",
    "        try:\n",
    "            features_dict = ast.literal_eval(features_str)\n",
    "            return features_dict.get('relation') is not None and features_dict['relation'] != 'NA'\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    biorel_filtered = dataframe[dataframe['dataset'] == 'biorel']\n",
    "    biorel_filtered = biorel_filtered[biorel_filtered['features'].apply(is_valid_relation)]\n",
    "\n",
    "    others = dataframe[dataframe['dataset'] != 'biorel']\n",
    "\n",
    "    result = pd.concat([biorel_filtered, others], ignore_index=True)\n",
    "    return result\n",
    "\n",
    "diabetes3 = filter_na_relations(diabetes3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12054"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diabetes3[diabetes3['dataset']=='biorel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36363"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diabetes3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'text': 'hla antigens , complement allotypes , insulin antibodies and thyrogastric autoantibodies were determined in 69 patients with type 1 ( insulin-dependent ) diabetes defined by a tendency to ketosis , non-obesity and insulin requirement within 2 years of diagnosis .', 'relation': 'may_be_treated_by', 'h': {'id': 'C0011854', 'name': 'insulin-dependent', 'pos': [134, 151]}, 't': {'id': 'C0021641', 'name': 'insulin', 'pos': [214, 221]}}\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes3[diabetes3['dataset']=='biorel']['features'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36363"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diabetes3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jaesung/anaconda3/envs/faiss_gpu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SentenceTransformer model on GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for dataset: bionli (1701 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 2.02 seconds for 1701 rows\n",
      "Applying MMR for dataset: bionli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:  14%|█▍        | 1/7 [00:04<00:25,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for dataset: biorel (9621 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:03<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 4.26 seconds for 9621 rows\n",
      "Applying MMR for dataset: biorel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:  29%|██▊       | 2/7 [00:28<01:20, 16.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for dataset: icliniq (356 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Processing datasets:  43%|████▎     | 3/7 [00:29<00:35,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 0.37 seconds for 356 rows\n",
      "Applying MMR for dataset: icliniq\n",
      "Generating embeddings for dataset: medmcqa (1684 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 1.08 seconds for 1684 rows\n",
      "Applying MMR for dataset: medmcqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:  57%|█████▋    | 4/7 [00:32<00:20,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for dataset: medqa (1424 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 1.18 seconds for 1424 rows\n",
      "Applying MMR for dataset: medqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:  71%|███████▏  | 5/7 [00:35<00:11,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for dataset: pubmedqa (6125 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 3.29 seconds for 6125 rows\n",
      "Applying MMR for dataset: pubmedqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:  86%|████████▌ | 6/7 [00:49<00:08,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for dataset: pubmed (8154 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:15<00:00,  7.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 23.65 seconds for 8154 rows\n",
      "Applying MMR for dataset: pubmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets: 100%|██████████| 7/7 [01:28<00:00, 12.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dataset split_data                                           features  \\\n",
      "0  bionli      train  {'id': 'BioNLI18619553', 'query': '\\nTASK: Ple...   \n",
      "1  bionli      train  {'id': 'BioNLI30390733', 'query': \"\\nTASK: Ple...   \n",
      "2  bionli      train  {'id': 'BioNLI21447232', 'query': '\\nTASK: Ple...   \n",
      "3  bionli      train  {'id': 'BioNLI21146692', 'query': \"\\nTASK: Ple...   \n",
      "4  bionli      train  {'id': 'BioNLI25180937', 'query': '\\nTASK: Ple...   \n",
      "\n",
      "                                               input  output  \\\n",
      "0  \\nTASK: Please classify the relationship betwe...       1   \n",
      "1  \\nTASK: Please classify the relationship betwe...       1   \n",
      "2  \\nTASK: Please classify the relationship betwe...       1   \n",
      "3  \\nTASK: Please classify the relationship betwe...       1   \n",
      "4  \\nTASK: Please classify the relationship betwe...       1   \n",
      "\n",
      "                                        for_sampling  \n",
      "0  {'input': '[PRE] Previously, we demonstrated t...  \n",
      "1  {'input': '[PRE] Dear Editor, Eczema is an inf...  \n",
      "2  {'input': '[PRE] Orexinergic signalling is cri...  \n",
      "3  {'input': '[PRE] A risk score for atrial fibri...  \n",
      "4  {'input': '[PRE] It is well known the particip...  \n",
      "총 샘플링된 행 수: 6300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def mmr(query_embedding, doc_embeddings, diversity, top_n):\n",
    "    faiss.normalize_L2(doc_embeddings)\n",
    "    faiss.normalize_L2(query_embedding.reshape(1, -1))\n",
    "\n",
    "    selected_indices = []\n",
    "    candidate_indices = list(range(len(doc_embeddings)))\n",
    "\n",
    "    for _ in range(top_n):\n",
    "        if not candidate_indices:\n",
    "            break\n",
    "\n",
    "        if len(selected_indices) == 0:\n",
    "            selected_idx = candidate_indices[np.argmax(np.dot(doc_embeddings[candidate_indices], query_embedding.T))]\n",
    "        else:\n",
    "            selected_embeddings = doc_embeddings[selected_indices]\n",
    "            similarity_to_selected = np.dot(doc_embeddings[candidate_indices], selected_embeddings.T)\n",
    "            diversity_scores = np.max(similarity_to_selected, axis=1)\n",
    "            relevance_scores = np.dot(doc_embeddings[candidate_indices], query_embedding.T).flatten()\n",
    "            mmr_scores = (1 - diversity) * relevance_scores - diversity * diversity_scores\n",
    "            selected_idx = candidate_indices[np.argmax(mmr_scores)]\n",
    "\n",
    "        selected_indices.append(selected_idx)\n",
    "        candidate_indices.remove(selected_idx)\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "def mmr_sampling(dataframe, sampling_dict, embedding_model='all-MiniLM-L6-v2', batch_size=64, diversity=0.7, seed=42):\n",
    "    set_seed(seed)\n",
    "\n",
    "    print(\"Loading SentenceTransformer model on GPU...\")\n",
    "    model = SentenceTransformer(embedding_model, device=\"cuda:0\")\n",
    "\n",
    "    sampled_rows = []\n",
    "\n",
    "    for dataset_name, sample_count in tqdm(sampling_dict.items(), desc=\"Processing datasets\"):\n",
    "        subset = dataframe[(dataframe['dataset'] == dataset_name) & (dataframe['split_data'] == 'train')].copy()\n",
    "        num_rows = len(subset)\n",
    "        if num_rows == 0:\n",
    "            print(f\"No data found for dataset: {dataset_name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Generating embeddings for dataset: {dataset_name} ({num_rows} rows)\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        embeddings = model.encode(\n",
    "            subset['for_sampling'].astype(str).tolist(),\n",
    "            batch_size=batch_size,\n",
    "            convert_to_numpy=True,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Embedding generation took {elapsed_time:.2f} seconds for {num_rows} rows\")\n",
    "\n",
    "        query_embedding = np.mean(embeddings, axis=0)\n",
    "\n",
    "        print(f\"Applying MMR for dataset: {dataset_name}\")\n",
    "        selected_indices = mmr(query_embedding, embeddings, diversity, sample_count)\n",
    "        sampled_subset = subset.iloc[selected_indices]\n",
    "        sampled_rows.append(sampled_subset)\n",
    "\n",
    "    return pd.concat(sampled_rows, ignore_index=True)\n",
    "\n",
    "# 샘플링 설정\n",
    "sampling_config = {\n",
    "    'bionli': 1000,\n",
    "    'biorel': 1000,\n",
    "    'icliniq': 300,\n",
    "    'medmcqa': 1000,\n",
    "    'medqa': 1000,\n",
    "    'pubmedqa': 1000,\n",
    "    'pubmed': 1000\n",
    "}\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# 샘플링 실행\n",
    "sampled_train = mmr_sampling(diabetes3, sampling_config, batch_size=4096, diversity=0.7, seed=42)\n",
    "\n",
    "# 결과 확인\n",
    "print(sampled_train.head())\n",
    "print(f\"총 샘플링된 행 수: {len(sampled_train)}\")\n",
    "\n",
    "# 결과 저장\n",
    "sampled_train.to_csv(\"final_combined_train_sample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SentenceTransformer model on GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for dataset: bionli (426 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "Processing datasets:  14%|█▍        | 1/7 [00:00<00:03,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 0.44 seconds for 426 rows\n",
      "Applying MMR for dataset: bionli\n",
      "Generating embeddings for dataset: biorel (2433 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 1.52 seconds for 2433 rows\n",
      "Applying MMR for dataset: biorel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:  29%|██▊       | 2/7 [00:02<00:07,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for dataset: icliniq (89 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 0.07 seconds for 89 rows\n",
      "Applying MMR for dataset: icliniq\n",
      "Generating embeddings for dataset: medmcqa (422 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n",
      "Processing datasets:  57%|█████▋    | 4/7 [00:03<00:02,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 0.31 seconds for 422 rows\n",
      "Applying MMR for dataset: medmcqa\n",
      "Generating embeddings for dataset: medqa (357 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "Processing datasets:  71%|███████▏  | 5/7 [00:03<00:01,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 0.27 seconds for 357 rows\n",
      "Applying MMR for dataset: medqa\n",
      "Generating embeddings for dataset: pubmedqa (1532 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 0.97 seconds for 1532 rows\n",
      "Applying MMR for dataset: pubmedqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:  86%|████████▌ | 6/7 [00:04<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for dataset: pubmed (2039 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation took 5.66 seconds for 2039 rows\n",
      "Applying MMR for dataset: pubmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets: 100%|██████████| 7/7 [00:10<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dataset split_data                                           features  \\\n",
      "0  bionli       test  {'id': 'BioNLI9284904', 'query': '\\nTASK: Plea...   \n",
      "1  bionli       test  {'id': 'BioNLI22820188', 'query': '\\nTASK: Ple...   \n",
      "2  bionli       test  {'id': 'BioNLI29104632', 'query': '\\nTASK: Ple...   \n",
      "3  bionli       test  {'id': 'BioNLI7793231', 'query': \"\\nTASK: Plea...   \n",
      "4  bionli       test  {'id': 'BioNLI12169771', 'query': '\\nTASK: Ple...   \n",
      "\n",
      "                                               input  output  \\\n",
      "0  \\nTASK: Please classify the relationship betwe...       1   \n",
      "1  \\nTASK: Please classify the relationship betwe...       1   \n",
      "2  \\nTASK: Please classify the relationship betwe...       1   \n",
      "3  \\nTASK: Please classify the relationship betwe...       1   \n",
      "4  \\nTASK: Please classify the relationship betwe...       1   \n",
      "\n",
      "                                        for_sampling  \n",
      "0  {'input': '[PRE] Because of a failure to detec...  \n",
      "1  {'input': '[PRE] Tumor necrosis factor-alpha (...  \n",
      "2  {'input': '[PRE] Uric acid nephropathy (UAN) i...  \n",
      "3  {'input': '[PRE] In an earlier report of our p...  \n",
      "4  {'input': '[PRE] Rat pituitary tumor cells (GC...  \n",
      "총 샘플링된 행 수: 1260\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def mmr(query_embedding, doc_embeddings, diversity, top_n):\n",
    "    faiss.normalize_L2(doc_embeddings)\n",
    "    faiss.normalize_L2(query_embedding.reshape(1, -1))\n",
    "\n",
    "    selected_indices = []\n",
    "    candidate_indices = list(range(len(doc_embeddings)))\n",
    "\n",
    "    for _ in range(top_n):\n",
    "        if not candidate_indices:\n",
    "            break\n",
    "\n",
    "        if len(selected_indices) == 0:\n",
    "            selected_idx = candidate_indices[np.argmax(np.dot(doc_embeddings[candidate_indices], query_embedding.T))]\n",
    "        else:\n",
    "            selected_embeddings = doc_embeddings[selected_indices]\n",
    "            similarity_to_selected = np.dot(doc_embeddings[candidate_indices], selected_embeddings.T)\n",
    "            diversity_scores = np.max(similarity_to_selected, axis=1)\n",
    "            relevance_scores = np.dot(doc_embeddings[candidate_indices], query_embedding.T).flatten()\n",
    "            mmr_scores = (1 - diversity) * relevance_scores - diversity * diversity_scores\n",
    "            selected_idx = candidate_indices[np.argmax(mmr_scores)]\n",
    "\n",
    "        selected_indices.append(selected_idx)\n",
    "        candidate_indices.remove(selected_idx)\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "def mmr_sampling(dataframe, sampling_dict, embedding_model='all-MiniLM-L6-v2', batch_size=64, diversity=0.7, seed=42):\n",
    "    set_seed(seed)\n",
    "\n",
    "    print(\"Loading SentenceTransformer model on GPU...\")\n",
    "    model = SentenceTransformer(embedding_model, device=\"cuda:0\")\n",
    "\n",
    "    sampled_rows = []\n",
    "\n",
    "    for dataset_name, sample_count in tqdm(sampling_dict.items(), desc=\"Processing datasets\"):\n",
    "        subset = dataframe[(dataframe['dataset'] == dataset_name) & (dataframe['split_data'] == 'test')].copy()\n",
    "        num_rows = len(subset)\n",
    "        if num_rows == 0:\n",
    "            print(f\"No data found for dataset: {dataset_name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Generating embeddings for dataset: {dataset_name} ({num_rows} rows)\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        embeddings = model.encode(\n",
    "            subset['for_sampling'].astype(str).tolist(),\n",
    "            batch_size=batch_size,\n",
    "            convert_to_numpy=True,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Embedding generation took {elapsed_time:.2f} seconds for {num_rows} rows\")\n",
    "\n",
    "        query_embedding = np.mean(embeddings, axis=0)\n",
    "\n",
    "        print(f\"Applying MMR for dataset: {dataset_name}\")\n",
    "        selected_indices = mmr(query_embedding, embeddings, diversity, sample_count)\n",
    "        sampled_subset = subset.iloc[selected_indices]\n",
    "        sampled_rows.append(sampled_subset)\n",
    "\n",
    "    return pd.concat(sampled_rows, ignore_index=True)\n",
    "\n",
    "# 샘플링 설정\n",
    "sampling_config = {\n",
    "    'bionli': 200,\n",
    "    'biorel': 200,\n",
    "    'icliniq': 60,\n",
    "    'medmcqa': 200,\n",
    "    'medqa': 200,\n",
    "    'pubmedqa': 200,\n",
    "    'pubmed': 200\n",
    "}\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# 샘플링 실행\n",
    "sampled_test = mmr_sampling(diabetes3, sampling_config, batch_size=4096, diversity=0.7, seed=42)\n",
    "\n",
    "# 결과 확인\n",
    "print(sampled_test.head())\n",
    "print(f\"총 샘플링된 행 수: {len(sampled_test)}\")\n",
    "\n",
    "# 결과 저장\n",
    "sampled_test.to_csv(\"final_combined_test_sample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_combined_train_sample = pd.read_csv(\"/data/jaesung/llm_for_diabetes/src/data/data1_diabetes/final_combined_train_sample.csv\")\n",
    "final_combined_test_sample = pd.read_csv(\"/data/jaesung/llm_for_diabetes/src/data/data1_diabetes/final_combined_test_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test 겹치는 feature 개수: 0\n"
     ]
    }
   ],
   "source": [
    "# 중복 제거 후 겹치는 개수 확인\n",
    "train_unique = final_combined_train_sample.drop_duplicates(subset='features')\n",
    "test_unique = final_combined_test_sample.drop_duplicates(subset='features')\n",
    "\n",
    "# train/test 겹치는 개수 계산\n",
    "overlapping_count = len(pd.merge(train_unique, test_unique, on='features'))\n",
    "print(f\"Train/Test 겹치는 feature 개수: {overlapping_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "final_combined_train_sample['task'] = None\n",
    "\n",
    "# bionli\n",
    "final_combined_train_sample.loc[final_combined_train_sample['dataset'] == 'bionli', 'task'] = 'nli' \n",
    "\n",
    "# biorel\n",
    "biorel_indices = final_combined_train_sample[final_combined_train_sample['dataset'] == 'biorel'].index\n",
    "biorel_splits = np.array_split(biorel_indices, 1)\n",
    "\n",
    "biorel_tasks = [\n",
    "    'ie_extract_relation',\n",
    "    # 'ie_classify_relation',\n",
    "    # 'ie_identify_relation_exist',\n",
    "    # 'ie_generate_relation_pair'\n",
    "]\n",
    "\n",
    "for split, task in zip(biorel_splits, biorel_tasks):\n",
    "    final_combined_train_sample.loc[split, 'task'] = task\n",
    "\n",
    "# icliniq\n",
    "final_combined_train_sample.loc[final_combined_train_sample['dataset'] == 'icliniq', 'task'] = 'generation'\n",
    "\n",
    "# medmcqa\n",
    "final_combined_train_sample.loc[final_combined_train_sample['dataset'] == 'medmcqa', 'task'] = 'qa_subjective'\n",
    "\n",
    "# medqa\n",
    "final_combined_train_sample.loc[final_combined_train_sample['dataset'] == 'medqa', 'task'] = 'qa_objective'\n",
    "\n",
    "# pubmedqa\n",
    "pubmedqa_indices = final_combined_train_sample[final_combined_train_sample['dataset'] == 'pubmedqa'].index\n",
    "pubmedqa_splits = np.array_split(pubmedqa_indices, 1)\n",
    "\n",
    "pubmedqa_tasks = [\n",
    "    # 'qa_mesh_tagging',\n",
    "    # 'qa_short_answer',\n",
    "    'qa_descriptive',\n",
    "    # 'qa_complex_answer'\n",
    "]\n",
    "\n",
    "for split, task in zip(pubmedqa_splits, pubmedqa_tasks):\n",
    "    final_combined_train_sample.loc[split, 'task'] = task\n",
    "\n",
    "# pubmed\n",
    "final_combined_train_sample.loc[final_combined_train_sample['dataset'] == 'pubmed', 'task'] = 'summarization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "final_combined_test_sample['task'] = None\n",
    "\n",
    "# bionli\n",
    "final_combined_test_sample.loc[final_combined_test_sample['dataset'] == 'bionli', 'task'] = 'nli' \n",
    "\n",
    "# biorel\n",
    "biorel_indices = final_combined_test_sample[final_combined_test_sample['dataset'] == 'biorel'].index\n",
    "biorel_splits = np.array_split(biorel_indices, 1)\n",
    "\n",
    "biorel_tasks = [\n",
    "    'ie_extract_relation',\n",
    "    # 'ie_classify_relation',\n",
    "    # 'ie_identify_relation_exist',\n",
    "    # 'ie_generate_relation_pair'\n",
    "]\n",
    "\n",
    "for split, task in zip(biorel_splits, biorel_tasks):\n",
    "    final_combined_test_sample.loc[split, 'task'] = task\n",
    "\n",
    "# icliniq\n",
    "final_combined_test_sample.loc[final_combined_test_sample['dataset'] == 'icliniq', 'task'] = 'generation'\n",
    "\n",
    "# medmcqa\n",
    "final_combined_test_sample.loc[final_combined_test_sample['dataset'] == 'medmcqa', 'task'] = 'qa_subjective'\n",
    "\n",
    "# medqa\n",
    "final_combined_test_sample.loc[final_combined_test_sample['dataset'] == 'medqa', 'task'] = 'qa_objective'\n",
    "\n",
    "# pubmedqa\n",
    "pubmedqa_indices = final_combined_test_sample[final_combined_test_sample['dataset'] == 'pubmedqa'].index\n",
    "pubmedqa_splits = np.array_split(pubmedqa_indices, 1)\n",
    "\n",
    "pubmedqa_tasks = [\n",
    "    # 'qa_mesh_tagging',\n",
    "    # 'qa_short_answer',\n",
    "    'qa_descriptive',\n",
    "    # 'qa_complex_answer'\n",
    "]\n",
    "\n",
    "for split, task in zip(pubmedqa_splits, pubmedqa_tasks):\n",
    "    final_combined_test_sample.loc[split, 'task'] = task\n",
    "\n",
    "# pubmed\n",
    "final_combined_test_sample.loc[final_combined_test_sample['dataset'] == 'pubmed', 'task'] = 'summarization'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "instruction_mapping = {\n",
    "    'nli': [\n",
    "        \"Please classify the relationship between the given premise and hypothesis into one of the following labels: entailment, contradiction, or neutral. return only the label.\"\n",
    "        # \"Given a premise and a hypothesis, determine their relationship: entailment, contradiction, or neutral.\",\n",
    "        # \"Read the given premise and hypothesis. Decide if the hypothesis logically follows from the premise.\",\n",
    "        # \"Classify the relationship between the premise and the hypothesis into one of three categories: entailment, contradiction, or neutral.\",\n",
    "        # \"Analyze the relationship between the given premise and hypothesis. Categorize it as entailment, contradiction, or neutral.\",\n",
    "        # \"Does the premise logically support the hypothesis? Answer as entailment, contradiction, or neutral.\",\n",
    "        # \"Evaluate if the hypothesis can be inferred from the premise. Label it as entailment, contradiction, or neutral.\",\n",
    "        # \"Does the hypothesis contradict the premise or is it entailed by it? If neither, classify it as neutral.\",\n",
    "        # \"For the given premise and hypothesis, determine their logical relationship: entailment, contradiction, or neutral.\"\n",
    "    ],\n",
    "    'ie_extract_relation': [\n",
    "        \"Predict the relationship between the given entities in the given sentence. \"\n",
    "        # \"Extract the relationship described between the given entities in the text.\",\n",
    "        # \"Identify the type of relationship that connects the specified entities based on the provided text.\",\n",
    "        # \"Determine the specific relationship mentioned between the entities in the text.\",\n",
    "        # \"From the text, describe the relationship that exists between the provided entities.\"\n",
    "    ],\n",
    "    # 'ie_identify_relation_exist': [\n",
    "    #     \"Does the text describe any relationship between the specified entities? Answer Yes or No.\",\n",
    "    #     \"Based on the text, determine if there is a connection or relationship between the given entities. Answer Yes or No.\",\n",
    "    #     \"Identify whether a relationship exists between the specified entities in the text. Answer Yes or No.\",\n",
    "    #     \"From the text, confirm whether there is a described relationship connecting the given entities. Answer Yes or No.\"\n",
    "    # ],\n",
    "    # 'ie_classify_relation': [\n",
    "    #     \"Classify the type of relationship described between the specified entities in the text.\",\n",
    "    #     \"Identify the category that best describes the relationship between the entities based on the text.\",\n",
    "    #     \"Determine whether the relationship described in the text falls into predefined categories such as physical, causal, or regulatory.\",\n",
    "    #     \"Based on the text, categorize the relationship between the entities into its most relevant type.\"\n",
    "    # ],\n",
    "    # 'ie_generate_relation_pair': [\n",
    "    #     \"Generate all possible entity pairs from the text and identify their relationships.\",\n",
    "    #     \"Extract all entity pairs mentioned in the text along with the relationships that connect them.\",\n",
    "    #     \"Identify all entity pairs present in the text and specify their corresponding relationships if available.\",\n",
    "    #     \"From the text, list all pairs of entities and describe the relationships that exist between them.\"\n",
    "    # ],\n",
    "    'generation': [\n",
    "        # \"What are the next steps or follow-up actions suggested in the doctor’s response?\",\n",
    "        \"Generate a comprehensive medical response based on the patient's query.\",\n",
    "        # \"Provide a concise and actionable answer to the patient's question.\",\n",
    "        # \"What advice or recommendations does the doctor provide in response to the patient's concerns?\",\n",
    "        # \"What follow-up steps does the doctor suggest in their response?\"\n",
    "    ],\n",
    "    'qa_objective': [\n",
    "        \"Select the most appropriate answer for the given medical question from the provided options.\",\n",
    "        # \"Identify the correct answer to the medical question from the four given options.\",\n",
    "        # \"Pick the correct choice for the given medical question based on the provided options.\",\n",
    "        # \"Determine the correct option that best answers the given medical question.\",\n",
    "        # \"Choose the answer that accurately addresses the given medical query from the options provided.\",\n",
    "        # \"From the provided choices, select the option that correctly answers the medical question.\",\n",
    "        # \"Based on the medical question, select the most accurate answer from the given options.\",\n",
    "        # \"Identify the best answer for the given medical question from the options below.\",\n",
    "        # \"Select the correct answer that corresponds to the given medical question.\",\n",
    "        # \"Determine the appropriate choice for the medical question from the list of options.\"\n",
    "    ],\n",
    "    'qa_subjective': [\n",
    "        \"Select the most appropriate answer for the given medical question from the provided options.\"\n",
    "    ],\n",
    "    # 'qa_mesh_tagging': [\n",
    "    #     \"Identify all MeSH terms mentioned in the context and list them.\",\n",
    "    #     \"Extract relevant MeSH terms from the provided text that describe the main topics.\",\n",
    "    #     \"Tag the context with appropriate MeSH terms that represent its primary themes.\",\n",
    "    #     \"Using the context, identify the MeSH terms that best summarize its content.\",\n",
    "    #     \"Highlight the MeSH terms in the text that are crucial for understanding the main subject.\",\n",
    "    #     \"Using the given context, tag the text with relevant MeSH terms that describe its focus.\",\n",
    "    #     \"From the context, extract key MeSH terms that align with the primary topics discussed.\",\n",
    "    #     \"Analyze the text and identify all MeSH terms that pertain to the discussed topics.\"\n",
    "    # ],\n",
    "    # 'qa_complex_answer': [\n",
    "    #     \"Predict the correct answer (Yes, No, Maybe) for the given question and provide a detailed explanation based on the context.\",\n",
    "    #     \"Determine whether the answer is Yes, No, or Maybe and explain your choice using evidence from the context.\",\n",
    "    #     \"Using the provided context, predict the correct answer and write a detailed response to justify it.\",\n",
    "    #     \"Select the correct decision (Yes, No, Maybe) for the given question and elaborate on the reasoning.\",\n",
    "    #     \"Provide both the correct answer and a comprehensive explanation to the given question using the context.\",\n",
    "    #     \"Answer the question with Yes, No, or Maybe, and support your decision with details from the context.\",\n",
    "    #     \"Generate a Yes, No, or Maybe answer for the question and add a long-form response explaining why.\",\n",
    "    #     \"Decide the answer to the medical question (Yes, No, Maybe) and provide a detailed justification using the given context.\",\n",
    "    #     \"Using the context, predict the answer (Yes, No, Maybe) and generate a detailed explanation for the question.\",\n",
    "    #     \"Write the correct decision (Yes, No, Maybe) for the question and support it with relevant findings from the context.\"\n",
    "    # ],\n",
    "    # 'qa_short_answer': [\n",
    "    #     \"Choose the correct answer (Yes, No, or Maybe) for the given question based on the provided context.\",\n",
    "    #     \"Determine the correct decision (Yes, No, or Maybe) for the medical question using the given context.\",\n",
    "    #     \"From the provided information, select whether the answer to the question is Yes, No, or Maybe.\",\n",
    "    #     \"Analyze the context and identify whether the question should be answered with Yes, No, or Maybe.\",\n",
    "    #     \"Based on the given data, decide if the answer to the question is Yes, No, or Maybe.\"\n",
    "    # ],\n",
    "    'qa_descriptive': [\n",
    "        \"Generate a detailed answer to the question using the provided context.\",\n",
    "        # \"Create a comprehensive explanation for the question based on the given information.\",\n",
    "        # \"Write a long and detailed response to the question using the context provided.\",\n",
    "        # \"Using the context, provide an in-depth answer to the question with relevant details.\"\n",
    "    ],\n",
    "    'summarization': [\n",
    "        # \"Summarize the given article into a concise abstract that highlights the key findings and conclusions.\",\n",
    "        # \"Generate a brief and coherent abstract from the provided article text.\",\n",
    "        \"Write a summary of the article that captures the main ideas and significant details.\",\n",
    "        # \"Condense the given article into a clear and concise abstract that represents its core content.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def assign_correct_instruction(row):\n",
    "    task = row['task']\n",
    "    if task in instruction_mapping:\n",
    "        return random.choice(instruction_mapping[task])\n",
    "    return \"Instruction not found\"\n",
    "\n",
    "final_combined_train_sample['instruction'] = final_combined_train_sample.apply(assign_correct_instruction, axis=1)\n",
    "final_combined_test_sample['instruction'] = final_combined_test_sample.apply(assign_correct_instruction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "def add_input_to_for_sampling(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    \n",
    "    # INPUT 값을 추출하여 새로운 컬럼에 추가\n",
    "    def extract_for_sampling(row):\n",
    "        if row['dataset'] == 'bionli':\n",
    "            features = ast.literal_eval(row['features']) \n",
    "            query = features.get('query', '') \n",
    "            input_text = query.split(\"INPUT: \")[1].split(\"[HYP]\")[0].strip() if \"INPUT: \" in query else None\n",
    "            answer = features.get('answer', None)\n",
    "            return {'input': input_text, 'output': answer}\n",
    "        elif row['dataset'] == 'biorel':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            text = features.get('text', None)\n",
    "            relation = features.get('relation', None)\n",
    "            return {'input': text, 'output': relation}\n",
    "        elif row['dataset'] == 'icliniq':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            input_text = features.get('input', None)\n",
    "            answer_iclinq = features.get('answer_iclinq', None)\n",
    "            return {'input': input_text, 'output': answer_iclinq}\n",
    "        elif row['dataset'] == 'medmcqa':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            input_text = features.get('question', None)\n",
    "            answer = \", \".join([\n",
    "                features.get('opa', ''),\n",
    "                features.get('opb', ''),\n",
    "                features.get('opc', ''),\n",
    "                features.get('opd', ''),\n",
    "            ]).strip()\n",
    "            return {'input': input_text, 'output': answer}\n",
    "        elif row['dataset'] == 'medqa':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            input_text = features.get('question', None)\n",
    "            answer = features.get('answer', None)\n",
    "            return {'input': input_text, 'output': answer}\n",
    "        elif row['dataset'] == 'pubmed':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            input_text = features.get('article', None)\n",
    "            abstract = features.get('abstract', None)\n",
    "            return {'input': input_text, 'output': abstract}\n",
    "        elif row['dataset'] == 'pubmedqa':\n",
    "            features = ast.literal_eval(row['features'])\n",
    "            question = features.get('QUESTION', None)\n",
    "            answer = features.get('LONG_ANSWER', None)\n",
    "            return {'input': question, 'output': answer}\n",
    "\n",
    "    dataframe['for_sampling'] = dataframe.apply(extract_for_sampling, axis=1)\n",
    "    return dataframe\n",
    "\n",
    "diabetes3 = add_input_to_for_sampling(diabetes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2002,\n",
       " 'icliniq',\n",
       " 'train',\n",
       " \"{'input': 'Hello doctor,I experienced difficulty in retracting the foreskin and pulling it down over the penis head (mild phimosis). With difficulty, I manage in 10 minutes. Do this fornightly to clean the penis. I wish to avoid circumcision and understand the application of Lignocaine gel will help. Should I apply it on penis gland or head or on top of the foreskin?', 'answer_icliniq': 'Hi. I can understand your concern about your symptoms. The application is a local anesthetic. Wherever you have pain when you retract foreskin (mostly skin will have pain). You can apply Lignocaine. You cannot apply Lignocaine inside of your foreskin since you have phimosis. So the external application is only possible. Considering your age, kindly rule our other causes of phimosis. Keep blood sugar under control and take antibiotics and apply the local moisturizing gel.  Take care.', 'answer_chatgpt': 'It is important to consult with a healthcare professional before attempting to treat phimosis on your own. Lignocaine gel can help with pain and discomfort during retraction, but it should only be used under the guidance of a healthcare professional. Applying the gel on the penis gland or head will provide more direct and concentrated pain relief, but again, it is important to seek medical advice before attempting any treatment. In some cases, if the phimosis is severe, circumcision may be necessary to prevent further complications.', 'answer_chatdoctor': 'Hi, Welcome to Chat Doctor forum. I am sorry that you have developed this problem. The lignocain is used to anesthetize the area before surgery. You can apply it locally on your penis head. It will not be effective if applied on the foreskin. It will cause burning sensation and you may feel uncomfortable. It has no side effects and does not cause any harm. Please try this and see the results. If after doing this for some time, you still find difficulty then you should consult a surgeon and get yourself operated. This is a simple procedure and usually done under local anesthesia. Wishing you good health. Thank you.'}\",\n",
       " 'Hi. I can understand your concern about your symptoms. The application is a local anesthetic. Wherever you have pain when you retract foreskin (mostly skin will have pain). You can apply Lignocaine. You cannot apply Lignocaine inside of your foreskin since you have phimosis. So the external application is only possible. Considering your age, kindly rule our other causes of phimosis. Keep blood sugar under control and take antibiotics and apply the local moisturizing gel.  Take care.',\n",
       " 1,\n",
       " \"{'input': 'Hello doctor,I experienced difficulty in retracting the foreskin and pulling it down over the penis head (mild phimosis). With difficulty, I manage in 10 minutes. Do this fornightly to clean the penis. I wish to avoid circumcision and understand the application of Lignocaine gel will help. Should I apply it on penis gland or head or on top of the foreskin?', 'output': None}\",\n",
       " 'generation',\n",
       " \"Generate a comprehensive medical response based on the patient's query.\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_combined_train_sample[final_combined_train_sample['task']=='generation'].iloc[2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def parse_features(row):\n",
    "    try:\n",
    "        return ast.literal_eval(row)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return {}\n",
    "        \n",
    "def generate_input_output(row):\n",
    "    input_value = \"\"; output_value = \"\"\n",
    "\n",
    "    task = row['task']\n",
    "    features = parse_features(row['features'])\n",
    "\n",
    "    if row['dataset']=='bionli' and task=='nli':\n",
    "        query = features.get('query', '') \n",
    "        input_value = query.split(\"INPUT: \")[1].split(\"[HYP]\")[0].strip() if \"INPUT: \" in query else None\n",
    "        output_value = features.get('answer', None)\n",
    "    elif row['dataset']=='biorel' and task=='ie_extract_relation':\n",
    "        input_value = features.get('text', None)\n",
    "        output_value = features.get('relation', None)\n",
    "    # elif row['dataset']=='biorel' and task=='ie_identify_relation_exist':\n",
    "    #     input_value = features.get('text', '')\n",
    "    #     output_value = 'YES' if features.get('relation') else 'NO'\n",
    "    # elif row['dataset']=='biorel' and task=='ie_classify_relation':\n",
    "    #     input_value = features.get('text', '')\n",
    "    #     output_value = features.get('relation', 'unknown')\n",
    "    # elif row['dataset']=='biorel' and task=='ie_generate_relation_pair':\n",
    "    #     input_value = features.get('text', '')\n",
    "    #     h_name = features.get('h', {}).get('name', 'unknown')\n",
    "    #     t_name = features.get('t', {}).get('name', 'unknown')\n",
    "    #     relation = features.get('relation', 'unknown')\n",
    "    #     output_value = f\"Entity Pair: ('{h_name}', '{t_name}'), Relationship: '{relation}'\"\n",
    "    elif row['dataset']=='icliniq' and task=='generation':\n",
    "        input_value = features.get('input', None)\n",
    "        output_value = features.get('answer_icliniq', None)\n",
    "    elif row['dataset']=='medqa' and task=='qa_objective':\n",
    "        question = features.get('question', None)\n",
    "        options = features.get('options', None)\n",
    "        answer = features.get('answer', None)\n",
    "        answer_idx = features.get('answer_idx', None)\n",
    "\n",
    "        input_value = (\n",
    "            f\"{question} Please select one of the following: A) {options['A']}, B) {options['B']}, C) {options['C']}, D) {options['D']}.\"\n",
    "        )\n",
    "        output_value = (\n",
    "            f\"{answer_idx}) {answer}\"\n",
    "        )\n",
    "    elif row['dataset']=='medmcqa' and task=='qa_subjective': \n",
    "        question = features.get('question', None)\n",
    "        options = {\n",
    "            'A': features.get('opa', '').strip(),\n",
    "            'B': features.get('opb', '').strip(),\n",
    "            'C': features.get('opc', '').strip(),\n",
    "            'D': features.get('opd', '').strip(),\n",
    "        }\n",
    "        answer_num = features.get('cop', None)\n",
    "        answer_idx = 'A' if answer_num == 0 else 'B' if answer_num == 1 else 'C' if answer_num == 2 else 'D'\n",
    "        answer = features.get('opa', '').strip() if answer_num == 0 else features.get('opb', '').strip() if answer_num == 1 else features.get('opc', '').strip() if answer_num == 2 else features.get('opd', '').strip()\n",
    "\n",
    "        input_value = (\n",
    "            f\"{question} Please select one of the following: A) {options['A']}, B) {options['B']}, C) {options['C']}, D) {options['D']}.\"\n",
    "        )\n",
    "        output_value = (\n",
    "            f\"{answer_idx}) {answer}\"\n",
    "        )\n",
    "\n",
    "    # elif row['dataset']=='pubmedqa' and task=='qa_mesh_tagging':\n",
    "    #     features = ast.literal_eval(row['features'])  \n",
    "    #     question = features.get('question', '').strip()\n",
    "    #     context = \" \".join(features.get('context', {}).get('contexts', [])).strip()\n",
    "    #     meshes = features.get('context', {}).get('meshes', [])\n",
    "        \n",
    "    #     input_value = (\n",
    "    #         f\"Question: {question} \"\n",
    "    #         f\"Context: {context}\"\n",
    "    #     )\n",
    "    #     output_value = f\"MeSH Tags: {', '.join(meshes)}\"\n",
    "    # elif row['dataset']=='pubmedqa' and task=='qa_complex_answer':\n",
    "    #     features = ast.literal_eval(row['features'])  \n",
    "    #     question = features.get('question', '').strip()\n",
    "    #     context = \" \".join(features.get('context', {}).get('contexts', [])).strip()\n",
    "    #     short_answer = features.get('final_decision', '').strip()  \n",
    "    #     long_answer = features.get('long_answer', '').strip()  \n",
    "\n",
    "    #     input_value = (\n",
    "    #         f\"Question: {question} \"\n",
    "    #         f\"Context: {context}\"\n",
    "    #     )\n",
    "    #     \n",
    "    #     output_value = (\n",
    "    #         f\"Short Answer: {short_answer} \"\n",
    "    #         f\"Long Answer: {long_answer}\"\n",
    "    #     )\n",
    "    # elif row['dataset']=='pubmedqa' and task=='qa_short_answer':\n",
    "    #     features = ast.literal_eval(row['features'])  \n",
    "    #     question = features.get('question', '').strip()\n",
    "    #     context = \" \".join(features.get('context', {}).get('contexts', [])).strip()\n",
    "    #     short_answer = features.get('long_answer', '').strip()  \n",
    "\n",
    "    #     input_value = (\n",
    "    #         f\"Question: {question} \"\n",
    "    #         f\"Context: {context}\"\n",
    "    #     )\n",
    "    #     output_value = f\"Answer: {short_answer}\"\n",
    "    elif row['dataset']=='pubmedqa' and task=='qa_descriptive':\n",
    "        question = features.get('QUESTION', '').strip()\n",
    "        context = \" \".join(features.get('CONTEXTS'))\n",
    "        long_answer = features.get('LONG_ANSWER', '').strip() \n",
    "\n",
    "        input_value = (\n",
    "            f\"Question: {question} \"\n",
    "            f\"Context: {context}\"\n",
    "        )\n",
    "        output_value = f\"{long_answer}\"\n",
    "\n",
    "    elif row['dataset']=='pubmed' and task=='summarization':\n",
    "        article = features.get('article', '').strip()  \n",
    "        abstract = features.get('abstract', '').strip() \n",
    "        \n",
    "        input_value = f\"{article}\"\n",
    "        output_value = abstract\n",
    "    return input_value, output_value\n",
    "\n",
    "final_combined_train_sample[['input', 'output']] = final_combined_train_sample.apply(\n",
    "    lambda row: pd.Series(generate_input_output(row)), axis=1\n",
    ")\n",
    "\n",
    "final_combined_test_sample[['input', 'output']] = final_combined_test_sample.apply(\n",
    "    lambda row: pd.Series(generate_input_output(row)), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bionli' 'biorel' 'icliniq' 'medmcqa' 'medqa' 'pubmedqa' 'pubmed']\n",
      "\n",
      "['nli' 'ie_extract_relation' 'generation' 'qa_subjective' 'qa_objective'\n",
      " 'qa_descriptive' 'summarization']\n"
     ]
    }
   ],
   "source": [
    "print(final_combined_train_sample['dataset'].unique())\n",
    "print('')\n",
    "print(final_combined_train_sample['task'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_df = pd.concat([final_combined_train_sample, final_combined_test_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combined_train_sample.to_json(\"/data/jaesung/llm_for_diabetes/src/data/data1_diabetes/train_instruction_dataset.json\", orient=\"columns\", indent=4)\n",
    "final_combined_test_sample.to_json(\"/data/jaesung/llm_for_diabetes/src/data/data1_diabetes/test_instruction_dataset.json\", orient=\"columns\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_gpu_kernel",
   "language": "python",
   "name": "faiss_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
