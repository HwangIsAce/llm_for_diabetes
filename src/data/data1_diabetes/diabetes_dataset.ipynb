{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) raw dataset\n",
    "2) keywords based extraction\n",
    "3) train/test split\n",
    "4) sample a specific number of samples (high cardinality)\n",
    "5) paste the instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71cc44df1f246929af06a1ac0bba1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import logout, notebook_login\n",
    "logout()\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset load\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# qa datasets\n",
    "medqa = load_dataset(\"GBaker/MedQA-USMLE-4-options\")\n",
    "# medqa = load_dataset(\"bigbio/med_qa\")\n",
    "medmcqa = load_dataset(\"openlifescienceai/medmcqa\")\n",
    "# pubmedqa = load_dataset(\"bigbio/pubmed_qa\")\n",
    "# pubmedqa = load_dataset(\"qiaojin/PubMedQA\", \"pqa_artificial\")\n",
    "# bioasq = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"question-answer-passages\")\n",
    "# mednli = load_dataset(\"bigbio/mednli\")\n",
    "\n",
    "# nli datasets\n",
    "# mednli = load_dataset(\"cnut1648/mnli_resampled_as_mednli\")\n",
    "bionli = load_dataset(\"clinicalnlplab/BioNLI_test\")\n",
    "\n",
    "# information extraction datasets\n",
    "# cie_mse = load_dataset(\"mitclinicalml/clinical-ie\", \"medication_status\", trust_remote_code=True) # medication status extraction\n",
    "# cie_ccr = load_dataset(\"mitclinicalml/clinical-ie\", \"coreference\", trust_remote_code=True) # clinical coreference resolution\n",
    "\n",
    "# medmentions = load_dataset(\"bigbio/medmentions\", trust_remote_code=True)\n",
    "# bc5cdr = load_dataset(\"bigbio/bc5cdr\", trust_remote_code=True)\n",
    "\n",
    "# chemdisgene = load_dataset(\"bigbio/chem_dis_gene\", trust_remote_code=True)\n",
    "# biored = load_dataset(\"bigbio/biored\", trust_remote_code=True)\n",
    "# biorelex = load_dataset(\"bigbio/biorelex\", trust_remote_code=True)\n",
    "biorel = load_dataset(\"DFKI-SLT/BioRel\")\n",
    "# biorex = load_dataset(\"bigbio/biorelex\", trust_remote_code=True)\n",
    "\n",
    "# generation task about clinical skills datasets\n",
    "# medichat = load_dataset(\"Mostafijur/medichat_conversation\", \"medichat_subset1\") # ~ medichat_subset15 # conv2note\n",
    "icliniq = load_dataset(\"lavita/ChatDoctor-iCliniq\")\n",
    "# mediqa = load_dataset(\"jonathankang/EN-MEDIQA\")\n",
    "pubmed = load_dataset(\"ccdv/pubmed-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "icliniq = icliniq['train'].train_test_split(test_size=0.3, seed=42)\n",
    "# pubmedqa = pubmedqa['train'].train_test_split(test_size=0.3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medqa\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer', 'options', 'meta_info', 'answer_idx', 'metamap_phrases'],\n",
      "        num_rows: 10178\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer', 'options', 'meta_info', 'answer_idx', 'metamap_phrases'],\n",
      "        num_rows: 1273\n",
      "    })\n",
      "})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "medmcqa\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n",
      "        num_rows: 182822\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n",
      "        num_rows: 6150\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n",
      "        num_rows: 4183\n",
      "    })\n",
      "})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "bionli\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'query', 'answer', 'choices', 'gold'],\n",
      "        num_rows: 5544\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'query', 'answer', 'choices', 'gold'],\n",
      "        num_rows: 12806\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'query', 'answer', 'choices', 'gold'],\n",
      "        num_rows: 6308\n",
      "    })\n",
      "})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "biorel\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'relation', 'h', 't'],\n",
      "        num_rows: 534277\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'relation', 'h', 't'],\n",
      "        num_rows: 114506\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'relation', 'h', 't'],\n",
      "        num_rows: 114565\n",
      "    })\n",
      "})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "icliniq\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input', 'answer_icliniq', 'answer_chatgpt', 'answer_chatdoctor'],\n",
      "        num_rows: 5124\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input', 'answer_icliniq', 'answer_chatgpt', 'answer_chatdoctor'],\n",
      "        num_rows: 2197\n",
      "    })\n",
      "})\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "pubmed\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'abstract'],\n",
      "        num_rows: 119924\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'abstract'],\n",
      "        num_rows: 6633\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'abstract'],\n",
      "        num_rows: 6658\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"medqa\")\n",
    "print(medqa)\n",
    "print('------------------------------------------------------------------------------'* 2) \n",
    "print(\"medmcqa\")\n",
    "print(medmcqa)\n",
    "print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"pubmedqa\")\n",
    "# print(pubmedqa)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"mednli\")\n",
    "# print(mednli)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "print(\"bionli\")\n",
    "print(bionli)\n",
    "print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"cie_mse\")\n",
    "# print(cie_mse)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"cie_ccr\")\n",
    "# print(cie_ccr)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"medmentions\")\n",
    "# print(medmentions)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"bc5cdr\")\n",
    "# print(bc5cdr)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"chem-dis-gene\")\n",
    "# print(chemdisgene)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"biored\")\n",
    "# print(biored)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"biorelex\")\n",
    "# print(biorelex)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "print(\"biorel\")\n",
    "print(biorel)\n",
    "print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"biorex\")\n",
    "# print(biorex)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"medichat\")\n",
    "# print(medichat)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "print(\"icliniq\")\n",
    "print(icliniq)\n",
    "print('------------------------------------------------------------------------------'* 2) \n",
    "# print(\"mediqa\")\n",
    "# print(mediqa)\n",
    "# print('------------------------------------------------------------------------------'* 2) \n",
    "print(\"pubmed\")\n",
    "print(pubmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medqa (train): 10178 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "medqa (test): 1273 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "medmcqa (train): 182822 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "medmcqa (test): 6150 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "medmcqa (validation): 4183 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "bionli (train): 11088 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "bionli (validation): 25612 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "bionli (test): 12616 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "biorel (train): 534277 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "biorel (validation): 114506 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "biorel (test): 114565 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "icliniq (train): 10248 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "icliniq (test): 4394 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "pubmed (train): 119924 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "pubmed (validation): 6633 rows processed and appended to all_data_filtered_by_keywords.csv\n",
      "pubmed (test): 6658 rows processed and appended to all_data_filtered_by_keywords.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    " \n",
    "keywords = [\n",
    "    # 질환 관련\n",
    "    \"diabetes\", \"HbA1c\", \"blood sugar\", \n",
    "    \"glucose\", \"ketoacidosis\",\n",
    "    \n",
    "    # 약물 및 치료\n",
    "    \"insuline\",\n",
    "    \"metformin\", \"SGLT2 inhibitors\", \"GLP-1 receptor agonist\",\n",
    "\n",
    "    # 합병증\n",
    "    \"neuropathy\", \"retinopathy\", \"nephropathy\",\n",
    "]\n",
    "\n",
    "def contains_keywords(text, keywords):\n",
    "    if not text or not isinstance(text, str): \n",
    "        return False\n",
    "    return any(keyword in text.lower() for keyword in keywords)\n",
    "\n",
    "def process_dataset_split(dataset_name, split_name, dataset, text_columns, output_file, keywords=[\"diabetes\", \"insulin\"]):\n",
    "    rows = []\n",
    "    for i in range(len(dataset)):\n",
    "        row = dataset[i]\n",
    "\n",
    "        for col in text_columns:\n",
    "            if col in row:\n",
    "                text = row[col]\n",
    "\n",
    "            elif col == \"abstract\" and \"passages\" in row:\n",
    "                if isinstance(row[\"passages\"], list):\n",
    "                    text = \" \".join([p[\"text\"] for p in row[\"passages\"] if p.get(\"type\") == \"abstract\"])\n",
    "                else:\n",
    "                    text = \"\"\n",
    "            else:\n",
    "                text = \"\"\n",
    "\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            is_related = 1 if contains_keywords(text, keywords) else 0\n",
    "\n",
    "            rows.append({\n",
    "                \"dataset\": dataset_name,\n",
    "                \"split_data\": split_name,\n",
    "                \"features\": row,  \n",
    "                \"input\": text,\n",
    "                \"output\": is_related\n",
    "            })\n",
    "\n",
    "    if rows:  \n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(output_file, mode=\"a\", header=not os.path.exists(output_file), index=False)\n",
    "        print(f\"{dataset_name} ({split_name}): {len(rows)} rows processed and appended to {output_file}\")\n",
    "    else:\n",
    "        print(f\"{dataset_name} ({split_name}): No rows processed.\")\n",
    "\n",
    "datasets = {\n",
    "    \"medqa\": {\"splits\": medqa, \"columns\": [\"question\"]},\n",
    "    \"medmcqa\": {\"splits\": medmcqa, \"columns\": [\"question\"]},\n",
    "    # \"pubmedqa\": {\"splits\": pubmedqa, \"columns\": [\"question\"]},\n",
    "    # \"mednli\": {\"splits\": mednli, \"columns\": [\"premise\", \"hypothesis\"]},\n",
    "    \"bionli\": {\"splits\": bionli, \"columns\": [\"query\", \"answer\"]},\n",
    "    # \"cie_mse\": {\"splits\": cie_mse, \"columns\": [\"snippet\"]},\n",
    "    # \"cie_ccr\": {\"splits\": cie_ccr, \"columns\": [\"snippet\"]},\n",
    "    # \"medmentions: {\"splits\": medmentions, \"columns\": [\"passages\"]},\n",
    "    # \"bc5cdr\": {\"splits\": bc5cdr, \"columns\": [\"passages\"]},\n",
    "    # \"chemdisgene\": {\"splits\": chemdisgene, \"columns\": [\"passages\"]},\n",
    "    # \"biored\": {\"splits\": biored, \"columns\": [\"passages\"]},\n",
    "    # \"biorelex\": {\"splits\": biorelex, \"columns\": [\"text\"]},\n",
    "    \"biorel\": {\"splits\": biorel, \"columns\": [\"text\"]},\n",
    "    # \"biorex\": {\"splits\": biorex, \"columns\": [\"text\"]},\n",
    "    # \"medichat\": {\"splits\": medichat, \"columns\": [\"conversation\"]},\n",
    "    \"icliniq\": {\"splits\": icliniq, \"columns\": [\"input\", \"answer_icliniq\"]},\n",
    "    \"pubmed\": {\"splits\": pubmed, \"columns\": [\"abstract\"]},\n",
    "}\n",
    "\n",
    "output_file = os.path.join(\"all_data_filtered_by_keywords.csv\")\n",
    "\n",
    "for dataset_name, details in datasets.items():\n",
    "    splits = details[\"splits\"]\n",
    "    text_columns = details[\"columns\"] \n",
    "\n",
    "    for split_name, split_data in splits.items():\n",
    "        process_dataset_split(dataset_name, split_name, split_data, text_columns, output_file, keywords=keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_df = pd.read_csv(\"src/data/data1_diabetes/all_data_filtered_by_keywords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_filtered_by_keyword\n",
    "diabetes = all_df[all_df['output'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split_data</th>\n",
       "      <th>features</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>medqa</td>\n",
       "      <td>train</td>\n",
       "      <td>{'question': 'A 68-year-old man presents to th...</td>\n",
       "      <td>A 68-year-old man presents to the emergency de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>medqa</td>\n",
       "      <td>train</td>\n",
       "      <td>{'question': 'A 68-year-old man comes to the p...</td>\n",
       "      <td>A 68-year-old man comes to the physician becau...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset split_data                                           features  \\\n",
       "15   medqa      train  {'question': 'A 68-year-old man presents to th...   \n",
       "17   medqa      train  {'question': 'A 68-year-old man comes to the p...   \n",
       "\n",
       "                                                input  output  \n",
       "15  A 68-year-old man presents to the emergency de...       1  \n",
       "17  A 68-year-old man comes to the physician becau...       1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset  split_data\n",
       "bionli   test            651\n",
       "         train           615\n",
       "         validation     1380\n",
       "biorel   test           2603\n",
       "         train         11644\n",
       "         validation     2566\n",
       "icliniq  test            162\n",
       "         train           373\n",
       "medmcqa  test             69\n",
       "         train          1992\n",
       "         validation       45\n",
       "medqa    test            187\n",
       "         train          1594\n",
       "pubmed   test            544\n",
       "         train          9119\n",
       "         validation      537\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.groupby(['dataset', 'split_data'])['output'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def re_train_test_split(dataframe, train_ratio=0.8):\n",
    "    new_rows = []\n",
    "\n",
    "    grouped = dataframe.groupby('dataset')\n",
    "\n",
    "    for dataset_name, group in grouped:\n",
    "        if dataset_name not in ['bionli', 'bioroel', 'icliniq', 'medmcqa', 'medqa', 'pubmed']: continue\n",
    "\n",
    "        train_data, test_data = train_test_split(\n",
    "            group,\n",
    "            test_size=1-train_ratio,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        train_data = train_data.copy()\n",
    "        train_data['split_data'] = 'train'\n",
    "\n",
    "        test_data = test_data.copy()\n",
    "        test_data['split_data'] = 'test'\n",
    "\n",
    "        new_rows.append(train_data)\n",
    "        new_rows.append(test_data)\n",
    "\n",
    "        result_df = pd.concat(new_rows, ignore_index=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "diabetes2 = re_train_test_split(diabetes, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset  split_data\n",
       "bionli   test           530\n",
       "         train         2116\n",
       "icliniq  test           107\n",
       "         train          428\n",
       "medmcqa  test           422\n",
       "         train         1684\n",
       "medqa    test           357\n",
       "         train         1424\n",
       "pubmed   test          2040\n",
       "         train         8160\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes2.groupby(['dataset', 'split_data'])['output'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:09<00:00, 60.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 선택된 샘플의 cardinality: 2505\n",
      "최종 샘플 크기: 8988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "sample_sizes = {\n",
    "    \"bionli\": 2000,\n",
    "    \"biorel\": 2000, \n",
    "    \"icliniq\": 500,\n",
    "    \"medmcqa\": 1000,\n",
    "    \"medqa\": 1000,\n",
    "    # \"pubmedqa\": 2000,\n",
    "    \"pubmed\": 2000,\n",
    "}\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "final_combined_sample = None\n",
    "highest_cardinality = -1\n",
    "\n",
    "\n",
    "def sample_data(dataset, sample_sizes, split_data=\"train\"):\n",
    "    sampled_data = []\n",
    "    for key, size in sample_sizes.items():\n",
    "        data_subset = dataset[(dataset['dataset'] == key) & (dataset['split_data'] == split_data)]\n",
    "        if len(data_subset) >= size:\n",
    "            sampled_data.append(data_subset.sample(n=size, random_state=random.randint(1, 10000)))\n",
    "        else:\n",
    "            sampled_data.append(data_subset.sample(n=len(data_subset), random_state=random.randint(1, 10000)))\n",
    "    return pd.concat(sampled_data)\n",
    "\n",
    "def remove_duplicates(combined_sample, threshold=0.7):\n",
    "    embeddings = model.encode(combined_sample['features'].tolist())\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    to_remove = set()\n",
    "\n",
    "    for i in range(len(similarity_matrix)):\n",
    "        for j in range(i + 1, len(similarity_matrix)):\n",
    "            if similarity_matrix[i, j] > threshold:\n",
    "                to_remove.add(j)\n",
    "    \n",
    "    return combined_sample.reset_index(drop=True).drop(index=list(to_remove))\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for iteration in tqdm(range(10)):\n",
    "\n",
    "    combined_sample = sample_data(diabetes, sample_sizes)\n",
    "    \n",
    "    # cardinality 계산\n",
    "    filtered_sample = remove_duplicates(combined_sample)\n",
    "    current_cardinality = filtered_sample['features'].nunique()\n",
    "\n",
    "    # cardinality가 더 높은 샘플 저장\n",
    "    if current_cardinality > highest_cardinality:\n",
    "        highest_cardinality = current_cardinality\n",
    "        final_combined_train_sample = combined_sample\n",
    "\n",
    "print(f\"최종 선택된 샘플의 cardinality: {highest_cardinality}\")\n",
    "print(f\"최종 샘플 크기: {len(final_combined_train_sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:09<00:00,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 선택된 샘플의 cardinality: 843\n",
      "최종 샘플 크기: 2381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "sample_sizes = {\n",
    "    \"bionli\": 500,\n",
    "    \"biorel\": 500, \n",
    "    \"icliniq\": 125, \n",
    "    \"medmcqa\": 250,\n",
    "    \"medqa\": 250,\n",
    "    # \"pubmedqa\": 500,\n",
    "    \"pubmed\": 500,\n",
    "}\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "final_combined_sample = None\n",
    "highest_cardinality = -1\n",
    "\n",
    "\n",
    "def sample_data(dataset, sample_sizes, split_data=\"train\"):\n",
    "    sampled_data = []\n",
    "    for key, size in sample_sizes.items():\n",
    "        data_subset = dataset[(dataset['dataset'] == key) & (dataset['split_data'] == split_data)]\n",
    "        if len(data_subset) >= size:\n",
    "            sampled_data.append(data_subset.sample(n=size, random_state=random.randint(1, 10000)))\n",
    "        else:\n",
    "            sampled_data.append(data_subset.sample(n=len(data_subset), random_state=random.randint(1, 10000)))\n",
    "    return pd.concat(sampled_data)\n",
    "\n",
    "\n",
    "def remove_duplicates(combined_sample, threshold=0.7):\n",
    "    embeddings = model.encode(combined_sample['features'].tolist())\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    to_remove = set()\n",
    "\n",
    "    for i in range(len(similarity_matrix)):\n",
    "        for j in range(i + 1, len(similarity_matrix)):\n",
    "            if similarity_matrix[i, j] > threshold:\n",
    "                to_remove.add(j)\n",
    "    \n",
    "    return combined_sample.reset_index(drop=True).drop(index=list(to_remove))\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for iteration in tqdm(range(10)):\n",
    "\n",
    "    combined_sample = sample_data(diabetes, sample_sizes, split_data='test')\n",
    "    \n",
    "    # cardinality 계산\n",
    "    filtered_sample = remove_duplicates(combined_sample)\n",
    "    current_cardinality = filtered_sample['features'].nunique()\n",
    "\n",
    "    # cardinality가 더 높은 샘플 저장\n",
    "    if current_cardinality > highest_cardinality:\n",
    "        highest_cardinality = current_cardinality\n",
    "        final_combined_test_sample = combined_sample\n",
    "\n",
    "print(f\"최종 선택된 샘플의 cardinality: {highest_cardinality}\")\n",
    "print(f\"최종 샘플 크기: {len(final_combined_test_sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combined_train_sample.to_csv(\"final_combined_train_sample.csv\")\n",
    "final_combined_test_sample.to_csv(\"final_combined_test_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_combined_train_sample = pd.read_csv(\"src/data/data1_diabetes/final_combined_train_sample.csv\")\n",
    "final_combined_test_sample = pd.read_csv(\"/src/data/data1_diabetes/final_combined_test_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/test 겹치는 개수\n",
    "len(pd.merge(final_combined_train_sample, final_combined_test_sample, on='features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "final_combined_train_sample['task'] = None\n",
    "\n",
    "# bionli\n",
    "final_combined_train_sample.loc[final_combined_train_sample['dataset'] == 'bionli', 'task'] = 'nli' \n",
    "\n",
    "# biorel\n",
    "biorel_indices = final_combined_train_sample[final_combined_train_sample['dataset'] == 'biorel'].index\n",
    "biorel_splits = np.array_split(biorel_indices, 1)\n",
    "\n",
    "biorel_tasks = [\n",
    "    'ie_extract_relation',\n",
    "    # 'ie_classify_relation',\n",
    "    # 'ie_identify_relation_exist',\n",
    "    # 'ie_generate_relation_pair'\n",
    "]\n",
    "\n",
    "for split, task in zip(biorel_splits, biorel_tasks):\n",
    "    final_combined_train_sample.loc[split, 'task'] = task\n",
    "\n",
    "# icliniq\n",
    "final_combined_train_sample.loc[final_combined_train_sample['dataset'] == 'icliniq', 'task'] = 'qa_subjective'\n",
    "\n",
    "# medmcqa\n",
    "final_combined_train_sample.loc[final_combined_train_sample['dataset'] == 'medmcqa', 'task'] = 'qa_objective'\n",
    "\n",
    "# medqa\n",
    "final_combined_train_sample.loc[final_combined_train_sample['dataset'] == 'medqa', 'task'] = 'qa_objective'\n",
    "\n",
    "# pubmedqa\n",
    "# pubmedqa_indices = final_combined_train_sample[final_combined_train_sample['dataset'] == 'pubmedqa'].index\n",
    "# pubmedqa_splits = np.array_split(pubmedqa_indices, 4)\n",
    "\n",
    "# pubmedqa_tasks = [\n",
    "#     'qa_mesh_tagging',\n",
    "#     'qa_short_answer',\n",
    "#     'qa_long_answer',\n",
    "#     'qa_complex_answer'\n",
    "# ]\n",
    "\n",
    "# for split, task in zip(pubmedqa_splits, pubmedqa_tasks):\n",
    "#     final_combined_train_sample.loc[split, 'task'] = task\n",
    "\n",
    "# pubmed\n",
    "final_combined_train_sample.loc[final_combined_train_sample['dataset'] == 'pubmed', 'task'] = 'summarization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "final_combined_test_sample['task'] = None\n",
    "\n",
    "# bionli\n",
    "final_combined_test_sample.loc[final_combined_test_sample['dataset'] == 'bionli', 'task'] = 'nli' \n",
    "\n",
    "# biorel\n",
    "biorel_indices = final_combined_test_sample[final_combined_test_sample['dataset'] == 'biorel'].index\n",
    "biorel_splits = np.array_split(biorel_indices, 1)\n",
    "\n",
    "biorel_tasks = [\n",
    "    'ie_extract_relation',\n",
    "    # 'ie_classify_relation',\n",
    "    # 'ie_identify_relation_exist',\n",
    "    # 'ie_generate_relation_pair'\n",
    "]\n",
    "\n",
    "for split, task in zip(biorel_splits, biorel_tasks):\n",
    "    final_combined_test_sample.loc[split, 'task'] = task\n",
    "\n",
    "# icliniq\n",
    "final_combined_test_sample.loc[final_combined_test_sample['dataset'] == 'icliniq', 'task'] = 'qa_subjective'\n",
    "\n",
    "# medmcqa\n",
    "final_combined_test_sample.loc[final_combined_test_sample['dataset'] == 'medmcqa', 'task'] = 'qa_objective'\n",
    "\n",
    "# medqa\n",
    "final_combined_test_sample.loc[final_combined_test_sample['dataset'] == 'medqa', 'task'] = 'qa_objective'\n",
    "\n",
    "# pubmedqa\n",
    "# pubmedqa_indices = final_combined_test_sample[final_combined_test_sample['dataset'] == 'pubmedqa'].index\n",
    "# pubmedqa_splits = np.array_split(pubmedqa_indices, 4)\n",
    "\n",
    "# pubmedqa_tasks = [\n",
    "#     'qa_mesh_tagging',\n",
    "#     'qa_short_answer',\n",
    "#     'qa_long_answer',\n",
    "#     'qa_complex_answer'\n",
    "# ]\n",
    "\n",
    "# for split, task in zip(pubmedqa_splits, pubmedqa_tasks):\n",
    "#     final_combined_test_sample.loc[split, 'task'] = task\n",
    "\n",
    "# pubmed\n",
    "final_combined_test_sample.loc[final_combined_test_sample['dataset'] == 'pubmed', 'task'] = 'summarization'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "instruction_mapping = {\n",
    "    'nli': [\n",
    "        \"Given a premise and a hypothesis, determine their relationship: entailment, contradiction, or neutral.\",\n",
    "        \"Read the given premise and hypothesis. Decide if the hypothesis logically follows from the premise.\",\n",
    "        \"Classify the relationship between the premise and the hypothesis into one of three categories: entailment, contradiction, or neutral.\",\n",
    "        \"Analyze the relationship between the given premise and hypothesis. Categorize it as entailment, contradiction, or neutral.\",\n",
    "        \"Does the premise logically support the hypothesis? Answer as entailment, contradiction, or neutral.\",\n",
    "        \"Evaluate if the hypothesis can be inferred from the premise. Label it as entailment, contradiction, or neutral.\",\n",
    "        \"Does the hypothesis contradict the premise or is it entailed by it? If neither, classify it as neutral.\",\n",
    "        \"For the given premise and hypothesis, determine their logical relationship: entailment, contradiction, or neutral.\"\n",
    "    ],\n",
    "    'ie_extract_relation': [\n",
    "        \"Extract the relationship described between the given entities in the text.\",\n",
    "        \"Identify the type of relationship that connects the specified entities based on the provided text.\",\n",
    "        \"Determine the specific relationship mentioned between the entities in the text.\",\n",
    "        \"From the text, describe the relationship that exists between the provided entities.\"\n",
    "    ],\n",
    "    # 'ie_identify_relation_exist': [\n",
    "    #     \"Does the text describe any relationship between the specified entities? Answer Yes or No.\",\n",
    "    #     \"Based on the text, determine if there is a connection or relationship between the given entities. Answer Yes or No.\",\n",
    "    #     \"Identify whether a relationship exists between the specified entities in the text. Answer Yes or No.\",\n",
    "    #     \"From the text, confirm whether there is a described relationship connecting the given entities. Answer Yes or No.\"\n",
    "    # ],\n",
    "    # 'ie_classify_relation': [\n",
    "    #     \"Classify the type of relationship described between the specified entities in the text.\",\n",
    "    #     \"Identify the category that best describes the relationship between the entities based on the text.\",\n",
    "    #     \"Determine whether the relationship described in the text falls into predefined categories such as physical, causal, or regulatory.\",\n",
    "    #     \"Based on the text, categorize the relationship between the entities into its most relevant type.\"\n",
    "    # ],\n",
    "    # 'ie_generate_relation_pair': [\n",
    "    #     \"Generate all possible entity pairs from the text and identify their relationships.\",\n",
    "    #     \"Extract all entity pairs mentioned in the text along with the relationships that connect them.\",\n",
    "    #     \"Identify all entity pairs present in the text and specify their corresponding relationships if available.\",\n",
    "    #     \"From the text, list all pairs of entities and describe the relationships that exist between them.\"\n",
    "    # ],\n",
    "    'qa_subjective': [\n",
    "        \"What are the next steps or follow-up actions suggested in the doctor’s response?\",\n",
    "        \"Generate a comprehensive medical response based on the patient's query.\",\n",
    "        \"Provide a concise and actionable answer to the patient's question.\",\n",
    "        \"What advice or recommendations does the doctor provide in response to the patient's concerns?\",\n",
    "        \"What follow-up steps does the doctor suggest in their response?\"\n",
    "    ],\n",
    "    'qa_objective': [\n",
    "        \"Select the most appropriate answer for the given medical question from the provided options.\",\n",
    "        \"Identify the correct answer to the medical question from the four given options.\",\n",
    "        \"Pick the correct choice for the given medical question based on the provided options.\",\n",
    "        \"Determine the correct option that best answers the given medical question.\",\n",
    "        \"Choose the answer that accurately addresses the given medical query from the options provided.\",\n",
    "        \"From the provided choices, select the option that correctly answers the medical question.\",\n",
    "        \"Based on the medical question, select the most accurate answer from the given options.\",\n",
    "        \"Identify the best answer for the given medical question from the options below.\",\n",
    "        \"Select the correct answer that corresponds to the given medical question.\",\n",
    "        \"Determine the appropriate choice for the medical question from the list of options.\"\n",
    "    ],\n",
    "    # 'qa_mesh_tagging': [\n",
    "    #     \"Identify all MeSH terms mentioned in the context and list them.\",\n",
    "    #     \"Extract relevant MeSH terms from the provided text that describe the main topics.\",\n",
    "    #     \"Tag the context with appropriate MeSH terms that represent its primary themes.\",\n",
    "    #     \"Using the context, identify the MeSH terms that best summarize its content.\",\n",
    "    #     \"Highlight the MeSH terms in the text that are crucial for understanding the main subject.\",\n",
    "    #     \"Using the given context, tag the text with relevant MeSH terms that describe its focus.\",\n",
    "    #     \"From the context, extract key MeSH terms that align with the primary topics discussed.\",\n",
    "    #     \"Analyze the text and identify all MeSH terms that pertain to the discussed topics.\"\n",
    "    # ],\n",
    "    # 'qa_complex_answer': [\n",
    "    #     \"Predict the correct answer (Yes, No, Maybe) for the given question and provide a detailed explanation based on the context.\",\n",
    "    #     \"Determine whether the answer is Yes, No, or Maybe and explain your choice using evidence from the context.\",\n",
    "    #     \"Using the provided context, predict the correct answer and write a detailed response to justify it.\",\n",
    "    #     \"Select the correct decision (Yes, No, Maybe) for the given question and elaborate on the reasoning.\",\n",
    "    #     \"Provide both the correct answer and a comprehensive explanation to the given question using the context.\",\n",
    "    #     \"Answer the question with Yes, No, or Maybe, and support your decision with details from the context.\",\n",
    "    #     \"Generate a Yes, No, or Maybe answer for the question and add a long-form response explaining why.\",\n",
    "    #     \"Decide the answer to the medical question (Yes, No, Maybe) and provide a detailed justification using the given context.\",\n",
    "    #     \"Using the context, predict the answer (Yes, No, Maybe) and generate a detailed explanation for the question.\",\n",
    "    #     \"Write the correct decision (Yes, No, Maybe) for the question and support it with relevant findings from the context.\"\n",
    "    # ],\n",
    "    # 'qa_short_answer': [\n",
    "    #     \"Choose the correct answer (Yes, No, or Maybe) for the given question based on the provided context.\",\n",
    "    #     \"Determine the correct decision (Yes, No, or Maybe) for the medical question using the given context.\",\n",
    "    #     \"From the provided information, select whether the answer to the question is Yes, No, or Maybe.\",\n",
    "    #     \"Analyze the context and identify whether the question should be answered with Yes, No, or Maybe.\",\n",
    "    #     \"Based on the given data, decide if the answer to the question is Yes, No, or Maybe.\"\n",
    "    # ],\n",
    "    # 'qa_long_answer': [\n",
    "    #     \"Generate a detailed answer to the question using the provided context.\",\n",
    "    #     \"Create a comprehensive explanation for the question based on the given information.\",\n",
    "    #     \"Write a long and detailed response to the question using the context provided.\",\n",
    "    #     \"Using the context, provide an in-depth answer to the question with relevant details.\"\n",
    "    # ],\n",
    "    'summarization': [\n",
    "        \"Summarize the given article into a concise abstract that highlights the key findings and conclusions.\",\n",
    "        \"Generate a brief and coherent abstract from the provided article text.\",\n",
    "        \"Write a summary of the article that captures the main ideas and significant details.\",\n",
    "        \"Condense the given article into a clear and concise abstract that represents its core content.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def assign_correct_instruction(row):\n",
    "    task = row['task']\n",
    "    if task in instruction_mapping:\n",
    "        return random.choice(instruction_mapping[task])\n",
    "    return \"Instruction not found\"\n",
    "\n",
    "final_combined_train_sample['instruction'] = final_combined_train_sample.apply(assign_correct_instruction, axis=1)\n",
    "final_combined_test_sample['instruction'] = final_combined_test_sample.apply(assign_correct_instruction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def parse_features(row):\n",
    "    try:\n",
    "        return ast.literal_eval(row)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return {}\n",
    "        \n",
    "def generate_input_output(row):\n",
    "    input_value = \"\"; output_value = \"\"\n",
    "\n",
    "    task = row['task']\n",
    "    features = parse_features(row['features'])\n",
    "\n",
    "    if row['dataset']=='bionli' and task=='nli':\n",
    "        input_value = features.get('query', '').split('###')[1].replace(\"INPUT:\", \"\").strip()\n",
    "        output_value = features.get('answer', 'unknown')\n",
    "    elif row['dataset']=='biorel' and task=='ie_extract_relation':\n",
    "        input_value = features.get('text', '')\n",
    "        output_value = features.get('relation', 'unknown')\n",
    "    # elif row['dataset']=='biorel' and task=='ie_identify_relation_exist':\n",
    "    #     input_value = features.get('text', '')\n",
    "    #     output_value = 'YES' if features.get('relation') else 'NO'\n",
    "    # elif row['dataset']=='biorel' and task=='ie_classify_relation':\n",
    "    #     input_value = features.get('text', '')\n",
    "    #     output_value = features.get('relation', 'unknown')\n",
    "    # elif row['dataset']=='biorel' and task=='ie_generate_relation_pair':\n",
    "    #     input_value = features.get('text', '')\n",
    "    #     h_name = features.get('h', {}).get('name', 'unknown')\n",
    "    #     t_name = features.get('t', {}).get('name', 'unknown')\n",
    "    #     relation = features.get('relation', 'unknown')\n",
    "    #     output_value = f\"Entity Pair: ('{h_name}', '{t_name}'), Relationship: '{relation}'\"\n",
    "    elif row['dataset']=='icliniq' and task=='qa_subjective':\n",
    "        input_value = features.get('input', '')\n",
    "        output_value = features.get('answer_icliniq', '')\n",
    "    elif row['dataset']=='medmcqa' and task=='qa_objective':\n",
    "        question =  features.get('question', '').strip()\n",
    "        options = {\n",
    "            'A': features.get('opa', '').strip(),\n",
    "            'B': features.get('opb', '').strip(),\n",
    "            'C': features.get('opc', '').strip(),\n",
    "            'D': features.get('opd', '').strip(),\n",
    "        }\n",
    "\n",
    "        cop_index = features.get('cop')\n",
    "        if cop_index in [0, 1, 2, 3]:\n",
    "            correct_option = ['A', 'B', 'C', 'D'][cop_index] \n",
    "            correct_answer = options[correct_option]\n",
    "        else:\n",
    "            correct_option = \"Unknwon\"\n",
    "            correct_answer = \"Invalid cop value\"\n",
    "\n",
    "        explanation = (features.get('exp') or '').strip()\n",
    "\n",
    "        input_value = (\n",
    "            f\"{question} Please select one of the following: A) {options['A']}, B) {options['B']}, C) {options['C']}, D) {options['D']}.\"\n",
    "        )\n",
    "        output_value = (\n",
    "            f\"The answer is {correct_option}) {correct_answer}. \"\n",
    "            f\"Explanation: {explanation}\"\n",
    "        )\n",
    "    elif row['dataset']=='medqa' and task=='qa_objective':\n",
    "        question = features.get('question', '').strip()\n",
    "        options = features.get('options', {})\n",
    "\n",
    "        answer_idx = features.get('answer_idx', '').strip()\n",
    "        correct_answer = options.get(answer_idx, \"Unknwon\")\n",
    "\n",
    "        input_value =  (\n",
    "            f\"{question} Please select one of the following: \"\n",
    "            f\"A) {options.get('A', 'N/A')}, B) {options.get('B', 'N/A')}, \"\n",
    "            f\"C) {options.get('C', 'N/A')}, D) {options.get('D', 'N/A')}.\"\n",
    "        )\n",
    "        output_value = f\"The answer is {answer_idx}) {correct_answer}.\"\n",
    "\n",
    "    # elif row['dataset']=='pubmedqa' and task=='qa_mesh_tagging':\n",
    "    #     features = ast.literal_eval(row['features'])  \n",
    "    #     question = features.get('question', '').strip()\n",
    "    #     context = \" \".join(features.get('context', {}).get('contexts', [])).strip()\n",
    "    #     meshes = features.get('context', {}).get('meshes', [])\n",
    "        \n",
    "    #     input_value = (\n",
    "    #         f\"Question: {question} \"\n",
    "    #         f\"Context: {context}\"\n",
    "    #     )\n",
    "    #     output_value = f\"MeSH Tags: {', '.join(meshes)}\"\n",
    "    # elif row['dataset']=='pubmedqa' and task=='qa_complex_answer':\n",
    "    #     features = ast.literal_eval(row['features'])  \n",
    "    #     question = features.get('question', '').strip()\n",
    "    #     context = \" \".join(features.get('context', {}).get('contexts', [])).strip()\n",
    "    #     short_answer = features.get('final_decision', '').strip()  \n",
    "    #     long_answer = features.get('long_answer', '').strip()  \n",
    "\n",
    "    #     input_value = (\n",
    "    #         f\"Question: {question} \"\n",
    "    #         f\"Context: {context}\"\n",
    "    #     )\n",
    "    #     \n",
    "    #     output_value = (\n",
    "    #         f\"Short Answer: {short_answer} \"\n",
    "    #         f\"Long Answer: {long_answer}\"\n",
    "    #     )\n",
    "    # elif row['dataset']=='pubmedqa' and task=='qa_short_answer':\n",
    "    #     features = ast.literal_eval(row['features'])  \n",
    "    #     question = features.get('question', '').strip()\n",
    "    #     context = \" \".join(features.get('context', {}).get('contexts', [])).strip()\n",
    "    #     short_answer = features.get('long_answer', '').strip()  \n",
    "\n",
    "    #     input_value = (\n",
    "    #         f\"Question: {question} \"\n",
    "    #         f\"Context: {context}\"\n",
    "    #     )\n",
    "    #     output_value = f\"Answer: {short_answer}\"\n",
    "\n",
    "    # elif row['dataset']=='pubmedqa' and task=='qa_long_answer':\n",
    "    #     features = ast.literal_eval(row['features'])  \n",
    "    #     question = features.get('question', '').strip()\n",
    "    #     context = \" \".join(features.get('context', {}).get('contexts', [])).strip()\n",
    "    #     long_answer = features.get('long_answer', '').strip() \n",
    "\n",
    "    #     input_value = (\n",
    "    #         f\"Question: {question} \"\n",
    "    #         f\"Context: {context}\"\n",
    "    #     )\n",
    "\n",
    "    #     output_value = f\"Answer: {long_answer}\"\n",
    "    elif row['dataset']=='pubmed' and task=='summarization':\n",
    "        features = ast.literal_eval(row['features'])  \n",
    "        article = features.get('article', '').strip()  \n",
    "        abstract = features.get('abstract', '').strip() \n",
    "        \n",
    "        # Input 구성\n",
    "        input_value = f\"Summarize the following article: {article}\"\n",
    "        \n",
    "        # Output 구성\n",
    "        output_value = abstract\n",
    "    return input_value, output_value\n",
    "\n",
    "final_combined_train_sample[['input', 'output']] = final_combined_train_sample.apply(\n",
    "    lambda row: pd.Series(generate_input_output(row)), axis=1\n",
    ")\n",
    "\n",
    "final_combined_test_sample[['input', 'output']] = final_combined_test_sample.apply(\n",
    "    lambda row: pd.Series(generate_input_output(row)), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split_data</th>\n",
       "      <th>features</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>task</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212958</td>\n",
       "      <td>bionli</td>\n",
       "      <td>train</td>\n",
       "      <td>{'id': 'BioNLI21940405', 'query': '\\nTASK: Ple...</td>\n",
       "      <td>[PRE] Obesity and age are risk factors for fel...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>nli</td>\n",
       "      <td>Read the given premise and hypothesis. Decide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214960</td>\n",
       "      <td>bionli</td>\n",
       "      <td>train</td>\n",
       "      <td>{'id': 'BioNLI28524086', 'query': '\\nTASK: Ple...</td>\n",
       "      <td>[PRE] Obesity is a risk factor for developing ...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>nli</td>\n",
       "      <td>Given a premise and a hypothesis, determine th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 dataset split_data  \\\n",
       "0      212958  bionli      train   \n",
       "1      214960  bionli      train   \n",
       "\n",
       "                                            features  \\\n",
       "0  {'id': 'BioNLI21940405', 'query': '\\nTASK: Ple...   \n",
       "1  {'id': 'BioNLI28524086', 'query': '\\nTASK: Ple...   \n",
       "\n",
       "                                               input      output task  \\\n",
       "0  [PRE] Obesity and age are risk factors for fel...  entailment  nli   \n",
       "1  [PRE] Obesity is a risk factor for developing ...  entailment  nli   \n",
       "\n",
       "                                         instruction  \n",
       "0  Read the given premise and hypothesis. Decide ...  \n",
       "1  Given a premise and a hypothesis, determine th...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_combined_train_sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_df = pd.concat([final_combined_train_sample, final_combined_test_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[~final_df['output'].str.contains('The answer is Unknwon)', regex=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "final_combined_train_sample.to_json(\"src/data/data1_diabetes/train_instruction_dataset.json\", orient=\"columns\", indent=4)\n",
    "final_combined_test_sample.to_json(\"src/data/data1_diabetes/test_instruction_dataset.json\", orient=\"columns\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meal_kernel",
   "language": "python",
   "name": "meal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
