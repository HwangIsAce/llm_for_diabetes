{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# \n",
    "file_paths = [\n",
    "    \"/data/jaesung/llm_for_diabetes/src/trial8/anlaysis/response/med_alpaca.jsonl\",\n",
    "    # \"/data/jaesung/llm_for_diabetes/src/trial/CoT_collection/model_response/test_1.jsonl\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "# medqa\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드 (API 키 설정)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turbo를 사용하여 true_answer와 model_answer가 같은 의미인지 판별\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT 응답이 YES면 정답 처리\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # 오류 발생 시 오답 처리\n",
    "\n",
    "# 데이터 로드 및 필터링\n",
    "qa1 = df[df['task'] == 'qa1']\n",
    "\n",
    "# 정답 판별 수행\n",
    "correct_count = 0\n",
    "total_count = len(qa1)\n",
    "\n",
    "for _, row in qa1.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy 계산\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.1800\n"
     ]
    }
   ],
   "source": [
    "# medmcqa\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드 (API 키 설정)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turbo를 사용하여 true_answer와 model_answer가 같은 의미인지 판별\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT 응답이 YES면 정답 처리\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # 오류 발생 시 오답 처리\n",
    "\n",
    "# 데이터 로드 및 필터링\n",
    "qa2 = df[df['task'] == 'qa2']\n",
    "\n",
    "# 정답 판별 수행\n",
    "correct_count = 0\n",
    "total_count = len(qa2)\n",
    "\n",
    "for _, row in qa2.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy 계산\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.7100\n"
     ]
    }
   ],
   "source": [
    "# pubmedqa\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드 (API 키 설정)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turbo를 사용하여 true_answer와 model_answer가 같은 의미인지 판별\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT 응답이 YES면 정답 처리\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # 오류 발생 시 오답 처리\n",
    "\n",
    "# 데이터 로드 및 필터링\n",
    "qa3 = df[df['task'] == 'qa3']\n",
    "\n",
    "# 정답 판별 수행\n",
    "correct_count = 0\n",
    "total_count = len(qa3)\n",
    "\n",
    "for _, row in qa3.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy 계산\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.2200\n"
     ]
    }
   ],
   "source": [
    "# bionli\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드 (API 키 설정)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turbo를 사용하여 true_answer와 model_answer가 같은 의미인지 판별\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT 응답이 YES면 정답 처리\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # 오류 발생 시 오답 처리\n",
    "\n",
    "# 데이터 로드 및 필터링\n",
    "nli = df[df['task'] == 'nli']\n",
    "\n",
    "# 정답 판별 수행\n",
    "correct_count = 0\n",
    "total_count = len(nli)\n",
    "\n",
    "for _, row in nli.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy 계산\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating drug/effect pairs: 100%|██████████| 100/100 [00:00<00:00, 22434.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Drug/Effect Pair Evaluation (Strict Match, cleaned)\n",
      "✅ Precision: 0.3434\n",
      "✅ Recall   : 0.3400\n",
      "✅ F1 Score : 0.3417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_drug_effect_clean(text):\n",
    "    \"\"\"\n",
    "    output 또는 model_output_32에서 drug와 effect 값을 추출하고,\n",
    "    \\n이나 특수 토큰 이후의 설명은 제거한다.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return {\"drug\": None, \"effect\": None}\n",
    "    \n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # drug 추출\n",
    "    drug_match = re.search(r'drug:\\s*([^,\\n|<]+)', text)\n",
    "    drug = drug_match.group(1).strip() if drug_match else None\n",
    "\n",
    "    # effect 추출\n",
    "    effect_match = re.search(r'effect:\\s*([^\\n|<]+)', text)\n",
    "    effect = effect_match.group(1).strip() if effect_match else None\n",
    "\n",
    "    return {\"drug\": drug, \"effect\": effect}\n",
    "\n",
    "# ✅ 're2' task만 필터링\n",
    "re_df = df[df['task'] == 're2'].reset_index(drop=True)\n",
    "\n",
    "# ✅ 통계 변수 초기화\n",
    "true_positive, false_positive, false_negative = 0, 0, 0\n",
    "\n",
    "# ✅ 평가 루프\n",
    "for _, row in tqdm(re_df.iterrows(), total=len(re_df), desc=\"Evaluating drug/effect pairs\"):\n",
    "    true_vals = extract_drug_effect_clean(row['output'])\n",
    "    pred_vals = extract_drug_effect_clean(row['model_output_32'])\n",
    "\n",
    "    if true_vals[\"drug\"] and true_vals[\"effect\"]:\n",
    "        if true_vals == pred_vals:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "            if pred_vals[\"drug\"] or pred_vals[\"effect\"]:\n",
    "                false_positive += 1\n",
    "    elif pred_vals[\"drug\"] or pred_vals[\"effect\"]:\n",
    "        false_positive += 1\n",
    "\n",
    "# ✅ 지표 계산\n",
    "precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# ✅ 출력\n",
    "print(\"\\n📊 Drug/Effect Pair Evaluation (Strict Match, cleaned)\")\n",
    "print(f\"✅ Precision: {precision:.4f}\")\n",
    "print(f\"✅ Recall   : {recall:.4f}\")\n",
    "print(f\"✅ F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 'ie' 태스크 필터링\n",
    "ie = df[df['task'] == 'ie'].copy()\n",
    "\n",
    "# 문자열 형태를 안전하게 리스트로 파싱하는 함수\n",
    "def safe_eval(val):\n",
    "    if isinstance(val, list):  \n",
    "        return [str(i).strip().lower() for i in val]\n",
    "    elif isinstance(val, str) and val.strip():  \n",
    "        try:\n",
    "            parsed = ast.literal_eval(val)\n",
    "            if isinstance(parsed, list):\n",
    "                return [str(i).strip().lower() for i in parsed]\n",
    "            else:\n",
    "                return [str(parsed).strip().lower()]\n",
    "        except:\n",
    "            return [val.strip().lower()]\n",
    "    return []\n",
    "\n",
    "# output과 model_output 모두 리스트 형태로 파싱\n",
    "ie[\"output\"] = ie[\"output\"].apply(safe_eval)\n",
    "ie[\"model_output_32\"] = ie[\"model_output_32\"].apply(safe_eval)\n",
    "\n",
    "# Precision, Recall, F1-score 계산 함수\n",
    "def calculate_scores(y_true, y_pred):\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for true_vals, pred_vals in zip(y_true, y_pred):\n",
    "        if not true_vals and not pred_vals:\n",
    "            all_precisions.append(1.0)\n",
    "            all_recalls.append(1.0)\n",
    "            all_f1s.append(1.0)\n",
    "            continue\n",
    "\n",
    "        true_count = Counter(true_vals)\n",
    "        pred_count = Counter(pred_vals)\n",
    "\n",
    "        TP = sum(min(true_count[k], pred_count[k]) for k in true_count.keys() & pred_count.keys())\n",
    "        FP = sum(pred_count[k] - true_count.get(k, 0) for k in pred_count.keys())\n",
    "        FN = sum(true_count[k] - pred_count.get(k, 0) for k in true_count.keys())\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    return sum(all_precisions) / len(all_precisions), sum(all_recalls) / len(all_recalls), sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "def calculate_scores_ignore_duplicates(y_true, y_pred):\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for true_vals, pred_vals in zip(y_true, y_pred):\n",
    "        true_set = set(true_vals)\n",
    "        pred_set = set(pred_vals)\n",
    "\n",
    "        TP = len(true_set & pred_set)\n",
    "        FP = len(pred_set - true_set)\n",
    "        FN = len(true_set - pred_set)\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    return sum(all_precisions) / len(all_precisions), sum(all_recalls) / len(all_recalls), sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "\n",
    "# 점수 계산\n",
    "precision, recall, f1 = calculate_scores_ignore_duplicates(ie[\"output\"], ie[\"model_output_32\"])\n",
    "\n",
    "# 출력\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0 \n",
      "  - The model's response starts well by reflecting the initial discussion between the doctor and patient, but it abruptly ends and doesn't cover the full scope or final recommendations as detailed in the context. It misses some parts of the examination and follow-up recommendations.\n",
      "  \n",
      "- Completeness: 2.0\n",
      "  - The model's response includes some key components of the patient's history, medical findings, and previous treatment, but it lacks details found in the context, such as the findings of the MRI or EEG and subsequent assessments. It does not capture the full spectrum of the true answer's content, missing elements pertinent to a comprehensive understanding of the case.\n",
      "  \n",
      "- Naturalness: 4.0\n",
      "  - The dialogue flows well between model's provided interactions, maintaining a conversational tone. However, the response feels incomplete, which affects the overall naturalness since a clinician would likely discuss the next steps or further findings addressed in the original dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0 - The model's response follows the dialogue format and aligns with the context of the conversation, maintaining the Q&A style between the doctor and the patient. However, it cuts off before completing the last question regarding family history, which slightly affects coherence.\n",
      "- Completeness: 3.5 - The response captures a significant portion of the input dialogue but stops midway through the last input question and doesn't cover the full context provided by the \"True Answer\". This omission leaves some questions unaddressed.\n",
      "- Naturalness: 4.5 - The dialogue is structured and flows naturally, mimicking a typical doctor-patient conversation with appropriate language and interactions. The premature cutoff is the only aspect that impacts the seamlessness slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "    The model's response logically aligns with the context provided. It repeats and stays consistent with the details about the patient's medical history, the lab results, and other findings. However, the response cuts off when providing biopsy details, impacting overall coherence very slightly.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "    While the model includes most of the key details from the input, it leaves out important information about the computed tomography (CT) findings, the negative EBER result, and the presence of lymphoma cells in the bone marrow. The response also cuts off mid-sentence, making it incomplete.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "    The interaction between the doctor and the patient in the model's response appears fluent and resembles a typical human conversation. However, the abrupt cutoff in the description affects the natural flow of the dialogue slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response generally aligns with the context provided, as it begins to capture interactions and relevant medical information. However, it is incomplete and ends abruptly without a proper conclusion, affecting overall coherence.\n",
      "  \n",
      "- Completeness: 2.5\n",
      "  - While the model's response captures some details from the provided context, it is incomplete because it truncates mid-sentence, leaving out vital information and the final outcome of the scenario. It doesn't fully summarize or encompass the true answer.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "  - The text maintains a somewhat natural and conversational tone consistent with a doctor-patient dialogue. However, the abrupt cutoff negatively impacts the fluency and human-like quality of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response accurately follows the sequence of events described in the input dialogue. It maintains alignment with the context, although it slightly cuts off at the end, which minimally impacts coherence.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response provides a detailed account of the patient's medical history and the treatments undertaken. However, it ends abruptly, which leads to a lack of closure in the conversation, particularly the unanswered question from the patient's family.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and mimics a natural conversation between a doctor and a patient. The language used is clear and understandable, although the abrupt ending slightly detracts from naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response maintains a logical sequence relevant to the dialogue and addresses the health concerns indicated in the conversation. However, a few questions from the input (e.g., \"Have you had any tongue bites or trauma in the past 6 months?\") are missing in the model's response, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model captures several essential points from the patient dialogue, some critical aspects, like the patient's medical history regarding tooth extraction and poor dental hygiene, are not explored in the model's response. This results in an incomplete portrayal of the patient's condition.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response mimics the conversational style of a medical dialogue, sounding fluent and human-like. It maintains an appropriate professional tone suitable for a medical consultation. However, the abrupt jump between some points could be further smoothed for better naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "  - The model's response partially aligns with the input, but it repeats portions of the conversation verbatim without synthesizing the information. It starts repeating the conversation rather than providing a summary or a concise report of the situation.\n",
      "\n",
      "- Completeness: 1.0\n",
      "  - The model's response does not sufficiently answer the question. It misses crucial information regarding the diagnosis, treatment, and any further steps that were discussed. It doesn't summarize the outcome or provide new insights beyond the repeated dialogue.\n",
      "\n",
      "- Naturalness: 2.5\n",
      "  - While portions of the response sound fluent, the abrupt cut-off and repetitive nature detract from its human-like quality. The response lacks the progression typical in a conversation or a structured explanation, which affects its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model’s response is mostly coherent as it logically aligns with the conversation context. It follows the structured dialogue between the doctor and the patient, maintaining the sequence of events and conditions discussed. However, it stops short and leaves out essential parts towards the end, which slightly affects full coherence.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The response is incomplete, as it doesn’t fully capture the conclusion of the conversation, notably missing details about the diagnosis, the treatment specifics, and the complete progression of the patient's condition as seen in the critical aspects of the diagnosis and treatment outlined in the true answer. It essentially stops before the doctor and patient finish their discussion.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The dialogue sounds fluent and human-like. It uses a conversational tone consistent with professional medical interactions. However, the abrupt ending detracts slightly from its overall naturalness, as typical conversations wouldn't conclude in such an incomplete manner abruptly.\n",
      "\n",
      "Overall, the response retains coherence and naturalness but lacks in completeness, primarily due to its abrupt termination.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response follows the logical progression of the dialogue provided in the input. It maintains the sequence of questions and answers between the doctor and the patient, ensuring that the conversation flows logically. However, it is incomplete and therefore cannot fully assess its coherence in later parts.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - The model captures a significant portion of the dialogue but abruptly cuts off towards the end, missing out on important explanations about the seriousness of the patient's condition and the planned treatment. It does not fully cover the details and outcomes presented in the true answer, such as specific treatments and additional test results.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The language used in the model's response is natural and resembles human dialogue. The interaction between the doctor and the patient is respectful and typical of a clinical setting. However, the abrupt ending slightly disrupts the natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response lacks coherence towards the end, introducing an illogical statement about the patient having passed away, making it inconsistent with a normal doctor-patient interaction. This inconsistency detracts from the overall coherence of the dialogue.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the response contains several accurate details and follows much of the context, it doesn't add significant value or clarification beyond what was provided in the input. The completion replicates the conversation without expanding or concluding meaningfully on the situation described in the true answer.\n",
      "\n",
      "- Naturalness: 2.5  \n",
      "  The response is initially natural but becomes jarring and peculiar with the inclusion of the patient's death in an otherwise routine medical exchange. This disrupts the human-like fluency and appropriateness, reducing the naturalness score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response closely matches the context provided and reflects the sequential exchange accurately between the doctor and the patient. However, it cuts off abruptly before the dialogue finishes, which could slightly impact the logical flow.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - The model's response contains a significant part of the dialogue, capturing the initial conversation and medical procedures. Nevertheless, it stops mid-sentence, omitting critical developments such as the decision to transfer the patient for a PCI and lacks the concluding statements from the original input.\n",
      "\n",
      "- Naturalness: 4.0 \n",
      "  - The style is conversational and maintains a human-like fluency throughout most of the text. However, the abrupt truncation diminishes its overall naturalness, leaving the conversation unfinished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is largely coherent and logically aligns with the context provided in the input. It repeats significant portions of the dialogue from the input, maintaining a consistent and logical flow. However, the response ends abruptly, cutting off the sentence, which slightly impacts coherence.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "While the model provides a comprehensive overview of the patient's medical history and initial hospital treatments, it does not complete the full intended response. It cuts off during a sentence about the patient's treatment, leaving out critical details from the third presentation discussed in the true answer. This incomplete response significantly affects the information conveyed.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The model's response is natural and human-like, following the format of a doctor-patient dialogue with appropriate medical terminology and a conversational tone. Nevertheless, the abrupt ending detracts from the natural flow of the conversation, impacting the impression of a fluent and complete response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided metrics, here's the evaluation of the model's response:\n",
      "\n",
      "- **Coherence: 4.5**\n",
      "  - The model's response maintains strong coherence with the context from the input conversation. The details about medical history, the onset of symptoms, the symptoms themselves, the differential diagnosis, and the results of biopsies align well with the context provided. However, the response is incomplete, affecting coherence slightly.\n",
      "\n",
      "- **Completeness: 4.0**\n",
      "  - The model's response captures a substantial portion of the key details presented in the true answer, such as the patient's medical history, symptoms, the results of biopsies, and the overall diagnostic process. However, it is cut off and does not cover the entire true answer, particularly the crucial diagnostic conclusion of PGA and additional treatment details. This results in a slightly lower score in completeness.\n",
      "\n",
      "- **Naturalness: 4.8**\n",
      "  - The dialogue sounds quite natural and human-like, maintaining a conversational tone consistent with the physician-patient consultation style. Despite being cut off, the excerpt given maintains fluency and feels realistic in the parts that are present, hence the high score.\n",
      "\n",
      "Overall, the response is logical and fluent but falls short in completeness because it doesn't fully encompass the conclusion and complete treatment details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response starts coherently with the dialogue, but it ends abruptly, with the text cutting off mid-sentence. This abrupt ending disrupts the logical flow of the interaction.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The model's response does not provide a complete answer or ending. Significant parts of the input scenario, specifically the patient's death and the subsequent explanation to the family, are missing. This lack of completeness significantly impacts the response's relevance and comprehensiveness.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "\n",
      "While the initial portions of the model's response sound natural and human-like, the abrupt end of the response makes it feel very unnatural. If the response had been complete, it would likely have rated higher on this metric.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 4.8\n",
      "\n",
      "**Evaluation:**\n",
      "1. **Coherence (4.5):** The model's response maintains logical consistency with the provided context, particularly in mirroring the dialogue structure and key information points. However, it is slightly lower than perfect due to omission of some context details towards the end.\n",
      "\n",
      "2. **Completeness (3.0):** The response successfully includes key details about the medical conditions and history of both the patient and the father of the fetus. However, it is incomplete in that it does not include any of the pregnancy plan details or targets, which are crucial components of the full picture provided in the true answer.\n",
      "\n",
      "3. **Naturalness (4.8):** The dialogue in the model's response mimics a natural conversational style typical of a doctor-patient interaction, mainly due to its faithful repetition of the original dialogue parts. There is, however, a slight loss in natural flow towards the latter part where the dialogue truncates abruptly, which prevents it from reaching a perfect score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 4.5\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence (4.5)**: The model's response is largely coherent with the provided context, maintaining logical flow and continuity with the initial discussion between the doctor and patient. It accurately reflects details from the input about symptoms, examination findings, and test results, ensuring coherence with the given context.\n",
      "\n",
      "- **Completeness (3.0)**: The model's response lacks completeness as it ends abruptly and does not fully encapsulate all the information present in the \"True Answer.\" Key procedural details and follow-up information are missing, which are crucial for fully understanding the situation as described in the \"True Answer.\"\n",
      "\n",
      "- **Naturalness (4.5)**: The model's response maintains a natural, fluent tone that resembles a human-like conversation between a doctor and a patient. The dialogue format helps in maintaining the naturalness of the exchange, closely mirroring typical conversational patterns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response more or less follows the sequence of the original conversation but lacks coherence in some areas. It omits some details from the dialogue and abruptly ends without completing the context or delivering a conclusive response.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The response captures some of the medical history details from the input conversation but misses important parts, such as the country of origin, the year of moving to Spain, and the follow-up specifics. It does not provide a coherent summary of the patient's condition and treatment history as the true answer does.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "The model's response sounds somewhat fluent and natural initially, replicating a conversational tone. However, the abrupt ending without completing the thought or providing a proper closing undermines its overall naturalness.\n",
      "\n",
      "Overall, the model's response lacks the depth needed to fully answer the prompt and misses nuances of a realistic interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is consistent and logically follows the progression of dialogue as presented in the input. However, there's a minor spelling error (\"thyroctomy\" instead of \"thyroidectomy\") which slightly affects coherence.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The model's response is incomplete when compared to the context of the original input. It ends abruptly and does not provide the later parts of the interaction, specifically the follow-up on malnutrition, dehydration, and further CT scan findings.\n",
      "  \n",
      "- Naturalness: 4.5\n",
      "  - The dialogue is mostly natural and emulates a human conversation well. Aside from the minor spelling mistake, the language used is fluent and representative of a dialogue between a doctor and patient in a medical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response follows the sequence of the provided conversation and aligns with the context logically. However, it stops abruptly before completing a relevant patient statement, impacting overall coherence in maintaining the flow.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model's response covers much of the key points in the dialogue, but it is missing some important details, such as the renal ultrasound finding and the conclusion with the patient's statement about the water deprivation process and subsequent diuresis. It also cuts off before the completion of a sentence.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response sounds fluent and human-like. The interaction is structured in a way that resembles a real conversation between a doctor and a patient. However, the abrupt ending slightly affects the natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response mostly aligns with the context provided, following a logical progression of the dialogue between doctor and patient. However, it abruptly ends without completing the conversation, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - While the model largely follows the initial interaction between the doctor and patient, it does not provide as many details as the true answer, particularly about the follow-up care and additional procedures. Important specific data like the involvement of the maxillary sinuses and detailed patient conditions are missing, leading to an incomplete response.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The language used in the model's response sounds fluent and human-like up to the point it ends. It generally captures the style of a doctor-patient conversation, but the abrupt cut-off at the end reduces its natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "In evaluating the model's response against the metrics of Coherence, Completeness, and Naturalness, here is the assessment:\n",
      "\n",
      "- **Coherence: 2.0**\n",
      "  - The model's response repeats a part of the input and leaves the sentence abruptly without providing a coherent continuation or conclusion. The text cut-off also contributes to a lack of logical alignment with the context, making it feel incomplete and hard to follow.\n",
      "\n",
      "- **Completeness: 1.5**\n",
      "  - The model's response does not provide a sufficient answer to the input query. Instead, it reproduces a portion of the input dialogue without addressing the overall scenario, patient's condition summary, or any form of conclusion, making it incomplete.\n",
      "\n",
      "- **Naturalness: 2.5**\n",
      "  - The language used is generally fluent and human-like in the part that is duplicated, but the abrupt cut-off and lack of conclusion degrade the naturalness score. The response does not exhibit the smooth flow typical of natural, coherent conversations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  - The model's response follows the context of the dialogue but appears to be truncated, breaking off mid-sentence. Up to that point, it remains logical and aligned with prior discussion.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  - The model's response is incomplete as it ends abruptly, leaving the explanation of SIADH unfinished. Important details from the dialogue and 'True Answer' regarding further evaluations and conditions are missing.\n",
      "\n",
      "- Naturalness: 3.0  \n",
      "  - The response maintains a conversational tone and sounds reasonably natural until it cuts off suddenly. The abrupt ending affects the overall fluency and human-like quality of the interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response closely mirrors the input context, maintaining logical alignment, but it cuts off abruptly, leading to slight incoherence near the end.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response generally covers key details from the conversation, but it omits some points covered in the true answer, such as specific laboratory findings and recommendations, and it ends abruptly.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The language used is very fluent and human-like, closely resembling a real doctor-patient interaction, but the abrupt cut-off at the end slightly affects the natural conversational flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 3.0\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence**: The model's response is largely an incomplete reproduction of the original dialogue. While it aligns with parts of the context, it stops abruptly and misses concluding parts of the conversation, leaving it somewhat disjointed.\n",
      "- **Completeness**: The response stops before discussing the treatment changes and resolution of the skin condition. It does not fully encapsulate the conclusion about the patient's recovery or the change in medication.\n",
      "- **Naturalness**: The dialogue sounds reasonably natural and mimics a typical doctor-patient conversation, though it is effectively a verbatim reproduction of portions of the original dialogue and lacks a conclusion, which reduces fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model’s response is coherent as it maintains a logical sequence in the dialogue similar to the input context. However, it lacks specific details such as the initial diagnosis related to gout and allopurinol administration, which adds context to the situation in the true answer.\n",
      "  \n",
      "- Completeness: 3.0  \n",
      "  - The model's response does not provide a complete answer as it misses key details from the true answer, such as the patient's initial treatment at an outside hospital, specific blood test results, the initial use of allopurinol, and additional medications given (loratadine and cetirizine). These details are important for a comprehensive understanding of the patient's condition.\n",
      "  \n",
      "- Naturalness: 5.0  \n",
      "  - The dialogue in the model’s response flows naturally and reads as a realistic conversation between a doctor and a patient. The language used is fluent and human-like, demonstrating a clear and personable interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided and follows the same sequence of dialogue as in the input. However, it cuts off abruptly during the CSF analysis discussion, which affects coherence slightly.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The response includes much of the conversation and details from the input but cuts off before providing the full information on the CSF analysis, electrodiagnostic study, and treatment plan, thus missing some vital details that are present in the true answer.\n",
      "  \n",
      "- Naturalness: 4.8\n",
      "  - The dialogue is fluent and human-like, maintaining a natural conversational flow. The language used is appropriate for a medical consultation setting. The abrupt ending is the only slight detractor from complete naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response aligns well with the given dialogue context. It accurately maintains the progression of the conversation and captures the sequence of information exchanged between the doctor and the patient. However, the model's response cuts off during the conversation, which slightly affects the overall coherence.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The model's response fails to complete the dialogue, leaving out further details discussed in the input. The response does not reach a conclusion or provide any follow-up on the patient’s next steps or treatments, which significantly impacts the completeness of the answer. It stops abruptly without addressing all potential concerns from the dialogue or concluding the appointment.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "The response maintains a natural flow and uses language typical of a conversation between a doctor and a patient. However, the abrupt cut-off at the end reduces the perception of it being a fluent and human-like interaction. If it had concluded the conversation naturally, the score for naturalness would be higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  * The model's response stays in line with the given dialogue and maintains logical consistency. However, it cuts off abruptly before completing the exchange, slightly affecting overall coherence.\n",
      "  \n",
      "- Completeness: 3.0  \n",
      "  * The response does not cover the entire interaction. It gets cut off during the explanation of activated clotting time, leading to a lack of completeness in the portrayal of the discussion.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  * The response maintains a natural and conversational tone, sounding fluent and human-like. The language used is appropriate for a doctor-patient interaction. However, the abrupt cutoff affects the perception of a complete, natural dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response starts coherently but is abruptly cut off, making it difficult to fully assess its logical alignment with the context. However, the part that is present does follow the conversation logically.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The model's response is incomplete; it is cut off mid-sentence and doesn't cover key elements of the True Answer, such as the referral to the family medicine specialist and the diagnosis of moderate anxiety disorder. The model fails to conclude the scenario and omits significant aspects.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "  - The response sounds natural and human-like up until it is cut off, matching the conversational pattern between the doctor and patient. However, the abrupt end impacts the fluency score negatively, as it disrupts the natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 5.0\n",
      "\n",
      "**Evaluation:**\n",
      "\n",
      "1. **Coherence (4.5)**: The model's response maintains logical alignment with the context of the conversation. The sequence of events and medical observations is consistent with the patient's symptoms and the doctor's examination findings. However, it is interrupted abruptly, which may affect the perception of coherence slightly.\n",
      "\n",
      "2. **Completeness (3.5)**: While the model's response captures a significant portion of the interaction, it does not completely answer the question as it cuts off mid-sentence. Important follow-up details about the findings and the doctor's recommendations are missing, which are present in the \"True Answer.\"\n",
      "\n",
      "3. **Naturalness (5.0)**: The language used in the model's response sounds very natural and human-like. The conversation flows smoothly and uses appropriate medical terminology in a contextual manner. There were no noticeable grammatical errors or awkward phrasing in the part provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is quite coherent as it aligns well with the context provided in the input, following the logical flow of the conversation between the doctor and the patient. However, it omits some of the details from the true answer, which affects its overall coherence.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The response captures the major parts of the patient's medical history and the planned pancreatic islet cell transplantation. However, it lacks a complete recount of the patient's detailed insulin regimen history, the specifics of her family status, as well as the mention of comas during hypoglycemic episodes. Additionally, the response cut off before finishing the interactions properly, which omits some concluding details that appear in the true answer.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The model’s response is largely natural and human-like, with dialogue that feels genuine and conversational. However, the abrupt cut-off after \"Patient\" affects its naturalness, leaving the conversation incomplete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.0**  \n",
      "The model's response logically aligns with the context provided in the input. It follows the structure and content of the dialogue between the doctor and the patient, maintaining the sequence of questions and responses. However, the repetition of prompts and lack of completion in some parts slightly hinder the coherence.\n",
      "\n",
      "- **Completeness: 3.5**  \n",
      "While the response captures many details from the context, such as bilateral lower extremity weakness, chronic conditions, and certain examination results, it cuts off abruptly, leaving out important concluding information about the patient's condition and treatment. This results in an incomplete representation of the full situation presented in the input.\n",
      "\n",
      "- **Naturalness: 3.5**  \n",
      "The language used in the model's response is generally fluent and mimics human-like conversation. However, the structure is somewhat mechanical, especially due to repetition, which detracts from the overall natural feel of a flowing dialogue. There is also an unfinished section that interrupts the natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response largely follows the sequence of dialogue from the input context but is abruptly cut off, missing the conclusion and therefore impacting the overall coherence.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The response is incomplete, ending mid-sentence and failing to provide a full answer to the question or conclusion to the conversation. Important details from the context are missing towards the end.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "  - The dialogue does initially sound like a natural human conversation but ends abruptly, which affects the overall fluency. Up until that point, the wording is mostly natural and akin to human dialogue. However, the abrupt termination hinders the natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 4.5\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "- **Coherence**: The model’s response largely maintains logical alignment with the context given in the input conversation. It follows the sequence of the medical dialogue between the doctor and patient accurately up to the point where the response is truncated. However, some coherence is lost due to the abrupt ending, leading to a slight deduction in score.\n",
      "\n",
      "- **Completeness**: The response captures the majority of the conversation, addressing the main medical examinations and findings as well as the patient's conditions. Nonetheless, it ends abruptly and omits details about the follow-up, such as the implications of the diagnosis and the proposed monitoring, leading to an incomplete conclusion relative to the provided dialogue.\n",
      "\n",
      "- **Naturalness**: The dialogue in the response is generally fluent and maintains a human-like interaction. The model effectively mimics the style of a medical conversation, using appropriate terminology and tone consistent with a doctor-patient dialogue, albeit the abrupt ending slightly affects the natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response maintains a logical alignment with the context provided in the input. The dialogue flows naturally and corresponds well to the initial scenario described until the conversation with the patient's family is omitted. The focus stays on discussing the patient's condition and suggested medical steps, which is well-maintained throughout.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model sufficiently covers the main aspects of the scenario by identifying the condition, suggesting a treatment plan, and advising follow-up actions. However, it does not address the eventual death of the patient or the subsequent conversation with the family, which is mentioned in the input context. The omission of this important development reduces the completeness.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The dialogue sounds fluent and human-like, accurately reflecting how a real-life conversation between a doctor and a patient might occur. The transitions between exchanges are smooth, and the model uses appropriate language for the clinical setting, making it sound very natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 5.0\n",
      "- Naturalness: 4.0\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence**: The model's response logically aligns with the context provided. It accurately follows the sequence of events and the information presented aligns well with the initial dialogue.\n",
      "- **Completeness**: The model's response covers all the necessary details and adequately answers the input, following the conversation from start to finish without missing information.\n",
      "- **Naturalness**: While the response captures the entirety of the conversation accurately, its presentation as a single block of text, without pauses or natural dialogue formatting, impacts its fluency and human-like quality slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0 - The model's response begins accurately following the dialogue flow and maintains logical consistency with the context provided. However, it is incomplete and was cut off abruptly, which might imply some minor misalignment towards the end.\n",
      "- Completeness: 2.0 - The response cuts off in the middle of a sentence, providing only a partial view of the situation and not sufficiently answering the input question. It also lacks critical examination and laboratory information which should logically be included.\n",
      "- Naturalness: 4.5 - Up to the point where the response is cut off, the conversation flows in a natural, human-like manner fitting into the context of a medical dialogue. Nonetheless, the abrupt ending affects the overall fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.0\n",
      "\n",
      "**Explanation**:\n",
      "1. **Coherence**: The model's response logically follows the context of the conversation between the doctor and the patient. It maintains the flow and continuity of the dialogue, addressing the patient's condition and the steps taken in the examination. As the dialogue is an exchange of information without significant deviation from the given context, the coherence is rated 4.5.\n",
      "\n",
      "2. **Completeness**: While the model accurately covers most of the detailed examination and findings that were part of the dialogue, it ends prematurely and doesn't provide the complete information as seen in the True Answer (e.g., referrals and the results of the blood and urine investigations are missing). This affects the completeness of the response, leading to a rating of 3.5.\n",
      "\n",
      "3. **Naturalness**: The dialogue has a clear and human-like interaction. However, because it cuts off mid-sentence, it slightly breaks the natural flow. Despite this, the language used is appropriate for this kind of interaction, so the naturalness scores a 4.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "\n",
      "The model's response logically aligns with the context given in the input. It accurately follows the sequence of events and the medical evaluation process as described in the input scenario.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "While the model's response captures most of the essential elements of the conversation between the doctor and the patient/patient's family, it omits the final part of the dialogue between the doctor and the patient's family, which is crucial for closing the interaction and delivering the full explanation. Therefore, the response is partially complete but not fully.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The response is fluent and human-like. It mirrors natural conversational exchanges between a doctor and a patient, using appropriate language and maintaining a professional tone throughout the interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response closely follows the dialogue in the input, maintaining logical consistency throughout the conversation. However, it lacks details provided in the true answer, such as the advanced condition at the time of presentation.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model accurately captures most aspects of the conversation, it omits important medical details like the patient's age, neuropathic state during presentation, and specific dosages of medication, which are present in the true answer. These elements are crucial for a comprehensive understanding of the patient's situation.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and mimics a natural and human-like interaction between a doctor and a patient. The language and structure align well with a typical medical dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is coherent and follows the logical flow of the dialogue up to the point it reaches. It aligns well with the given context, maintaining the conversation's structure and continuity. However, it cuts off before finishing, which slightly affects the full coherence with the preceding dialogue.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The response is incomplete as it truncates halfway through, failing to cover the entire scenario provided in the true answer. Key details regarding the patient's critical postoperative events, such as cardiac arrests, the CT scan findings, and further medical interventions, are missing, leaving the answer insufficient in terms of thoroughness.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The language used in the response sounds fluent and resembles a human-like tone. It follows conversational patterns typical of a doctor-patient interaction. However, the lack of a complete response does detract somewhat from its perceived naturalness since real conversations would typically reach a more conclusive point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided input, model's response, and true answer, here is the evaluation of the QA model's response:\n",
      "\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response logically aligns with the context provided in the input. The conversation between the doctor and the patient matches the medical history and progression details. However, the response cuts off, indicating a lack of completion in the dialogue, which slightly affects coherence.\n",
      "\n",
      "- **Completeness: 3.0**  \n",
      "  While the response covers a large part of the patient's medical history as outlined in the input, it is incomplete. The conversation stops abruptly, lacking the latter part of the patient's treatment details and the doctor's explanation, which are included in the true answer.\n",
      "\n",
      "- **Naturalness: 4.7**  \n",
      "  The language used in the response is fluent and sounds natural. The dialogue format between the doctor and patient flows well, resembling a typical medical conversation. However, the abrupt cut-off again slightly diminishes the natural continuation of conversation.\n",
      "  \n",
      "Overall, the model performs well in maintaining fluency and coherence with the data provided but lacks completeness due to the premature halt in the exchange.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.8  \n",
      "  The model's response logically aligns with the context provided. It accurately tracks the sequence of medical events and conversations between the doctor and patient. There is a good match between the input dialogue and the model's output, although it slightly glosses over details, like specifying the patient's age.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The response adequately captures the main elements of the medical history, diagnosis, and treatment. However, it omits certain specific details found in the True Answer, such as the age of the patient, consideration of MRONJ as a differential diagnosis, and the lack of microbiologic cultures, which slightly affects the completeness.\n",
      "\n",
      "- Naturalness: 4.9  \n",
      "  The response is very fluent and human-like. The conversational tone is consistent and appropriate for the doctor-patient dialogue, making it sound authentic and credible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "   - The model's response closely follows the conversation context from the input, maintaining logical consistency from one interaction to the next. There is a slight truncation at the end, but overall it aligns well with the context.\n",
      "\n",
      "- Completeness: 3.0\n",
      "   - The response captures a significant portion of the conversation but is incomplete as it ends abruptly during the examination results without reaching the diagnosis or the discussion about hospital admission, thus not providing a full answer.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "   - The dialogue in the model's response reads fluently and mimics a natural, human-like conversation. Apart from the truncation, the exchanges occur in a manner typical of a medical consultation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. The dialogue maintains continuity and makes sense given the context, although the response cuts off towards the end, which slightly disrupts the coherence.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model's response repeats most of the input conversation accurately but stops abruptly, missing key points such as the post-surgery result and follow-up advice. It doesn't address all the key aspects of the true answer, like the patient's age, detailed medical history, and blood pressure.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The dialogue flows naturally for most parts and sounds fluent and human-like. However, the abrupt cutoff of the model's response detracts from the consistency and overall natural conversational structure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is largely coherent with the context provided in the input. It maintains a logical flow, accurately reflecting the conversation between the doctor and the patient. However, it misses some specific details such as the age of the patient, the exact size of the original tumor, and the grading of the extrahepatic bile duct cancer, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The model's response captures the essence of the patient's medical history but is not complete compared to the true answer. It lacks some specific details such as the precise measurements of the original tumor and the pT4N1M0 staging. Additionally, it misses out on the detailed explanation of the patient's visit to the new hospital and the criteria met for further treatment.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The model's response is very natural, retaining a conversational tone typical in a doctor-patient dialogue. The questions and answers flow well, and the language used is fluent and human-like, making the exchange sound realistic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically follows the context provided in the input. It maintains a clear and structured conversation between the doctor and the patient, aligning well with the progression of the medical history and symptoms discussed. However, it is rated slightly less than perfect because it cuts off abruptly at the end, which somewhat disrupts coherence.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model's response covers most key details correctly, such as the progression of symptoms after receiving dexamethasone and other personal medical history. However, it ends abruptly and does not address the question regarding the long-term effects of Cushing's syndrome or offer an explicit explanation of what the blood test results mean, missing some important elements that were clarified in the input.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "\n",
      "The model's response is fairly natural and maintains a human-like tone throughout. However, the abrupt cut-off at the end negatively impacts its fluency, making it sound incomplete and thus less natural. Additionally, there are noticeable repetitions in the response, such as repeated dialogue points, which detract from the conversational flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response generally follows the logical flow of the conversation up to a point. It manages to cover a substantial part of the interaction between the doctor and the patient, maintaining logical consistency up until it abruptly cuts off. The coherence falls short because it doesn't capture the full dialogue or the doctor's conclusions and recommendations.\n",
      "  \n",
      "- Completeness: 2.0\n",
      "  - The response is incomplete as it cuts off in the middle of a conversation, missing large portions of the relevant medical diagnosis and recommendations. Critical tests and their results, along with the doctor's final observations and suggestions for further monitoring, are omitted, which are crucial for a complete answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The model's response sounds natural and fluent. The language used is typical of human conversational exchanges between a doctor and a patient. However, the abrupt ending detracts slightly from the perceived fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5 \n",
      "  - The model's response is coherent in terms of reflecting the dialog between the doctor and the patient. However, it stops before including vital parts of the case, resulting in partial alignment with the provided context.\n",
      "\n",
      "- Completeness: 2.0 \n",
      "  - The response only covers a portion of the information presented in the input. It omits several essential details about the patient's treatment, diagnosis, and outcomes, which are crucial for a proper case presentation.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The phrasing and structure of the model's response follow the dialogue seamlessly, maintaining a natural and conversational tone that aligns well with human communication. However, since it repeats parts of the interaction verbatim, it could appear less natural if judged purely on originality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response maintains coherence with the context provided in the input. The sequence of dialogue is logically aligned with the interaction between the doctor and the patient. However, the model's output is cut off, which affects the overall coherence compared to the continuity seen in the true answer.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The model's response captures the patient-doctor interaction but misses several details that are present in the true answer. The cut-off at the end omits part of the treatment plan and potential outcomes after treatment. These missing elements impact the ability to fully encapsulate the entire situation described in the true answer.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The dialogue sounds fluent and human-like, effectively simulating a realistic interaction between a doctor and a patient. The conversational flow is smooth and reflects an appropriate medical consultation setting. The naturalness slightly suffers only due to the abrupt ending rather than due to the structure or style of the dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response maintains a logical flow and aligns well with the input context up to the point given. However, it cuts off, which slightly affects coherence.\n",
      "  \n",
      "- Completeness: 2.5\n",
      "  - The model's response is incomplete as it cuts off before finishing the dialogue or addressing the family's update, leading to an inadequate answer compared to the \"True Answer\" provided.\n",
      "  \n",
      "- Naturalness: 4.0\n",
      "  - The dialogue is mostly natural and human-like, maintaining a conversational tone. However, the abrupt cutoff at the end disrupts the fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.0**\n",
      "  - The model's response generally aligns with the context provided. It accurately follows the sequence of events and patient-doctor dialogue, but the repetition of \"It means that you have a positive result for the COVID-19 test\" might cause slight confusion as it's somewhat redundant.\n",
      "\n",
      "- **Completeness: 3.0**\n",
      "  - The response covers essential aspects of the patient-doctor conversation, but it is incomplete as there is an abrupt ending without fully addressing or emphasizing important medical findings such as the CT scan results and the seriousness of the brain injury. Additionally, there is a repetition, which may have omitted an explanation for other results or symptoms.\n",
      "\n",
      "- **Naturalness: 3.5**\n",
      "  - The dialogue sounds mostly fluent and structured, maintaining a natural conversational tone. However, the redundancy in explanation concerning the COVID-19 test affects the natural flow. The abrupt cut-off at the end also disrupts the natural progression of the conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response aligns logically with the context provided. However, it repeats the entire conversation without highlighting additional contextual elements like the 10-year duration of symptoms, educational background, or occupation of the patient, which are mentioned in the true answer.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - The model's response covers most of the interaction, but it lacks details such as the patient's age, educational level, occupation, symptom duration, and specific insights from the mental state examination (MSE) present in the true answer. These missing pieces make the answer less complete.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The model's response is fluent and human-like, maintaining the original conversation format of the doctor-patient interaction. However, it slightly deviates in naturalness by failing to close the conversation naturally, as it omits the doctor's final goodbye present in the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response appears to be coherent in terms of the dialogue structure, maintaining consistency with the patient-doctor interaction. However, it does not provide a summary or key insights of the medical case as presented in the \"True Answer.\" The original context included specific patient details like age and department of admission, which the model's dialogue version lacks.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The model's response repeats the dialogue but doesn't cover the specific factual information about the patient's age, gender, or smoking status, nor details about her menstrual history and childbirth mentioned in the True Answer. These elements are important for the medical case context.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response sounds natural and largely mirrors a realistic doctor-patient conversation. The dialogue flows logically and uses language that would be expected in such a setting. However, because it repeats the same information, any added naturalness from variance is absent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns with the context provided in the input. It accurately follows the sequence of dialogue between the doctor and the patient, maintaining the context of the conversation.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The response is quite complete and covers all major points mentioned in the true answer. It captures the patient's conditions, symptoms, diagnosis process, treatment, and follow-up results. However, minor details such as the patient's age and the parietal-occipital diffusion aspect of the headache are missing, which slightly lowers completeness.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is fluent and sounds human-like. The dialogue flows naturally, mimicking a realistic conversation between a doctor and a patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided input and the model's response, here is the evaluation:\n",
      "\n",
      "- **Coherence: 4.5**\n",
      "  - The model's response is largely coherent with the given context, maintaining the sequence and logical alignment of the conversation between the doctor and the patient. However, it cuts off abruptly towards the end without concluding the statement about antinuclear antibodies.\n",
      "\n",
      "- **Completeness: 3.0**\n",
      "  - The response covers most details from the dialogue but leaves out a significant portion of the conversation, ending abruptly without providing a full response. It does not reach a conclusion or offer a summary of the patient's condition and doctor's advice. Furthermore, details in the \"True Answer\" about specific values or times are missing, which affects the completeness.\n",
      "\n",
      "- **Naturalness: 4.0**\n",
      "  - The model's response sounds fluent and human-like for most parts. The language used by the doctor echoes natural conversational patterns, although the abrupt cut-off weakens the overall naturalness of the dialogue flow.\n",
      "\n",
      "Please let me know if further information or breakdowns on these scores are needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response presents a portion of the conversation between the doctor and the patient, which aligns with the context provided in the input. However, it abruptly cuts off and does not cover the entirety of the interaction, particularly the concluding parts essential for coherence in summarizing the hospital case.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The model's response is incomplete. It omits significant aspects of the medical case such as details about the cesarean section, subsequent surgeries, and treatments administered postpartum. Key diagnostic information, treatment outcomes, and the discussion context are missing, leading to a lack of comprehensive coverage.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The dialogue presented in the response is natural and human-like, resembling a typical conversation between a doctor and a patient. The language is fluent and appropriately mirrors the conversational tone expected in a clinical setting. However, the abrupt cut-off at the end detracts slightly from its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response generally aligns with the context provided, continuing the dialogue in a logical manner that connects with the symptoms and medical history discussed. However, the conversation is abruptly cut off after the patient reports chest pain while playing squash, making it unclear what further actions the doctor takes beyond this point.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The model's response is incomplete as it ends in the middle of a conversation without addressing the full scope of the situation or the outcomes of the actions taken by the healthcare team. The progression of the patient's condition and subsequent events, including the myocardial infarction, are not presented.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response is fluent and human-like, maintaining a conversational flow between the doctor and patient. The language used is appropriate for a medical scenario and realistic, though the abrupt ending affects the overall natural flow of the dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 4.8\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence**: The model's response is coherent and logically aligns well with the input context, as it follows the dialogue structure and maintains consistency with the events described. However, there are minor parts where the detail could be slightly clearer, for instance, the \"bulging\" at burr hole sites and \"tiger hide\" appearance are mentioned in the true answer but not in the model's response.\n",
      "\n",
      "- **Completeness**: The response captures most of the key elements from the original dialogue but is cut off at the end, missing the completion of the final statement which affects the completeness. It captures the sequence of medical events and treatments reasonably well but lacks some specific details like \"bulging,\" \"tiger hide\" descriptions, and “midline shift” which are available in the True Answer.\n",
      "\n",
      "- **Naturalness**: The language used in the model's response is fluent and sounds human-like. It clearly mimics the style of a doctor-patient interaction efficiently, demonstrating excellent naturalness with regards to human language norms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "The model's response captures most of the procedural and interpersonal exchanges between the doctor and the patient logically and aligned with the context. However, it cuts off before completing the doctor's description of the laboratory tests and subsequent developments.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "The response fails to cover the entirety of the provided context and the true answer, missing out on details such as the second ECG and the exacerbation of symptoms following the endoscopy. Important updates and the conclusion of the scenario are also absent.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "The dialogue in the model's response flows smoothly and appears human-like. The language used is appropriate and fluent, closely resembling a natural conversation between a doctor and a patient. The cutoff prevents it from being rated higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context provided in the input. It correctly refers to the final pathology revealing a non-functional non-β cells pituitary adenoma, which is a logical continuation of the given conversation.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The model's response is quite brief and does not cover the comprehensive information provided in the true answer about the patient's condition and the details of the pathology report. It omits many key details that could provide a more complete understanding.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response is fluent and human-like. It reads naturally as part of the ongoing dialogue between the doctor and the patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.7\n",
      "\n",
      "**Coherence**: The model's response is fairly coherent with the input context. It follows the logical progression of the conversation between the doctor and the patient, often directly matching the original dialogue and symptoms presented. However, the response cuts off towards the end without addressing the MRI findings clarity fully, which slightly affects coherence.\n",
      "\n",
      "**Completeness**: The response covers many crucial aspects of the conversation but is incomplete as it stops abruptly during the explanation of the MRI results. As a result, it does not fully convey all the significant findings and assessments shared in the true answer, such as the absence of changes in the brain MRI and the exclusion of spinal cord vascular system abnormalities.\n",
      "\n",
      "**Naturalness**: The response generally maintains a fluent and human-like tone, closely mirroring a doctor's responses during a medical consultation. The dialogue sounds natural, but the sudden cutoff at the end impacts the naturalness slightly, as conversations typically have more definitive conclusions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 4.5\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence**: The model's response follows logically from the input information. It maintained consistency with the context provided by the dialogue without introducing any new or contradictory information.\n",
      "- **Completeness**: The model missed one detail from the true answer: the time it took for the lesion to heal with treatment (2 weeks). This slightly affects its completeness in addressing all the important details about the treatment and healing timeline.\n",
      "- **Naturalness**: The dialogue flows well and sounds natural for a doctor-patient conversation. However, the model response did not completely finish the final sentence, which slightly impacts the flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response generally aligns with the context and maintains a logical flow throughout the conversation. However, there is a slight inconsistency as the context discusses the patient's status posthumously, while the conversation with the patient continues as if they are still alive.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The model's response does cover most of the key points mentioned in the true answer, such as the patient's admission, sepsis diagnosis, and subsequent medical issues. However, the response could be clearer in summarizing the entire situation and resolution, as well as structurally concluding the conversation.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The conversation is fluent and mimics a realistic interaction between a doctor and patient. The language used is natural and human-like, although slight awkwardness arises from the posthumous context not being appropriately handled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 2.5\n",
      "- Naturalness: 5.0\n",
      "\n",
      "**Evaluation:**\n",
      "\n",
      "- **Coherence (4.5):** The model's response aligns logically with the conversation up to the point provided. It follows the sequence of the dialogue and correctly states the patient's medical history and pre-operative procedures. However, since the model didn't include the events after the surgery (e.g., post-operative events, complications during the hospital stay), it slightly lacks the complete picture, slightly affecting coherence in terms of the entire hospital visit.\n",
      "\n",
      "- **Completeness (2.5):** The model's response does not sufficiently answer the question because it stops before including significant post-operative details, such as the episode of hypotension, the patient's condition, and the sudden bilateral vision loss. These details are crucial to understanding the patient's complete clinical journey.\n",
      "\n",
      "- **Naturalness (5.0):** The dialogue in the model's response sounds fluent and human-like, accurately mimicking a conversation between a doctor and a patient. It maintains a natural and professional tone throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response largely aligns logically with the context provided. However, it repeats the initial dialogue rather than delivering a concise answer. It partially matches the situation but lacks full context alignment, especially toward the end.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The response captures several key details from the input dialogue, such as the medical conditions, symptoms, and examination results. However, it does not provide a complete summary or answer the implied question regarding the patient's condition and next steps in care.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The model's response sounds fluent and maintains a conversational tone similar to human dialogue. It follows the sequence of topics naturally, although it resembles a rephrased copy of the input rather than providing a synthesized or original response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  - The model's response aligns well with the input context and effectively reproduces most of the conversation between the doctor and the patient. However, it omits the last part about the patient's pregnancy and the assurance that the doctor gave, which slightly impacts the coherence.\n",
      "  \n",
      "- Completeness: 3.5  \n",
      "  - The response captures a significant portion of the dialogue, but it stops abruptly, missing the conclusion of the conversation where the doctor confirms the patient's pregnancy and plans for monitoring. This omission affects the completeness of the response.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  - The model’s response is fluent and closely resembles a human conversation, maintaining a natural progression through most of the dialogue. The abrupt ending slightly affects its natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response aligns well with the provided context. It follows the dialogue format accurately and maintains logical progression in the conversation.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The model's response is incomplete. It ends abruptly without providing the full details found in the true answer or reaching a conclusion about the patient's situation. The response misses crucial conclusions and follow-up plans made by the doctor.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The dialogue sounds fluent and natural, with appropriate conversational flow. The language is consistent with what might be expected in a medical consultation setting. However, the sudden cut-off impacts the overall delivery of the final assessment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response closely mirrors the context provided in the input. It maintains the logical flow and exchanges between the doctor and the patient. However, the model response is incomplete, which slightly affects the full assessment of coherence in this instance.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The model's response is truncated and does not fully capture the necessary information or continue the conversation to a meaningful conclusion. The patient and doctor dialogue ends abruptly without addressing the full context or providing a diagnosis, management plan, or closure, which the true answer suggests.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "  - The language and flow of the model's response sound fluent and human-like. The dialogue mirrors natural doctor-patient interactions with a compassionate tone. The abrupt cutoff detracts slightly from the overall naturalness, but the parts provided are well-constructed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response follows the given context up to a point but abruptly cuts off and does not completely relay the entire exchange. It is coherent up to the portion provided but fails to conclude the discussion or decision-making process.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The model's response fails to provide a comprehensive summary or answer. It repeats part of the conversation but stops mid-response without addressing the doctor's assessment or recommendation for hospitalization, which are critical points mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The dialogue appears natural and fluent in terms of language and interaction style. The conversation between the doctor and the patient is formulated in a human-like manner up to the point where it is terminated prematurely. However, the abrupt cut-off reduces the overall naturalness of the interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is mostly coherent and follows the flow of the conversation logically. However, it is slightly incomplete, stopping abruptly during the explanation of the MRI findings and the potential diagnoses.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model begins to address the possibilities of the cystic mass but does not complete the conversation or discuss the subsequent actions, treatments, or prognosis that are present in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's responses are quite natural and mimic a real doctor-patient interaction effectively. There aren't any significant grammatical errors or awkward phrasings, but the abrupt cutoff slightly affects the natural flow of the dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response closely mirrors the provided input, maintaining logical alignment. However, it misses some details that would match more precisely with some elements of the true answer, such as the complete list of symptoms for clarity, and mentions of specific observations like the Glasgow Coma Scale.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model's response addresses the main points but lacks completeness by omitting some specific details from the true answer, such as the previous liver issues with cirrhosis, the specific medication details, and certain examination findings (like GCS score) which can be crucial for a full understanding. \n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The dialogue in the model's response sounds fluent and conversational, closely resembling how a human doctor-patient conversation would progress. However, minor repetitiveness (repeating the initial question) slightly impacts the natural flow, but it remains largely human-like and easy to follow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0 - The model's response accurately replicates the dialog given in the input, logically aligning with the context.\n",
      "- Completeness: 5.0 - The model's response provides a complete transcription of the dialogue between the doctor and the patient, covering all parts of the conversation.\n",
      "- Naturalness: 5.0 - The model's response maintains a natural and fluent conversation flow, capturing the nuances of human dialogue accurately.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response maintains coherence with the dialogue's flow, accurately capturing the essence of the patient's current health status and treatment plan. However, it misses some specific medical details present in the true answer, such as certain conditions and medication details. \n",
      "\n",
      "- Completeness: 3.5  \n",
      "\n",
      "While the model's response covers the general management plan, it lacks specific medical information contained in the true answer, like the patient's detailed medical history (e.g., chronic obstructive pulmonary disease, HIV on HAART therapy) and the particular medications involved. This reduces the depth of the response compared to the full context the doctor could have addressed.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "\n",
      "The model's response is natural and mimics a real-life conversation between a doctor and a patient. It maintains a human-like, conversational tone conducive to a typical medical consultation. However, the use of a dialogue format throughout, repeating the entire dialogue, slightly detracts from the flow expected in such settings, impacting the naturalness slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "- Completeness: 2.5\n",
      "- Naturalness: 3.5\n",
      "\n",
      "**Coherence**: The model's response closely follows the dialogue path but lacks the inclusion of specific details about the patient's nationality or travels, which are relevant context from the true answer. This slightly impacts coherence with the more extended narrative of the patient's history.\n",
      "\n",
      "**Completeness**: The response captures the key aspects of the medical condition, such as the presence of Listeria monocytogenes and an abscess, alongside aspects of diabetes control. However, it misses additional vital context, such as the patient's repeat trips to Haiti, his prior health conditions related to the kidney transplant, and the past occurrence of a lesion on the scalp indicating potential complications. Thus, it doesn't completely cover the context from the true answer.\n",
      "\n",
      "**Naturalness**: The dialogue flows naturally and generally sounds human-like. However, it abruptly ends, missing the continuation of an important recommended treatment plan related to the diabetes management and follow-up appointments, which slightly affects its naturalness as a complete interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response largely aligns with the context of the conversation between the doctor and the patient. It follows a logical progression of questions and answers, mirroring the structure of the original dialogue.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - The model's response captures the initial part of the interaction accurately but is not complete as it cuts off mid-sentence and doesn’t fully summarize the outcome or the medical findings later in the conversation. It misses details such as the exploratory laparotomy findings and the post-surgical complications.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The model's response maintains a natural, conversational tone that sounds fluent and human-like. The dialogue format is well-executed, mimicking a real interaction between a doctor and patient. However, the abrupt ending slightly reduces the perceived naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model’s response generally maintains coherence with the context provided in the input. It follows the dialogue flow and addresses the symptoms and medical history shared by the patient, which aligns logically with the given situation. However, the response is incomplete and ends abruptly, possibly affecting some aspects of coherence.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The model's response is incomplete as it trails off in the middle of recounting events in 2015, which impacts its performance on this metric. Compared to the true answer, the model's response misses critical details and fails to provide a complete summary of the patient’s medical history.\n",
      "\n",
      "- Naturalness: 3.8\n",
      "  - The dialogue in the model’s response is generally natural and human-like. The conversational flow between the doctor and the patient is reasonable, but the sudden cut-off and abrupt ending slightly detract from the naturalness of the conversation. Further, while the dialogue segments included are fluent, the lack of conclusion lowers the overall perception of naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response maintains logical alignment with the context of the input and progresses in a coherent conversational manner. However, there is a slight cutoff before the model could complete the doctor's sentence, which slightly impacts the flow.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response repeats a large portion of the conversation up to the point of the input but fails to reach a comprehensive conclusion. It does not mention any conclusions or pathology results, which are necessary to answer questions about the progression and the outcome of the evaluation.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The dialogue sounds natural and fluently mimics a human-like conversation. However, the abrupt end of the response detracts slightly from the overall naturalness. The response generally maintains a professional tone appropriate for a doctor's dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It follows the sequence of events and details mentioned in the dialogue, maintaining the consistency and progression of the medical history discussed by the doctor and the patient.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  The model's response is incomplete. While it covers a portion of the conversation accurately, it ends abruptly and fails to include important details from the later part of the dialogue, such as the further diagnosis stages, additional MRI findings, subsequent treatments, and referrals to the clinic. It also noticeably ends midway without addressing the complete scenario presented in the input or the true answer, particularly the patient's current medical status and tests.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The dialogue in the model’s response sounds fluent and human-like. The conversation flows naturally, mimicking a typical doctor-patient interaction and using suitable language and context-appropriate medical terminology. However, the abrupt ending slightly affects its overall naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "  The model's response follows the input context fairly well, maintaining the logical sequence of the initial dialog until it stops abruptly at \"you developed symptoms consistent with anxiety and.\" Up to this point, the response aligns well with the input context but the unfinished sentence impacts coherence slightly as it does not reach a logical conclusion.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "  The model's response does not completely answer the question or provide all the details present in the True Answer. It stops mid-sentence and omits several critical details about the patient's story, particularly events following the development of anxiety symptoms. Important aspects such as the suicide attempt, subsequent medical findings, and surgical interventions are missing, resulting in a less thorough response.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "  The response is mostly fluent and human-like in the part that it covers. The conversation between the doctor and patient flows naturally with clear and appropriate language use, but the abrupt halt in the sentence weakens the perception of naturalness. If completed, it would likely score higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response contains transcribed dialogue from the initial input, which means it aligns well with the context provided. However, it cuts off abruptly and doesn't capture any conclusions or insights beyond the dialogue itself, which may slightly affect coherence as it lacks the final touches to lead into a summarized understanding. \n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The response is mostly a verbatim repetition of the input and abruptly terminates without moving to the concluding and key diagnostic aspects of the case. It misses capturing the significant elements like the treatment plan and improvement in the patient's condition that were conveyed in the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The dialogue flow as presented sounds natural and fluent, maintaining a conversational tone true to human interactions typical of a doctor-patient exchange. The transcription's format does not detract from its natural quality, hence a full score here.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response closely follows the conversation flow of the input, maintaining logical consistency and accurately reproducing much of the original dialogue. However, it doesn't fully account for the specific context provided by the patient's detailed medical history and timeline in the true answer.\n",
      "\n",
      "- **Completeness: 3.0**  \n",
      "  While the model provides a substantial amount of information consistent with the input, it omits critical details about the patient's hospitalization timeline, specific medical history details (e.g., radiotherapy, the operations for orbital compression, etc.), and treatment regimens. These omissions make it less comprehensive than the true answer.\n",
      "\n",
      "- **Naturalness: 4.8**  \n",
      "  The model's response mimics a natural conversational flow between a doctor and patient, sounding fluent and human-like. It captures the structure of typical doctor-patient interactions well, although it doesn't fully complete the conversation as outlined in the model’s response instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response largely aligns logically with the provided context, maintaining the dialogue between the doctor and the patient coherently. However, it does not explicitly summarize the patient's detailed medical history as presented in the \"True Answer,\" slightly affecting completeness. The naturalness of the language used is quite fluent and human-like, resembling a real conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 3.5\n",
      "\n",
      "**Evaluation:**\n",
      "\n",
      "- **Coherence (4.0):** The model's response is reasonably coherent when aligned with the input text. It maintains the sequence of the conversation effectively until it abruptly stops. It does maintain logical progression in the conversation based on earlier context.\n",
      "\n",
      "- **Completeness (2.0):** The response is incomplete. It cuts off in the middle of the sentence when discussing the renal biopsy results. This leaves significant gaps in the information that was conveyed in the original text, such as the detailed results from the renal biopsy and its implications on patient care.\n",
      "\n",
      "- **Naturalness (3.5):** The dialogue sounds mostly fluent and follows conversational cues, which makes it relatively natural. However, the abrupt ending makes it feel less human-like, as human dialogue would not typically stop in the middle of a sentence without a clear reason.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "\n",
      "The model's response repeats parts of the input dialogue and provides a good logical flow in alignment with the input conversation between the doctor and the patient. However, it abruptly ends without completing the exchange as the original dialogue did, introducing slight logical inconsistency.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The model's response captures segments of the input dialogue but lacks completeness because it does not fully progress through the conversation to address the full context leading to the patient's current medical situation. Key details about the suspected diabetes insipidus and endocrinological diagnosis of complete panhypopituitarism are not covered.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The response reflects a conversational tone typical of a doctor-patient interaction, maintaining fluency and a human-like narrative style. It uses professional medical vocabulary suitably for the context, though its abrupt ending does diminish the natural conversational flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response matches the conversation context, repeating the interaction verbatim. However, it doesn't use the provided information to derive a more comprehensive or instructive response, which would show deeper alignment with the input.\n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The model's response simply repeats the input conversation without answering the question about laboratory findings in further detail. There is no additional information provided beyond copying the conversation, leading to an incomplete answer as compared to the True Answer.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The model's response maintains a fluent and human-like dialogue format, reproducing the conversational input naturally. Nonetheless, it doesn't add any new insights or information that might enhance its believability in a complete interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the input context, effectively maintaining the dialogue flow between the doctor and the patient. The sequence of medical findings, discussions, and planned interventions are coherent with the events in the input. However, since the response cuts off abruptly, it slightly hampers the coherence.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The model's response is incomplete as it ends abruptly. It covers the medical background and part of the doctor's final response but does not provide a full turn of dialogue or any conclusion. Key information from the True Answer, such as specifics about medical conditions and intervention plans, is omitted.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The dialogue in the model's response appears fluent and human-like. The conversation sounds realistic and natural, similar to how a doctor and patient would communicate in a medical setting. The abrupt ending affects the fluidity slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The response is coherent with the prior conversation, aligning well with the context of the discussion about the patient's treatment options. There is consistency in terms of the information provided about possible treatments.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  The response does not sufficiently cover the detailed background and findings from the provided true answer. It only focuses on the treatment options and monitoring without addressing specific details about the patient's condition or discussing the diagnosis in depth.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response sounds fluent and human-like, resembling a typical doctor-patient interaction. The language used is appropriate for a medical setting without being overly technical.\n",
      "\n",
      "The model's response is coherent and natural but lacks completeness in terms of delivering the full breadth of information as found in the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context provided. It accurately follows the conversation between the doctor and patient without introducing any inconsistencies.\n",
      "  \n",
      "- Completeness: 4.5\n",
      "  - The model reproduces the conversation faithfully and includes all the necessary details from the patient's medical journey and the surgery performed. However, it cuts off slightly before the end compared to the true answer, omitting a small part of the closing statement.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The conversation in the model's response flows naturally and sounds fluently human-like, effectively capturing the patient-doctor interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response aligns perfectly with the context provided. The dialogue structure is coherent and logically mirrors an actual conversation that occurred in the medical scenario given.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The model's response accurately captures the patient's dialogue and part of the doctor's dialogue. However, it stops abruptly and does not provide the follow-up medical analysis, treatments, and conclusions that are present in the true answer. The summary should have included information about the CT scan, diagnosis of pyogenic meningitis, and the treatments being administered for completeness.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The dialogue is fluent and sounds human-like. It effectively simulates a realistic conversation between a doctor and a patient, maintaining a natural flow that would commonly be expected in such scenarios.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response contains a lot of data, but it does not logically align with the context. It introduces repetitive and irrelevant cardiac imaging details that don't connect with the previous discussion. Additionally, there are inaccuracies like mentioning \"sinus tachycardia with a heart rate of 110 b.p.m,\" which conflicts with prior information stating \"sinus rhythm at 80 b.p.m.\"\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  While the model provides extensive laboratory test results, it doesn't sufficiently address the specific context of the patient's condition and the important details of the differential diagnosis or treatment plan raised in the preamble. Additionally, there are redundancies and missing context regarding the initial complaint and diagnostic considerations.\n",
      "\n",
      "- Naturalness: 2.5  \n",
      "  Although parts of the response sound somewhat medical and informative, the repetitive nature and irrelevant details detract from the fluency and human-like quality of the response. The unrealistic inclusion of every possible cardiac imaging test also makes it sound unnatural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.0**  \n",
      "  The model's response does maintain logical alignment with the context of the input. It correctly follows the sequence of the patient-doctor interaction and provides accurate details about the patient's symptoms, medical history, and the procedures conducted. However, it is incomplete toward the end of the response.\n",
      "\n",
      "- **Completeness: 2.5**  \n",
      "  The model's response is largely a repetition of the input conversation with a sudden cutoff, making it incomplete. Although it initially captures the case and details quite well, it ends abruptly, missing out on crucial details such as the surgical management and the discussion regarding adjuvant chemotherapy, which were part of the input.\n",
      "\n",
      "- **Naturalness: 4.5**  \n",
      "  The model's dialogue captures a human-like fluency and matches the conversational structure of a doctor-patient interaction effectively. However, the abrupt ending slightly detracts from the overall natural feel, as it doesn't conclude the conversation naturally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response maintains a logical progression of the conversation between the doctor and the patient. It generally aligns well with the input context, following the natural flow of the dialogue concerning the patient's diabetes management and condition during the hospital stay. However, it lacks specificity in a few areas, such as the exact insulin doses and the details of the psoriasis treatment, which are present in the True Answer.\n",
      "  \n",
      "- Completeness: 3.0  \n",
      "  While the model's response covers much of the conversation about the patient's diabetes management and recent health issues, it misses some specific details included in the True Answer. The information about the precise amount of insulin required, the details of the examination during hospitalization, and the specific method of applying the fluocinonide cream are not addressed, which reduces the completeness of the answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The conversation in the model's response is fluent and reads like a natural human interaction. The dialogue between the patient and doctor flows smoothly, with appropriate transitions between topics and a reassuring tone that would be expected in a medical consultation setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  - The model's response partially reflects the structured interaction between the doctor and patient and aligns with the context. However, it cuts off mid-sentence, which affects the overall logical flow.\n",
      "- Completeness: 3.0  \n",
      "  - The response omits some details present in the true answer. It cuts off mid-sentence and does not include the entire sequence of medical procedures and findings, which impacts the completeness of the answer.\n",
      "- Naturalness: 4.0  \n",
      "  - The dialogue sounds natural and human-like up until it abruptly ends. The model maintains a conversational tone, which suits the interaction, but the interruption affects the perception of naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the context provided. It maintains the flow of the conversation and follows the logical sequence as per the input dialogue. However, the latter part of the response is incomplete, affecting the overall coherence slightly.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model's response does not fully capture all the essential details from the input. It ends abruptly without addressing or answering all the subsequent questions and events discussed in the input. The true answer provides more information about the aneurysm, surgical procedures, and post-operative complications, which the model's response does not cover.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The language used in the model's response is fluent and sounds human-like. The conversation style between the doctor and patient feels natural and realistic, matching the typical tone and manner of a medical dialogue. There are no grammatical errors or awkward phrasing that detracts from the fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5\n",
      "  - The model's response repeats part of the conversation present in the input instead of providing a summarized answer or insight into the case. The response doesn't logically follow the prompt of a QA answer but instead recycles dialogue from the input.\n",
      "\n",
      "- Completeness: 1.5\n",
      "  - The model's output does not sufficiently answer the question or provide a meaningful summary. It fails to capture many key medical details and conclusions drawn in the true answer, thereby lacking depth and understanding of the situation.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "  - The dialogue format used by the model sounds natural and reflects a conversational flow, consistent with a human interaction. However, because it repeats input content instead of synthesizing new information or insights, it lacks variability and creativity that would further boost its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response is partially coherent with the input as it starts repeating the initial part of the doctor-patient conversation accurately. However, it abruptly cuts off mid-sentence and does not include the entire conversation, leading to a loss of logical alignment with the full context.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The model's response does not fully answer the implicit question of summarizing or understanding the entire patient visit and the doctor's findings. It stops abruptly and does not provide a complete recounting of the patient's condition, examination, or discussion regarding the treatment plan and hospital admission.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - While the repeated portion of the doctor-patient dialogue maintains a natural and human-like tone, the response is abruptly truncated, which affects the overall flow. However, the naturalness of the modeled conversation itself is still high in the segment that is provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically follows the context provided in the input, maintaining consistency with the details of the patient's medical situation and ongoing discussion.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - While the model reiterates much of the initial conversation, it is missing the conclusion or continuation of dialogue to complete the patient's question regarding what actions should be taken next, such as medication instructions and activity restrictions.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The model's response closely mimics natural human conversational flow, including logical question and response patterns. However, the absence of a full completion in the final turn slightly detracts from the naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response abruptly stops mid-sentence and fails to fully capture the patient's medical background or the subsequent developments shared in the input. This leads to a partial misalignment with the input context.\n",
      "  \n",
      "- Completeness: 2.0\n",
      "  - The response is incomplete and cuts off before significant details are included, such as the patient's condition after a year, recent tests, and outcome. It leaves out critical parts of the timeline and subsequent medical findings or actions mentioned in the input and true answer.\n",
      "  \n",
      "- Naturalness: 3.5\n",
      "  - While the text maintains a professional tone and partially resembles a human-like dialogue, the truncation and sudden cut-off detract from the fluidity and complete naturalness of the conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model maintains a clear and logical sequence that aligns with the initial context, accurately capturing the critical elements and progressing logically through the conversation. However, it truncates towards the end without completing the dialogue, which slightly affects coherence.\n",
      "  \n",
      "- Completeness: 2.5\n",
      "  - The response begins well and covers many of the details from the input but stops abruptly, leaving out important elements in the latter part of the conversation. Key information about the outcome of the patient's condition and consultation with the patient's family is missing.\n",
      "  \n",
      "- Naturalness: 4.8\n",
      "  - The dialogue flows well and sounds fluent and human-like, capturing the conversational tone of a typical doctor-patient interaction. The language used is appropriate and natural throughout the portion provided. However, the abrupt ending somewhat detracts from the potential naturalness it could have achieved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 점수:\n",
      "Coherence       4.093000\n",
      "Completeness    2.880000\n",
      "Naturalness     4.244000\n",
      "BLEURT          0.717371\n",
      "BERTScore_F1    0.605372\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# summarization\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT 모델 로드\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 평가 함수\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 점수 추출\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT 점수 계산\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT 및 BERTScore 계산\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# 점수 정규화 함수\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "summarization = df[df['task'] == 'summarization']\n",
    "results = []\n",
    "\n",
    "for _, row in summarization.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output_512'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # 기본값 설정\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' 컬럼이 존재하는지 확인 후 정규화 수행\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"평균 점수:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context provided. It acknowledges the user's current treatment and offers general lifestyle and dietary advice suited for someone with diabetes.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the response provides useful information on diet and exercise, it lacks specific advice on potential adjustments to medication, which was part of the user's question. The true answer suggests introducing an additional tablet, which the model's response omits.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and human-like, displaying a polite and considerate tone typical of a healthcare professional. The language used is clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "\n",
      "    The response lacks coherence as it fails to provide a logical and relevant explanation aligned with the context provided. The repetition of sentences regarding low insulin levels without connection to the specific case details or addressing the concern about pancreatic cancer indicates a lack of alignment with the input.\n",
      "\n",
      "- Completeness: 1.0\n",
      "\n",
      "    The response does not answer the primary concerns mentioned in the input about the possibility of pancreatic cancer. It also does not explore the plausible reasons why insulin levels might have dropped despite the absence of changes in diet and lifestyle, nor does it give any guidance on whether further medical examinations are warranted.\n",
      "\n",
      "- Naturalness: 1.0\n",
      "\n",
      "    The response is not natural due to its repetitive and robotic language. The continuously repeated statements about low insulin levels without variance and lack of conversational flow make it sound unnatural and not human-like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context provided, explaining the purpose of Lucentis and Accentrix, and pointing out the options suggested by the consulted doctors. However, it doesn't elaborate on how it reached its recommendation for laser treatment, which causes a slight drop in coherence.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides general information about the treatments mentioned but lacks depth in explaining why laser treatment is specifically recommended over the alternatives. It partially answers the question but doesn't fully address the user's dilemma or mention considering a specialist's advice.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is mostly fluent and human-like. It uses polite and professional language, suitable for a medical consultation. However, the transition between suggesting medications and recommending a treatment is somewhat abrupt, reducing the natural flow slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context of the input. It correctly identifies the issue of erectile dysfunction and suggests that it could have psychological or physical causes, which is coherent with the condition described by the user.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response partially answers the question. It suggests consulting a psychiatrist and provides a medication recommendation (tadalafil). However, it does not ask about underlying medical conditions like diabetes or hypertension, as mentioned in the true answer. It also lacks alternative medication suggestions and a note on the need for prescriptions, which makes it somewhat incomplete.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response is generally fluent and human-like. The language is clear, but it lacks the conversational elements present in the true answer, such as follow-up questions about the user's medical history and detailed guidance on medication use. This slightly reduces the naturalness of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context of the input by addressing the question about white spots on the gums and their potential relation to diabetes. However, it provides specific information about leukoplakia without initially requesting more details from the user, which might have been warranted considering the diverse potential causes detailed in the True Answer.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - While the model provides a detailed explanation of leukoplakia, suggesting it is benign and unrelated to diabetes, it does not fully consider the necessity of more information or images to give a more accurate assessment. The True Answer implies that more evaluation is necessary before making definitive statements, highlighting a gap in completenss in covering potential uncertainties.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The model's response is fluent and human-like. It is well-structured and provides information in a conversational tone. The response uses appropriate medical terminology and offers reassurance, mimicking what one might expect from a professional consultation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "  The model's response aligns logically with the input context. It acknowledges the history of the symptoms and the suggestion of frozen shoulder from the orthopedic. However, it lacks precision in providing a personalized treatment plan which aligns with the detail available in the input context.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "  The model's response addresses the frozen shoulder issue by recommending continuation of prescribed medicines and physiotherapy, but it is less comprehensive compared to the true answer. The true answer provides more explicit guidance, including specific medications and tests (like diabetes screening and a potential ultrasound), which the model's response does not mention.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "  The model's response is generally fluent and sounds human-like. It uses appropriate medical language and maintains a professional tone suitable for a consultation, although it sounds somewhat generic and less engaging than it could be with more personal interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It reinforces the idea of continuing with the current medication and integrates some general advice on diet and lifestyle, which is coherent with managing diabetes.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the response covers basic advice on diet and exercise, it lacks specific details and medication adjustments that are present in the True Answer. The suggestion of a diet plan is missing, and the model does not provide an additional medication recommendation or a follow-up plan.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent and human-like. It uses professional yet conversational language appropriate for a doctor responding to a patient's query. The language is clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model’s response logically aligns with the context provided. It correctly associates fatty liver with potential causes, fibroids with potential symptoms, and high blood sugar with possible diabetes and complications. However, it doesn’t fully connect each condition to the individual case in the input.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The response identifies possible causes or related issues for each condition mentioned in the report but fails to interpret these findings into a direct diagnosis or suggest next steps like in the True Answer. It misses addressing the underlying implications and recommended actions specific to the mother's situation.\n",
      "  \n",
      "- Naturalness: 4.7\n",
      "  - The response sounds fluent and natural, resembling how a doctor might explain each condition to a patient. It uses appropriate medical terminology while being understandable to a layperson. There are no grammatical errors or awkward phrasing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is coherent and logically aligns with the symptoms described in the input. It suggests a range of possible causes for the burning sensation, which aligns with the symptom of burning sensation in the body or ribs. However, the model does not specifically address nerve irritation or neuropathy, which could have been an important consideration.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response provides several potential causes for the symptoms and suggests appropriate tests and consultations, which makes it relatively complete. However, it lacks specific mention of neuropathy and related investigations, such as an X-ray of the cervical spine, which are highlighted in the true answer. Including these would make the response more comprehensive.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The model's response is fluent and sounds human-like. It uses polite, professional language appropriate for a doctor-patient interaction, and the structure of offering explanations followed by recommendations reflects a natural conversational pattern.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The response does somewhat logically align with the context provided, as it focuses on the patient's glucose levels and offers advice on medication and lifestyle. However, the mention of being an \"infectious diseases specialist\" is not relevant to the context of diabetes care, which slightly detracts from coherence.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a comprehensive answer with specific medical advice regarding medication (metformin), lifestyle modifications, and follow-up. While it doesn't directly acknowledge the attached HbA1c report, it does mention retesting HbA1c, which is relevant.\n",
      "\n",
      "- Naturalness: 3.5  \n",
      "  The response generally sounds human-like and fluent but includes some repetitive phrases (like mentioning \"Chat Doctor, infectious diseases specialist\") and an awkward invitation to use a URL, which makes it sound slightly less natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response is somewhat coherent since it tries to address the symptoms of double vision. However, it suggests a more severe possibility (like a brain tumor) rather than aligning with the context where the issue might be age-related due to refractive changes.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model suggests possible reasons for double vision, such as palsy or paralysis of eye muscles, and recommends an MRI, offering a thorough investigation route. However, it doesn't adequately cover the age-related aspects or alternative solutions provided in the true answer.\n",
      "\n",
      "- Naturalness: 3.8\n",
      "\n",
      "The response is generally fluent and understandable, though it lacks variety due to repeated phrases (\"Please get in touch with your doctor for a referral to an ophthalmologist\"). It doesn't fully capture a conversational or reassuring tone as seen in the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It identifies a potential condition (frenulum breve) that could explain the symptoms described. It also offers appropriate medical steps to address the concern, which aligns well with the described problem.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a fairly complete answer by suggesting a potential diagnosis and recommending consulting a urologist for further examination and treatment options. However, it could be slightly more complete by acknowledging other possible causes or ensuring the user knows to seek immediate medical attention if symptoms worsen.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, giving it a natural conversational quality. The language is clear and appropriately professional given the medical context, making it sound like advice from a healthcare professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "  - The model's response begins by identifying itself as a Urologist, which is incongruent with the necessary expertise for the question at hand, as a cardiologist or vascular specialist would be more appropriate. Additionally, the specific advice provided about the condition lacks accuracy in regard to the specifics asked in the query. \n",
      "\n",
      "- Completeness: 2.5\n",
      "  - While the model does touch on some key points such as the use of statins, blood thinning, and lifestyle changes, it fails to address specific treatment options and professionals to consult that were mentioned in the true answer, such as vascular surgeons or specific surgical procedures. \n",
      "\n",
      "- Naturalness: 3.5\n",
      "  - The response is mostly fluent and human-like, though slightly repetitive with the phrase \"You need to be on a very\" repeated multiple times. It concludes politely but the initial identity error pulls somewhat from its natural tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The response somewhat aligns with the context, acknowledging the patient's concerns; however, suggesting an \"increase of the antidiabetic Chat Doctor\" is unclear, likely meant to refer to medication, which reduces coherence.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The response fails to address the specific issue of weight loss associated with diabetes. It suggests increasing medication without sufficient justification or any exploration of the potential causes of the weight loss, leading to an incomplete answer.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "  - While the response is generally fluent and polite, the phrase \"increase the dose of your antidiabetic Chat Doctor\" is awkward and detracts from the overall naturalness, suggesting a potential error in terminology or an incorrect word choice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It addresses the user's concerns by acknowledging that the CT angiogram is normal and reinforces the continuation of current diabetes medication and a healthy lifestyle. However, it misses some specific medical nuances found in the true answer, such as the mention of \"minor disease\" and the potential for myocardial bridging.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response covers basic advice on lifestyle and confirms the normal results of the CT angiogram. However, it lacks specific recommendations for additional medications such as antiplatelet therapy and statins, as well as potential future tests like echocardiograms and treadmill testing, which are mentioned in the true answer. These omissions make the response less comprehensive in terms of medical advice and preventive measures.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent and human-like, using clear and understandable language. The tone is appropriate for a professional medical setting, though it slightly lacks the detail present in the true answer, which could add a bit more depth and reassurance to the interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response doesn't logically align with the details in the provided context. It incorrectly states that sickle cell trait and male hormones aren't causing any symptoms, which are in contrast with the medical context provided. Additionally, it suggests treatment for \"POD\" instead of PCOS, indicating a misunderstanding or miscommunication.\n",
      "\n",
      "- Completeness: 1.5  \n",
      "  The model's response does not sufficiently address the variety of symptoms and conditions mentioned in the input. It overlooks critical elements such as thyroid issues, diabetes indicators, and potential treatment avenues like surgery for fibroids or hormonal treatments, which are covered in the true answer.\n",
      "\n",
      "- Naturalness: 3.0  \n",
      "  The response is somewhat fluent and human-like but lacks specificity and detail, which hinders its natural flow in a medical consultation context. The model uses phrases such as \"Hope I have answered your query\" which contribute to a conversational tone, but the overall content lacks the depth and attention expected from a professional medical response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "\n",
      "    The model's response does not logically align with the context provided. The user is asking about the medication \"Accentrix,\" which is not correctly identified as a Chat Doctor in the response. Instead, the user likely expects information about a medical treatment or advice regarding their condition related to diabetes and the OCT reports.\n",
      "\n",
      "- Completeness: 1.0\n",
      "\n",
      "    The response does not sufficiently answer the question. The user provided OCT reports and asked for guidance regarding Accentrix, but the model's response mistakenly describes it as a type of insulin rather than providing relevant information about the user's eye condition or potential treatment related to their diabetes.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "    The response sounds relatively fluent and human-like in structure, but the incorrect and irrelevant information disrupts its efficacy. The conclusion (\"I hope this information was helpful. Best wishes\") is polite and typical of a human response, which boosts its naturalness score, but the factual inaccuracies heavily impact its overall quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response generally aligns with the context provided. It addresses the possibility of an infection leading to the swelling and boils, which is consistent with the details shared in the input about pus buildup and the need for surgery.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the model suggests that surgery is the best option, it lacks depth in its explanation and does not address potential underlying issues like diabetes, as highlighted in the true answer. It also does not discuss alternative management or medications that might be considered before opting for surgery.\n",
      "\n",
      "- Naturalness: 4.2  \n",
      "  The response is mostly fluent and human-like. It maintains a professional tone appropriate for a medical context, though the phrase \"Chat Doctor\" seems out of place and detracts slightly from the overall polish.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is generally coherent and aligns logically with the user's query about handling anxiety. It offers practical suggestions, such as relaxation techniques and consulting a psychiatrist, which are logical given the context of seeking help for severe anxiety.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a list of potential strategies for managing anxiety, such as medication and therapy, which covers the basics. However, it lacks depth in addressing the user's concern about whether their anxiety might be indicative of something more severe. The provided suggestions could be supplemented with additional insights about potential underlying issues.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and human-like, maintaining a professional and comforting tone. It offers clear and concise advice, making it easy to follow for someone seeking guidance on anxiety management.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "    \n",
      "  The model's response logically aligns with the context of the user's concerns about dry eyes, floaters, and the impact of eyelid closure after a vitrectomy. However, the response could benefit from more detailed connections about how these factors specifically relate to the user's experiences.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "  The response provides a general explanation about dry eyes and floaters, and suggests cataract surgery for better vision. However, it lacks depth in addressing all symptoms mentioned, such as cloudy vision with nonmoving black dots in both eyes, and doesn't explore potential underlying causes or solutions as the true answer does.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "    \n",
      "  The response is fluent and mostly human-like, though a bit stiff and formulaic in tone, especially with phrases like \"Hope above information is helpful to you\" which isn't as natural in conversational flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response logically aligns with the context provided in the input, addressing the concerns about mild LVH not being a problem, which matches the doctor's assertion in the provided context. However, it could have enhanced coherence by acknowledging the mentioned anxiety factor related to heart health.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The response gives a brief answer regarding mild LVH but does not address the concerns about anxiety or offer any advice on managing the anxiety related to heart health, nor does it provide additional context or reassurance as the true answer does.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response sounds fluent and human-like, though it uses slightly formal language that might come across as less conversational. Nonetheless, it maintains a professional and empathetic tone expected in a medical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is generally coherent and logically aligns with the context provided. It notes the medical history and conditions mentioned, such as diabetes, medication concerns, and cardiac issues. However, it slightly loses focus by not addressing the primary concern of changing medication and instead focuses on recommending various tests and checkups.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The model's response doesn't fully address the user's main query about changing diabetes medication considering the associated weight concerns and potential kidney issues due to the new medications. While it suggests additional tests and health history inquiries, it falls short of providing specific guidance or considerations based on the current medications mentioned and the concerns raised.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response generally sounds fluent and human-like, with a professional tone suitable for a medical consultation. However, it might feel a bit repetitive and slightly less engaging due to the extensive list of tests and inquiries without providing more personalized advice or specific next steps concerning medication.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the input. It addresses the issue of foot pain directly by suggesting analgesics and consulting an orthopedic. However, it lacks some context-specific guidance related to flat foot provided in the true answer.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The response offers basic advice on pain relief and recommends consulting a specialist if symptoms persist. However, it misses several important details such as possible causes of the pain, weight consideration, and recommendations for orthotics and exercises which are present in the true answer.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The response is fluent and sounds human-like. It has a polite, conversational tone and ends with a typical service closure which enhances naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response is generally coherent and aligns with the context provided by acknowledging the patient's symptoms and the findings related to the liver lesion. However, there are some inaccuracies, such as mentioning elevated alpha-fetoprotein levels which are not supported by the context.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The model's response correctly identifies the hemangioma as a benign lesion and mentions the treatment approach for symptom control. However, it lacks guidance on the need for follow-up imaging and does not address the need to send a CBC report to check for possible infection, as mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "  - The response is mostly fluent and human-like. However, the abrupt mention of \"pleural fluid Chat Doctor\" indicates a potential model error or miscommunication, which detracts from the naturalness and clarity of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response generally aligns with the context, acknowledging the link between sleep apnea and stroke. However, it lacks specific reference to the patient's medical history details, which reduces its coherence with the input.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The response briefly mentions the link between sleep apnea and stroke and recommends consulting a pulmonologist. However, it misses the complexity and depth observed in the true answer, such as addressing additional risk factors, irreversibility of brain changes, and further specific investigations or treatments.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The model's response is fluent and reads like a human would, with clear sentences and a polite tone typical of professional medical advice. However, the lack of depth slightly detracts from the naturalness expected in a detailed medical consultation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response aligns with the context in terms of addressing the concern about metformin and recommending continued use, claiming it's not recalled due to cancer scare. However, it lacks sufficient context regarding the high sugar level mentioned in the input, which impacts overall logical alignment.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  While the model does address the concern about metformin, it fails to provide alternatives or a plan given the high sugar level reported in the input. It also does not mention the potential need for additional investigations or adjustments in medication, as noted in the true answer.\n",
      "\n",
      "- Naturalness: 3.5  \n",
      "  The response is generally fluent and relatively human-like, with polite expressions and clear language. However, some phrasing is slightly stiff and can be improved for a more natural conversational tone. Furthermore, the inclusion of the signature \"ChatDoctorInfectious disease specialist.</s><s>\" seems out of place for the context provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response is somewhat coherent with the input as it suggests a possible medical explanation (a pinched nerve) that aligns with the symptom described by the user. However, it doesn't fully consider the user's recent recovery from a cold which might provide additional relevant context.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  The model provides only one possible explanation (a pinched nerve) and does not explore other potential causes such as vitamin deficiencies, side effects of medication, or sinusitis as outlined in the true answer. It also doesn't ask follow-up questions that could help in providing a better assessment.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response sounds quite fluent and human-like, using polite language and offering additional assistance. However, the phrase \"Hope I have answered your query\" seems a bit mechanical and formulaic, which slightly reduces its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context, providing a detailed explanation of ringworm and addressing possible reasons for persistent infection.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model suggests numerous reviews and practices for managing infection but lacks a specific treatment plan or alternative medications, which the true answer provides. \n",
      "\n",
      "- Naturalness: 3.0  \n",
      "  The response is somewhat repetitive and mechanical, especially with the repeated recommendation to review various factors with a doctor, which affects fluency and human-like quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "\n",
      "The model's response lacks coherence with the context provided. The user specifically asks about the risks associated with anesthesia and surgery, given their age and medical conditions. The response claims the procedures are safe for elderly patients, but it lacks specific details tailored to the user's extensive medical history, such as their obesity, diabetes, emphysema, and other conditions that could impact surgical risks.\n",
      "\n",
      "- Completeness: 1.5\n",
      "\n",
      "The response does not sufficiently answer the user's question. It provides a generic assurance about the safety of laparoscopic surgery and anesthesia for elderly patients, but it fails to address the user's individual risk factors, like emphysema and the use of a sleep apnea machine, which are critical given their medical background. Specific advice about their personal situation or a recommendation to consult with an anesthesiologist more suited to evaluating risk would have been more complete.\n",
      "\n",
      "- Naturalness: 2.5\n",
      "\n",
      "The response attempts to adopt a professional tone, but it sounds repetitive and mechanical, especially with the twice-repeated introduction and sign-off (\"I am Chat Doctor, infectious diseases specialist, answering your query\"). It lacks fluency and personalization, which are essential for a natural, human-like response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The response logically aligns with the input provided, addressing the main concern of anxiety and its related symptoms of bloating and constipation. However, it lacks direct acknowledgment of the patient's existing medication and conditions like coronary artery disease and diabetes.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "While the response gives some advice on managing anxiety-related symptoms with antacids and exercise, it does not address the potential need for medication adjustment or a more comprehensive treatment plan considering the patient's coronary artery disease and diabetes. This makes it less complete compared to the true answer.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The response is generally fluent and human-like. However, the phrasing \"Chat Doctor\" is awkward and detracts from the overall naturalness. Additionally, the response ends abruptly without a proper closing, which can make it feel less conversational.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  *Assessment: The model's response is generally coherent, as it provides information about the potential cause of the jerks (side effects of sedatives) and states that they should subside once the medication is stopped. However, it could better align with the context by considering if other factors like Alzheimer's or diabetes medications might be contributing factors.*\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  *Assessment: The response partially answers the question by attributing the jerks to sedative side effects. However, it does not fully address whether the jerks might return or consider the possibility of other drugs affecting the situation. Suggestions for further medical consultation are also missing.*\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  *Assessment: The response is generally fluent and human-like, with a friendly and reassuring tone. It does, however, lack a little bit of the personal touch and additional follow-up questions or guidance that might be typical in a conversation with a concerned family member.*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response partially aligns with the context provided, addressing the concerns about hemoglobin and diabetes. However, it does not mention the attached reports or specific medications, which reduces coherence with the given query.\n",
      "  \n",
      "- Completeness: 2.5\n",
      "  - The response addresses general advice on managing hemoglobin levels and diabetes, but it lacks specific recommendations and does not fully elaborate on the necessary steps or consider the shared medical context. It misses the request for a detailed explanation, including types of medicines.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The language used in the response is fluent and human-like, with a clear conversational tone. However, it could be more detailed and engaging to enhance its naturalness further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response aligns with the context in terms of discussing the thyroid levels, but it is incorrect to say that the TSH level is within the normal range when it is slightly elevated. This affects the logical alignment with medical standards.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The model's response does not provide a comprehensive answer. It fails to mention the concept of sub-clinical hypothyroidism, the absence of symptoms needed for diagnosis, potential further testing for confirmation, and the suggestion to repeat thyroid tests.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and sounds human-like, though it's a bit too dismissive given the context, which slightly affects its natural conversational tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "   - The model’s response is somewhat coherent as it touches on relevant issues like diabetes and suggests the necessity of a color Doppler. However, it incorrectly attributes the cause of swelling primarily to high blood pressure, which was not mentioned as a condition in the input, and lacks the depth and specificity found in the true answer.\n",
      "\n",
      "- Completeness: 3.0\n",
      "   - The response is partially complete. It advises hospitalization and a color Doppler, which aligns with part of the true answer. However, it misses important advice about ceasing antibiotics without evidence of active infection and the importance of podiatric care or consultation with specialists, which are critical elements in the true answer.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "   - The response is fairly natural and fluent in terms of language. It follows a logical structure that is reminiscent of what a human doctor might articulate, but there is a slightly mechanical tone and lack of depth that detracts from a fully natural impression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided input and model response, here are the evaluations for each metric:\n",
      "\n",
      "- **Coherence: 1.0**\n",
      "  - The model's response lacks logical alignment with the context, as it repeatedly suggests a diagnosis (neurofibroma) that is not relevant to the typical description of skin changes related to diabetes or common dermatological issues discussed in the true answer. The repetition and lack of addressing the context render it incoherent.\n",
      "\n",
      "- **Completeness: 1.0**\n",
      "  - The response is overly repetitive and does not provide a complete answer to the question asked. It fails to discuss potential causes or remedies that are relevant to the patient's condition, such as frictional hyperkeratosis or acanthosis nigricans, and offers no management or treatment advice.\n",
      "\n",
      "- **Naturalness: 1.0**\n",
      "  - The response does not sound fluent or human-like due to the excessive repetition of phrases and the lack of variation or coherent explanation, which detracts from the naturalness of the model's answer. It does not reflect how a human expert would communicate.\n",
      "\n",
      "Overall, the model's response falls short across all evaluation metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5\n",
      "\n",
      "The model's response partially aligns with the context by addressing the problem of nightfall. However, it incorrectly suggests that taking tadalafil is a way to avoid nightfall, which indicates a misunderstanding of the condition. The suggestion focuses more on improving erections rather than addressing the underlying causes of weakness during sex or nightfall, as mentioned in the input.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The response does not sufficiently answer the user's question about both the reason for and remedy of the weakness experienced during sex. It only focuses on nightfall and doesn't consider the broader aspect of sexual and general weakness or the potential underlying health issues, as the true answer does.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The model's response is quite fluent and generally human-like, though it could be improved with more empathetic language. The closing statement, \"Hope I have answered your query. Let me know if I can assist you further,\" sounds professional and courteous, contributing to its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context provided. It acknowledges the MRI findings and the need for more specific information, which is coherent with the situation described. However, it could have acknowledged the burst vessel's potential relevance to the symptoms more explicitly, like in the true answer.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model does not sufficiently address whether the leg and hand function can be restored, which is the main concern of the input question. It mainly focuses on requesting more data without giving any indication or general information regarding possible outcomes, falling short of providing a complete answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, showing empathy and a polite manner, which is typical of a conversational context with a patient. It uses a professional tone, making it sound natural, albeit slightly mechanical due to the repetitive request for additional information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is mostly coherent with the context, addressing the issue of chest pain and providing general advice on potential causes and diagnostic steps. However, it does not specifically relate to the father being taken to the hospital and instead focuses on general possibilities without referencing the details provided.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response only partially answers the query. It suggests potential causes and offers some tips for muscular pain but doesn't directly address monitoring or managing the described heart condition and does not mention ongoing medications or lifestyle changes, which were included in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds quite fluent and human-like, with a conversational tone and common expressions a doctor might use, although it ends a bit abruptly with a hope that the query is answered without specific closure—this slightly affects its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 2.0**  \n",
      "  The response begins appropriately by acknowledging the concern, but then becomes largely incoherent. It asks for additional information repeatedly and redundantly without addressing the specific details provided about the child's blood sugar levels. The repetition of the phrase \"I would like to know the history of any...\" becomes nonsensical towards the end.\n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "  The response does not answer the main question regarding whether the child's blood sugar levels are within normal ranges or if they are a cause for concern. Instead, it focuses on asking for more information without providing any evaluation or conclusion about the details given in the query. Thus, it fails to provide any useful insight or guidance.\n",
      "\n",
      "- **Naturalness: 1.5**  \n",
      "  Initially, the model's response sounds somewhat human-like, as it shows understanding and asks relevant follow-up questions. However, the excessive repetition and listing of history inquiries make it sound mechanical and unnatural, detracting significantly from its overall fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "  - The model's response includes several logical steps involved in the examination of erection problems; however, it presents too many potential tests and steps that may not fit every scenario, slightly misaligning with more context-sensitive real-world procedures mentioned in the true answer.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The response covers a wide range of possible examinations and tests, which provides a thorough picture of what might happen during a medical assessment for erection problems. Though slightly less focused compared to the true answer, it includes more thorough detail than necessary.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The response uses proper, structured language and is mostly fluent. However, the repetitive use of \"He/she will also\" makes it sound less natural and more mechanical. A more varied sentence structure could improve fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It acknowledges the user's symptoms and the seriousness of the situation, emphasizing the availability of treatment options. However, it lacks specific acknowledgment of the suicidal thoughts mentioned in the input, which is a crucial aspect.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a broad range of suggestions and encourages seeking help. However, it does not address the urgency related to thoughts of death or suicide as strongly as the true answer does, which mentions consulting a psychiatrist quickly and considering the possibility of inpatient care.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds human-like. It uses empathetic language and provides practical suggestions in a supportive manner. There are no unusual phrases or unclear statements, making it sound very natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context, identifying potential causes for the nerve pain and suggesting appropriate actions, such as consulting with a neurologist.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a sufficient and reasonable answer to the user's concern, mentioning potential diagnoses and suggesting a course of action. However, it lacks some of the detailed inquiries and recommendations for medication present in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and sounds human-like, with a professional tone appropriate for a doctor's response. It reads smoothly, although the closing \"Best wishes,\" followed by a sentence fragment might slightly disrupt the natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.5\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "- **Coherence**: The model's response is mostly coherent with the context provided in the input. It focuses on frequent urination and suggests possible underlying conditions, advising the user to seek medical advice, which makes sense given the user's concerns. However, it does not address the specific mention of feeling aroused, which might have been considered to improve coherence slightly.\n",
      "\n",
      "- **Completeness**: The model's response covers the aspect of frequent urination and suggests seeing a specialist, but it falls short of providing a comprehensive answer. The true answer provides additional insight into the sensation experienced when the bladder is full, which the model omits. Including this element would have made the response more complete.\n",
      "\n",
      "- **Naturalness**: The response is generally fluent and human-like, offering a suggestion and reassuring the user, which makes it natural-sounding. The phrasing \"I suggest you to consult a urologist\" is slightly awkward, but overall, the response maintains a natural tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5 \n",
      "  - The model's response is somewhat coherent with the input, as it addresses frequent urination and suggests possible causes like diabetes or a urinary tract infection. However, it ignores some context from the input, such as the burning sensation or the fact that the individual has already done a uroflowmetry test.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - The response partially addresses the question by suggesting potential causes for frequent urination and recommending tests to rule these out. However, it does not consider stress or prostate gland swelling, as suggested in the true answer, nor does it offer any relief measures for the symptoms besides tests.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The response is mostly fluent and human-like, with clear and understandable language. However, the repetition of suggesting a uroflowmetry test, which the user has already mentioned doing, slightly detracts from its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "  The model's response generally aligns with the context provided. It acknowledges the medications mentioned and attempts to explain the bitter taste in the mouth. However, the sentence appears to be cut off, which slightly affects overall coherence.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "  The response is incomplete, as it doesn't address all parts of the query. It only partially deals with the bitter taste by attributing it to diabetes medications but doesn't recommend how to reduce the side effects or mention any possible medications. The conclusion of the sentence about metabolites is missing, which leaves the explanation hanging.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "  The response starts off sounding fairly natural, but the abrupt cut at the end and the inclusion of \"Chat Doctor\" impact its fluency, making it less human-like. Without these issues, the response could have scored higher for naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "    The model's response suggests a pinched nerve in the wrist, which is not the most logical explanation considering the symptoms. There is no mention of other possible causes such as cervical spondylosis or diabetic neuropathy, which are addressed in the true answer. Thus, the response partially aligns with the symptom description but misses exploring more likely causes.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "    The response offers a potential cause and a suggestion for action, but it lacks examination of alternative diagnoses and does not consider the absence of swelling, discoloration, or injury. It also overlooks connections to potential systemic issues like diabetes or cervical spine problems that could explain the symptoms.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "    The response is generally fluent and employs polite, professional language. It resembles the way a medical professional might communicate, maintaining clarity and a natural tone throughout the advice given. However, the closing line, \"Hope I have answered your query,\" feels somewhat abrupt and less aligned with a detailed medical explanation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is logically aligned with the input context relating to leukocytic material and its potential implication in myelodysplastic syndrome. However, it does not address the specific inquiry about fibrino-leukocytic consistency, leaving a slight gap in alignment.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model offers useful information about leukocytic material but does not fully address the specific question regarding whether this material's nature proves the suspected condition. It falls short in advising further diagnostic actions compared to the True Answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is mostly fluent and human-like, expressing willingness to help and providing a concise explanation. It could sound slightly more conversational, but overall it maintains a natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response recognizes the relevance of diabetes to foot injuries but incorrectly attributes the color change to infection without considering the possibility of bruising or venous blood leakage, which is addressed in the true answer. This undermines the logical alignment with the provided context.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The model covers some important aspects like the risk of infection and emphasizes the need for immediate care but misses addressing other crucial points such as monitoring blood sugar levels, the possibility of a fracture, and the recommendation to keep the foot elevated to aid recovery.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response sounds fluent and is structured in a clear and professional manner, similar to human-like language used by a healthcare provider. However, the response is somewhat generic, lacking specific tailored advice that would improve its naturalness further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response somewhat aligns with the context provided in the input. It acknowledges the user's issue and provides a suggestion for antifungal treatment. However, it does not address some of the specific details from the input, such as the recurrence of the infection, the stopping of Oxra, or the symptoms experienced after sexual activity.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The response partially answers the question by suggesting a treatment (fluconazole) and the application of antifungal cream. However, it does not address why the infection may have recurred or consider all aspects of the problem, such as the effect of stopping Oxra or the possibility of reinfection from the partner. There is also no mention of checking with a healthcare professional for a comprehensive and personalized treatment plan.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "The response sounds fairly natural and human-like, but it lacks personalization and empathy. The phrase \"I will be happy to answer your further concerned can contact me\" is awkwardly phrased and detracts from the fluency. The mention of \"Chat Doctor\" feels out of place and detracts from the conversational tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response is coherent to some extent, as it addresses the concern by acknowledging that the needle did not pierce the skin, which implies low risk for viral infection transmission. However, it incorrectly mentions applying pressure to the needle rather than where it touched, which slightly affects the logical flow.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response lacks depth by only reassuring the user based on the fact that the needle did not pierce the skin. It doesn't address other important aspects, such as mentioning the possibility of transmission through specific viruses, discussing the status of the diabetic person, or recommending follow-up testing like the true answer does, which provides a comprehensive view.\n",
      "\n",
      "- Naturalness: 2.5  \n",
      "  The response sounds somewhat artificial and disjointed due to phrases like \"Thank you for your contact to Chat Doctor\" and \"Chat Doctor. Infectious disease specialist.\" Moreover, the use of \"I will suggest you to take some multivitamin tablets for a week\" seems like an irrelevant addition in this context, making the response less natural and more scripted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response logically aligns with the context by identifying that the fasting glucose level is slightly above normal and recommending lifestyle changes such as diet and exercise. The response addresses the blood glucose levels, HbA1c, and lack of sugar in the urine accurately based on medical knowledge.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The model provides a thorough answer with practical advice on dietary and lifestyle changes to manage blood glucose levels. However, it could improve completeness by suggesting a consultation with a healthcare provider for personalized advice or potential medical intervention.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is fluent and reads like something a human could say. There is a minor issue with coherence in \"avoid sugary foods and refined carboy Chat Doctor,\" which slightly affects naturalness. Otherwise, it maintains a professional and human-like tone, asking if further assistance is needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response is logically aligned with the context provided in the input. It correctly explains that supplements do not directly reduce HbA1c and provides a general overview of how HbA1c reflects blood sugar levels over time.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - While the model accurately states that there aren't any supplements to specifically reduce HbA1c, it could have given additional advice on lifestyle modifications, such as those detailed in the true answer, to manage HbA1c levels effectively. It mentions consulting a doctor for a treatment plan but lacks specific lifestyle or dietary recommendations.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent, clear, and sounds human-like. It uses appropriate language and structure that one would expect in a natural conversation between a doctor and a patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response provides some advice relevant to alleviating symptoms related to post nasal drip and sinus issues. However, it begins with a redundant phrase \"post nasal Chat Doctor,\" which disrupts logical alignment with the rest of the response. The rest of the advice is coherent with typical treatment suggestions.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The response does not fully address all the symptoms and concerns mentioned in the input, such as the sore throat and stiffness of the throat. It also lacks a personalized approach considering the patient's medical history, such as details on medications already taken or alternatives. There could be more guidance given the duration and severity of the symptoms described.\n",
      "\n",
      "- Naturalness: 3.0  \n",
      "  The response starts off in a friendly, conversational manner but soon includes repetitive phrases (\"post nasal Chat Doctor\") that detract from its naturalness. The rest of the language is grammatically correct and reasonably fluent, recommending common treatments in a generally human-like manner. It ends with a polite closure, enhancing its naturalness somewhat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response provides a general understanding of the medical situation, mentioning factors such as diabetes and Alzheimer's being risk factors for heart disease. However, it doesn't fully align with the patient's condition, as it recommends angioplasty despite the patient's age and complex health factors which are reasons why angioplasty is typically not recommended.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The response is incomplete in addressing the complexity of the patient's condition. It fails to acknowledge critical details such as the patient's ejection fraction and the complexity of the lesion, which are important factors in making a treatment decision. The true answer suggests coronary artery bypass graft (CABG) and discusses minimally invasive procedures, which are missing in the model's response.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The response is generally fluent and human-like, using appropriate medical terminology and a professional tone. However, some additional details and a more thorough explanation would improve naturalness by providing a more comprehensive overview consistent with the complexity of the patient's condition.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0  \n",
      "  The model's response does not logically align with the context. Instead of addressing the question about BP medication alternatives, it repeats a list of diagnostic questions, many of which are redundant.\n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The response fails to answer the core question of suggesting a non-diuretic BP medication. None of the requested details provide a solution or direction related to what's being asked, thus making it incomplete.\n",
      "\n",
      "- Naturalness: 2.0  \n",
      "  While the language used resembles human queries and exhibits fluency, the repetitive and excessive nature of the questions detracts significantly from sounding natural or purposeful in a typical conversational or professional context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "  - The model's response does not logically align with the input as it fails to address the context provided. Instead of suggesting next steps or tests based on the information given, it repeatedly asks unrelated questions and seems disorganized.\n",
      "\n",
      "- Completeness: 1.5\n",
      "  - The response does not sufficiently answer the question. It does not provide any actionable advice or recommendations for further evaluation or diagnosis, which are expected in a medical consultation context.\n",
      "\n",
      "- Naturalness: 1.0\n",
      "  - The response is not fluent or human-like as it is highly repetitive and lacks coherence, making it difficult to follow. This repetition of questions diminishes the natural flow expected in a conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "  The model's response aligns with the context of the question regarding the medical conditions mentioned. However, it diverges into asking numerous detailed questions rather than providing an actionable immediate step, such as seeking a neurosurgery consultation, which results in partial coherence.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "  The response does not sufficiently answer the question of what immediate action should be taken. Instead of giving clear guidance, it solicits further medical information and tests which may not be feasible for an immediate response, particularly given the context of urgency suggested by the diagnosis.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "  The response sounds relatively fluent and maintains a human-like tone. However, the repetitive request for detailed tests and information decreases the overall naturalness, making it seem less conversational and empathetic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  - The model's response logically aligns with the context by acknowledging the current and previous treatments and emphasizes the need to continue the medication. However, it fails to address the core issue of recurring symptoms after discontinuation adequately and doesn't explore potential underlying conditions like diabetes, making it partially coherent with the user's main concern.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  - The model's response repeats the already known treatment duration but doesn't provide new insights or address the patient's concern about recurring symptoms or alternative treatment options. It lacks suggestions for what to do if symptoms continue after medication and omits lifestyle recommendations for symptom management. Therefore, it falls short in completeness.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  - The language used in the model's response is generally fluent, polite, and maintains a professional tone appropriate for a medical query. However, the repetition of certain phrases impacts the natural flow slightly, but overall, it still sounds human-like and coherent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is generally coherent and provides a logical explanation about nasal polyps, their causes, and treatments. It aligns with the context of the query regarding a nasal polyp but misses addressing some specific details such as the need for a biopsy and the severity assessment related to age and single-sided presentation.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response provides some relevant information about nasal polyps, their symptoms, and treatment. However, it falls short in addressing specific parts of the user's query, such as the necessity of a biopsy given the age and condition mentioned. It also doesn't provide a direct opinion on the severity level, which is a part of the original question.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is mostly fluent and reads naturally, resembling a human-like conversation. The language used is clear and professional, suitable for a healthcare context. There is slight repetitiveness, but overall, it maintains a human-like tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is generally coherent and aligns logically with the input context. It identifies the elevated creatinine and triglyceride levels, and it correctly notes the potential risks associated with high triglycerides and elevated creatinine levels. However, it misses the connection between diabetes management and kidney function, which is present in the true answer.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model addresses the elevated creatinine and triglyceride levels and suggests continuing with diet and exercise, it lacks depth regarding the need to restart diabetic medication due to elevated HbA1c levels and potential kidney risks, as highlighted in the true answer. It should have recommended consulting a healthcare professional about medication, especially given the context of not taking medication for six months.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and reads naturally. It is structured in a manner that is typical of human-like interaction. However, the use of technical terms like \"sensitive marker of kidney function\" could potentially be simplified for broader understanding, but this does not significantly detract from the naturalness of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 2.0**  \n",
      "  The model's response does not logically align with the specific context and questions provided. It lacks specific references to the medication changes mentioned in the input, such as the switch from Prolomet XL to Tazloc-H. It also repeats certain statements unnecessarily, which detracts from coherence.\n",
      "\n",
      "- **Completeness: 1.5**  \n",
      "  The model's response is incomplete. It fails to specifically address whether the current medication regimen is appropriate, what the effects of replacing Prolomet XL with Tazloc-H might be, and does not address any potential issues with heart rate management. It also overlooks the user's query about the dosage frequency of Metformin.\n",
      "\n",
      "- **Naturalness: 2.5**  \n",
      "  The response includes repeated phrases, making it sound less fluent and human-like. While it uses some medical terminology appropriately, the repetition and lack of detailed, personalized advice reduce its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5\n",
      "\n",
      "The model's response lacks coherence with the context provided. It makes a sudden leap to a definitive diagnosis of lymphoma, which seems unwarranted given the information presented. The original query details negative results for infectious diseases and other normal findings, yet the model presumes a serious condition without sufficient justification.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The response does not sufficiently address all aspects of the patient's concerns. It focuses heavily on recommending surgical intervention without acknowledging or providing insights into the other symptoms like stiffness, numbness, and weakness. The model response also fails to suggest additional diagnostic tests or alternative explanations that the true answer provides, making it incomplete.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "\n",
      "The model's response attempts to maintain a professional and polite tone, but it has an abrupt and repetitive structure that affects its fluency. Phrases like \"I studied your query in full details updated from you,\" and repetitive encouragement to reach out for further queries can feel unnatural and more mechanical than human-like. It also ends with an awkward and informal closing, \"Have a Good Day. Chat Doctor. N.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is quite coherent with the context. It correctly addresses the individual's concern about diabetes by stating that a blood sugar level of 125 in the morning is not diagnostic of diabetes, which aligns with standard medical guidelines.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response provides a sufficiently direct answer to the question \"Am I diabetic?\" by clarifying that a level of 125 is not enough to diagnose diabetes. However, additional advice such as consulting a doctor for further assessments or lifestyle modification tips could enhance completeness.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, with a polite greeting and clear, concise language. It provides a rationale for further actions, which feels natural and informative.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response logically aligns with the context provided. It addresses the issue of a recurring ingrown toenail and offers explanations about potential underlying causes, such as foot deformities and medical conditions, which are relevant to the user's situation.\n",
      "\n",
      "- **Completeness: 3.0**  \n",
      "  The model suggests seeing a podiatrist to determine the cause and begin treatment, which is a valid recommendation. However, it doesn't provide specific actionable steps that the user can take immediately, such as home remedies or specific medications, which the true answer does. The response could be more thorough by including additional self-care advice.\n",
      "\n",
      "- **Naturalness: 4.8**  \n",
      "  The response is fluent and sounds quite human-like. It uses polite language and properly constructed sentences, making the communication feel natural. The small deduction in the score is due to its relative brevity, which lightly impacts the perceived depth without sacrificing quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "\n",
      "  The model's response is logically aligned with certain aspects of the context, particularly regarding the symptoms described in the chest area. However, it does not address the sensation in the right index finger, which is an important part of the provided context. Therefore, while the response has some coherence with the chest-related symptoms, it is not fully coherent in covering all aspects of the situation described in the input.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "  The model's response provides an incomplete answer to the question. It focuses solely on the possibility of angina and suggests consulting a cardiologist, without addressing the potential neurological issues related to the sensation in the finger and potential nerve involvement. The true answer encompasses both cardiac and neurological evaluations, making the model's response lacking in necessary breadth.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "  The response is generally fluent, with a natural and professional tone consistent with a doctor's communication style. A slight improvement could be made in the wording to enhance clarity and avoid incomplete phrases like \"tab. Pariet,\" which might confuse a general audience, thus marginally impacting its naturalness. Nonetheless, it sounds human-like and well-structured for most of the text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response is coherent and logically aligns with the context provided. It correctly explains the significance of the elevated C-reactive protein level and relates it to inflammation, which is relevant given the symptoms described. However, the response could have explicitly linked the inflammation to diabetes, which is mentioned in the input.\n",
      "\n",
      "- **Completeness: 4.0**  \n",
      "  The model's response is generally complete, explaining why the C-reactive protein level might be high and suggesting a possible cause for the joint pain. However, it lacks a direct link to the recent diabetes diagnosis and doesn’t fully explore alternatives or further steps specific to managing diabetes-related inflammation.\n",
      "\n",
      "- **Naturalness: 5.0**  \n",
      "  The response is fluent and human-like. It uses clear, natural language and maintains a professional, conversational tone appropriate for a medical query response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  - The model's response logically aligns with the context by suggesting a medical consultation based on the symptoms. However, it does not consider all potential causes or test results that were part of the input.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  - The response suggests a possible cause (peripheral neuropathy) and recommends a specialist consultation, which is a narrow focus compared to the range of possibilities and tests mentioned in the true answer. It doesn't address other potential diagnoses or acknowledge the provided test results.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  - The response is fluent and human-like, using well-structured sentences and appropriate medical advice language.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "  The model's response is coherent with the input context to some extent. It correctly identifies the main issues related to the patient's medical history and the AV fistula query. However, it overlooks the complexity and potential issues with placing the fistula given the partial amputation and doesn't consider all the specific concerns, such as the limitation of movement if placed in the right hand.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  \n",
      "  The response is lacking in completeness. While it mentions the possibility of placing a fistula in either hand, it does not discuss alternative sites such as near the chest or leg or the specifics of different types of fistula. It also doesn't address the complications or considerations due to the partial amputation or the impact on the patient's self-care abilities.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "  The response is generally fluent and understandable, but it is somewhat repetitive with phrases like \"It is a surgical procedure and can be done in any hand.\" This repetition and lack of nuanced language slightly detracts from the naturalness and human-like quality of the response.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  - The response lacks coherence with the provided context. While the input specifies the presence of grade 2 diastolic dysfunction, the model erroneously states that there is no diastolic dysfunction, leading to a misaligned response regarding the user's condition.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  - The model's answer is not fully complete as it omits addressing the specific question about whether mild concentric LVH might regress with diet and exercise. Furthermore, it does not provide a suggestion to follow up with a cardiologist, which is important for medical conditions like this.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  - The response sounds quite fluent and human-like, with a polite and conversational tone. However, there are slight redundancies in wording, such as \"I would suggest you to\" being repeated, which slightly affects the overall fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "\n",
      "The model's response lacks coherence as it provides a list of medications, including several assumptions on what the patient might be taking rather than direct answers concerning potential interactions or unnecessary medications as per the input's query. This does not align logically with the detailed concerns about medication interactions and the completion of TB treatment.\n",
      "\n",
      "- Completeness: 1.5\n",
      "\n",
      "The response is incomplete as it fails to advise on potential bad interactions or unnecessary medications effectively. The model merely lists medications with speculative additions and does not provide guidance on the TB treatment continuation concern or discuss medication interactions, which was the core of the user's query.\n",
      "\n",
      "- Naturalness: 2.5\n",
      "\n",
      "While the model's language is generally fluent, the repetitive speculative statements (\"I think she is also taking...\") decrease its naturalness and clarity. The response starts off with an attempt to address the user's concern but then devolves into a repetitive and uncertain list, which detracts from a human-like delivery.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "The model's response logically aligns with the context, offering a general understanding of hepatitis E and the significance of the ANA test. It advises consulting a gastroenterologist, which is a coherent suggestion.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "The response covers the basics of hepatitis E but lacks detail about its implications specific to the user's condition (such as the impact on diabetics or the suggested dietary considerations). It doesn't explicitly address whether the condition is life-threatening or discuss potential complications, unlike the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "The model's response is fluently written and sounds human-like. It follows a logical structure and uses formal language appropriate for a medical setting. However, the phrase \"I hope this advice will help you\" slightly detracts from the expert tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is generally coherent as it addresses the issue of knee pain with recommendations for pain relief and suggests further consultation, which aligns with the user's context of ongoing knee pain despite a normal MRI result. However, the suggestion to consult an orthopedic again may seem redundant as the user has already done so.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides a basic suggestion for pain management and a recommendation to consult a professional if the issue persists. Nonetheless, the advice could be more tailored to the specific case, especially considering the user's diabetes, and could cover more potential underlying causes or treatment alternatives given the chronic nature of the pain and the normal MRI.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The language of the response is fluent and human-like, with only minor awkwardness. It uses appropriate medical terminology for a medical consultation context, and the closing phrases like \"Hope I have answered your query\" and \"Let me know if I can assist you further\" are characteristic of a human interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "\n",
      "The model's response lacks logical coherence with the input information and context. It suggests taking antibiotics and painkillers without identifying an infection or detailing the nature of the pain, as delineated in the true answer. Furthermore, it offers a long list of dietary restrictions without clear justification tied to the individual's specific condition, making it appear fragmented and unfocused.\n",
      "\n",
      "- Completeness: 1.5\n",
      "\n",
      "The model's response does not sufficiently address the main query, which is to suggest further actions based on the gallstone diagnosis and current symptoms. It fails to acknowledge the necessity for further diagnostic information to provide a comprehensive recommendation, unlike the true answer.\n",
      "\n",
      "- Naturalness: 2.0\n",
      "\n",
      "The response is somewhat fluent and human-like in isolated sentences, but it quickly devolves into an extensive and repetitive list of dietary restrictions, which diminishes its overall naturalness and readability. The verbosity and repetition detract from a conversational or professional tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response provides a general explanation of bronchiectasis and its treatment, which is somewhat related to the input question. However, it lacks specific details about early bronchiectatic changes and their implications, which makes the answer only partially coherent with the input.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The response does not fully address the input questions, such as the difference between early bronchiectatic changes and bronchiectasis, specific concerns about life expectancy, or detailed treatment suggestions including the use of Guaifenesin. It is an incomplete answer to the user's detailed and multifaceted inquiry.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The language used by the model is fluent and human-like, using appropriate medical terminology and a polite, professional tone. However, the abrupt closure (\"Hope I have answered your query. Let me know if I can assist you further.\") slightly disrupts the natural flow without providing a personalized follow-up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response is partially coherent. It acknowledges the mother's underlying health conditions and medications but misinterprets the symptoms as indicative of a colon issue without considering other possibilities like acid reflux or medication side effects mentioned in the True Answer.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response offers a course of action, suggesting diagnostic tests such as colonoscopy and stool tests. However, it doesn't explore all possible reasons for the symptoms, such as stress-related acid reflux as suggested in the True Answer. Hence, it lacks completeness.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is generally fluent and human-like. It uses appropriate medical terminology and provides clear suggestions, making it feel like a plausible human response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 3.0**  \n",
      "The model's response lacks coherence in parts. While it correctly identifies the meningioma from the MRI, it inaccurately describes the lightened area as a \"normal MRI finding\" without considering the provided context. Furthermore, it doesn't address the user's medical history or medication details thoroughly, which could have been tied into the response for better coherence.\n",
      "\n",
      "- **Completeness: 2.5**  \n",
      "The response partially answers the user's questions. It addresses some specific inquiries, like the concern about acetyl carnitine, but fails to discuss potential causes of brain atrophy comprehensively or examine the implications of the medications mentioned. The response should have also touched upon the possibility of infections or other explanations for hyperintense lesions.\n",
      "\n",
      "- **Naturalness: 3.0**  \n",
      "The response contains some unnatural phrasing, especially with parts being cut-off (e.g., \"The atrophy is due to the Chat Doctor\"). Some sentences are straightforward, yet it lacks the empathetic tone expected in a medical discussion, which affects the perceived fluency and human-like quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  - The model's response is somewhat coherent with the context provided, as it connects the bleeding to recent sexual intercourse and mentions that this can be common for someone newly sexually active. However, it doesn't address the full range of possible causes for the bleeding considering the user's menstrual cycle and timing.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  - The response is lacking in completeness because it doesn't provide a thorough examination of possible causes of the bleeding. It suggests a possible link to intercourse but omits other medical considerations mentioned in the True Answer, like pregnancy, thyroid issues, and other potential medical conditions. It also lacks advice on seeking further medical evaluation or tests.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  - The model's response is generally fluent and reads naturally. It uses polite language and explains its reasoning in a clear manner, though it prescribes medication without specific professional guidance, which slightly reduces the naturalness of how a real doctor might respond.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response somewhat aligns with the context provided. It identifies the issue as a potential fungal infection, which is consistent with the symptoms described. However, it lacks alignment with the context concerning the advice already provided by the local doctor and other specific conditions that need consideration.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model's response suggests a course of treatment for a fungal infection and some hygiene tips. However, it does not address all aspects of the situation—such as the question's details about the effects of hot water or the possibility of other conditions like herpes or chancroid that the true answer mentions. It also doesn't advise stopping Surfaz SN, which is significant advice present in the true answer.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response sounds mostly fluent and human-like but lacks natural engagement such as questioning and further probing for additional symptoms or contributing factors, which makes the true answer sound more conversational and comprehensive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The response aligns with the context provided but diverges into suggesting a comprehensive checkup rather than directly addressing the patient's inquiry about medication changes. Some aspects mentioned, like dietary habits and family history, seem less immediately relevant to the requested guidance on medication adjustment.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the model provides detailed suggestions for additional tests and checks, it does not directly address the patient's specific concerns about alternative medications for diabetes management or the implications of those medications on weight and kidney health. The model fails to guide the patient about the specific concerns and kind of lifestyle or medication adjustment that could be considered, given the patient's conditions.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, with proper use of medical terminology, and it maintains a professional tone. However, it is slightly formal and might feel impersonal due to the repeated emphasis on what the patient \"has not mentioned,\" rather than offering direct advice based on the provided data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response mostly aligns with the context provided. It addresses the individual's condition, dietary needs, and preferences. The response is directly relevant to the user's situation, though there could be some minor discrepancies such as the interpretation of a \"low protein\" diet instead of specific protein measurements.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response provides a clear recommendation on the frequency of consuming fish and chicken, it doesn't fully address the complexities of the dietary requirements mentioned (e.g., specifics on low potassium, uric acid, and phosphorus). The advice lacks detailed guidance on the entire diet beyond non-vegetarian food.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds human-like. It is polite and offers clear advice concisely. However, the phrasing could be slightly more varied and personalized to improve the naturalness further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is partially coherent as it addresses the reassurance that the person is \"alright,\" but it lacks an explanation of why this conclusion was reached. It also overlooks discussing the implications of the tests conducted, which would enhance coherence by aligning more closely with the user's narrative and concerns.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The model's response is incomplete because it does not address the user's specific question about what actions they should take. The reassurance \"nothing to worry\" is not sufficient; the response should include advice on lifestyle changes or consulting a specialist, as suggested by the true answer, to adequately answer the user's concerns.\n",
      "\n",
      "- Naturalness: 3.5  \n",
      "  The response is somewhat natural, as it attempts to address the user's concern in a concise manner. However, the phrasing is a bit abrupt and lacks the empathetic tone and detailed explanation that would make it sound more human-like and understanding. The introduction also feels a bit stilted due to the \"Hi, I am Chat Doctor\" line, affecting overall fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Sure, let's evaluate the model's response using the given metrics:\n",
      "\n",
      "- **Coherence: 3.5**\n",
      "  - The response somewhat aligns with the context provided but lacks precision in addressing the specific queries. The mention of \"angioplasty\" is technically correct, as it relates to stenting, but given the detailed nature of the true answer, the model doesn't fully delve into the context around arterial blockages, their implications, and additional factors.\n",
      "\n",
      "- **Completeness: 2.5**\n",
      "  - The model's response suggests treatment options but does not provide a thorough explanation of the situation's urgency or detail the differences between stenting and angioplasty in the context of the given arterial blockages. It also fails to mention other important considerations like cholesterol level, diabetes, or other factors as highlighted in the true answer, which are crucial for a comprehensive response.\n",
      "\n",
      "- **Naturalness: 4.0**\n",
      "  - The response is generally fluent and human-like. The language is polite and professional, appropriately fitting for a medical consultation context. However, the mention of specifics like being an \"infectious diseases specialist\" seems out of place given the context about heart disease.\n",
      "\n",
      "These ratings highlight the areas where the model's response could improve in specificity and context alignment to better meet genuine patient inquiries, particularly in medical applications.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the given input, here's the evaluation of the model's response:\n",
      "\n",
      "- **Coherence: 3.5**\n",
      "  - The model's response somewhat aligns with the input. It correctly identifies possible causes of penile pain during an erection, such as Peyronie's disease, which is also mentioned in the true answer. However, it overlooks some potential causes mentioned in the true answer, like frenulum issues and partial phimosis, which may affect coherence.\n",
      "  \n",
      "- **Completeness: 3.0**\n",
      "  - The model provides a detailed explanation of Peyronie's disease and some diagnostic steps, but it doesn't address other possible causes of the symptoms, which are included in the true answer. It mostly centers around Peyronie's disease without considering other common causes that may be relevant given the patient's context.\n",
      "  \n",
      "- **Naturalness: 4.5**\n",
      "  - The response is fluent and sounds professional and human-like. It follows a logical structure typical of medical consultations, with clear explanations and suggested next steps. It slightly leans towards being overly formal, but overall maintains a natural tone.\n",
      "\n",
      "In conclusion, while the model's response is professionally articulated, it could provide a more thorough coverage of other possible diagnoses for a more complete answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The response starts coherently by acknowledging the context of the query and suggesting common causes for the fever. However, it lacks precise alignment with the specific situation presented, especially regarding the suggestion that fever is related to the father's diabetes without further context. The repetition undermines coherence as it does not progress logically.\n",
      "\n",
      "- Completeness: 1.5  \n",
      "  Although the model suggests some diagnostic tests, it fails to provide specific guidance on the immediate question asked, which is about the choice of an antibiotic and an anti-diabetic treatment. The repetition also detracts from providing a complete answer, as the model does not conclude with a specific treatment plan or recommendation relevant to the query.\n",
      "\n",
      "- Naturalness: 1.0  \n",
      "  The response starts fluently but is severely affected by unnatural repetition of the same sentence multiple times, making it robotic and impractical for human-like interaction. The initial part of the response maintains some naturalness; however, the repeated text heavily impacts the overall fluency and human-like quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is generally coherent and aligns logically with the context provided in the input. It acknowledges the symptoms and suggests possible causes like anemia, hypoglycemia, thyroid issues, and vitamin deficiencies, which are reasonable given the symptoms described. However, the inclusion of \"anorexia\" seems somewhat unrelated to the symptoms mentioned, making coherence slightly less than perfect.\n",
      "\n",
      "- Completeness: 4.5\n",
      "\n",
      "The model's response is quite complete as it suggests a wide range of potential issues and advises getting specific tests (complete blood count, thyroid function test, vitamin B12, and vitamin D level). This advice is generally in line with the true answer. However, it misses the mention of diabetes as a potential concern, which is included in the true answer. \n",
      "\n",
      "- Naturalness: 3.0\n",
      "\n",
      "The response is relatively natural but is somewhat stilted and includes phrases like \"dairy have gone through your question,\" which seems like a typographical error. Additionally, \"Thanks for using Chat Doctor. Wish you a very good health\" feels less conversational and more like a scripted line, diminishing naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response is moderately coherent with the given input. It addresses some of the user's concerns, specifically about the elevated cholesterol and potential side effects of medication. However, it does not fully take into account the user's specific lifestyle details or familial history, and it misguides by suggesting that the user should avoid alcohol and smoking, although the user already stated they do not smoke.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The response partially answers the user's queries. While it suggests the use of statins and mentions side effects, it does not provide a potential reason for the high cholesterol given the user's lifestyle, nor does it fully address the hereditary aspect mentioned in the input. It lacks detailed lifestyle modification advice beyond general suggestions to exercise and avoid alcohol.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response is quite fluent and sounds human-like. It starts with a polite introduction and ends with a positive closing, making it sound natural. However, it references its role as an \"infectious diseases specialist,\" which does not match the context, affecting its credibility slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent as it aligns logically with the details provided in the input. It addresses the issues related to urinary retention and connects them to the patient's diabetes diagnosis, which is reasonable given the context.\n",
      "  \n",
      "- Completeness: 4.0  \n",
      "  The response provides a reasonable suggestion for the next step by advising the consultation of a urologist and exploring catheterization or medication options. However, it could have been improved by asking for more details or considering other potential causes beyond diabetes-related nerve damage.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response sounds fluent and human-like. It uses clear and professional medical language appropriate for a doctor-patient interaction. The suggestion \"Hope this helps\" adds a personable touch to the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "\n",
      "The model's response logically aligns with the context and question provided. It directly addresses the concern about whether the menstrual cycle affects the results of a glucose test, providing a clear explanation.\n",
      "\n",
      "- Completeness: 5.0\n",
      "\n",
      "The response sufficiently answers the question asked by explaining that the menstrual cycle does not affect the glucose test results. It also provides reassurance by highlighting the importance of fasting for accurate results.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is mostly fluent and human-like. The language used is clear and easy to understand. However, the initial statement about the AI model not having beliefs or opinions is somewhat unnatural and not directly relevant to the question. It would be more natural if the response started directly with the factual information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response partially aligns with the provided context, acknowledging the high WBC count and its potential link to inflammation caused by hypertension and diabetes. However, the response contains inaccuracies as high WBC count is not typically directly caused by these conditions.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  While the response addresses the high WBC count, it does not provide sufficient guidance or reasoning. The suggestion to consult a doctor is appropriate, but the explanation lacks depth and a more accurate medical evaluation or a suggestion to see a specialist, which is crucial in this scenario.\n",
      "\n",
      "- Naturalness: 2.0  \n",
      "  The response contains several grammatical errors and unnatural phrases (\"Hi, dairy have gone through your question\" and \"you have doubt then I will be happy to answer\"). These detract from the fluency and human-like quality of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The response addresses some aspects of the input context, such as the concern about sugar levels and the need for a urologist's evaluation. However, it does not explicitly compare or contrast the advice given by the two doctors or dive into the specifics of the conditions discussed (frenulum tear versus infections).\n",
      "  \n",
      "- Completeness: 2.5\n",
      "  - The response is lacking in depth regarding the main query: whether to undergo frenuloplasty or circumcision. It does not directly address or provide a recommendation between the two procedures, thus leaving the user's decision unresolved.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The response is phrased in a clear, respectful manner that suits a medical professional. It appears fluent and polite, but it somewhat lacks the depth expected from expert medical advice, which affects its overall naturalness in the given healthcare context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "The model's response logically aligns with the context. It correctly interprets the provided glucose levels as concerning and suggests lifestyle changes to mitigate progression to diabetes. However, it doesn't mention the inconsistency in test results or discuss the need for a more reliable diagnostic measurement, which is noted in the true answer.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "The response addresses some necessary measures to take considering the pre-diabetic range but lacks complete information on ensuring an accurate diagnosis. It fails to mention further diagnostic steps like HbA1c tests, which are crucial as per the true answer.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "The response is fluent and sounds natural. The advice is broken down into clear, actionable steps, which strengthens the human-like quality of the response. However, a slightly robotic tone could be interpreted from the repetitiveness of suggestions that are somewhat generic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response logically aligns with the context provided in the input, addressing the main query about getting pregnant through a direct and simple approach. It mentions the importance of having regular unprotected sex during the fertile period, which is a logical component of the conception process.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The model's response does not sufficiently cover the full range of factors involved in increasing the chances of getting pregnant. It omits crucial details surrounding pre-conception health checks, lifestyle changes, and potential medical consultations, especially for partners over certain ages or with health issues, as highlighted in the true answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is generally fluent and sounds human-like. It begins with a greeting similar to conversational style, and the sentence structure is simple and clear. However, it lacks detail that might make the response feel more personal and nuanced.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "   The model's response is coherent with the context provided by the user. It addresses the potential cause of the pain, aligning logically with the symptoms described. The suggestion to see a doctor is a coherent and logical step given the symptoms.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "   The response identifies a probable cause (prostate inflammation) and suggests seeing a doctor. However, it lacks detailed exploration of other possible causes or questions that could further clarify the issue, which are covered in the true answer. It doesn't investigate factors like previous medical history, recent symptoms, or additional causes such as psychological factors.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "   The language used by the model is generally fluent and human-like. It is professional and concise, though perhaps slightly abrupt, especially with the incomplete phrase \"Chat Doctor.\" A more natural response would not include uncontextualized closing lines.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It expresses sympathy and provides a detailed explanation of potential causes for miscarriages and suggests further investigations. However, it doesn't mention ruling out diabetes or pelvic inflammatory disease directly, which were included in the true answer.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response offers a comprehensive list of possible causes for miscarriages and advises several tests and evaluations to explore these possibilities. However, it omits diabetes testing and some other specific examinations mentioned in the true answer, which could be relevant as part of a complete response.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is mostly fluent and human-like. The introduction and closing statements are polite and appropriate, and the overall structure is consistent with how a human might communicate in such a setting. Some sentences could be slightly simplified to improve flow, but generally, it maintains a natural conversational tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is mostly coherent with the context, acknowledging the normal blood sugar levels and suggesting a balanced diet and exercise regimen. However, it fails to specifically address the context of vitamin D levels provided, which is crucial for coherence in this case.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  The model does not sufficiently answer the question about preventive measures. It misses the key detail regarding the vitamin D level, which is identified as borderline in the true answer and suggests a specific action (taking cholecalciferol granules). The response lacks this important preventive measure.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and human-like, with a polite and concise reply format. The language used is clear and easy to understand, though slightly generic in tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  - The model's response partially aligns with the context by suggesting the continuation of current medication and exercise, but it lacks specific mention of blood sugar management, which is central to the input context.\n",
      "\n",
      "- Completeness: 1.0  \n",
      "  - The response does not sufficiently answer the question, particularly regarding how to manage the high blood sugar levels. It repeats the advice to reduce fat intake, which is not directly related to the user's question or current urgent needs.\n",
      "\n",
      "- Naturalness: 1.0  \n",
      "  - The response is highly unnatural due to the excessive repetition of \"You should also reduce your fat intake.\" It makes the response incoherent and mechanically generated, lacking a smooth and human-like tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response correctly identifies the issue of high blood sugar levels following gestational diabetes, which aligns with the context provided. However, it makes an incorrect suggestion that gestational diabetes could occur again postpartum, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response addresses the concern by suggesting a physician consultation, it fails to provide actionable advice on managing high blood sugar, such as lifestyle changes and target sugar levels, as seen in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is generally fluent and human-like, with clear language and a comforting tone. Minor grammatical issues, like \"suggest you to get your blood sugar levels checked,\" slightly detract from the naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the context provided in the input. It gives a generic first-line management solution for foot pain and suggests seeing an orthopedic if symptoms persist. However, it doesn't directly address the possibility of plantar fasciitis, which is implied by the pattern of pain and the context.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model provides a basic answer about immediate pain relief and suggests further consultation if needed, but it lacks a detailed diagnosis or a comprehensive treatment plan compared to the true answer. The recommendation to get an MRI is appropriate, but it doesn't comment on possible conditions or provide specific medication advice.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The model's response is mostly fluent and human-like. It is polite and professional but sounds slightly mechanical in parts, particularly the closing sentence. Adjusting the tone towards a more conversational language could help improve naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response is somewhat coherent with the context since it suggests a likely cause for the pain based on the given information. However, it lacks depth in addressing potential other causes and doesn't connect well with the user's specific query details.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The response provides a potential cause for the symptom (muscular origin) but does not sufficiently investigate other possibilities or ask for further information that could help in diagnosing the issue more accurately. It lacks depth in exploring the user's medical background or potential underlying conditions.\n",
      "\n",
      "- Naturalness: 2.0\n",
      "  - The response does not sound fully natural or human-like, partly due to awkward phrasing such as \"Welcome to Chat Doctor.come\" and abrupt transitions like \"* Needs clinical examination for confirmation.\" It feels robotic and lacks a conversational tone that a human doctor might use.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0  \n",
      "  The model's response is a direct copy-paste of the input, rather than providing any new information or analysis. It does not address the question or explain the relationship between CRP and ESR levels, making it poorly aligned with the input context.\n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The response fails to provide any actual answer to the questions posed. It does not explain the possible reasons for the elevated CRP or the discrepancy between CRP and ESR levels, leaving the user's concerns unaddressed.\n",
      "\n",
      "- Naturalness: 1.0  \n",
      "  The response lacks fluency and human-like quality since it is an unaltered repetition of the input content. It does not provide a conversational or explanatory tone typical of human responses.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 점수:\n",
      "Coherence       3.515000\n",
      "Completeness    2.800000\n",
      "Naturalness     3.799000\n",
      "BLEURT          0.564366\n",
      "BERTScore_F1    0.606769\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# generation\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT 모델 로드\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 평가 함수\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 점수 추출\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT 점수 계산\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT 및 BERTScore 계산\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# 점수 정규화 함수\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "generation = df[df['task'] == 'generation']\n",
    "results = []\n",
    "\n",
    "for _, row in generation.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output_512'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # 기본값 설정\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' 컬럼이 존재하는지 확인 후 정규화 수행\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"평균 점수:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column BLEURT not found in DataFrame. Skipping normalization.\n",
      "Warning: Column BERTScore_F1 not found in DataFrame. Skipping normalization.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Coherence', 'Completeness', 'Naturalness', 'BLEURT', 'BERTScore_F1'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 147\u001b[0m\n\u001b[1;32m    144\u001b[0m evaluation_df \u001b[38;5;241m=\u001b[39m normalize_scores(evaluation_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEURT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m evaluation_df \u001b[38;5;241m=\u001b[39m normalize_scores(evaluation_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore_F1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m average_scores \u001b[38;5;241m=\u001b[39m evaluation_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoherence\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleteness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaturalness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEURT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore_F1\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m평균 점수:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(average_scores)\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Coherence', 'Completeness', 'Naturalness', 'BLEURT', 'BERTScore_F1'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# daily_diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT 모델 로드\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 평가 함수\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 점수 추출\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT 점수 계산\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT 및 BERTScore 계산\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# 점수 정규화 함수\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "daily = df[df['task'] == 'daily_diets']\n",
    "results = []\n",
    "\n",
    "for i, row in daily.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_outpu_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Evaluation {i+1} result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # 기본값 설정\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' 컬럼이 존재하는지 확인 후 정규화 수행\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"평균 점수:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 점수:\n",
      "Coherence       3.223577\n",
      "Completeness    2.880081\n",
      "Naturalness     3.008130\n",
      "BLEURT          0.488236\n",
      "BERTScore_F1    0.627131\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# alternative_diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT 모델 로드\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 평가 함수\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 점수 추출\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT 점수 계산\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT 및 BERTScore 계산\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# 점수 정규화 함수\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "alternative = df[df['task'] == 'alternative_diet']\n",
    "results = []\n",
    "\n",
    "for _, row in alternative.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Evaluation {i+1} result:\\n{evaluation}\")\n",
    "            \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # 기본값 설정\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' 컬럼이 존재하는지 확인 후 정규화 수행\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"평균 점수:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>servings</th>\n",
       "      <th>steps</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition_facts</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark</td>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark: Dive into ...</td>\n",
       "      <td>10 min</td>\n",
       "      <td>4 hr</td>\n",
       "      <td>6 Servings</td>\n",
       "      <td>['Cover a freezer-safe tray with parchment pap...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...</td>\n",
       "      <td>{'Servings': '6 Servings', 'Serving Size': '1 ...</td>\n",
       "      <td>[{'label': 'Plain Nonfat Greek yogurt', 'us_me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maple-Pumpkin Spice Oatmeal Cookies</td>\n",
       "      <td>Description not found</td>\n",
       "      <td>10 min</td>\n",
       "      <td>25 min</td>\n",
       "      <td>14 Servings</td>\n",
       "      <td>['Preheat the oven to 350 degrees F. Line two ...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...</td>\n",
       "      <td>{'Servings': '14 Servings', 'Serving Size': '1...</td>\n",
       "      <td>[{'label': 'old-fashioned rolled oats', 'us_me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0   Raspberry Swirl Frozen Yogurt Bark   \n",
       "1  Maple-Pumpkin Spice Oatmeal Cookies   \n",
       "\n",
       "                                         description prep_time cook_time  \\\n",
       "0  Raspberry Swirl Frozen Yogurt Bark: Dive into ...    10 min      4 hr   \n",
       "1                              Description not found    10 min    25 min   \n",
       "\n",
       "      servings                                              steps  \\\n",
       "0   6 Servings  ['Cover a freezer-safe tray with parchment pap...   \n",
       "1  14 Servings  ['Preheat the oven to 350 degrees F. Line two ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...   \n",
       "1  ['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...   \n",
       "\n",
       "                                     nutrition_facts  \\\n",
       "0  {'Servings': '6 Servings', 'Serving Size': '1 ...   \n",
       "1  {'Servings': '14 Servings', 'Serving Size': '1...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  [{'label': 'Plain Nonfat Greek yogurt', 'us_me...  \n",
       "1  [{'label': 'old-fashioned rolled oats', 'us_me...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfh = pd.read_csv(\"/data/jaesung/llm_for_diabetes/src/data/data2_daily_diets/diabetes_food_hub_new_nutri_facts.csv\")\n",
    "dfh.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [00:00<00:00, 22063.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results for Each Row ===\n",
      "Row Index: 661\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 662\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 663\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 664\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 665\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 666\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 667\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 668\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 669\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 670\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 671\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 672\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 673\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 674\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 675\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 676\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 677\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 678\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 679\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 680\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 681\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 682\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 683\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 684\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 685\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 686\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 687\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 688\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 689\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 690\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 691\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 692\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 693\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 694\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 695\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 696\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 697\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 698\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 699\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 700\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 701\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 702\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 703\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 704\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 705\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 706\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 707\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 708\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 709\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 710\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 711\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 712\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 713\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 714\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 715\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 716\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 717\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 718\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 719\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 720\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 721\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 722\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 723\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 724\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 725\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 726\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 727\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 728\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 729\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 730\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 731\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 732\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 733\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 734\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 735\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 736\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 737\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 738\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 739\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 740\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 741\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 742\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 743\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 744\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 745\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 746\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 747\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 748\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 749\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 750\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 751\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 752\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 753\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 754\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 755\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 756\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 757\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 758\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 759\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 760\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 761\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 762\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 763\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 764\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 765\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 766\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 767\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 768\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 769\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 770\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 771\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 772\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 773\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 774\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 775\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 776\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 777\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 778\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 779\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 780\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 781\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 782\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 783\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 784\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 785\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 786\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 787\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 788\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 789\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 790\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 791\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 792\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 793\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 794\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 795\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 796\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 797\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 798\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 799\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 800\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 801\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 802\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 803\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 804\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 805\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 806\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 807\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 808\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 809\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 810\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 811\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 812\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 813\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 814\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 815\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 816\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 817\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 818\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 819\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 820\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 821\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 822\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 823\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 824\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 825\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 826\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 827\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 828\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 829\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 830\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 831\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 832\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 833\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 834\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 835\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 836\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 837\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 838\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 839\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 840\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 841\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 842\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 843\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 844\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 845\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 846\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 847\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 848\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 849\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 850\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 851\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 852\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 853\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 854\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 855\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 856\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 857\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 858\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 859\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 860\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 861\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 862\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 863\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 864\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 865\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 866\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 867\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 868\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 869\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 870\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 871\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 872\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 873\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 874\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 875\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 876\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 877\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 878\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 879\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 880\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 881\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 882\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 883\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 884\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 885\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 886\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 887\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 888\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 889\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 890\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 891\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 892\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 893\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 894\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 895\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 896\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 897\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 898\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 899\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 900\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 901\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 902\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 903\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 904\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 905\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 906\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 907\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 908\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 909\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 910\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 911\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 912\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 913\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 914\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 915\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 916\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 917\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 918\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 919\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 920\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 921\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 922\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 923\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 924\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 925\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 926\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 927\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 928\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 929\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 930\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 931\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 932\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 933\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 934\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "=== Overall Averages ===\n",
      "Output Average Nutri-Score: None\n",
      "Model Output Average Nutri-Score: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# daily diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return all(key in data for key in ['Breakfast', 'Lunch', 'Dinner'])\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # 과일/채소 비율을 100g 기준으로 변환\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data) if isinstance(data, (int, float, str)) else default\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # 전체 무게 계산\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g 기준으로 성분 정규화\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_meal_nutri_score(meal_data, dfh):\n",
    "    meal_scores = {}\n",
    "\n",
    "    for meal, title in meal_data.items():\n",
    "        matched_row = find_most_similar_row(title, dfh)\n",
    "        if matched_row is None:\n",
    "            continue\n",
    "\n",
    "        nutrition_facts = matched_row['nutrition_facts']\n",
    "        ingredients = matched_row['ingredients']\n",
    "        score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "\n",
    "        if score is None:\n",
    "            print(f\"Warning: Nutri-Score calculation failed for meal '{meal}' with title '{title}'.\")\n",
    "            grade = \"N/A\"\n",
    "        else:\n",
    "            grade = get_nutri_score_grade(score)\n",
    "\n",
    "        meal_scores[meal] = {'score': score, 'grade': grade}\n",
    "\n",
    "    return meal_scores\n",
    "\n",
    "def calculate_scores_with_comparison(df, dfh):\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        output_scores = {}\n",
    "        model_scores = {}\n",
    "        if is_valid_meal_structure(row.get('output', '')):\n",
    "            output_data = json.loads(row['output'])\n",
    "            output_scores = calculate_meal_nutri_score(output_data, dfh)\n",
    "        if is_valid_meal_structure(row.get('model_output_512', '')):\n",
    "            model_data = json.loads(row['model_output_512'])\n",
    "            model_scores = calculate_meal_nutri_score(model_data, dfh)\n",
    "        results.append({'row_index': idx, 'output_scores': output_scores, 'model_scores': model_scores})\n",
    "    return results\n",
    "\n",
    "def calculate_average_scores(results):\n",
    "    \"\"\"\n",
    "    Calculate the average Nutri-Scores for outputs and model outputs.\n",
    "    \"\"\"\n",
    "    output_total_score = 0\n",
    "    model_total_score = 0\n",
    "    output_count = 0\n",
    "    model_count = 0\n",
    "\n",
    "    for result in results:\n",
    "        # Extract output scores\n",
    "        for meal, score_data in result['output_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                output_total_score += score_data['score']\n",
    "                output_count += 1\n",
    "\n",
    "        # Extract model scores\n",
    "        for meal, score_data in result['model_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                model_total_score += score_data['score']\n",
    "                model_count += 1\n",
    "\n",
    "    # Calculate averages\n",
    "    output_avg = output_total_score / output_count if output_count > 0 else None\n",
    "    model_avg = model_total_score / model_count if model_count > 0 else None\n",
    "\n",
    "    return output_avg, model_avg\n",
    "\n",
    "\n",
    "# 'daily_diets' task Nutri-Score calculation\n",
    "filtered_df = df[df['task'] == 'daily_diets']\n",
    "results = calculate_scores_with_comparison(filtered_df, dfh)\n",
    "\n",
    "# Calculate overall averages\n",
    "output_avg, model_avg = calculate_average_scores(results)\n",
    "\n",
    "# Print results\n",
    "print(\"=== Results for Each Row ===\")\n",
    "for result in results:\n",
    "    print(f\"Row Index: {result['row_index']}\")\n",
    "    print(f\"Output Scores: {result['output_scores']}\")\n",
    "    print(f\"Model Output Scores: {result['model_scores']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== Overall Averages ===\")\n",
    "print(f\"Output Average Nutri-Score: {output_avg}\")\n",
    "print(f\"Model Output Average Nutri-Score: {model_avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/246 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 158/246 [03:34<01:46,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error identifying fruits and vegetables: unterminated string literal (detected at line 1) (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 207/246 [04:37<00:40,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Total weight is zero. Skipping calculation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [05:27<00:00,  1.33s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 216\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# Execution\u001b[39;00m\n\u001b[1;32m    215\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malternative_diet\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 216\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_scores_with_comparison_no_meals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Cell \u001b[0;32mIn[32], line 207\u001b[0m, in \u001b[0;36mcalculate_scores_with_comparison_no_meals\u001b[0;34m(df, dfh)\u001b[0m\n\u001b[1;32m    200\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    201\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_index\u001b[39m\u001b[38;5;124m'\u001b[39m: idx,\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         })\n\u001b[1;32m    206\u001b[0m final_output_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(output_scores_list) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(output_scores_list) \u001b[38;5;28;01mif\u001b[39;00m output_scores_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m final_model_output_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_output_scores_list\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(model_output_scores_list) \u001b[38;5;28;01mif\u001b[39;00m model_output_scores_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Average Nutri-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_output_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Output Average Nutri-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_model_output_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# alternative diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return isinstance(data, dict)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # 과일/채소 비율을 100g 기준으로 변환\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # 전체 무게 계산\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g 기준으로 성분 정규화\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_scores_with_comparison_no_meals(df, dfh):\n",
    "    results = []\n",
    "    output_scores_list = []\n",
    "    model_output_scores_list = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            output_text = row.get('output', '')\n",
    "            if output_text:\n",
    "                matched_row = find_most_similar_row(output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    output_scores_list.append(output_score)\n",
    "                else:\n",
    "                    output_score = None\n",
    "\n",
    "            model_output_text = row.get('model_output_512', '')\n",
    "            if model_output_text:\n",
    "                matched_row = find_most_similar_row(model_output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    model_output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    model_output_scores_list.append(model_output_score)\n",
    "                else:\n",
    "                    model_output_score = None\n",
    "\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': output_score,\n",
    "                'model_output_score': model_output_score\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': None,\n",
    "                'model_output_score': None\n",
    "            })\n",
    "\n",
    "    final_output_avg = sum(output_scores_list) / len(output_scores_list) if output_scores_list else None\n",
    "    final_model_output_avg = sum(model_output_scores_list) / len(model_output_scores_list) if model_output_scores_list else None\n",
    "\n",
    "    print(f\"Output Average Nutri-Score: {final_output_avg}\")\n",
    "    print(f\"Model Output Average Nutri-Score: {final_model_output_avg}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Execution\n",
    "filtered_df = df[df['task'] == 'alternative_diet']\n",
    "results = calculate_scores_with_comparison_no_meals(filtered_df, dfh)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env_kernel",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
