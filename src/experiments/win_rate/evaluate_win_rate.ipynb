{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd681e6491a4e568e6ea0baaf0302b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import logout, notebook_login\n",
    "# logout()\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7897aef07a44b19207567d239ab60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/434 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae04feba872348948ac00c2a31aecf95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00004-1949301f12e51c42.parquet:   0%|          | 0.00/109M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4843005bdfa14b23aca2fc13fdb84323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00001-of-00004-a4cd9ef5eaa4f14a.parquet:   0%|          | 0.00/115M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622580c545614b01b53865e123485ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00002-of-00004-9d12bf5267a07ac2.parquet:   0%|          | 0.00/209M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3d6e8f728c4959866ce9ff9cbd219f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00003-of-00004-e49d8d0bebbbf654.parquet:   0%|          | 0.00/87.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fe714a9d344a4c84cc348b1ea9c107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1990915 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'response'],\n",
       "        num_rows: 1990915\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973c7ba58fc44b4a9b049a384194cee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1990915 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'response'],\n",
      "    num_rows: 1383\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sni = load_dataset(\"andersonbcdefg/supernatural-instructions-2m\")\n",
    "sni\n",
    "\n",
    "diabetes_keyword = ['diabetes']\n",
    "\n",
    "def extract_indices(dataset, keywords, columns=['prompt', 'response']):\n",
    "    indices = []\n",
    "    for i, row in enumerate(dataset):\n",
    "        for col in columns:\n",
    "            if any(keyword.lower() in str(row[col]).lower() for keyword in keywords):\n",
    "                indices.append(i)\n",
    "                break\n",
    "    return indices\n",
    "\n",
    "train_indices = extract_indices(sni['train'], diabetes_keyword)\n",
    "\n",
    "filtered_train = sni[\"train\"].filter(lambda row: any(keyword.lower() in str(row[\"prompt\"]).lower() for keyword in diabetes_keyword))\n",
    "\n",
    "print(filtered_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"In this task, you're given passages that contain mentions of names of people, places, or things. Some of these mentions refer to the same person, place, or thing. Your job is to write questions that evaluate one's understanding of such references. Good questions are expected to link pronouns (she, her, him, his, their, etc.) or other mentions to people, places, or things to which they may refer. Do not ask questions that can be answered correctly without understanding the paragraph or having multiple answers. Avoid questions that do not link phrases referring to the same entity. For each of your questions, the answer should be one or more phrases in the paragraph, and it should be unambiguous.\\nPassage: Oklahoma was the 21st-largest recipient of medical funding from the federal government in 2005, with health-related federal expenditures in the state totaling $75,801,364; immunizations, bioterrorism preparedness, and health education were the top three most funded medical items. Instances of major diseases are near the national average in Oklahoma, and the state ranks at or slightly above the rest of the country in percentage of people with asthma, diabetes, cancer, and hypertension.In 2000, Oklahoma ranked 45th in physicians per capita and slightly below the national average in nurses per capita, but was slightly over the national average in hospital beds per 100,000 people and above the national average in net growth of health services over a 12-year period. One of the worst states for percentage of insured people, nearly 25 percent of Oklahomans between the age of 18 and 64 did not have health insurance in 2005, the fifth-highest rate in the nation.Oklahomans are in the upper half of Americans in terms of obesity prevalence, and the state is the 5th most obese in the nation, with 30.3 percent of its population at or near obesity. Oklahoma ranked last among the 50 states in a 2007 study by the Commonwealth Fund on health care performance.The OU Medical Center, Oklahoma's largest collection of hospitals, is the only hospital in the state designated a Level I trauma center by the American College of Surgeons. OU Medical Center is on the grounds of the Oklahoma Health Center in Oklahoma City, the state's largest concentration of medical research facilities.The Cancer Treatment Centers of America at Southwestern Regional Medical Center in Tulsa is one of four such regional facilities nationwide, offering cancer treatment to the entire southwestern United States, and is one of the largest cancer treatment hospitals in the country. The largest osteopathic teaching facility in the nation, Oklahoma State University Medical Center at Tulsa, also rates as one of the largest facilities in the field of neuroscience.\\nOn June 26, 2018, Oklahoma made marijuana legal for medical purposes. This was a milestone for a state in the Bible Belt.\",\n",
       " 'response': 'In what city is the only Level 1 trauma center in Oklahoma located?'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Task Classification: 100%|██████████| 1383/1383 [35:58<00:00,  1.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task classification complete. Dataset updated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"OpenAI API Key is missing! Please set OPENAI_API in .env file.\")\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def classify_task(prompt, response):\n",
    "    system_prompt = \"\"\"You are an AI assistant that classifies NLP tasks based on the given prompt and response. \n",
    "    Given a prompt and response, return only the most relevant NLP task category from the following list without any extra text:\n",
    "    \n",
    "    Named Entity Recognition (NER)\n",
    "    Coreference Resolution\n",
    "    Question Answering (QA)\n",
    "    Summarization\n",
    "    Text Classification\n",
    "    Text Generation\n",
    "    Relation Extraction (RE)\n",
    "    Natural Language Inference (NLI)\n",
    "    Information Extraction (IE)\n",
    "    Commonsense Reasoning\n",
    "    Other\n",
    "\n",
    "    Ensure that identical or similar tasks receive exactly the same category name from the list.\n",
    "    If unsure, return 'Other' without explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    user_input = f\"Prompt: {prompt}\\nResponse: {response}\\nWhat is the most appropriate NLP task category?\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "df = pd.DataFrame(filtered_train)\n",
    "df[\"task_category\"] = \"Pending\"  \n",
    "\n",
    "with open(\"task_classification_log_file.txt\", \"a\") as log_file:\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Task Classification\"):\n",
    "        try:\n",
    "            result = classify_task(row[\"prompt\"], row[\"response\"])\n",
    "            df.at[index, \"task_category\"] = result\n",
    "\n",
    "            log_file.write(f\"Index {index}: {result}\\n\")\n",
    "            log_file.flush()  \n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {index}: {e}\")\n",
    "            df.at[index, \"task_category\"] = \"Error\"\n",
    "\n",
    "filtered_train = Dataset.from_pandas(df)\n",
    "print(\"Task classification complete. Dataset updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filtered_train\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_train' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf5459c5f4d46ed99741ddc328dd441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a08953ed092495ea217b913f447444a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset successfully uploaded to: https://huggingface.co/datasets/passionMan/diabetes_sni\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "from huggingface_hub import HfApi\n",
    "import os\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN_WRITE\") \n",
    "if not hf_token:\n",
    "    raise ValueError(\"Hugging Face API Token is missing! Please set HF_TOKEN in .env file.\")\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "dataset_dict = DatasetDict({\"test\": filtered_train})\n",
    "\n",
    "repo_name = \"passionMan/diabetes_sni\"  \n",
    "\n",
    "dataset_dict.push_to_hub(repo_name, token=hf_token)\n",
    "\n",
    "print(f\"✅ Dataset successfully uploaded to: https://huggingface.co/datasets/{repo_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "sni = load_dataset(\"passionMan/test_dataset2\")\n",
    "sni\n",
    "\n",
    "df = pd.DataFrame(sni['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'] = df['instruction'].str.strip() + \" \" + df['input'].str.strip()\n",
    "\n",
    "df = df.rename(columns={\n",
    "    'output': 'response',\n",
    "    'task': 'task_category'\n",
    "})\n",
    "\n",
    "df = df[['prompt', 'response', 'task_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>task_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You will be presented with a multiple-choice m...</td>\n",
       "      <td>A</td>\n",
       "      <td>qa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You will be presented with a multiple-choice m...</td>\n",
       "      <td>B</td>\n",
       "      <td>qa1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt response task_category\n",
       "0  You will be presented with a multiple-choice m...        A           qa1\n",
       "1  You will be presented with a multiple-choice m...        B           qa1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_category\n",
       "qa1              100\n",
       "qa2              100\n",
       "qa3              100\n",
       "nli              100\n",
       "ie               100\n",
       "re               100\n",
       "summarization    100\n",
       "generation       100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['task_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt response task_category\n",
      "0  You will be presented with a multiple-choice m...        B           qa1\n",
      "1  You will be presented with a multiple-choice m...        C           qa1\n",
      "2  You will be presented with a multiple-choice m...        A           qa1\n",
      "3  You will be presented with a multiple-choice m...        B           qa1\n",
      "4  You will be presented with a multiple-choice m...        A           qa1\n",
      "✅ 총 샘플 개수: 160\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "num_samples_main = 20  \n",
    "\n",
    "main_tasks = [\n",
    "    \"qa1\", \"qa2\", \"qa3\", \"nli\", \"ie\", \"re\", \"summarization\", \"generation\",\n",
    "]\n",
    "\n",
    "sampled_dfs = []\n",
    "\n",
    "for task in main_tasks:\n",
    "    sampled_dfs.append(df[df[\"task_category\"] == task].sample(n=num_samples_main, random_state=30, replace=False))\n",
    "\n",
    "df_sampled = pd.concat(sampled_dfs, ignore_index=True)\n",
    "\n",
    "print(df_sampled.head())\n",
    "print(f\"✅ 총 샘플 개수: {len(df_sampled)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>task_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You will be presented with a multiple-choice m...</td>\n",
       "      <td>B</td>\n",
       "      <td>qa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You will be presented with a multiple-choice m...</td>\n",
       "      <td>C</td>\n",
       "      <td>qa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You will be presented with a multiple-choice m...</td>\n",
       "      <td>A</td>\n",
       "      <td>qa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You will be presented with a multiple-choice m...</td>\n",
       "      <td>B</td>\n",
       "      <td>qa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You will be presented with a multiple-choice m...</td>\n",
       "      <td>A</td>\n",
       "      <td>qa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Generate a clear, professional, and medically ...</td>\n",
       "      <td>Hello. 1. Eat a healthy diet. Women are always...</td>\n",
       "      <td>generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Generate a clear, professional, and medically ...</td>\n",
       "      <td>Hi. It would be better if you would send me th...</td>\n",
       "      <td>generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Generate a clear, professional, and medically ...</td>\n",
       "      <td>Hi. Implant supported bridge is an extremely g...</td>\n",
       "      <td>generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Generate a clear, professional, and medically ...</td>\n",
       "      <td>Hi. There are three main types of AVF (arterio...</td>\n",
       "      <td>generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Generate a clear, professional, and medically ...</td>\n",
       "      <td>Hello, Welcome to the icliniq.com. The opinion...</td>\n",
       "      <td>generation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0    You will be presented with a multiple-choice m...   \n",
       "1    You will be presented with a multiple-choice m...   \n",
       "2    You will be presented with a multiple-choice m...   \n",
       "3    You will be presented with a multiple-choice m...   \n",
       "4    You will be presented with a multiple-choice m...   \n",
       "..                                                 ...   \n",
       "155  Generate a clear, professional, and medically ...   \n",
       "156  Generate a clear, professional, and medically ...   \n",
       "157  Generate a clear, professional, and medically ...   \n",
       "158  Generate a clear, professional, and medically ...   \n",
       "159  Generate a clear, professional, and medically ...   \n",
       "\n",
       "                                              response task_category  \n",
       "0                                                    B           qa1  \n",
       "1                                                    C           qa1  \n",
       "2                                                    A           qa1  \n",
       "3                                                    B           qa1  \n",
       "4                                                    A           qa1  \n",
       "..                                                 ...           ...  \n",
       "155  Hello. 1. Eat a healthy diet. Women are always...    generation  \n",
       "156  Hi. It would be better if you would send me th...    generation  \n",
       "157  Hi. Implant supported bridge is an extremely g...    generation  \n",
       "158  Hi. There are three main types of AVF (arterio...    generation  \n",
       "159  Hello, Welcome to the icliniq.com. The opinion...    generation  \n",
       "\n",
       "[160 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.12: Fast Llama patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA A100-PCIE-40GB. Max memory: 39.394 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e011e8fefaa451eb9318319f89c5bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.12 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n",
      "Generating Responses: 100%|██████████| 160/160 [13:24<00:00,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt response task_category  \\\n",
      "0  You will be presented with a multiple-choice m...        B           qa1   \n",
      "1  You will be presented with a multiple-choice m...        C           qa1   \n",
      "2  You will be presented with a multiple-choice m...        A           qa1   \n",
      "3  You will be presented with a multiple-choice m...        B           qa1   \n",
      "4  You will be presented with a multiple-choice m...        A           qa1   \n",
      "\n",
      "                                       llama3_output  \\\n",
      "0        C: Corticosteroid injections<|end_of_text|>   \n",
      "1                                   C<|end_of_text|>   \n",
      "2           A) It exists as a monomer<|end_of_text|>   \n",
      "3                                   B<|end_of_text|>   \n",
      "4  A) Obtain an ECG and troponin T levels<|end_of...   \n",
      "\n",
      "                                        gpt4o_output  \n",
      "0  The presentation in this case is consistent wi...  \n",
      "1                        C) Large-volume lumbar tap.  \n",
      "2                         B) It exists as a pentamer  \n",
      "3                            B) Reduced-calorie diet  \n",
      "4             A) Obtain an ECG and troponin T levels  \n",
      "✅ LLaMA3 & GPT-4o outputs successfully added and saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"OpenAI API Key is missing! Please set OPENAI_API_KEY in .env file.\")\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"/data/jaesung/llm_for_diabetes/src/train_model/train/llama3_8B/outputs/real_seed_IFD_rIFD14/checkpoint-474\",\n",
    "    max_seq_length = 1024,\n",
    "    dtype = None,\n",
    "    load_in_4bit = False,\n",
    ")\n",
    "\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token \n",
    "\n",
    "FastLanguageModel.for_inference(model) \n",
    "\n",
    "def generate_response(instruction_text, input_text, max_new_tokens=128):\n",
    "    try:\n",
    "\n",
    "        max_input_length = getattr(model.config, \"max_position_embeddings\", 1024)\n",
    "\n",
    "        input_tokens = tokenizer(\n",
    "            alpaca_prompt.format(instruction_text, input_text, \"\"),\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        input_length = input_tokens['input_ids'].shape[1]\n",
    "\n",
    "        if input_length > max_input_length:\n",
    "            print(f\"[WARNING] Truncating input from {input_length} to {max_input_length} tokens.\")\n",
    "            input_text = tokenizer.decode(input_tokens['input_ids'][0, :max_input_length], skip_special_tokens=True)\n",
    "\n",
    "        outputs = model.generate(\n",
    "            **tokenizer(alpaca_prompt.format(instruction_text, input_text, \"\"), return_tensors=\"pt\").to(\"cuda\"),\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            use_cache=True\n",
    "        )\n",
    "\n",
    "        decoded_outputs = tokenizer.batch_decode(outputs)\n",
    "        response_texts = [output.split(\"### Response:\\n\")[-1].strip() for output in decoded_outputs]\n",
    "        return response_texts[0].replace(\"<eot_id>\", \"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Exception in response generation: {str(e)}\")\n",
    "        return \"Error\"\n",
    "\n",
    "def get_gpt4o_response(prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Exception in GPT-4o response: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "df_sampled[\"llama3_output\"] = \"Pending\"\n",
    "df_sampled[\"gpt4o_output\"] = \"Pending\"\n",
    "\n",
    "for index, row in tqdm(df_sampled.iterrows(), total=len(df_sampled), desc=\"Generating Responses\"):\n",
    "    prompt = row[\"prompt\"]\n",
    "\n",
    "    df_sampled.at[index, \"llama3_output\"] = generate_response(instruction_text=\"\", input_text=prompt)\n",
    "\n",
    "    df_sampled.at[index, \"gpt4o_output\"] = get_gpt4o_response(prompt)\n",
    "\n",
    "    time.sleep(1) \n",
    "\n",
    "print(df_sampled.head())\n",
    "\n",
    "df_sampled.to_csv(\"df_sampled_with_outputs_bio3.csv\", index=False)\n",
    "\n",
    "print(\"✅ LLaMA3 & GPT-4o outputs successfully added and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>task_category</th>\n",
       "      <th>llama3_output</th>\n",
       "      <th>gpt4o_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You will be presented with a multiple-choice m...</td>\n",
       "      <td>B</td>\n",
       "      <td>qa1</td>\n",
       "      <td>C: Corticosteroid injections&lt;|end_of_text|&gt;</td>\n",
       "      <td>The presentation in this case is consistent wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You will be presented with a multiple-choice m...</td>\n",
       "      <td>C</td>\n",
       "      <td>qa1</td>\n",
       "      <td>C&lt;|end_of_text|&gt;</td>\n",
       "      <td>C) Large-volume lumbar tap.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt response task_category  \\\n",
       "0  You will be presented with a multiple-choice m...        B           qa1   \n",
       "1  You will be presented with a multiple-choice m...        C           qa1   \n",
       "\n",
       "                                 llama3_output  \\\n",
       "0  C: Corticosteroid injections<|end_of_text|>   \n",
       "1                             C<|end_of_text|>   \n",
       "\n",
       "                                        gpt4o_output  \n",
       "0  The presentation in this case is consistent wi...  \n",
       "1                        C) Large-volume lumbar tap.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating responses:   0%|          | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating responses: 100%|██████████| 160/160 [04:42<00:00,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"OpenAI API Key is missing! Please set OPENAI_API_KEY in .env file.\")\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def evaluate_response(prompt, llama3_output, gpt4o_output):\n",
    "    system_prompt = \"\"\"You are an AI evaluator that compares two model-generated responses to a given prompt.\n",
    "You will decide which response is better or if they are equally good.\n",
    "\n",
    "Format your response as:\n",
    "- \"Llama3\" if the Llama3 response is better\n",
    "- \"GPT-4o\" if the GPT-4o response is better\n",
    "- \"Tie\" if both are equally good\n",
    "\n",
    "Here is the comparison:\n",
    "\n",
    "Prompt: {prompt}\n",
    "Llama3 Response: {llama3_output}\n",
    "GPT-4o Response: {gpt4o_output}\n",
    "\n",
    "Which response is better?\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt.format(\n",
    "                prompt=prompt,\n",
    "                llama3_output=llama3_output,\n",
    "                gpt4o_output=gpt4o_output\n",
    "            )}]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Evaluation failed: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "df_sampled[\"evaluation\"] = \"Pending\"\n",
    "\n",
    "for index, row in tqdm(df_sampled.iterrows(), total=len(df_sampled), desc=\"Evaluating responses\"):\n",
    "    prompt = row[\"prompt\"]\n",
    "    llama3_output = row[\"llama3_output\"]\n",
    "    gpt4o_output = row[\"gpt4o_output\"]\n",
    "\n",
    "    df_sampled.at[index, \"evaluation\"] = evaluate_response(prompt, llama3_output, gpt4o_output)\n",
    "    time.sleep(1)  # API Rate Limit 방지\n",
    "\n",
    "task_win_counts = df_sampled.groupby(\"task_category\")[\"evaluation\"].value_counts().unstack().fillna(0)\n",
    "\n",
    "task_win_counts[\"Total Matches\"] = task_win_counts[\"Llama3\"] + task_win_counts[\"GPT-4o\"]\n",
    "task_win_counts[\"Llama3 Win-Rate\"] = task_win_counts[\"Llama3\"] / task_win_counts[\"Total Matches\"]\n",
    "\n",
    "df_sampled.to_csv(\"df_sampled_with_outputs_evaluations_bio3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>evaluation</th>\n",
       "      <th>\"GPT-4o\"</th>\n",
       "      <th>\"GPT-4o\" if the GPT-4o response is better</th>\n",
       "      <th>\"GPT-4o\" is better.</th>\n",
       "      <th>\"Llama3\"</th>\n",
       "      <th>\"Tie\"</th>\n",
       "      <th>\"Tie\" if both are equally good</th>\n",
       "      <th>- \"GPT-4o\" if the GPT-4o response is better</th>\n",
       "      <th>- \"Llama3\" if the Llama3 response is better</th>\n",
       "      <th>- \"Llama3\" if the Llama3 response is better\\n- \"GPT-4o\" if the GPT-4o response is better\\n- \"Tie\" if both are equally good</th>\n",
       "      <th>Based on the context provided, the results of the study indicate that vildagliptin does improve glycemic control in subjects with type 2 diabetes, as shown by the significant reductions in HbA1c, fasting glucose, and mean prandial glucose levels. The correct answer to the question is \"Yes.\" Therefore, the better response is:\\n\\n- \"GPT-4o\"</th>\n",
       "      <th>...</th>\n",
       "      <th>The GPT-4o response is better because it clearly answers the question with a definitive \"Yes,\" indicating that waist circumference does predict cardiometabolic and global Framingham risk among women screened during National Woman's Heart Day. The context provides evidence supporting this conclusion, describing correlations and statistical models linking waist circumference to these risks. The Llama3 response is insufficient as it provides both \"Yes\" and \"No,\" which is contradictory and does not directly address the prompt's requirement for a single answer. Therefore, GPT-4o's response is more appropriate and accurate.\\n\\n- \"GPT-4o\"</th>\n",
       "      <th>The better response is \"GPT-4o\" because the sentence provided in the prompt discusses a general drug-drug interaction (a combination of two drugs in a study) without specifying any particular effect or mechanism related to their interaction.</th>\n",
       "      <th>The better response is \"GPT-4o\". \\n\\nIn a case of previous hepatitis B infection, the immunoglobulin subtype that typically binds to the core antigen is IgM, which exists as a pentamer.</th>\n",
       "      <th>The context provided clearly states that none of the polymorphisms in VAMP4, alone or in combination, were found to be associated with type 2 diabetes (T2DM) or impaired glucose homeostasis (IGH) in the studied Amish population. The description of the study results specifically mentions that these genetic variations were not associated with T2DM or significant differences in diabetes-related traits. Therefore, the correct answer to the question is \"No\", as stated by GPT-4o.\\n\\nGPT-4o</th>\n",
       "      <th>The correct classification for the relationship between the sentences \"Polyneuropathy manifested lack of balance\" and \"the patient has diabetes\" is \"Neutral\". While polyneuropathy can be a complication of diabetes, there is no direct logical entailment between lacking balance due to polyneuropathy and having diabetes without additional context. Therefore, the response should be \"Neutral\". \\n\\nGPT-4o's response is correct, classifying the relationship as \"Neutral\". \\n\\nThus, the better response is from \"GPT-4o\".</th>\n",
       "      <th>The correct relationship between the sentences \"sentence1\" and \"sentence2\" is \"Neutral\". There is no information in sentence1 that directly addresses whether the patient is diabetic or not, thus there is no logical implication or contradiction concerning diabetes. \\n\\n- \"Llama3\" incorrectly identifies the relationship as \"Contradiction\".\\n- \"GPT-4o\" correctly identifies the relationship as \"Neutral\".\\n\\nTherefore, the better response is \"GPT-4o\".</th>\n",
       "      <th>The prompt asks for a simple \"Yes\" or \"No\" answer based on the given context regarding the effects of tungstate on diabetic female rats' reproductive function. The context provided shows that tungstate treatment partially recovered libido and increased fertility in diabetic rats, also improving relevant hormone levels and receptor expression. This indicates an improvement in reproductive function.\\n\\nTherefore, the correct answer to the question \"Does tungstate administration improve the sexual and reproductive function in female rats with streptozotocin-induced diabetes?\" based on the context should be \"Yes.\"\\n\\nThus, the better response is:\\n\\n- \"GPT-4o\"</th>\n",
       "      <th>Tie</th>\n",
       "      <th>Total Matches</th>\n",
       "      <th>Llama3 Win-Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>generation</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ie</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nli</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summarization</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "evaluation     \"GPT-4o\"  \"GPT-4o\" if the GPT-4o response is better  \\\n",
       "task_category                                                        \n",
       "generation          2.0                                        0.0   \n",
       "ie                 12.0                                        0.0   \n",
       "nli                14.0                                        0.0   \n",
       "qa1                 0.0                                        0.0   \n",
       "qa2                 6.0                                        0.0   \n",
       "qa3                 4.0                                        1.0   \n",
       "re                  2.0                                        0.0   \n",
       "summarization      12.0                                        0.0   \n",
       "\n",
       "evaluation     \"GPT-4o\" is better.  \"Llama3\"  \"Tie\"  \\\n",
       "task_category                                         \n",
       "generation                     1.0       0.0    0.0   \n",
       "ie                             0.0       1.0    3.0   \n",
       "nli                            0.0       0.0    0.0   \n",
       "qa1                            0.0       0.0    2.0   \n",
       "qa2                            0.0       0.0    2.0   \n",
       "qa3                            0.0       0.0    1.0   \n",
       "re                             0.0       0.0    0.0   \n",
       "summarization                  0.0       0.0    0.0   \n",
       "\n",
       "evaluation     \"Tie\" if both are equally good  \\\n",
       "task_category                                   \n",
       "generation                                0.0   \n",
       "ie                                        0.0   \n",
       "nli                                       1.0   \n",
       "qa1                                       0.0   \n",
       "qa2                                       0.0   \n",
       "qa3                                       0.0   \n",
       "re                                        0.0   \n",
       "summarization                             0.0   \n",
       "\n",
       "evaluation     - \"GPT-4o\" if the GPT-4o response is better  \\\n",
       "task_category                                                \n",
       "generation                                             0.0   \n",
       "ie                                                     0.0   \n",
       "nli                                                    0.0   \n",
       "qa1                                                    1.0   \n",
       "qa2                                                    0.0   \n",
       "qa3                                                    0.0   \n",
       "re                                                     0.0   \n",
       "summarization                                          0.0   \n",
       "\n",
       "evaluation     - \"Llama3\" if the Llama3 response is better  \\\n",
       "task_category                                                \n",
       "generation                                             0.0   \n",
       "ie                                                     1.0   \n",
       "nli                                                    0.0   \n",
       "qa1                                                    0.0   \n",
       "qa2                                                    0.0   \n",
       "qa3                                                    2.0   \n",
       "re                                                     0.0   \n",
       "summarization                                          0.0   \n",
       "\n",
       "evaluation     - \"Llama3\" if the Llama3 response is better\\n- \"GPT-4o\" if the GPT-4o response is better\\n- \"Tie\" if both are equally good  \\\n",
       "task_category                                                                                                                               \n",
       "generation                                                   0.0                                                                            \n",
       "ie                                                           1.0                                                                            \n",
       "nli                                                          0.0                                                                            \n",
       "qa1                                                          0.0                                                                            \n",
       "qa2                                                          0.0                                                                            \n",
       "qa3                                                          0.0                                                                            \n",
       "re                                                           0.0                                                                            \n",
       "summarization                                                0.0                                                                            \n",
       "\n",
       "evaluation     Based on the context provided, the results of the study indicate that vildagliptin does improve glycemic control in subjects with type 2 diabetes, as shown by the significant reductions in HbA1c, fasting glucose, and mean prandial glucose levels. The correct answer to the question is \"Yes.\" Therefore, the better response is:\\n\\n- \"GPT-4o\"  \\\n",
       "task_category                                                                                                                                                                                                                                                                                                                                                         \n",
       "generation                                                   0.0                                                                                                                                                                                                                                                                                                      \n",
       "ie                                                           0.0                                                                                                                                                                                                                                                                                                      \n",
       "nli                                                          0.0                                                                                                                                                                                                                                                                                                      \n",
       "qa1                                                          0.0                                                                                                                                                                                                                                                                                                      \n",
       "qa2                                                          0.0                                                                                                                                                                                                                                                                                                      \n",
       "qa3                                                          1.0                                                                                                                                                                                                                                                                                                      \n",
       "re                                                           0.0                                                                                                                                                                                                                                                                                                      \n",
       "summarization                                                0.0                                                                                                                                                                                                                                                                                                      \n",
       "\n",
       "evaluation     ...  \\\n",
       "task_category  ...   \n",
       "generation     ...   \n",
       "ie             ...   \n",
       "nli            ...   \n",
       "qa1            ...   \n",
       "qa2            ...   \n",
       "qa3            ...   \n",
       "re             ...   \n",
       "summarization  ...   \n",
       "\n",
       "evaluation     The GPT-4o response is better because it clearly answers the question with a definitive \"Yes,\" indicating that waist circumference does predict cardiometabolic and global Framingham risk among women screened during National Woman's Heart Day. The context provides evidence supporting this conclusion, describing correlations and statistical models linking waist circumference to these risks. The Llama3 response is insufficient as it provides both \"Yes\" and \"No,\" which is contradictory and does not directly address the prompt's requirement for a single answer. Therefore, GPT-4o's response is more appropriate and accurate.\\n\\n- \"GPT-4o\"  \\\n",
       "task_category                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "generation                                                   0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "ie                                                           0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "nli                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "qa1                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "qa2                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "qa3                                                          1.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "re                                                           0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "summarization                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "\n",
       "evaluation     The better response is \"GPT-4o\" because the sentence provided in the prompt discusses a general drug-drug interaction (a combination of two drugs in a study) without specifying any particular effect or mechanism related to their interaction.  \\\n",
       "task_category                                                                                                                                                                                                                                                      \n",
       "generation                                                   0.0                                                                                                                                                                                                   \n",
       "ie                                                           0.0                                                                                                                                                                                                   \n",
       "nli                                                          0.0                                                                                                                                                                                                   \n",
       "qa1                                                          0.0                                                                                                                                                                                                   \n",
       "qa2                                                          0.0                                                                                                                                                                                                   \n",
       "qa3                                                          0.0                                                                                                                                                                                                   \n",
       "re                                                           1.0                                                                                                                                                                                                   \n",
       "summarization                                                0.0                                                                                                                                                                                                   \n",
       "\n",
       "evaluation     The better response is \"GPT-4o\". \\n\\nIn a case of previous hepatitis B infection, the immunoglobulin subtype that typically binds to the core antigen is IgM, which exists as a pentamer.  \\\n",
       "task_category                                                                                                                                                                                              \n",
       "generation                                                   0.0                                                                                                                                           \n",
       "ie                                                           0.0                                                                                                                                           \n",
       "nli                                                          0.0                                                                                                                                           \n",
       "qa1                                                          1.0                                                                                                                                           \n",
       "qa2                                                          0.0                                                                                                                                           \n",
       "qa3                                                          0.0                                                                                                                                           \n",
       "re                                                           0.0                                                                                                                                           \n",
       "summarization                                                0.0                                                                                                                                           \n",
       "\n",
       "evaluation     The context provided clearly states that none of the polymorphisms in VAMP4, alone or in combination, were found to be associated with type 2 diabetes (T2DM) or impaired glucose homeostasis (IGH) in the studied Amish population. The description of the study results specifically mentions that these genetic variations were not associated with T2DM or significant differences in diabetes-related traits. Therefore, the correct answer to the question is \"No\", as stated by GPT-4o.\\n\\nGPT-4o  \\\n",
       "task_category                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "generation                                                   0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "ie                                                           0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "nli                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "qa1                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "qa2                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "qa3                                                          1.0                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "re                                                           0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "summarization                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "\n",
       "evaluation     The correct classification for the relationship between the sentences \"Polyneuropathy manifested lack of balance\" and \"the patient has diabetes\" is \"Neutral\". While polyneuropathy can be a complication of diabetes, there is no direct logical entailment between lacking balance due to polyneuropathy and having diabetes without additional context. Therefore, the response should be \"Neutral\". \\n\\nGPT-4o's response is correct, classifying the relationship as \"Neutral\". \\n\\nThus, the better response is from \"GPT-4o\".  \\\n",
       "task_category                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "generation                                                   0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "ie                                                           0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "nli                                                          1.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "qa1                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "qa2                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "qa3                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "re                                                           0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "summarization                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "\n",
       "evaluation     The correct relationship between the sentences \"sentence1\" and \"sentence2\" is \"Neutral\". There is no information in sentence1 that directly addresses whether the patient is diabetic or not, thus there is no logical implication or contradiction concerning diabetes. \\n\\n- \"Llama3\" incorrectly identifies the relationship as \"Contradiction\".\\n- \"GPT-4o\" correctly identifies the relationship as \"Neutral\".\\n\\nTherefore, the better response is \"GPT-4o\".  \\\n",
       "task_category                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "generation                                                   0.0                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "ie                                                           0.0                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "nli                                                          1.0                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "qa1                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "qa2                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "qa3                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "re                                                           0.0                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "summarization                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "\n",
       "evaluation     The prompt asks for a simple \"Yes\" or \"No\" answer based on the given context regarding the effects of tungstate on diabetic female rats' reproductive function. The context provided shows that tungstate treatment partially recovered libido and increased fertility in diabetic rats, also improving relevant hormone levels and receptor expression. This indicates an improvement in reproductive function.\\n\\nTherefore, the correct answer to the question \"Does tungstate administration improve the sexual and reproductive function in female rats with streptozotocin-induced diabetes?\" based on the context should be \"Yes.\"\\n\\nThus, the better response is:\\n\\n- \"GPT-4o\"  \\\n",
       "task_category                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "generation                                                   0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "ie                                                           0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "nli                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "qa1                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "qa2                                                          0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "qa3                                                          1.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "re                                                           0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "summarization                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "\n",
       "evaluation      Tie  Total Matches  Llama3 Win-Rate  \n",
       "task_category                                        \n",
       "generation      0.0           17.0         0.000000  \n",
       "ie              0.0            2.0         0.000000  \n",
       "nli             1.0            2.0         0.000000  \n",
       "qa1             7.0            9.0         0.000000  \n",
       "qa2             2.0           10.0         0.000000  \n",
       "qa3             5.0            3.0         0.333333  \n",
       "re             12.0            5.0         0.000000  \n",
       "summarization   0.0            8.0         0.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_win_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env_kernel",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
