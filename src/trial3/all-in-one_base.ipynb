{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505ab531393a4062a66a86352a6ff2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import logout, notebook_login\n",
    "# logout()\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac26ef9b0e3d493194d7f6dfa26fc326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/352 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0567f5571e144fba24a23a2c6aca68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/5.49M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e89f453b2744c1bceba440d48a376b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 3351\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "base = load_dataset(\"passionMan/dataset_base\")\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 03-06 09:29:41 __init__.py:190] Automatically detected platform cuda.\n",
      "==((====))==  Unsloth 2025.2.12: Fast Llama patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA A100-PCIE-40GB. Max memory: 39.394 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
    "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
    "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Not an error, but Unsloth cannot patch O projection layer with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Unsloth 2025.2.12 patched 32 layers with 32 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e99c54672b1473799f28a2a9a0f2b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"passionMan/dataset_base\", split = \"train\")\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d1ce760ccb4c0d997ca165a311a5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset (num_proc=8):   0%|          | 0/3351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cf51d58c6c49d890ece6508a981090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset (num_proc=8):   0%|          | 0/3351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e6a3036c524d4bb935947fae4ffb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset (num_proc=8):   0%|          | 0/3351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 8,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 32,\n",
    "        gradient_accumulation_steps = 1,\n",
    "        warmup_steps = 30, # 50\n",
    "        num_train_epochs = 3, # Set this for 1 full training run.\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 50,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs/model_base\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "        save_steps = 100,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 3,351 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 32 | Gradient Accumulation steps = 1\n",
      "\\        /    Total batch size = 32 | Total steps = 315\n",
      " \"-____-\"     Number of trainable parameters = 9,437,184\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [315/315 1:54:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.662600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.601900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.558200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.568300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/240] Sample processed in 0.67s, ETA: 2.69 min\n",
      "[2/240] Sample processed in 0.30s, ETA: 1.94 min\n",
      "[3/240] Sample processed in 0.31s, ETA: 1.69 min\n",
      "[4/240] Sample processed in 0.48s, ETA: 1.74 min\n",
      "[5/240] Sample processed in 0.60s, ETA: 1.86 min\n",
      "[6/240] Sample processed in 0.15s, ETA: 1.64 min\n",
      "[7/240] Sample processed in 0.39s, ETA: 1.61 min\n",
      "[8/240] Sample processed in 0.73s, ETA: 1.76 min\n",
      "[9/240] Sample processed in 0.14s, ETA: 1.62 min\n",
      "[10/240] Sample processed in 0.30s, ETA: 1.56 min\n",
      "[11/240] Sample processed in 0.13s, ETA: 1.46 min\n",
      "[12/240] Sample processed in 0.44s, ETA: 1.47 min\n",
      "[13/240] Sample processed in 0.60s, ETA: 1.53 min\n",
      "[14/240] Sample processed in 0.71s, ETA: 1.61 min\n",
      "[15/240] Sample processed in 0.61s, ETA: 1.64 min\n",
      "[16/240] Sample processed in 0.39s, ETA: 1.63 min\n",
      "[17/240] Sample processed in 0.39s, ETA: 1.61 min\n",
      "[18/240] Sample processed in 0.45s, ETA: 1.60 min\n",
      "[19/240] Sample processed in 0.30s, ETA: 1.57 min\n",
      "[20/240] Sample processed in 0.26s, ETA: 1.53 min\n",
      "[21/240] Sample processed in 0.49s, ETA: 1.54 min\n",
      "[22/240] Sample processed in 0.47s, ETA: 1.54 min\n",
      "[23/240] Sample processed in 0.49s, ETA: 1.54 min\n",
      "[24/240] Sample processed in 0.26s, ETA: 1.51 min\n",
      "[25/240] Sample processed in 0.39s, ETA: 1.50 min\n",
      "[26/240] Sample processed in 0.30s, ETA: 1.48 min\n",
      "[27/240] Sample processed in 0.13s, ETA: 1.43 min\n",
      "[28/240] Sample processed in 0.39s, ETA: 1.42 min\n",
      "[29/240] Sample processed in 1.13s, ETA: 1.50 min\n",
      "[30/240] Sample processed in 0.14s, ETA: 1.46 min\n",
      "[31/240] Sample processed in 0.40s, ETA: 1.45 min\n",
      "[32/240] Sample processed in 0.14s, ETA: 1.42 min\n",
      "[33/240] Sample processed in 0.39s, ETA: 1.41 min\n",
      "[34/240] Sample processed in 0.13s, ETA: 1.37 min\n",
      "[35/240] Sample processed in 1.68s, ETA: 1.49 min\n",
      "[36/240] Sample processed in 0.35s, ETA: 1.48 min\n",
      "[37/240] Sample processed in 0.13s, ETA: 1.44 min\n",
      "[38/240] Sample processed in 0.39s, ETA: 1.43 min\n",
      "[39/240] Sample processed in 0.48s, ETA: 1.43 min\n",
      "[40/240] Sample processed in 0.44s, ETA: 1.42 min\n",
      "[41/240] Sample processed in 0.39s, ETA: 1.41 min\n",
      "[42/240] Sample processed in 0.57s, ETA: 1.42 min\n",
      "[43/240] Sample processed in 0.39s, ETA: 1.41 min\n",
      "[44/240] Sample processed in 0.13s, ETA: 1.38 min\n",
      "[45/240] Sample processed in 0.39s, ETA: 1.37 min\n",
      "[46/240] Sample processed in 0.13s, ETA: 1.34 min\n",
      "[47/240] Sample processed in 0.73s, ETA: 1.35 min\n",
      "[48/240] Sample processed in 0.47s, ETA: 1.35 min\n",
      "[49/240] Sample processed in 0.35s, ETA: 1.34 min\n",
      "[50/240] Sample processed in 0.39s, ETA: 1.33 min\n",
      "[51/240] Sample processed in 0.96s, ETA: 1.36 min\n",
      "[52/240] Sample processed in 0.91s, ETA: 1.38 min\n",
      "[53/240] Sample processed in 0.26s, ETA: 1.36 min\n",
      "[54/240] Sample processed in 0.13s, ETA: 1.34 min\n",
      "[55/240] Sample processed in 0.52s, ETA: 1.33 min\n",
      "[56/240] Sample processed in 0.13s, ETA: 1.31 min\n",
      "[57/240] Sample processed in 0.39s, ETA: 1.30 min\n",
      "[58/240] Sample processed in 0.30s, ETA: 1.29 min\n",
      "[59/240] Sample processed in 0.26s, ETA: 1.27 min\n",
      "[60/240] Sample processed in 0.35s, ETA: 1.26 min\n",
      "[61/240] Sample processed in 0.14s, ETA: 1.24 min\n",
      "[62/240] Sample processed in 0.15s, ETA: 1.22 min\n",
      "[63/240] Sample processed in 0.13s, ETA: 1.20 min\n",
      "[64/240] Sample processed in 0.14s, ETA: 1.18 min\n",
      "[65/240] Sample processed in 0.13s, ETA: 1.16 min\n",
      "[66/240] Sample processed in 0.13s, ETA: 1.14 min\n",
      "[67/240] Sample processed in 0.13s, ETA: 1.13 min\n",
      "[68/240] Sample processed in 0.14s, ETA: 1.11 min\n",
      "[69/240] Sample processed in 0.13s, ETA: 1.09 min\n",
      "[70/240] Sample processed in 0.13s, ETA: 1.07 min\n",
      "[71/240] Sample processed in 0.13s, ETA: 1.06 min\n",
      "[72/240] Sample processed in 0.14s, ETA: 1.04 min\n",
      "[73/240] Sample processed in 0.13s, ETA: 1.03 min\n",
      "[74/240] Sample processed in 0.13s, ETA: 1.01 min\n",
      "[75/240] Sample processed in 0.14s, ETA: 1.00 min\n",
      "[76/240] Sample processed in 0.13s, ETA: 0.98 min\n",
      "[77/240] Sample processed in 0.19s, ETA: 0.97 min\n",
      "[78/240] Sample processed in 0.14s, ETA: 0.96 min\n",
      "[79/240] Sample processed in 0.14s, ETA: 0.94 min\n",
      "[80/240] Sample processed in 0.15s, ETA: 0.93 min\n",
      "[81/240] Sample processed in 0.14s, ETA: 0.92 min\n",
      "[82/240] Sample processed in 0.15s, ETA: 0.91 min\n",
      "[83/240] Sample processed in 0.13s, ETA: 0.89 min\n",
      "[84/240] Sample processed in 0.13s, ETA: 0.88 min\n",
      "[85/240] Sample processed in 0.19s, ETA: 0.87 min\n",
      "[86/240] Sample processed in 0.15s, ETA: 0.86 min\n",
      "[87/240] Sample processed in 0.15s, ETA: 0.85 min\n",
      "[88/240] Sample processed in 0.14s, ETA: 0.84 min\n",
      "[89/240] Sample processed in 0.14s, ETA: 0.83 min\n",
      "[90/240] Sample processed in 0.13s, ETA: 0.82 min\n",
      "[91/240] Sample processed in 0.22s, ETA: 0.81 min\n",
      "[92/240] Sample processed in 0.22s, ETA: 0.80 min\n",
      "[93/240] Sample processed in 0.21s, ETA: 0.79 min\n",
      "[94/240] Sample processed in 0.21s, ETA: 0.78 min\n",
      "[95/240] Sample processed in 0.22s, ETA: 0.78 min\n",
      "[96/240] Sample processed in 0.22s, ETA: 0.77 min\n",
      "[97/240] Sample processed in 0.13s, ETA: 0.76 min\n",
      "[98/240] Sample processed in 0.22s, ETA: 0.75 min\n",
      "[99/240] Sample processed in 0.22s, ETA: 0.74 min\n",
      "[100/240] Sample processed in 0.22s, ETA: 0.73 min\n",
      "[101/240] Sample processed in 0.22s, ETA: 0.73 min\n",
      "[102/240] Sample processed in 0.21s, ETA: 0.72 min\n",
      "[103/240] Sample processed in 0.22s, ETA: 0.71 min\n",
      "[104/240] Sample processed in 0.22s, ETA: 0.71 min\n",
      "[105/240] Sample processed in 0.13s, ETA: 0.70 min\n",
      "[106/240] Sample processed in 0.22s, ETA: 0.69 min\n",
      "[107/240] Sample processed in 0.22s, ETA: 0.68 min\n",
      "[108/240] Sample processed in 0.13s, ETA: 0.67 min\n",
      "[109/240] Sample processed in 0.22s, ETA: 0.67 min\n",
      "[110/240] Sample processed in 0.22s, ETA: 0.66 min\n",
      "[111/240] Sample processed in 0.21s, ETA: 0.65 min\n",
      "[112/240] Sample processed in 0.22s, ETA: 0.65 min\n",
      "[113/240] Sample processed in 0.22s, ETA: 0.64 min\n",
      "[114/240] Sample processed in 0.21s, ETA: 0.63 min\n",
      "[115/240] Sample processed in 0.22s, ETA: 0.63 min\n",
      "[116/240] Sample processed in 0.22s, ETA: 0.62 min\n",
      "[117/240] Sample processed in 0.21s, ETA: 0.61 min\n",
      "[118/240] Sample processed in 0.13s, ETA: 0.60 min\n",
      "[119/240] Sample processed in 0.21s, ETA: 0.60 min\n",
      "[120/240] Sample processed in 0.22s, ETA: 0.59 min\n",
      "[121/240] Sample processed in 4.18s, ETA: 0.65 min\n",
      "[122/240] Sample processed in 2.87s, ETA: 0.69 min\n",
      "[123/240] Sample processed in 4.38s, ETA: 0.74 min\n",
      "[124/240] Sample processed in 5.60s, ETA: 0.82 min\n",
      "[125/240] Sample processed in 5.61s, ETA: 0.89 min\n",
      "[126/240] Sample processed in 5.58s, ETA: 0.96 min\n",
      "[127/240] Sample processed in 0.61s, ETA: 0.95 min\n",
      "[128/240] Sample processed in 5.58s, ETA: 1.02 min\n",
      "[129/240] Sample processed in 5.60s, ETA: 1.08 min\n",
      "[130/240] Sample processed in 5.59s, ETA: 1.14 min\n",
      "[131/240] Sample processed in 4.98s, ETA: 1.19 min\n",
      "[132/240] Sample processed in 5.61s, ETA: 1.25 min\n",
      "[133/240] Sample processed in 4.34s, ETA: 1.29 min\n",
      "[134/240] Sample processed in 2.75s, ETA: 1.30 min\n",
      "[135/240] Sample processed in 4.43s, ETA: 1.34 min\n",
      "[136/240] Sample processed in 2.09s, ETA: 1.34 min\n",
      "[137/240] Sample processed in 2.54s, ETA: 1.35 min\n",
      "[138/240] Sample processed in 5.64s, ETA: 1.40 min\n",
      "[139/240] Sample processed in 5.68s, ETA: 1.44 min\n",
      "[140/240] Sample processed in 5.68s, ETA: 1.49 min\n",
      "[141/240] Sample processed in 5.66s, ETA: 1.53 min\n",
      "[142/240] Sample processed in 5.66s, ETA: 1.57 min\n",
      "[143/240] Sample processed in 5.66s, ETA: 1.60 min\n",
      "[144/240] Sample processed in 0.92s, ETA: 1.59 min\n",
      "[145/240] Sample processed in 5.65s, ETA: 1.62 min\n",
      "[146/240] Sample processed in 0.74s, ETA: 1.60 min\n",
      "[147/240] Sample processed in 5.64s, ETA: 1.63 min\n",
      "[148/240] Sample processed in 5.66s, ETA: 1.66 min\n",
      "[149/240] Sample processed in 5.66s, ETA: 1.69 min\n",
      "[150/240] Sample processed in 1.98s, ETA: 1.68 min\n",
      "[151/240] Sample processed in 0.22s, ETA: 1.65 min\n",
      "[152/240] Sample processed in 0.22s, ETA: 1.63 min\n",
      "[153/240] Sample processed in 0.22s, ETA: 1.60 min\n",
      "[154/240] Sample processed in 0.22s, ETA: 1.57 min\n",
      "[155/240] Sample processed in 0.26s, ETA: 1.55 min\n",
      "[156/240] Sample processed in 0.22s, ETA: 1.52 min\n",
      "[157/240] Sample processed in 0.22s, ETA: 1.50 min\n",
      "[158/240] Sample processed in 0.22s, ETA: 1.47 min\n",
      "[159/240] Sample processed in 0.22s, ETA: 1.44 min\n",
      "[160/240] Sample processed in 0.26s, ETA: 1.42 min\n",
      "[161/240] Sample processed in 0.22s, ETA: 1.40 min\n",
      "[162/240] Sample processed in 0.22s, ETA: 1.37 min\n",
      "[163/240] Sample processed in 0.22s, ETA: 1.35 min\n",
      "[164/240] Sample processed in 0.22s, ETA: 1.32 min\n",
      "[165/240] Sample processed in 0.22s, ETA: 1.30 min\n",
      "[166/240] Sample processed in 0.22s, ETA: 1.28 min\n",
      "[167/240] Sample processed in 0.22s, ETA: 1.25 min\n",
      "[168/240] Sample processed in 0.22s, ETA: 1.23 min\n",
      "[169/240] Sample processed in 0.22s, ETA: 1.21 min\n",
      "[170/240] Sample processed in 0.22s, ETA: 1.18 min\n",
      "[171/240] Sample processed in 0.22s, ETA: 1.16 min\n",
      "[172/240] Sample processed in 0.22s, ETA: 1.14 min\n",
      "[173/240] Sample processed in 0.22s, ETA: 1.12 min\n",
      "[174/240] Sample processed in 0.21s, ETA: 1.10 min\n",
      "[175/240] Sample processed in 0.22s, ETA: 1.08 min\n",
      "[176/240] Sample processed in 0.22s, ETA: 1.05 min\n",
      "[177/240] Sample processed in 0.22s, ETA: 1.03 min\n",
      "[178/240] Sample processed in 0.22s, ETA: 1.01 min\n",
      "[179/240] Sample processed in 0.21s, ETA: 0.99 min\n",
      "[180/240] Sample processed in 0.26s, ETA: 0.97 min\n",
      "[181/240] Sample processed in 15.70s, ETA: 1.03 min\n",
      "[182/240] Sample processed in 2.99s, ETA: 1.03 min\n",
      "[183/240] Sample processed in 32.23s, ETA: 1.17 min\n",
      "[184/240] Sample processed in 7.80s, ETA: 1.18 min\n",
      "[185/240] Sample processed in 17.17s, ETA: 1.24 min\n",
      "[186/240] Sample processed in 4.19s, ETA: 1.23 min\n",
      "[187/240] Sample processed in 5.01s, ETA: 1.23 min\n",
      "[188/240] Sample processed in 9.69s, ETA: 1.24 min\n",
      "[189/240] Sample processed in 7.52s, ETA: 1.25 min\n",
      "[190/240] Sample processed in 10.41s, ETA: 1.26 min\n",
      "[191/240] Sample processed in 44.96s, ETA: 1.42 min\n",
      "[192/240] Sample processed in 8.32s, ETA: 1.42 min\n",
      "[193/240] Sample processed in 7.05s, ETA: 1.41 min\n",
      "[194/240] Sample processed in 44.98s, ETA: 1.55 min\n",
      "[195/240] Sample processed in 8.21s, ETA: 1.54 min\n",
      "[196/240] Sample processed in 13.09s, ETA: 1.55 min\n",
      "[197/240] Sample processed in 9.98s, ETA: 1.54 min\n",
      "[198/240] Sample processed in 10.98s, ETA: 1.54 min\n",
      "[199/240] Sample processed in 44.90s, ETA: 1.65 min\n",
      "[200/240] Sample processed in 6.63s, ETA: 1.62 min\n",
      "[201/240] Sample processed in 7.36s, ETA: 1.60 min\n",
      "[202/240] Sample processed in 23.53s, ETA: 1.62 min\n",
      "[203/240] Sample processed in 6.16s, ETA: 1.59 min\n",
      "[204/240] Sample processed in 25.44s, ETA: 1.62 min\n",
      "[205/240] Sample processed in 11.54s, ETA: 1.60 min\n",
      "[206/240] Sample processed in 4.04s, ETA: 1.55 min\n",
      "[207/240] Sample processed in 3.38s, ETA: 1.51 min\n",
      "[208/240] Sample processed in 7.58s, ETA: 1.48 min\n",
      "[209/240] Sample processed in 28.59s, ETA: 1.49 min\n",
      "[210/240] Sample processed in 21.37s, ETA: 1.49 min\n",
      "[211/240] Sample processed in 14.50s, ETA: 1.47 min\n",
      "[212/240] Sample processed in 5.35s, ETA: 1.42 min\n",
      "[213/240] Sample processed in 44.89s, ETA: 1.46 min\n",
      "[214/240] Sample processed in 1.23s, ETA: 1.40 min\n",
      "[215/240] Sample processed in 9.45s, ETA: 1.36 min\n",
      "[216/240] Sample processed in 2.33s, ETA: 1.30 min\n",
      "[217/240] Sample processed in 17.14s, ETA: 1.27 min\n",
      "[218/240] Sample processed in 17.60s, ETA: 1.24 min\n",
      "[219/240] Sample processed in 20.23s, ETA: 1.21 min\n",
      "[220/240] Sample processed in 5.17s, ETA: 1.16 min\n",
      "[221/240] Sample processed in 44.92s, ETA: 1.16 min\n",
      "[222/240] Sample processed in 8.58s, ETA: 1.10 min\n",
      "[223/240] Sample processed in 1.17s, ETA: 1.04 min\n",
      "[224/240] Sample processed in 2.49s, ETA: 0.98 min\n",
      "[225/240] Sample processed in 44.87s, ETA: 0.96 min\n",
      "[226/240] Sample processed in 44.93s, ETA: 0.94 min\n",
      "[227/240] Sample processed in 44.96s, ETA: 0.91 min\n",
      "[228/240] Sample processed in 44.85s, ETA: 0.88 min\n",
      "[229/240] Sample processed in 17.95s, ETA: 0.82 min\n",
      "[230/240] Sample processed in 44.86s, ETA: 0.77 min\n",
      "[231/240] Sample processed in 3.94s, ETA: 0.69 min\n",
      "[232/240] Sample processed in 24.70s, ETA: 0.63 min\n",
      "[233/240] Sample processed in 5.47s, ETA: 0.55 min\n",
      "[234/240] Sample processed in 9.32s, ETA: 0.47 min\n",
      "[235/240] Sample processed in 10.13s, ETA: 0.40 min\n",
      "[236/240] Sample processed in 44.90s, ETA: 0.33 min\n",
      "[237/240] Sample processed in 4.68s, ETA: 0.25 min\n",
      "[238/240] Sample processed in 8.36s, ETA: 0.16 min\n",
      "[239/240] Sample processed in 6.83s, ETA: 0.08 min\n",
      "[240/240] Sample processed in 1.36s, ETA: 0.00 min\n",
      "\n",
      "All samples processed. Total time: 19.71 min\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "### ✅ Hugging Face에서 데이터 로드\n",
    "dataset_name = \"passionMan/test_dataset4\"\n",
    "dataset = load_dataset(dataset_name, split=\"test\")  # 'test' split 로드\n",
    "\n",
    "### ✅ JSONL 저장 함수 (평가 결과 저장용)\n",
    "def save_to_jsonl(file_path, data):\n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f: \n",
    "        f.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "### ✅ 모델 응답 생성 함수\n",
    "def generate_response(instruction_text, input_text, max_new_tokens=128):\n",
    "    try:\n",
    "        FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
    "\n",
    "        # ✅ 모델의 최대 입력 길이 가져오기 (보통 4096 또는 2048)\n",
    "        max_input_length = getattr(model.config, \"max_position_embeddings\", 4096)\n",
    "\n",
    "        # ✅ 입력 토큰 길이 확인\n",
    "        input_tokens = tokenizer(\n",
    "            alpaca_prompt.format(instruction_text, input_text, \"\"), \n",
    "            return_tensors=\"pt\"\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        input_length = input_tokens['input_ids'].shape[1]\n",
    "\n",
    "        # 🔥 입력이 너무 길면 최대 입력 길이에 맞게 자름\n",
    "        if input_length > max_input_length:\n",
    "            print(f\"[WARNING] Truncating input from {input_length} to {max_input_length} tokens.\")\n",
    "            input_text = tokenizer.decode(input_tokens['input_ids'][0, :max_input_length], skip_special_tokens=True)\n",
    "\n",
    "        # ✅ 생성 수행 (max_new_tokens을 적용)\n",
    "        outputs = model.generate(\n",
    "            **tokenizer(alpaca_prompt.format(instruction_text, input_text, \"\"), return_tensors=\"pt\").to(\"cuda\"),\n",
    "            max_new_tokens=max_new_tokens,  # ✅ 생성 길이 적용\n",
    "            use_cache=True\n",
    "        )\n",
    "\n",
    "        decoded_outputs = tokenizer.batch_decode(outputs)\n",
    "        response_texts = [output.split(\"### Response:\\n\")[-1].strip() for output in decoded_outputs]\n",
    "        return response_texts[0].replace(\"<|eot_id|>\", \"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Exception in response generation: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# ✅ 데이터 경로 설정 (결과 저장용)\n",
    "output_json_path = \"/data/jaesung/llm_for_diabetes/src/trial/model_response/model_output_base.jsonl\"\n",
    "\n",
    "# ✅ Task별 데이터 그룹화 (각 태스크별 0~29번 샘플 선택)\n",
    "grouped_data = defaultdict(list)\n",
    "for item in dataset:\n",
    "    grouped_data[item[\"task\"]].append(item)\n",
    "\n",
    "# ✅ 성능 평가할 데이터 생성 (각 태스크별 30개만 추출)\n",
    "sampled_data = []\n",
    "for task, samples in grouped_data.items():\n",
    "    sampled_data.extend(samples[:30])  # 최대 30개 선택\n",
    "\n",
    "# ✅ 성능 평가 시작\n",
    "start_time = time.time()\n",
    "total_samples = len(sampled_data)\n",
    "\n",
    "for idx, item in enumerate(sampled_data):\n",
    "    sample_start_time = time.time()\n",
    "\n",
    "    input_text = item.get(\"input\", \"\")\n",
    "    instruction = item.get(\"instruction\", \"\")\n",
    "    task = item.get(\"task\", \"\").lower()\n",
    "\n",
    "    # ✅ 생성할 토큰 길이 설정 (생성 토큰 수 조절)\n",
    "    short_context_tasks = {\"qa1\", \"qa2\", \"qa3\", \"nli\", \"re\"}  # 생성 32\n",
    "    medium_context_tasks = {\"ie\"} # 생성 128\n",
    "    long_context_tasks = {\"summarization\", \"generation\", \"daily_diets\", \"alternative_diet\"}  # 생성 1024\n",
    "\n",
    "    if task in short_context_tasks:\n",
    "        max_new_tokens = 128  # ✅ 생성 길이 128\n",
    "    elif task in medium_context_tasks:\n",
    "        max_new_tokens = 128\n",
    "    elif task in long_context_tasks:\n",
    "        max_new_tokens = 1024  # ✅ 생성 길이 1024\n",
    "    else:\n",
    "        max_new_tokens = 128  # 기본값\n",
    "\n",
    "    try:\n",
    "        model_output = generate_response(instruction, input_text, max_new_tokens)\n",
    "\n",
    "        if model_output is not None:\n",
    "            output_data = item.copy()\n",
    "            output_data.update({f\"model_output_{max_new_tokens}\": model_output})\n",
    "            save_to_jsonl(output_json_path, output_data)\n",
    "        else:\n",
    "            print(f\"[WARNING] Skipping sample {idx+1}/{total_samples} due to length limit or generation failure.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Skipping sample {idx+1}/{total_samples} due to unexpected error: {str(e)}\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    avg_time_per_sample = elapsed_time / (idx + 1) \n",
    "    remaining_samples = total_samples - (idx + 1)\n",
    "    estimated_remaining_time = remaining_samples * avg_time_per_sample\n",
    "\n",
    "    print(f\"[{idx+1}/{total_samples}] Sample processed in {time.time() - sample_start_time:.2f}s, ETA: {estimated_remaining_time/60:.2f} min\")\n",
    "\n",
    "print(f\"\\nAll samples processed. Total time: {(time.time() - start_time)/60:.2f} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[658/1181] Sample processed in 21.42s, ETA: 0.28 min\n",
      "[659/1181] Sample processed in 15.49s, ETA: 0.49 min\n",
      "[660/1181] Sample processed in 9.47s, ETA: 0.61 min\n",
      "[661/1181] Sample processed in 13.25s, ETA: 0.78 min\n",
      "[662/1181] Sample processed in 6.73s, ETA: 0.87 min\n",
      "[663/1181] Sample processed in 7.48s, ETA: 0.96 min\n",
      "[664/1181] Sample processed in 7.95s, ETA: 1.06 min\n",
      "[665/1181] Sample processed in 9.28s, ETA: 1.18 min\n",
      "[666/1181] Sample processed in 6.28s, ETA: 1.25 min\n",
      "[667/1181] Sample processed in 7.46s, ETA: 1.35 min\n",
      "[668/1181] Sample processed in 6.33s, ETA: 1.42 min\n",
      "[669/1181] Sample processed in 8.95s, ETA: 1.53 min\n",
      "[670/1181] Sample processed in 7.25s, ETA: 1.62 min\n",
      "[671/1181] Sample processed in 7.06s, ETA: 1.70 min\n",
      "[672/1181] Sample processed in 5.59s, ETA: 1.77 min\n",
      "[673/1181] Sample processed in 6.52s, ETA: 1.84 min\n",
      "[674/1181] Sample processed in 5.77s, ETA: 1.91 min\n",
      "[675/1181] Sample processed in 6.45s, ETA: 1.98 min\n",
      "[676/1181] Sample processed in 6.23s, ETA: 2.05 min\n",
      "[677/1181] Sample processed in 9.86s, ETA: 2.17 min\n",
      "[678/1181] Sample processed in 7.74s, ETA: 2.26 min\n",
      "[679/1181] Sample processed in 7.92s, ETA: 2.35 min\n",
      "[680/1181] Sample processed in 5.39s, ETA: 2.41 min\n",
      "[681/1181] Sample processed in 5.53s, ETA: 2.46 min\n",
      "[682/1181] Sample processed in 7.52s, ETA: 2.55 min\n",
      "[683/1181] Sample processed in 5.86s, ETA: 2.61 min\n",
      "[684/1181] Sample processed in 8.46s, ETA: 2.70 min\n",
      "[685/1181] Sample processed in 7.27s, ETA: 2.78 min\n",
      "[686/1181] Sample processed in 6.31s, ETA: 2.85 min\n",
      "[687/1181] Sample processed in 7.28s, ETA: 2.93 min\n",
      "[688/1181] Sample processed in 5.70s, ETA: 2.98 min\n",
      "[689/1181] Sample processed in 7.18s, ETA: 3.06 min\n",
      "[690/1181] Sample processed in 6.07s, ETA: 3.12 min\n",
      "[691/1181] Sample processed in 8.89s, ETA: 3.21 min\n",
      "[692/1181] Sample processed in 8.00s, ETA: 3.30 min\n",
      "[693/1181] Sample processed in 8.38s, ETA: 3.38 min\n",
      "[694/1181] Sample processed in 6.17s, ETA: 3.44 min\n",
      "[695/1181] Sample processed in 9.17s, ETA: 3.54 min\n",
      "[696/1181] Sample processed in 6.91s, ETA: 3.61 min\n",
      "[697/1181] Sample processed in 7.33s, ETA: 3.68 min\n",
      "[698/1181] Sample processed in 5.40s, ETA: 3.73 min\n",
      "[699/1181] Sample processed in 7.26s, ETA: 3.80 min\n",
      "[700/1181] Sample processed in 5.03s, ETA: 3.84 min\n",
      "[701/1181] Sample processed in 8.31s, ETA: 3.92 min\n",
      "[702/1181] Sample processed in 6.16s, ETA: 3.98 min\n",
      "[703/1181] Sample processed in 9.03s, ETA: 4.07 min\n",
      "[704/1181] Sample processed in 7.91s, ETA: 4.14 min\n",
      "[705/1181] Sample processed in 6.71s, ETA: 4.21 min\n",
      "[706/1181] Sample processed in 7.29s, ETA: 4.27 min\n",
      "[707/1181] Sample processed in 6.77s, ETA: 4.33 min\n",
      "[708/1181] Sample processed in 7.10s, ETA: 4.40 min\n",
      "[709/1181] Sample processed in 9.00s, ETA: 4.48 min\n",
      "[710/1181] Sample processed in 6.38s, ETA: 4.54 min\n",
      "[711/1181] Sample processed in 9.28s, ETA: 4.62 min\n",
      "[712/1181] Sample processed in 6.48s, ETA: 4.68 min\n",
      "[713/1181] Sample processed in 7.38s, ETA: 4.74 min\n",
      "[714/1181] Sample processed in 6.84s, ETA: 4.80 min\n",
      "[715/1181] Sample processed in 6.60s, ETA: 4.85 min\n",
      "[716/1181] Sample processed in 7.48s, ETA: 4.92 min\n",
      "[717/1181] Sample processed in 6.41s, ETA: 4.97 min\n",
      "[718/1181] Sample processed in 6.18s, ETA: 5.02 min\n",
      "[719/1181] Sample processed in 7.63s, ETA: 5.08 min\n",
      "[720/1181] Sample processed in 5.62s, ETA: 5.12 min\n",
      "[721/1181] Sample processed in 7.55s, ETA: 5.19 min\n",
      "[722/1181] Sample processed in 6.02s, ETA: 5.23 min\n",
      "[723/1181] Sample processed in 6.14s, ETA: 5.28 min\n",
      "[724/1181] Sample processed in 7.59s, ETA: 5.34 min\n",
      "[725/1181] Sample processed in 8.63s, ETA: 5.41 min\n",
      "[726/1181] Sample processed in 5.88s, ETA: 5.45 min\n",
      "[727/1181] Sample processed in 9.61s, ETA: 5.53 min\n",
      "[728/1181] Sample processed in 7.24s, ETA: 5.59 min\n",
      "[729/1181] Sample processed in 6.82s, ETA: 5.64 min\n",
      "[730/1181] Sample processed in 7.01s, ETA: 5.69 min\n",
      "[731/1181] Sample processed in 7.57s, ETA: 5.75 min\n",
      "[732/1181] Sample processed in 8.56s, ETA: 5.81 min\n",
      "[733/1181] Sample processed in 6.53s, ETA: 5.86 min\n",
      "[734/1181] Sample processed in 5.64s, ETA: 5.90 min\n",
      "[735/1181] Sample processed in 8.83s, ETA: 5.96 min\n",
      "[736/1181] Sample processed in 6.25s, ETA: 6.01 min\n",
      "[737/1181] Sample processed in 9.26s, ETA: 6.08 min\n",
      "[738/1181] Sample processed in 6.53s, ETA: 6.12 min\n",
      "[739/1181] Sample processed in 6.81s, ETA: 6.17 min\n",
      "[740/1181] Sample processed in 6.12s, ETA: 6.21 min\n",
      "[741/1181] Sample processed in 7.52s, ETA: 6.26 min\n",
      "[742/1181] Sample processed in 8.03s, ETA: 6.31 min\n",
      "[743/1181] Sample processed in 6.45s, ETA: 6.35 min\n",
      "[744/1181] Sample processed in 7.19s, ETA: 6.40 min\n",
      "[745/1181] Sample processed in 8.61s, ETA: 6.46 min\n",
      "[746/1181] Sample processed in 5.00s, ETA: 6.49 min\n",
      "[747/1181] Sample processed in 6.04s, ETA: 6.52 min\n",
      "[748/1181] Sample processed in 6.62s, ETA: 6.56 min\n",
      "[749/1181] Sample processed in 8.58s, ETA: 6.62 min\n",
      "[750/1181] Sample processed in 6.61s, ETA: 6.66 min\n",
      "[751/1181] Sample processed in 8.02s, ETA: 6.71 min\n",
      "[752/1181] Sample processed in 7.23s, ETA: 6.76 min\n",
      "[753/1181] Sample processed in 8.06s, ETA: 6.81 min\n",
      "[754/1181] Sample processed in 6.02s, ETA: 6.84 min\n",
      "[755/1181] Sample processed in 7.67s, ETA: 6.89 min\n",
      "[756/1181] Sample processed in 7.65s, ETA: 6.93 min\n",
      "[757/1181] Sample processed in 10.01s, ETA: 7.00 min\n",
      "[758/1181] Sample processed in 7.69s, ETA: 7.05 min\n",
      "[759/1181] Sample processed in 6.34s, ETA: 7.08 min\n",
      "[760/1181] Sample processed in 6.92s, ETA: 7.12 min\n",
      "[761/1181] Sample processed in 9.43s, ETA: 7.18 min\n",
      "[762/1181] Sample processed in 6.59s, ETA: 7.21 min\n",
      "[763/1181] Sample processed in 9.48s, ETA: 7.27 min\n",
      "[764/1181] Sample processed in 6.62s, ETA: 7.31 min\n",
      "[765/1181] Sample processed in 9.12s, ETA: 7.36 min\n",
      "[766/1181] Sample processed in 4.59s, ETA: 7.38 min\n",
      "[767/1181] Sample processed in 7.69s, ETA: 7.42 min\n",
      "[768/1181] Sample processed in 7.12s, ETA: 7.45 min\n",
      "[769/1181] Sample processed in 6.70s, ETA: 7.49 min\n",
      "[770/1181] Sample processed in 6.37s, ETA: 7.51 min\n",
      "[771/1181] Sample processed in 6.52s, ETA: 7.54 min\n",
      "[772/1181] Sample processed in 6.13s, ETA: 7.57 min\n",
      "[773/1181] Sample processed in 8.34s, ETA: 7.62 min\n",
      "[774/1181] Sample processed in 6.08s, ETA: 7.64 min\n",
      "[775/1181] Sample processed in 7.60s, ETA: 7.68 min\n",
      "[776/1181] Sample processed in 6.41s, ETA: 7.71 min\n",
      "[777/1181] Sample processed in 8.19s, ETA: 7.75 min\n",
      "[778/1181] Sample processed in 7.23s, ETA: 7.78 min\n",
      "[779/1181] Sample processed in 10.09s, ETA: 7.84 min\n",
      "[780/1181] Sample processed in 6.49s, ETA: 7.86 min\n",
      "[781/1181] Sample processed in 8.09s, ETA: 7.90 min\n",
      "[782/1181] Sample processed in 6.57s, ETA: 7.93 min\n",
      "[783/1181] Sample processed in 8.08s, ETA: 7.97 min\n",
      "[784/1181] Sample processed in 5.46s, ETA: 7.98 min\n",
      "[785/1181] Sample processed in 7.21s, ETA: 8.01 min\n",
      "[786/1181] Sample processed in 7.29s, ETA: 8.04 min\n",
      "[787/1181] Sample processed in 7.38s, ETA: 8.08 min\n",
      "[788/1181] Sample processed in 5.13s, ETA: 8.09 min\n",
      "[789/1181] Sample processed in 7.43s, ETA: 8.12 min\n",
      "[790/1181] Sample processed in 6.48s, ETA: 8.14 min\n",
      "[791/1181] Sample processed in 8.55s, ETA: 8.18 min\n",
      "[792/1181] Sample processed in 7.83s, ETA: 8.21 min\n",
      "[793/1181] Sample processed in 7.42s, ETA: 8.24 min\n",
      "[794/1181] Sample processed in 7.12s, ETA: 8.27 min\n",
      "[795/1181] Sample processed in 7.47s, ETA: 8.30 min\n",
      "[796/1181] Sample processed in 6.41s, ETA: 8.32 min\n",
      "[797/1181] Sample processed in 6.29s, ETA: 8.34 min\n",
      "[798/1181] Sample processed in 5.63s, ETA: 8.35 min\n",
      "[799/1181] Sample processed in 6.19s, ETA: 8.37 min\n",
      "[800/1181] Sample processed in 6.39s, ETA: 8.38 min\n",
      "[801/1181] Sample processed in 7.83s, ETA: 8.41 min\n",
      "[802/1181] Sample processed in 6.04s, ETA: 8.43 min\n",
      "[803/1181] Sample processed in 5.70s, ETA: 8.44 min\n",
      "[804/1181] Sample processed in 6.68s, ETA: 8.46 min\n",
      "[805/1181] Sample processed in 5.95s, ETA: 8.47 min\n",
      "[806/1181] Sample processed in 7.62s, ETA: 8.50 min\n",
      "[807/1181] Sample processed in 7.74s, ETA: 8.53 min\n",
      "[808/1181] Sample processed in 7.49s, ETA: 8.55 min\n",
      "[809/1181] Sample processed in 5.72s, ETA: 8.56 min\n",
      "[810/1181] Sample processed in 4.34s, ETA: 8.56 min\n",
      "[811/1181] Sample processed in 7.07s, ETA: 8.58 min\n",
      "[812/1181] Sample processed in 4.66s, ETA: 8.58 min\n",
      "[813/1181] Sample processed in 7.43s, ETA: 8.60 min\n",
      "[814/1181] Sample processed in 5.52s, ETA: 8.61 min\n",
      "[815/1181] Sample processed in 7.82s, ETA: 8.64 min\n",
      "[816/1181] Sample processed in 6.63s, ETA: 8.65 min\n",
      "[817/1181] Sample processed in 5.73s, ETA: 8.66 min\n",
      "[818/1181] Sample processed in 5.04s, ETA: 8.66 min\n",
      "[819/1181] Sample processed in 9.07s, ETA: 8.69 min\n",
      "[820/1181] Sample processed in 6.20s, ETA: 8.71 min\n",
      "[821/1181] Sample processed in 8.37s, ETA: 8.73 min\n",
      "[822/1181] Sample processed in 6.87s, ETA: 8.75 min\n",
      "[823/1181] Sample processed in 9.67s, ETA: 8.78 min\n",
      "[824/1181] Sample processed in 6.09s, ETA: 8.79 min\n",
      "[825/1181] Sample processed in 7.88s, ETA: 8.81 min\n",
      "[826/1181] Sample processed in 5.90s, ETA: 8.82 min\n",
      "[827/1181] Sample processed in 7.39s, ETA: 8.84 min\n",
      "[828/1181] Sample processed in 5.95s, ETA: 8.84 min\n",
      "[829/1181] Sample processed in 6.21s, ETA: 8.85 min\n",
      "[830/1181] Sample processed in 6.66s, ETA: 8.86 min\n",
      "[831/1181] Sample processed in 8.34s, ETA: 8.89 min\n",
      "[832/1181] Sample processed in 5.25s, ETA: 8.89 min\n",
      "[833/1181] Sample processed in 5.99s, ETA: 8.89 min\n",
      "[834/1181] Sample processed in 6.19s, ETA: 8.90 min\n",
      "[835/1181] Sample processed in 9.28s, ETA: 8.93 min\n",
      "[836/1181] Sample processed in 6.14s, ETA: 8.93 min\n",
      "[837/1181] Sample processed in 6.64s, ETA: 8.94 min\n",
      "[838/1181] Sample processed in 5.52s, ETA: 8.94 min\n",
      "[839/1181] Sample processed in 6.87s, ETA: 8.95 min\n",
      "[840/1181] Sample processed in 5.78s, ETA: 8.95 min\n",
      "[841/1181] Sample processed in 8.32s, ETA: 8.97 min\n",
      "[842/1181] Sample processed in 7.42s, ETA: 8.99 min\n",
      "[843/1181] Sample processed in 6.68s, ETA: 8.99 min\n",
      "[844/1181] Sample processed in 7.95s, ETA: 9.01 min\n",
      "[845/1181] Sample processed in 7.23s, ETA: 9.02 min\n",
      "[846/1181] Sample processed in 5.45s, ETA: 9.02 min\n",
      "[847/1181] Sample processed in 8.90s, ETA: 9.04 min\n",
      "[848/1181] Sample processed in 6.33s, ETA: 9.04 min\n",
      "[849/1181] Sample processed in 8.59s, ETA: 9.06 min\n",
      "[850/1181] Sample processed in 6.44s, ETA: 9.07 min\n",
      "[851/1181] Sample processed in 8.93s, ETA: 9.09 min\n",
      "[852/1181] Sample processed in 8.37s, ETA: 9.10 min\n",
      "[853/1181] Sample processed in 7.83s, ETA: 9.11 min\n",
      "[854/1181] Sample processed in 6.85s, ETA: 9.12 min\n",
      "[855/1181] Sample processed in 7.53s, ETA: 9.13 min\n",
      "[856/1181] Sample processed in 6.07s, ETA: 9.13 min\n",
      "[857/1181] Sample processed in 8.40s, ETA: 9.14 min\n",
      "[858/1181] Sample processed in 5.27s, ETA: 9.14 min\n",
      "[859/1181] Sample processed in 7.84s, ETA: 9.15 min\n",
      "[860/1181] Sample processed in 7.07s, ETA: 9.15 min\n",
      "[861/1181] Sample processed in 8.38s, ETA: 9.16 min\n",
      "[862/1181] Sample processed in 6.15s, ETA: 9.16 min\n",
      "[863/1181] Sample processed in 8.06s, ETA: 9.17 min\n",
      "[864/1181] Sample processed in 7.79s, ETA: 9.18 min\n",
      "[865/1181] Sample processed in 6.52s, ETA: 9.18 min\n",
      "[866/1181] Sample processed in 6.90s, ETA: 9.18 min\n",
      "[867/1181] Sample processed in 7.42s, ETA: 9.19 min\n",
      "[868/1181] Sample processed in 6.10s, ETA: 9.18 min\n",
      "[869/1181] Sample processed in 8.34s, ETA: 9.19 min\n",
      "[870/1181] Sample processed in 7.60s, ETA: 9.20 min\n",
      "[871/1181] Sample processed in 7.13s, ETA: 9.20 min\n",
      "[872/1181] Sample processed in 6.50s, ETA: 9.20 min\n",
      "[873/1181] Sample processed in 6.21s, ETA: 9.20 min\n",
      "[874/1181] Sample processed in 5.07s, ETA: 9.19 min\n",
      "[875/1181] Sample processed in 7.41s, ETA: 9.19 min\n",
      "[876/1181] Sample processed in 7.28s, ETA: 9.19 min\n",
      "[877/1181] Sample processed in 6.02s, ETA: 9.18 min\n",
      "[878/1181] Sample processed in 6.74s, ETA: 9.18 min\n",
      "[879/1181] Sample processed in 7.52s, ETA: 9.19 min\n",
      "[880/1181] Sample processed in 6.23s, ETA: 9.18 min\n",
      "[881/1181] Sample processed in 6.57s, ETA: 9.18 min\n",
      "[882/1181] Sample processed in 6.87s, ETA: 9.17 min\n",
      "[883/1181] Sample processed in 6.40s, ETA: 9.17 min\n",
      "[884/1181] Sample processed in 7.54s, ETA: 9.17 min\n",
      "[885/1181] Sample processed in 7.94s, ETA: 9.17 min\n",
      "[886/1181] Sample processed in 6.13s, ETA: 9.17 min\n",
      "[887/1181] Sample processed in 7.59s, ETA: 9.17 min\n",
      "[888/1181] Sample processed in 5.53s, ETA: 9.16 min\n",
      "[889/1181] Sample processed in 7.75s, ETA: 9.16 min\n",
      "[890/1181] Sample processed in 6.23s, ETA: 9.15 min\n",
      "[891/1181] Sample processed in 7.77s, ETA: 9.15 min\n",
      "[892/1181] Sample processed in 6.33s, ETA: 9.14 min\n",
      "[893/1181] Sample processed in 7.43s, ETA: 9.14 min\n",
      "[894/1181] Sample processed in 7.35s, ETA: 9.14 min\n",
      "[895/1181] Sample processed in 8.27s, ETA: 9.14 min\n",
      "[896/1181] Sample processed in 8.73s, ETA: 9.14 min\n",
      "[897/1181] Sample processed in 5.80s, ETA: 9.13 min\n",
      "[898/1181] Sample processed in 6.17s, ETA: 9.12 min\n",
      "[899/1181] Sample processed in 8.30s, ETA: 9.12 min\n",
      "[900/1181] Sample processed in 5.33s, ETA: 9.11 min\n",
      "[901/1181] Sample processed in 7.54s, ETA: 9.10 min\n",
      "[902/1181] Sample processed in 6.41s, ETA: 9.10 min\n",
      "[903/1181] Sample processed in 8.49s, ETA: 9.10 min\n",
      "[904/1181] Sample processed in 7.18s, ETA: 9.09 min\n",
      "[905/1181] Sample processed in 8.26s, ETA: 9.09 min\n",
      "[906/1181] Sample processed in 6.61s, ETA: 9.08 min\n",
      "[907/1181] Sample processed in 7.07s, ETA: 9.07 min\n",
      "[908/1181] Sample processed in 6.63s, ETA: 9.06 min\n",
      "[909/1181] Sample processed in 6.84s, ETA: 9.05 min\n",
      "[910/1181] Sample processed in 5.86s, ETA: 9.04 min\n",
      "[911/1181] Sample processed in 6.80s, ETA: 9.03 min\n",
      "[912/1181] Sample processed in 6.30s, ETA: 9.02 min\n",
      "[913/1181] Sample processed in 5.86s, ETA: 9.00 min\n",
      "[914/1181] Sample processed in 5.99s, ETA: 8.99 min\n",
      "[915/1181] Sample processed in 7.44s, ETA: 8.98 min\n",
      "[916/1181] Sample processed in 6.00s, ETA: 8.97 min\n",
      "[917/1181] Sample processed in 8.35s, ETA: 8.96 min\n",
      "[918/1181] Sample processed in 6.83s, ETA: 8.95 min\n",
      "[919/1181] Sample processed in 7.77s, ETA: 8.95 min\n",
      "[920/1181] Sample processed in 6.93s, ETA: 8.93 min\n",
      "[921/1181] Sample processed in 5.40s, ETA: 8.92 min\n",
      "[922/1181] Sample processed in 6.81s, ETA: 8.90 min\n",
      "[923/1181] Sample processed in 7.34s, ETA: 8.89 min\n",
      "[924/1181] Sample processed in 8.86s, ETA: 8.89 min\n",
      "[925/1181] Sample processed in 8.00s, ETA: 8.88 min\n",
      "[926/1181] Sample processed in 6.49s, ETA: 8.87 min\n",
      "[927/1181] Sample processed in 8.55s, ETA: 8.86 min\n",
      "[928/1181] Sample processed in 5.40s, ETA: 8.84 min\n",
      "[929/1181] Sample processed in 7.15s, ETA: 8.83 min\n",
      "[930/1181] Sample processed in 5.83s, ETA: 8.81 min\n",
      "[931/1181] Sample processed in 7.80s, ETA: 8.80 min\n",
      "[932/1181] Sample processed in 6.12s, ETA: 8.79 min\n",
      "[933/1181] Sample processed in 8.13s, ETA: 8.78 min\n",
      "[934/1181] Sample processed in 6.23s, ETA: 8.76 min\n",
      "[935/1181] Sample processed in 6.79s, ETA: 8.75 min\n",
      "[936/1181] Sample processed in 2.77s, ETA: 8.71 min\n",
      "[937/1181] Sample processed in 2.53s, ETA: 8.68 min\n",
      "[938/1181] Sample processed in 3.27s, ETA: 8.65 min\n",
      "[939/1181] Sample processed in 1.97s, ETA: 8.61 min\n",
      "[940/1181] Sample processed in 2.70s, ETA: 8.58 min\n",
      "[941/1181] Sample processed in 1.86s, ETA: 8.54 min\n",
      "[942/1181] Sample processed in 2.11s, ETA: 8.51 min\n",
      "[943/1181] Sample processed in 3.00s, ETA: 8.47 min\n",
      "[944/1181] Sample processed in 2.18s, ETA: 8.44 min\n",
      "[945/1181] Sample processed in 2.28s, ETA: 8.40 min\n",
      "[946/1181] Sample processed in 1.86s, ETA: 8.37 min\n",
      "[947/1181] Sample processed in 2.91s, ETA: 8.33 min\n",
      "[948/1181] Sample processed in 2.24s, ETA: 8.30 min\n",
      "[949/1181] Sample processed in 2.22s, ETA: 8.26 min\n",
      "[950/1181] Sample processed in 2.22s, ETA: 8.23 min\n",
      "[951/1181] Sample processed in 2.31s, ETA: 8.19 min\n",
      "[952/1181] Sample processed in 2.08s, ETA: 8.16 min\n",
      "[953/1181] Sample processed in 2.06s, ETA: 8.12 min\n",
      "[954/1181] Sample processed in 2.08s, ETA: 8.09 min\n",
      "[955/1181] Sample processed in 3.00s, ETA: 8.05 min\n",
      "[956/1181] Sample processed in 2.20s, ETA: 8.02 min\n",
      "[957/1181] Sample processed in 2.51s, ETA: 7.98 min\n",
      "[958/1181] Sample processed in 2.28s, ETA: 7.95 min\n",
      "[959/1181] Sample processed in 2.64s, ETA: 7.92 min\n",
      "[960/1181] Sample processed in 2.87s, ETA: 7.88 min\n",
      "[961/1181] Sample processed in 2.32s, ETA: 7.85 min\n",
      "[962/1181] Sample processed in 1.85s, ETA: 7.81 min\n",
      "[963/1181] Sample processed in 2.14s, ETA: 7.78 min\n",
      "[964/1181] Sample processed in 2.69s, ETA: 7.74 min\n",
      "[965/1181] Sample processed in 2.26s, ETA: 7.71 min\n",
      "[966/1181] Sample processed in 2.29s, ETA: 7.67 min\n",
      "[967/1181] Sample processed in 2.38s, ETA: 7.64 min\n",
      "[968/1181] Sample processed in 2.18s, ETA: 7.60 min\n",
      "[969/1181] Sample processed in 2.31s, ETA: 7.57 min\n",
      "[970/1181] Sample processed in 3.87s, ETA: 7.54 min\n",
      "[971/1181] Sample processed in 1.85s, ETA: 7.50 min\n",
      "[972/1181] Sample processed in 1.86s, ETA: 7.46 min\n",
      "[973/1181] Sample processed in 2.84s, ETA: 7.43 min\n",
      "[974/1181] Sample processed in 2.51s, ETA: 7.40 min\n",
      "[975/1181] Sample processed in 2.61s, ETA: 7.36 min\n",
      "[976/1181] Sample processed in 2.75s, ETA: 7.33 min\n",
      "[977/1181] Sample processed in 2.24s, ETA: 7.29 min\n",
      "[978/1181] Sample processed in 2.75s, ETA: 7.26 min\n",
      "[979/1181] Sample processed in 2.96s, ETA: 7.23 min\n",
      "[980/1181] Sample processed in 3.11s, ETA: 7.19 min\n",
      "[981/1181] Sample processed in 1.99s, ETA: 7.16 min\n",
      "[982/1181] Sample processed in 2.22s, ETA: 7.12 min\n",
      "[983/1181] Sample processed in 2.53s, ETA: 7.09 min\n",
      "[984/1181] Sample processed in 2.13s, ETA: 7.05 min\n",
      "[985/1181] Sample processed in 2.88s, ETA: 7.02 min\n",
      "[986/1181] Sample processed in 2.74s, ETA: 6.98 min\n",
      "[987/1181] Sample processed in 2.86s, ETA: 6.95 min\n",
      "[988/1181] Sample processed in 2.59s, ETA: 6.92 min\n",
      "[989/1181] Sample processed in 1.95s, ETA: 6.88 min\n",
      "[990/1181] Sample processed in 2.26s, ETA: 6.84 min\n",
      "[991/1181] Sample processed in 2.61s, ETA: 6.81 min\n",
      "[992/1181] Sample processed in 2.98s, ETA: 6.78 min\n",
      "[993/1181] Sample processed in 1.89s, ETA: 6.74 min\n",
      "[994/1181] Sample processed in 2.65s, ETA: 6.71 min\n",
      "[995/1181] Sample processed in 1.99s, ETA: 6.67 min\n",
      "[996/1181] Sample processed in 2.52s, ETA: 6.63 min\n",
      "[997/1181] Sample processed in 2.11s, ETA: 6.60 min\n",
      "[998/1181] Sample processed in 1.72s, ETA: 6.56 min\n",
      "[999/1181] Sample processed in 1.76s, ETA: 6.52 min\n",
      "[1000/1181] Sample processed in 2.96s, ETA: 6.49 min\n",
      "[1001/1181] Sample processed in 1.92s, ETA: 6.45 min\n",
      "[1002/1181] Sample processed in 2.37s, ETA: 6.42 min\n",
      "[1003/1181] Sample processed in 2.38s, ETA: 6.38 min\n",
      "[1004/1181] Sample processed in 1.78s, ETA: 6.35 min\n",
      "[1005/1181] Sample processed in 2.31s, ETA: 6.31 min\n",
      "[1006/1181] Sample processed in 2.73s, ETA: 6.28 min\n",
      "[1007/1181] Sample processed in 2.35s, ETA: 6.24 min\n",
      "[1008/1181] Sample processed in 2.61s, ETA: 6.21 min\n",
      "[1009/1181] Sample processed in 2.25s, ETA: 6.17 min\n",
      "[1010/1181] Sample processed in 2.77s, ETA: 6.14 min\n",
      "[1011/1181] Sample processed in 2.31s, ETA: 6.10 min\n",
      "[1012/1181] Sample processed in 2.24s, ETA: 6.07 min\n",
      "[1013/1181] Sample processed in 3.56s, ETA: 6.03 min\n",
      "[1014/1181] Sample processed in 2.17s, ETA: 6.00 min\n",
      "[1015/1181] Sample processed in 2.48s, ETA: 5.96 min\n",
      "[1016/1181] Sample processed in 2.21s, ETA: 5.93 min\n",
      "[1017/1181] Sample processed in 2.97s, ETA: 5.89 min\n",
      "[1018/1181] Sample processed in 3.05s, ETA: 5.86 min\n",
      "[1019/1181] Sample processed in 1.82s, ETA: 5.82 min\n",
      "[1020/1181] Sample processed in 3.43s, ETA: 5.79 min\n",
      "[1021/1181] Sample processed in 1.98s, ETA: 5.75 min\n",
      "[1022/1181] Sample processed in 2.43s, ETA: 5.72 min\n",
      "[1023/1181] Sample processed in 1.66s, ETA: 5.68 min\n",
      "[1024/1181] Sample processed in 2.30s, ETA: 5.65 min\n",
      "[1025/1181] Sample processed in 1.72s, ETA: 5.61 min\n",
      "[1026/1181] Sample processed in 2.41s, ETA: 5.57 min\n",
      "[1027/1181] Sample processed in 1.68s, ETA: 5.54 min\n",
      "[1028/1181] Sample processed in 1.94s, ETA: 5.50 min\n",
      "[1029/1181] Sample processed in 1.30s, ETA: 5.46 min\n",
      "[1030/1181] Sample processed in 2.57s, ETA: 5.43 min\n",
      "[1031/1181] Sample processed in 1.46s, ETA: 5.39 min\n",
      "[1032/1181] Sample processed in 2.44s, ETA: 5.35 min\n",
      "[1033/1181] Sample processed in 1.65s, ETA: 5.32 min\n",
      "[1034/1181] Sample processed in 3.14s, ETA: 5.28 min\n",
      "[1035/1181] Sample processed in 1.88s, ETA: 5.25 min\n",
      "[1036/1181] Sample processed in 2.61s, ETA: 5.21 min\n",
      "[1037/1181] Sample processed in 2.24s, ETA: 5.18 min\n",
      "[1038/1181] Sample processed in 1.89s, ETA: 5.14 min\n",
      "[1039/1181] Sample processed in 2.31s, ETA: 5.10 min\n",
      "[1040/1181] Sample processed in 1.73s, ETA: 5.07 min\n",
      "[1041/1181] Sample processed in 2.02s, ETA: 5.03 min\n",
      "[1042/1181] Sample processed in 2.08s, ETA: 5.00 min\n",
      "[1043/1181] Sample processed in 1.80s, ETA: 4.96 min\n",
      "[1044/1181] Sample processed in 1.99s, ETA: 4.92 min\n",
      "[1045/1181] Sample processed in 2.58s, ETA: 4.89 min\n",
      "[1046/1181] Sample processed in 2.25s, ETA: 4.85 min\n",
      "[1047/1181] Sample processed in 2.51s, ETA: 4.82 min\n",
      "[1048/1181] Sample processed in 2.45s, ETA: 4.78 min\n",
      "[1049/1181] Sample processed in 2.38s, ETA: 4.75 min\n",
      "[1050/1181] Sample processed in 1.82s, ETA: 4.71 min\n",
      "[1051/1181] Sample processed in 2.11s, ETA: 4.67 min\n",
      "[1052/1181] Sample processed in 1.96s, ETA: 4.64 min\n",
      "[1053/1181] Sample processed in 2.31s, ETA: 4.60 min\n",
      "[1054/1181] Sample processed in 2.02s, ETA: 4.56 min\n",
      "[1055/1181] Sample processed in 2.57s, ETA: 4.53 min\n",
      "[1056/1181] Sample processed in 2.05s, ETA: 4.49 min\n",
      "[1057/1181] Sample processed in 1.76s, ETA: 4.46 min\n",
      "[1058/1181] Sample processed in 2.21s, ETA: 4.42 min\n",
      "[1059/1181] Sample processed in 2.49s, ETA: 4.39 min\n",
      "[1060/1181] Sample processed in 1.99s, ETA: 4.35 min\n",
      "[1061/1181] Sample processed in 2.59s, ETA: 4.31 min\n",
      "[1062/1181] Sample processed in 3.01s, ETA: 4.28 min\n",
      "[1063/1181] Sample processed in 3.38s, ETA: 4.25 min\n",
      "[1064/1181] Sample processed in 1.85s, ETA: 4.21 min\n",
      "[1065/1181] Sample processed in 2.19s, ETA: 4.17 min\n",
      "[1066/1181] Sample processed in 1.28s, ETA: 4.14 min\n",
      "[1067/1181] Sample processed in 1.60s, ETA: 4.10 min\n",
      "[1068/1181] Sample processed in 1.90s, ETA: 4.06 min\n",
      "[1069/1181] Sample processed in 1.89s, ETA: 4.03 min\n",
      "[1070/1181] Sample processed in 1.86s, ETA: 3.99 min\n",
      "[1071/1181] Sample processed in 2.55s, ETA: 3.95 min\n",
      "[1072/1181] Sample processed in 2.22s, ETA: 3.92 min\n",
      "[1073/1181] Sample processed in 2.49s, ETA: 3.88 min\n",
      "[1074/1181] Sample processed in 3.51s, ETA: 3.85 min\n",
      "[1075/1181] Sample processed in 3.11s, ETA: 3.82 min\n",
      "[1076/1181] Sample processed in 3.46s, ETA: 3.78 min\n",
      "[1077/1181] Sample processed in 2.19s, ETA: 3.75 min\n",
      "[1078/1181] Sample processed in 3.04s, ETA: 3.71 min\n",
      "[1079/1181] Sample processed in 2.01s, ETA: 3.67 min\n",
      "[1080/1181] Sample processed in 2.70s, ETA: 3.64 min\n",
      "[1081/1181] Sample processed in 2.90s, ETA: 3.60 min\n",
      "[1082/1181] Sample processed in 2.38s, ETA: 3.57 min\n",
      "[1083/1181] Sample processed in 2.05s, ETA: 3.53 min\n",
      "[1084/1181] Sample processed in 2.35s, ETA: 3.50 min\n",
      "[1085/1181] Sample processed in 2.15s, ETA: 3.46 min\n",
      "[1086/1181] Sample processed in 2.15s, ETA: 3.42 min\n",
      "[1087/1181] Sample processed in 1.63s, ETA: 3.39 min\n",
      "[1088/1181] Sample processed in 1.26s, ETA: 3.35 min\n",
      "[1089/1181] Sample processed in 2.64s, ETA: 3.32 min\n",
      "[1090/1181] Sample processed in 2.22s, ETA: 3.28 min\n",
      "[1091/1181] Sample processed in 3.05s, ETA: 3.24 min\n",
      "[1092/1181] Sample processed in 2.15s, ETA: 3.21 min\n",
      "[1093/1181] Sample processed in 1.99s, ETA: 3.17 min\n",
      "[1094/1181] Sample processed in 1.50s, ETA: 3.14 min\n",
      "[1095/1181] Sample processed in 2.18s, ETA: 3.10 min\n",
      "[1096/1181] Sample processed in 2.52s, ETA: 3.06 min\n",
      "[1097/1181] Sample processed in 2.05s, ETA: 3.03 min\n",
      "[1098/1181] Sample processed in 3.54s, ETA: 2.99 min\n",
      "[1099/1181] Sample processed in 2.38s, ETA: 2.96 min\n",
      "[1100/1181] Sample processed in 2.96s, ETA: 2.92 min\n",
      "[1101/1181] Sample processed in 2.55s, ETA: 2.89 min\n",
      "[1102/1181] Sample processed in 1.93s, ETA: 2.85 min\n",
      "[1103/1181] Sample processed in 2.02s, ETA: 2.81 min\n",
      "[1104/1181] Sample processed in 2.13s, ETA: 2.78 min\n",
      "[1105/1181] Sample processed in 2.11s, ETA: 2.74 min\n",
      "[1106/1181] Sample processed in 2.35s, ETA: 2.71 min\n",
      "[1107/1181] Sample processed in 2.41s, ETA: 2.67 min\n",
      "[1108/1181] Sample processed in 1.27s, ETA: 2.63 min\n",
      "[1109/1181] Sample processed in 1.33s, ETA: 2.60 min\n",
      "[1110/1181] Sample processed in 2.25s, ETA: 2.56 min\n",
      "[1111/1181] Sample processed in 3.61s, ETA: 2.53 min\n",
      "[1112/1181] Sample processed in 1.86s, ETA: 2.49 min\n",
      "[1113/1181] Sample processed in 1.39s, ETA: 2.45 min\n",
      "[1114/1181] Sample processed in 2.42s, ETA: 2.42 min\n",
      "[1115/1181] Sample processed in 2.25s, ETA: 2.38 min\n",
      "[1116/1181] Sample processed in 2.55s, ETA: 2.34 min\n",
      "[1117/1181] Sample processed in 2.18s, ETA: 2.31 min\n",
      "[1118/1181] Sample processed in 2.46s, ETA: 2.27 min\n",
      "[1119/1181] Sample processed in 2.41s, ETA: 2.24 min\n",
      "[1120/1181] Sample processed in 2.91s, ETA: 2.20 min\n",
      "[1121/1181] Sample processed in 1.78s, ETA: 2.17 min\n",
      "[1122/1181] Sample processed in 1.85s, ETA: 2.13 min\n",
      "[1123/1181] Sample processed in 1.92s, ETA: 2.09 min\n",
      "[1124/1181] Sample processed in 1.91s, ETA: 2.06 min\n",
      "[1125/1181] Sample processed in 1.83s, ETA: 2.02 min\n",
      "[1126/1181] Sample processed in 1.95s, ETA: 1.98 min\n",
      "[1127/1181] Sample processed in 2.21s, ETA: 1.95 min\n",
      "[1128/1181] Sample processed in 1.76s, ETA: 1.91 min\n",
      "[1129/1181] Sample processed in 1.89s, ETA: 1.87 min\n",
      "[1130/1181] Sample processed in 1.55s, ETA: 1.84 min\n",
      "[1131/1181] Sample processed in 3.18s, ETA: 1.80 min\n",
      "[1132/1181] Sample processed in 2.75s, ETA: 1.77 min\n",
      "[1133/1181] Sample processed in 2.41s, ETA: 1.73 min\n",
      "[1134/1181] Sample processed in 2.15s, ETA: 1.70 min\n",
      "[1135/1181] Sample processed in 2.05s, ETA: 1.66 min\n",
      "[1136/1181] Sample processed in 2.01s, ETA: 1.62 min\n",
      "[1137/1181] Sample processed in 2.09s, ETA: 1.59 min\n",
      "[1138/1181] Sample processed in 2.54s, ETA: 1.55 min\n",
      "[1139/1181] Sample processed in 2.43s, ETA: 1.52 min\n",
      "[1140/1181] Sample processed in 1.89s, ETA: 1.48 min\n",
      "[1141/1181] Sample processed in 2.05s, ETA: 1.44 min\n",
      "[1142/1181] Sample processed in 2.38s, ETA: 1.41 min\n",
      "[1143/1181] Sample processed in 2.52s, ETA: 1.37 min\n",
      "[1144/1181] Sample processed in 2.61s, ETA: 1.34 min\n",
      "[1145/1181] Sample processed in 2.65s, ETA: 1.30 min\n",
      "[1146/1181] Sample processed in 2.27s, ETA: 1.26 min\n",
      "[1147/1181] Sample processed in 2.09s, ETA: 1.23 min\n",
      "[1148/1181] Sample processed in 1.82s, ETA: 1.19 min\n",
      "[1149/1181] Sample processed in 2.24s, ETA: 1.15 min\n",
      "[1150/1181] Sample processed in 2.75s, ETA: 1.12 min\n",
      "[1151/1181] Sample processed in 1.22s, ETA: 1.08 min\n",
      "[1152/1181] Sample processed in 2.31s, ETA: 1.05 min\n",
      "[1153/1181] Sample processed in 2.81s, ETA: 1.01 min\n",
      "[1154/1181] Sample processed in 2.57s, ETA: 0.97 min\n",
      "[1155/1181] Sample processed in 2.08s, ETA: 0.94 min\n",
      "[1156/1181] Sample processed in 2.51s, ETA: 0.90 min\n",
      "[1157/1181] Sample processed in 2.68s, ETA: 0.87 min\n",
      "[1158/1181] Sample processed in 2.34s, ETA: 0.83 min\n",
      "[1159/1181] Sample processed in 2.25s, ETA: 0.79 min\n",
      "[1160/1181] Sample processed in 1.92s, ETA: 0.76 min\n",
      "[1161/1181] Sample processed in 1.90s, ETA: 0.72 min\n",
      "[1162/1181] Sample processed in 0.77s, ETA: 0.69 min\n",
      "[1163/1181] Sample processed in 2.49s, ETA: 0.65 min\n",
      "[1164/1181] Sample processed in 1.99s, ETA: 0.61 min\n",
      "[1165/1181] Sample processed in 2.56s, ETA: 0.58 min\n",
      "[1166/1181] Sample processed in 2.55s, ETA: 0.54 min\n",
      "[1167/1181] Sample processed in 1.75s, ETA: 0.51 min\n",
      "[1168/1181] Sample processed in 2.54s, ETA: 0.47 min\n",
      "[1169/1181] Sample processed in 2.99s, ETA: 0.43 min\n",
      "[1170/1181] Sample processed in 2.21s, ETA: 0.40 min\n",
      "[1171/1181] Sample processed in 1.92s, ETA: 0.36 min\n",
      "[1172/1181] Sample processed in 1.88s, ETA: 0.32 min\n",
      "[1173/1181] Sample processed in 2.35s, ETA: 0.29 min\n",
      "[1174/1181] Sample processed in 2.08s, ETA: 0.25 min\n",
      "[1175/1181] Sample processed in 2.19s, ETA: 0.22 min\n",
      "[1176/1181] Sample processed in 2.08s, ETA: 0.18 min\n",
      "[1177/1181] Sample processed in 2.51s, ETA: 0.14 min\n",
      "[1178/1181] Sample processed in 2.08s, ETA: 0.11 min\n",
      "[1179/1181] Sample processed in 2.38s, ETA: 0.07 min\n",
      "[1180/1181] Sample processed in 2.61s, ETA: 0.04 min\n",
      "[1181/1181] Sample processed in 2.39s, ETA: 0.00 min\n",
      "\n",
      "All samples processed. Total time: 42.66 min\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# import time\n",
    "\n",
    "# def load_json(file_path):\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#         return json.load(file)\n",
    "\n",
    "# def save_to_jsonl(file_path, data):\n",
    "#     with open(file_path, \"a\", encoding=\"utf-8\") as f: \n",
    "#         f.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# def generate_response(instruction_text, input_text, max_tokens):\n",
    "#     FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "#     inputs = tokenizer(\n",
    "#     [\n",
    "#         alpaca_prompt.format(\n",
    "#             instruction_text, # instruction\n",
    "#             input_text, # input\n",
    "#             \"\", # output - leave this blank for generation!\n",
    "#         )\n",
    "#     ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "#     outputs = model.generate(**inputs, \n",
    "#                              max_new_tokens=max_tokens, \n",
    "#                              use_cache=True,)\n",
    "#     decoded_outputs = tokenizer.batch_decode(outputs)\n",
    "\n",
    "#     response_texts = [output.split(\"### Response:\\n\")[-1].strip() for output in decoded_outputs]\n",
    "\n",
    "#     return response_texts[0].replace(\"<|eot_id|>\", \"\")\n",
    "\n",
    "# # 실행 \n",
    "# input_json_paths = [\"/data/jaesung/llm_for_diabetes/src/model/unsloth/test_dataset/data_classification_test.json\",\n",
    "# \"/data/jaesung/llm_for_diabetes/src/model/unsloth/test_dataset/data_generation_test.json\"]\n",
    "# output_json_path = \"/data/jaesung/llm_for_diabetes/src/trial/model_response/model_output.jsonl\"\n",
    "\n",
    "# data = []\n",
    "# for json_path in input_json_paths:\n",
    "#     data.extend(load_json(json_path))\n",
    "\n",
    "# start_idx = 657\n",
    "\n",
    "# start_time = time.time()\n",
    "# total_samples = len(data)\n",
    "# for idx, item in enumerate(data[start_idx:], start=start_idx):\n",
    "#     sample_start_time = time.time()\n",
    "\n",
    "#     input_text = item.get(\"input\", \"\")\n",
    "#     instruction = item.get(\"instruction\", \"\")\n",
    "\n",
    "#     try:\n",
    "#         model_output_128 = generate_response(instruction, input_text, 128)\n",
    "#         model_output_1024 = generate_response(instruction, input_text, 1024)\n",
    "\n",
    "#         # 예외 발생 시 저장하지 않음\n",
    "#         if model_output_128 is not None and model_output_1024 is not None:\n",
    "#             output_data = item.copy()\n",
    "#             output_data.update({\n",
    "#                 \"model_output_128\": model_output_128,\n",
    "#                 \"model_output_1024\": model_output_1024,\n",
    "#             })\n",
    "#             save_to_jsonl(output_json_path, output_data)\n",
    "#         else:\n",
    "#             print(f\"[WARNING] Skipping sample {idx+1}/{total_samples} due to generation failure.\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] Skipping sample {idx+1}/{total_samples} due to unexpected error: {str(e)}\")\n",
    "\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     avg_time_per_sample = elapsed_time / (idx + 1) \n",
    "#     remaining_samples = total_samples - (idx + 1)\n",
    "#     estimated_remaining_time = remaining_samples * avg_time_per_sample\n",
    "\n",
    "#     print(f\"[{idx+1}/{total_samples}] Sample processed in {time.time() - sample_start_time:.2f}s, ETA: {estimated_remaining_time/60:.2f} min\")\n",
    "\n",
    "# print(f\"\\nAll samples processed. Total time: {(time.time() - start_time)/60:.2f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env_kernel",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
