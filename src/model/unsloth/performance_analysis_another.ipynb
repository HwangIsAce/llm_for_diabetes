{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n",
      "2025-02-06 22:41:38.424362: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-06 22:41:38.438839: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738849298.456275 3563688 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738849298.461501 3563688 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-06 22:41:38.481004: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/data/jaesung/anaconda3/envs/meal/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:568: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pad_token_id` explicitly as `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aae6f5e35ec4c82bb65bc4da09156fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# huggingface model load\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "tokenizer = transformers.LlamaTokenizer.from_pretrained('chaoyi-wu/PMC_LLAMA_7B')\n",
    "model = transformers.LlamaForCausalLM.from_pretrained('chaoyi-wu/PMC_LLAMA_7B')\n",
    "model.cuda()  # move the model to GPU\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token  # 또는 tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_input = (\n",
    "#     'Below is an instruction that describes a task, paired with an input that provides further context.'\n",
    "#     'Write a response that appropriately completes the request.\\n\\n'\n",
    "#     '### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:'\n",
    "# )\n",
    "\n",
    "# example = {\n",
    "#     \"instruction\": \"You're a doctor, kindly address the medical queries according to the patient's account. Answer with the best option directly.\",\n",
    "#     \"input\": (\n",
    "#         \"###Question: A 23-year-old pregnant woman at 22 weeks gestation presents with burning upon urination. \"\n",
    "#         \"She states it started 1 day ago and has been worsening despite drinking more water and taking cranberry extract. \"\n",
    "#         \"She otherwise feels well and is followed by a doctor for her pregnancy. \"\n",
    "#         \"Her temperature is 97.7°F (36.5°C), blood pressure is 122/77 mmHg, pulse is 80/min, respirations are 19/min, and oxygen saturation is 98% on room air.\"\n",
    "#         \"Physical exam is notable for an absence of costovertebral angle tenderness and a gravid uterus. \"\n",
    "#         \"Which of the following is the best treatment for this patient?\"\n",
    "#         \"###Options: A. Ampicillin B. Ceftriaxone C. Doxycycline D. Nitrofurantoin\"\n",
    "#     )\n",
    "# }\n",
    "# input_str = [prompt_input.format_map(example)]\n",
    "\n",
    "# model_inputs = tokenizer(\n",
    "#     input_str,\n",
    "#     return_tensors='pt',\n",
    "#     padding=True,\n",
    "# )\n",
    "\n",
    "# # print( f\"\\033[32mmodel_inputs\\033[0m: { model_inputs }\" )\n",
    "\n",
    "\n",
    "# topk_output = model.generate(\n",
    "#     model_inputs.input_ids.cuda(),\n",
    "#     max_new_tokens=1000,\n",
    "#     top_k=5\n",
    "# )\n",
    "# output_str = tokenizer.batch_decode(topk_output)\n",
    "# print('model predict: ', output_str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: daily_diets, Sampled: 25\n",
      "{'dataset': 'diabetes_food_hub', 'split_data': 'test', 'task': 'daily_diets', 'instruction': 'Design a daily dietary plan featuring a particular ingredient.', 'input': 'Create a diet that includes Chinese five-spice powder.', 'output': '{\"Breakfast\": \"Spinach, Tomato and Feta Cheese Baked Egg\", \"Lunch\": \"Turkey Meatball \\\\u201cWonton\\\\u201d Soup with Bok Choy & Carrots\", \"Dinner\": \"Roasted Sweet Potatoes with Lemon-Dill Yogurt Sauce\"}', 'text_length': 305, '__index_level_0__': 28288}\n",
      "{'dataset': 'diabetes_food_hub', 'split_data': 'test', 'task': 'daily_diets', 'instruction': 'Create a daily meal plan that incorporates a given ingredient.', 'input': 'Create a diet that includes lower sodium soy sauce.', 'output': '{\"Breakfast\": \"Curried Chickpea Stew with Roasted Vegetables\", \"Lunch\": \"Cranberry Almond Spinach Salad\", \"Dinner\": \"Turkey Meatball \\\\u201cWonton\\\\u201d Soup with Bok Choy & Carrots\"}', 'text_length': 285, '__index_level_0__': 27690}\n",
      "{'dataset': 'diabetes_food_hub', 'split_data': 'test', 'task': 'daily_diets', 'instruction': 'Recommend the next meal that ensures a nutritionally balanced diet, considering the previous meal.', 'input': 'Ensure the daily carbohydrate intake does not exceed 72.0g, protein intake is at least 56.0g, and fat intake does not exceed 17.0g.', 'output': '{\"Breakfast\": \"Salmon and Rice Bowls\", \"Lunch\": \"Colorful Pasta Salad\", \"Dinner\": \"Turkey Meatball \\\\u201cWonton\\\\u201d Soup with Bok Choy & Carrots\"}', 'text_length': 367, '__index_level_0__': 27627}\n",
      "{'dataset': 'diabetes_food_hub', 'split_data': 'test', 'task': 'daily_diets', 'instruction': 'Suggest a suitable next meal to maintain dietary balance based on the prior meal.', 'input': 'Create a diet that includes cheddar cheese(reduced-fat, shredded).', 'output': '{\"Breakfast\": \"Garlic Pita Crisps\", \"Lunch\": \"Chicken and Spinach Enchiladas\", \"Dinner\": \"Watermelon Quinoa Salad\"}', 'text_length': 262, '__index_level_0__': 28443}\n",
      "{'dataset': 'diabetes_food_hub', 'split_data': 'test', 'task': 'daily_diets', 'instruction': 'Create a daily meal plan that incorporates a given ingredient.', 'input': 'Create a diet that includes diced cucumber.', 'output': '{\"Breakfast\": \"Mediterranean Chicken Pita\", \"Lunch\": \"Easy Garlic Bok Choy\", \"Dinner\": \"Chicken Tacos\"}', 'text_length': 208, '__index_level_0__': 27645}\n",
      "Task: generation, Sampled: 25\n",
      "{'dataset': 'meddialog', 'split_data': 'test', 'task': 'generation', 'instruction': \"As a medical AI assistant, your role is to generate an accurate and concise response to the patient's query, simulating a doctor's reply. Ensure that your response is both medically sound and relevant to the question.\", 'input': 'Hello doctor,  I have a pimple-like bump on my toe. When I tried to pop it I noticed that it was hard. It hurts when I walk and I now have three bumps. Two of them are flat now.', 'output': 'Hello,  Welcome to icliniq.com. We appreciate your concern about your skin eruption. Before I am able to help you in this regard, I would like to have the following additional information: What was the location of the original and recent bumps? Specifically, were they on the upper side of the toe near the hairy area or over the soles? What has been the duration of the first bump? Can you post a photograph of the same? In case the bumps are on the upper side of the toe, in particular, if they seem to be arising from or near the hair follicles, then they could indicate furuncles, which are deep-seated infections of the hair follicle and though they can arise in healthy individuals, they are a little more common in diabetics. They are painful, warm and become hard, but often show a visible yellowish pus point. In that case, we would have to suggest a short course of oral antibiotics and anti-inflammatory medicines and suggest an antibiotic cream. In case they are on the sole i.e. undersurface of the toes, then they could be corns. But corns typically are of long duration, appear over pressure prone areas of the toe and do not subside on their own. They also hurt on walking. They can be treated medically as well as surgically. Thus, to be able to guide you for the best treatment, I need to have your answers to my three questions raised above.', 'text_length': 1754, '__index_level_0__': 27292}\n",
      "{'dataset': 'meddialog', 'split_data': 'test', 'task': 'generation', 'instruction': \"As a medical AI assistant, your role is to generate an accurate and concise response to the patient's query, simulating a doctor's reply. Ensure that your response is both medically sound and relevant to the question.\", 'input': 'Hello doctor, I have a problem with my foreskin swelling and also experiencing pain. I am a 37-year-old male and had my circumcision done seven years back. There were some inflammation and occasional pain through these years but recently have been experiencing more inflammation and pain in that area. Please advise on the treatment for this. I am currently using anti-inflammatory medication and a corticosteriod cream to the inflamed area. Siloderm mixi, Augmentin 625 mg and Lytix-D tablets.', 'output': 'Hi. The treatment you are taking is perfect. Since how many days are you taking these current medications? Based on the information you already gave, I recommend you to add on to this treatment. Xylocaine jelly 2% or Lidocaine spray local application twice a day, tablet Pregabalin 75 mg OD for four weeks and see for the results. Any history of exposure to a new partner or unprotected sex? Are you a diabetic? Have you ever been checked for the same? It will be great if you can upload a picture depicting your swollen glans. I am asking the picture because the swelling and inflammation you are talking off may not be actually the same, instead, you might be having hyperesthesia or neurogenic pain. So, in that case, we might have to revise the treatment.', 'text_length': 1470, '__index_level_0__': 27278}\n",
      "{'dataset': 'meddialog', 'split_data': 'test', 'task': 'generation', 'instruction': 'Generate a medically accurate and precise doctor’s response based on the given patient’s query. Your task as a medical AI assistant is to ensure that the response is professional and aligned with medical guidelines.', 'input': 'Hello doctor, I have breathlessness while walking or taking stairs, chest congestion at times, and sleeplessness. I am diabetic and take Insulin twice a day. Please find the attached reports of ECG, echo, and angiography. Is angioplasty required? Can blockage be tackled with medicines alone?', 'output': 'Hello. I have seen the reports (attachment removed to protect patient identity). Hope this helps you and get back if you have any doubts. For further queries consult a cardiologist online --> https://www.icliniq.com/ask-a-doctor-online/cardiologist', 'text_length': 755, '__index_level_0__': 27280}\n",
      "{'dataset': 'meddialog', 'split_data': 'test', 'task': 'generation', 'instruction': \"Generate a comprehensive medical response based on the patient's query.\", 'input': 'Hi doctor, I am a 66 year old female. I am suffering from hypertension and diabetes since 20 years. I have got an implemented stent a month ago. I am taking medicines for the all above I have mentioned. In my recent blood count, my WBC is 70000. Why?', 'output': 'Hi. Based on your query, my opinion is as follows. Revert back with the details mentioned above to a hematologist online --> https://www.icliniq.com/ask-a-doctor-online/hematologist', 'text_length': 502, '__index_level_0__': 27283}\n",
      "{'dataset': 'meddialog', 'split_data': 'test', 'task': 'generation', 'instruction': 'Generate a medically accurate and precise doctor’s response based on the given patient’s query. Your task as a medical AI assistant is to ensure that the response is professional and aligned with medical guidelines.', 'input': 'Hello doctor, I have suffered from AS since 10 years. I manage it by diet, walking, and a few simple exercises. But since three months, I am suffering from right leg pain with neck pain, right eye redness and pain (HLA-B27 positive) and getting some pain relief tablets along with B12 injections, and Vitamin D3 60K tablets. I am also diabetic since 10 years. Please suggest better medicines.', 'output': 'Hello. Ankylosing spondylitis is a chronic problem and lifelong. However, treatment is very important because the fusion of joints may cause problems with the movements of the body. Redness of eye is called scleritis and can occur in AS. NSAID (non-steroidal anti-inflammatory drugs) are the first line drugs and if the patient fails to improve with them, then biologics are given. You need to get evaluated and examined by a rheumatologist for disease activity to look at which treatment you will need at this point. The activity is calculated by physically examining the patient and doing few investigations like ESR (erythrocyte sedimentation rate) and CRP (C-reactive protein). For more information consult a rheumatologist online --> https://www.icliniq.com/ask-a-doctor-online/rheumatologist', 'text_length': 1404, '__index_level_0__': 27263}\n",
      "Task: alternative_diet, Sampled: 25\n",
      "{'dataset': 'diabetes_food_hub', 'split_data': 'test', 'task': 'alternative_diet', 'instruction': 'Design a daily dietary plan featuring a particular ingredient.', 'input': 'Cheese, Monterey', 'output': \"Brown Rice and Pinto Bean Bowl with Chicken and Pico de Gallo is recommended. The reason is The 'Brown Rice and Pinto Bean Bowl with Chicken and Pico de Gallo' complements 'Cheese, Monterey' by providing a balanced combination of protein, carbohydrates, and essential vitamins and minerals. It can help address the deficiencies in the consumed cheese while offering a healthier and more nutritious option. One cautionary point is that individuals should be mindful of the sodium content in the pico de\", 'text_length': 579, '__index_level_0__': 30735}\n",
      "{'dataset': 'diabetes_food_hub', 'split_data': 'test', 'task': 'alternative_diet', 'instruction': 'Create a daily meal plan that incorporates a given ingredient.', 'input': 'Cornmeal mush, fat not added in cooking', 'output': 'Greek Orzo Salad with Peas, Lemon and Kalamata Olives is recommended. The reason is The Greek Orzo Salad with Peas, Lemon and Kalamata Olives complements Cornmeal mush by providing a good source of protein, healthy fats, fiber, and various vitamins and minerals that are lacking in the Cornmeal mush. However, it is important to note that the salad may contain added sodium from ingredients like olives and feta cheese, so individuals watching their sodium intake should be', 'text_length': 574, '__index_level_0__': 31105}\n",
      "{'dataset': 'diabetes_food_hub', 'split_data': 'test', 'task': 'alternative_diet', 'instruction': 'Suggest a full-day diet that includes a specified ingredient in the meals.', 'input': 'Cheese, cream', 'output': \"Herbed Soft Scrambled Eggs on Toast is recommended. The reason is 'Herbed Soft Scrambled Eggs on Toast' complements 'Cheese, cream' as it provides a balanced mix of protein, carbohydrates, and fats along with added nutrients like potassium and fiber. However, individuals should be cautious of the cholesterol content in the dish, especially if they have dietary restrictions or health concerns related to cholesterol intake.\", 'text_length': 512, '__index_level_0__': 30600}\n",
      "{'dataset': 'diabetes_food_hub', 'split_data': 'test', 'task': 'alternative_diet', 'instruction': 'Suggest a full-day diet that includes a specified ingredient in the meals.', 'input': 'Wine, table, red', 'output': 'Mediterranean Lentil Soup is recommended. The reason is Mediterranean Lentil Soup complements Wine, table, red by providing a good source of protein, fiber, potassium, and other essential nutrients that are lacking in the consumed food. However, caution should be taken with the sodium content in the soup, as it may be high for individuals with certain dietary restrictions.', 'text_length': 465, '__index_level_0__': 30343}\n",
      "{'dataset': 'diabetes_food_hub', 'split_data': 'test', 'task': 'alternative_diet', 'instruction': 'Design a daily dietary plan featuring a particular ingredient.', 'input': 'Cream, half and half', 'output': \"Orange Cream Italian Soda is recommended. The reason is 'Orange Cream Italian Soda' complements 'Cream, half and half' by providing a refreshing and flavorful alternative with lower calories and sugar. However, caution should be taken as it may contain artificial sweeteners which some individuals may want to avoid.\", 'text_length': 398, '__index_level_0__': 30365}\n",
      "Task: summarization, Sampled: 25\n",
      "{'dataset': 'pubmed', 'split_data': 'test', 'task': 'summarization', 'instruction': 'Extract the key insights from the given PubMed article and organize them into the following structured sections: Objective, Methods, Results, and Conclusion.', 'input': 'A 56-year-old male with a history of type 2 diabetes mellitus and hypertension presented with complaints of intractable burning paresthesia of bilateral extremities, hyperesthesia, and unintentional weight loss. Other symptoms included anorexia, orthostatic hypotension, bowel and bladder dysfunction, and painful burning sensation on the soles of the feet. Emotional lability and a melancholy mood were noted. After laboratory tests including CSF analysis, biopsies, and three months of treatment that did not bring relief, the patient was diagnosed with diabetic neuropathic cachexia (DNC). While his diabetes remained well-controlled, the patient was unable to improve his nutritional status and his condition progressively worsened, and he later died from cardiac arrest. DNC is an important differential diagnosis to consider in patients with neuropathy and weight loss. Early detection of DNC in conjunction with weight loss investigation may reduce pain and speed recovery with a good prognosis.', 'output': 'A Case Report of a Rare Debilitating Complication of Diabetes Neuropathic Cachexia.', 'text_length': 1242, '__index_level_0__': 27389}\n",
      "{'dataset': 'pubmed', 'split_data': 'test', 'task': 'summarization', 'instruction': 'Summarize the provided PubMed article by structuring the main points into four key fields: Objective, Methods, Results, and Conclusion.', 'input': 'Epilepsy is a prevalent and frequently devastating neurological disorder defined by recurring spontaneous seizures caused by aberrant electrical activity in the brain. Over ten million people worldwide suffer from drug-resistant epilepsy. This severe condition requires novel treatment approaches. Both oxidative and nitrosative stress are thought to have a role in the etiology of epilepsy. Liraglutide is a glucagon-like peptide-1 (GLP-1) analogue that is used to treat type-2 diabetes mellitus. According to recent studies, Liraglutide also shows neuroprotective properties, improving memory retention and total hippocampus pyramidal neuronal population in mice. The purpose of this investigation was to determine the anti-seizure and anti-oxidative effects of liraglutide in a pentylenetetrazole (PTZ)-induced rat model of epilepsy. 48 rats were randomly assigned to two groups those who had electroencephalography (EEG) recordings and those who underwent behavioral assessment. Rats received either intraperitoneal (IP) liraglutide at two different dosages (3-6 mgkg) or a placebo, followed by pentylenetetrazole (IP). To determine if liraglutide has anti-seizure characteristics, we examined seizure activity in rats using EEG, the Racine convulsion scale (RCS), the time of first myoclonic jerk (FMJ), and MDA, SOD, TNF-α, IL-1β and GAD-67 levels. The mean EEG spike wave percentage score was reduced from 75.8% (placebo) to 59.4% (lower-dose) and 41.5% (higher-dose). FMJ had increased from a mean of 70.6 s (placebo) to 181.2 s (lower-dose) and 205.2 s (higher-dose). RCS was reduced from a mean of 5.5 (placebo) to 2.7 (lower-dose) and 2.4 (higher-dose). Liraglutide (3 and 6 mgkg i.p.) successfully decreased the spike percentages and RCS associated with PTZ induced epilepsy, as well as considerably decreased MDA, TNF-α, IL-1β and elevated SOD, GAD-67 levels in rat brain. Liraglutide significantly decreased seizure activity at both dosages when compared to control, most likely due to its anti-oxidant and anti-inflammatory properties. The potential clinical role of liraglutide as an anti-seizure medication should be further explored.', 'output': 'The Anti-Seizure Effect of Liraglutide on Ptz-Induced Convulsions Through its Anti-Oxidant and Anti-Inflammatory Properties.', 'text_length': 2410, '__index_level_0__': 27365}\n",
      "{'dataset': 'pubmed', 'split_data': 'test', 'task': 'summarization', 'instruction': 'Write a summary of the article that captures the main ideas and significant details.', 'input': 'This study assessed impaired fasting glucose and associated factors among perinatally HIV-infected adolescents and youths in Dar es salaam Tanzania. Impaired fasting glucose is a marker of heightened risk for developing type 2 diabetes among perinatally HIV-infected individuals. Therefore, identifying individuals at this stage is crucial to enable early intervention. Therefore, we assessed impaired fasting glucose (IFG) and associated factors among perinatally HIV-infected population in Dar es salaam Tanzania. A cross-sectional study was conducted among 152 adolescents and youth attending HIV clinic at Muhimbili National Hospital and Infectious Disease Centre from July to August 2020. Fasting blood glucose (>8 hours) was measured using Of the 152 participants, the majority were male (n8354.6%), and the median age was 15(14-18) years. Overweight or obesity was prevalent in 16.4%, while more than one in ten (13.2%) had high blood pressure (≥14990mmHg). All participants were on antiretroviral therapy (ART) 46% had used medication for over ten years, and about one in three had poor medication adherence. Among the recruited participants, 29% had impaired fasting glucose. The odds of IFG were two times higher in males compared to females (PR, 2.07, 95% CI 1.19 -3.59 p0.001). Moreover, we found with every increase of Interleukin 6 biomarker there was a 1.01 probability increase of impaired fasting glucose (PR, 1.01, 95% CI 1.00 - 1.02 p0.003). About one in three perinatally HIV-infected youths had impaired fasting glucose in Dar es Salaam, Tanzania, with males bearing the biggest brunt. Moreover, with every increase of 1.101 of the probability of having IFG increased. This calls for urgent measures to interrupt the progression to diabetes disease and prevent the dual burden of disease for this uniquely challenged population.', 'output': 'Impaired fasting glucose levels among perinatally HIV-infected adolescents and youths in Dar es Salaam, Tanzania.', 'text_length': 2046, '__index_level_0__': 27341}\n",
      "{'dataset': 'pubmed', 'split_data': 'test', 'task': 'summarization', 'instruction': 'Write a summary of the article that captures the main ideas and significant details.', 'input': 'Indoxyl sulfate is a metabolite of tryptophan and its urinary level reflects the status of bacterial flora in the intestine. Indoxyl sulfate possesses prooxidant properties and is implicated in various diseases including chronic kidney disease and cardiovascular diseases. However, the relation of urinary indoxyl sulfate to oxidative stress is not known. The association of urinary indoxyl sulfate levels with urinary levels of oxidative stress markers, 15-isoprostane F Urinary levels of indoxyl sulfate, pteridines, and 15-isoprostane F Urinary indoxyl sulfate levels showed associations with urinary levels of oxidative stress markers, and the associations were independent of age, sex, insulin therapy for diabetes, body mass index, blood pressure, glycemic status, renal function, smoking, and alcohol drinking. Indoxyl sulfate appears to be an important determinant of redox balance in patients with diabetes.', 'output': 'Evidence for Indoxyl Sulfate as an Inducer of Oxidative Stress in Patients With Diabetes.', 'text_length': 1089, '__index_level_0__': 27353}\n",
      "{'dataset': 'pubmed', 'split_data': 'test', 'task': 'summarization', 'instruction': 'Generate a concise summary of the given PubMed article, categorizing the content into Objective, Methods, Results, and Conclusion for clarity.', 'input': 'Metformin is a common drug for the management of type 2 diabetes mellitus however, it causes various adverse gastrointestinal effects, especially after prolonged treatment. It is thus of interest to identify an adjuvant treatment that synergizes with the efficacy of metformin while mitigating its adverse effects. Since previous evidence supports that the gut microbiota is a target of metformin, this study investigated the beneficial effect and mechanism of the coadministration of probiotics with metformin in the management of type 2 diabetes mellitus by conducting a 3-month randomized, double-blind, placebo-controlled clinical trial (', 'output': 'Adjunctive Probio-X Treatment Enhances the Therapeutic Effect of a Conventional Drug in Managing Type 2 Diabetes Mellitus by Promoting Short-Chain Fatty Acid-Producing Bacteria and Bile Acid Pathways.', 'text_length': 984, '__index_level_0__': 27399}\n",
      "Task: re, Sampled: 25\n",
      "{'dataset': 'ddi', 'split_data': 'test', 'task': 're', 'instruction': \"Analyze the sentence with two drugs labeled as @DRUG_A$ and @DRUG_B$. Extract the interaction between @DRUG_A$ and @DRUG_B$ from the input sentence by selecting only one of the following options: 'DDI-effect', 'DDI-mechanism', 'DDI-advise', 'DDI-false', and 'DDI-int'. 'DDI-effect': Choose this when the interaction describes an effect or a pharmacodynamic mechanism. 'DDI-mechanism': Choose this for interactions explained by pharmacokinetic mechanisms. 'DDI-advise': Choose this when the sentence provides a recommendation or advice about the drug interaction. 'DDI-false': Choose this if there is no actual drug-drug interaction in the sentence. 'DDI-int': Choose this when a drug-drug interaction is mentioned without additional detail.\", 'input': 'TRENTAL has been used concurrently with @DRUG_A$, beta blockers, digitalis, @DRUG_B$, antidiabetic agents, and antiarrhythmics, without observed problems.', 'output': 'DDI-false', 'text_length': 903, '__index_level_0__': 27217}\n",
      "{'dataset': 'ddi', 'split_data': 'test', 'task': 're', 'instruction': \"Analyze the sentence with two drugs labeled as @DRUG_A$ and @DRUG_B$. Extract the interaction between @DRUG_A$ and @DRUG_B$ from the input sentence by selecting only one of the following options: 'DDI-effect', 'DDI-mechanism', 'DDI-advise', 'DDI-false', and 'DDI-int'. 'DDI-effect': Choose this when the interaction describes an effect or a pharmacodynamic mechanism. 'DDI-mechanism': Choose this for interactions explained by pharmacokinetic mechanisms. 'DDI-advise': Choose this when the sentence provides a recommendation or advice about the drug interaction. 'DDI-false': Choose this if there is no actual drug-drug interaction in the sentence. 'DDI-int': Choose this when a drug-drug interaction is mentioned without additional detail.\", 'input': 'Certain drugs, including nonsteroidal anti-inflammatory agents (NSAIDs), @DRUG_A$, @DRUG_B$, and non-selective beta-adrenergic-blocking agents may potentiate the hypoglycemic action of Starlix and other oral antidiabetic drugs.', 'output': 'DDI-false', 'text_length': 976, '__index_level_0__': 27191}\n",
      "{'dataset': 'ddi', 'split_data': 'test', 'task': 're', 'instruction': \"Analyze the sentence with two drugs labeled as @DRUG_A$ and @DRUG_B$. Extract the interaction between @DRUG_A$ and @DRUG_B$ from the input sentence by selecting only one of the following options: 'DDI-effect', 'DDI-mechanism', 'DDI-advise', 'DDI-false', and 'DDI-int'. 'DDI-effect': Choose this when the interaction describes an effect or a pharmacodynamic mechanism. 'DDI-mechanism': Choose this for interactions explained by pharmacokinetic mechanisms. 'DDI-advise': Choose this when the sentence provides a recommendation or advice about the drug interaction. 'DDI-false': Choose this if there is no actual drug-drug interaction in the sentence. 'DDI-int': Choose this when a drug-drug interaction is mentioned without additional detail.\", 'input': '@DRUG_A$ may interact with alcohol, blood thinners, decongestant drugs (allergy, cold, and sinus medicines), diabetic drugs, @DRUG_B$, norepinephrine, NSAIDs like Aleve or Ibuprofen, and high blood pressure medications.', 'output': 'DDI-int', 'text_length': 966, '__index_level_0__': 27190}\n",
      "{'dataset': 'ddi', 'split_data': 'test', 'task': 're', 'instruction': \"Analyze the sentence with two drugs labeled as @DRUG_A$ and @DRUG_B$. Extract the interaction between @DRUG_A$ and @DRUG_B$ from the input sentence by selecting only one of the following options: 'DDI-effect', 'DDI-mechanism', 'DDI-advise', 'DDI-false', and 'DDI-int'. 'DDI-effect': Choose this when the interaction describes an effect or a pharmacodynamic mechanism. 'DDI-mechanism': Choose this for interactions explained by pharmacokinetic mechanisms. 'DDI-advise': Choose this when the sentence provides a recommendation or advice about the drug interaction. 'DDI-false': Choose this if there is no actual drug-drug interaction in the sentence. 'DDI-int': Choose this when a drug-drug interaction is mentioned without additional detail.\", 'input': '@DRUG_A$: A clinical study in 6 insulin-dependent diabetic patients demonstrated no effect of EXTRANEAL on insulin absorption from the peritoneal cavity or on insulins ability to control blood glucose when insulin was administered intraperitoneally with @DRUG_B$.', 'output': 'DDI-false', 'text_length': 1012, '__index_level_0__': 27194}\n",
      "{'dataset': 'ddi', 'split_data': 'test', 'task': 're', 'instruction': \"Analyze the sentence with two drugs labeled as @DRUG_A$ and @DRUG_B$. Extract the interaction between @DRUG_A$ and @DRUG_B$ from the input sentence by selecting only one of the following options: 'DDI-effect', 'DDI-mechanism', 'DDI-advise', 'DDI-false', and 'DDI-int'. 'DDI-effect': Choose this when the interaction describes an effect or a pharmacodynamic mechanism. 'DDI-mechanism': Choose this for interactions explained by pharmacokinetic mechanisms. 'DDI-advise': Choose this when the sentence provides a recommendation or advice about the drug interaction. 'DDI-false': Choose this if there is no actual drug-drug interaction in the sentence. 'DDI-int': Choose this when a drug-drug interaction is mentioned without additional detail.\", 'input': 'The following are examples of substances that may increase the blood-glucose-lowering effect and susceptibility to hypoglycemia: oral antidiabetes products, ACE inhibitors, disopyramide, fibrates, @DRUG_A$, MAO inhibitors, @DRUG_B$, salicylates, somatostatin analog (e.g., octreotide), sulfonamide antibiotics.', 'output': 'DDI-false', 'text_length': 1059, '__index_level_0__': 27216}\n",
      "Task: qa1, Sampled: 25\n",
      "{'dataset': 'medqa', 'split_data': 'test', 'task': 'qa1', 'instruction': 'You are given a multiple-choice medical question with four possible answers. Your task is to identify and select the single most appropriate answer. based on your medical knowledge. Provide your response as a single letter: A, B, C, or D.', 'input': 'A 64-year-old woman presents to the surgical oncology clinic as a new patient for evaluation of recently diagnosed breast cancer. She has a medical history of type 2 diabetes mellitus for which she takes metformin. Her surgical history is a total knee arthroplasty 7 years ago. Her family history is insignificant. Physical examination is notable for an irregular nodule near the surface of her right breast. Her primary concern today is which surgical approach will be chosen to remove her breast cancer. Which of the following procedures involves the removal of a portion of a breast? Please select one of the following: A) Vasectomy, B) Mastectomy, C) Lumpectomy, D) Laminectomy.', 'output': 'C) Lumpectomy', 'text_length': 933, '__index_level_0__': 26769}\n",
      "{'dataset': 'medqa', 'split_data': 'test', 'task': 'qa1', 'instruction': 'You are given a multiple-choice medical question with four possible answers. Your task is to identify and select the single most appropriate answer. based on your medical knowledge. Provide your response as a single letter: A, B, C, or D.', 'input': 'A 57-year-old man with diabetes mellitus type 2 presents for a routine follow-up. His blood glucose levels have been inconsistently controlled with metformin and lifestyle modifications since his diagnosis 3 years ago. He is currently is on metformin and diet control with exercise. The vital signs are as follows a blood pressure of 122/82 mm Hg, a pulse of 83/min, a temperature of 36.3°C (97.4°F), and a respiratory rate of 10/min. At this current visit, the urinalysis results are as follows:\\npH 6.2\\nColor light yellow\\nRBC none\\nWBC none\\nProtein 4+\\nCast RBC casts\\nGlucose absent\\nCrystal none\\nKetone absent\\nNitrite absent\\n24-h urine protein excretion 3.7 g\\nThe urine albumin loss mapping shows:\\nUrine albumin loss/24h current: 215 mg\\nUrine albumin loss/24h 3 months ago: 28 mg\\nThe blood sugar analysis shows:\\nFasting blood sugar 153 mg/dL\\nPost-prandial blood sugar 225 mg/dL\\nHbA1c 7.4%\\nWhich of the following best describes the expected microscopic finding on renal biopsy? Please select one of the following: A) Normal kidney biopsy; no pathological finding is evident at this time, B) Glomerular hypertrophy with slight glomerular basement membrane thickening, C) Significant global glomerulosclerosis, D) Glomerular basement membrane thickening and mesangial expansion.', 'output': 'D) Glomerular basement membrane thickening and mesangial expansion', 'text_length': 1578, '__index_level_0__': 26851}\n",
      "{'dataset': 'medqa', 'split_data': 'test', 'task': 'qa1', 'instruction': 'You are given a multiple-choice medical question with four possible answers. Your task is to identify and select the single most appropriate answer. based on your medical knowledge. Provide your response as a single letter: A, B, C, or D.', 'input': \"A 72-year-old multiparous woman comes to the physician for the evaluation of episodes of involuntary urine leakage for the past 6 months. She loses small amounts of urine without warning after laughing or sneezing. She also sometimes forgets the names of her grandchildren and friends. She is retired and lives at an assisted-living facility. She has insulin-dependent diabetes mellitus type 2. Her mother received a ventriculoperitoneal shunt around her age. She walks without any problems. Sensation to pinprick and light touch is normal. Which of the following is the primary underlying etiology for this patient's urinary incontinence? Please select one of the following: A) Detrusor-sphincter dyssynergia, B) Urethral hypermobility, C) Impaired detrusor contractility, D) Loss of sphincter control.\", 'output': 'B) Urethral hypermobility', 'text_length': 1066, '__index_level_0__': 26792}\n",
      "{'dataset': 'medqa', 'split_data': 'test', 'task': 'qa1', 'instruction': 'You are given a multiple-choice medical question with four possible answers. Your task is to identify and select the single most appropriate answer. based on your medical knowledge. Provide your response as a single letter: A, B, C, or D.', 'input': \"During the exam of a 2-day-old female neonate you determine that she appears lethargic, cyanotic, and has a coarse tremor of her right arm. The patient's mother explains that she observed what she believed to be seizure-like activity just before you arrived in the room. The mother has a history of type two diabetes mellitus and during childbirth there was a delay in cord clamping. You decide to get electrolytes and a complete blood count to work up this patient. The labs are significant for mild hypoglycemia and a hematocrit of 72%. What is the most effective treatment for this patient's condition? Please select one of the following: A) Partial exchange transfusion with hydration, B) Fluid resuscitation, C) Hydroxyurea, D) Interferon alpha.\", 'output': 'A) Partial exchange transfusion with hydration', 'text_length': 1034, '__index_level_0__': 26808}\n",
      "{'dataset': 'medqa', 'split_data': 'test', 'task': 'qa1', 'instruction': 'You are given a multiple-choice medical question with four possible answers. Your task is to identify and select the single most appropriate answer. based on your medical knowledge. Provide your response as a single letter: A, B, C, or D.', 'input': 'A 49-year-old woman presents to the emergency room with bloody stool and malaise. She developed a fever and acute left lower quadrant abdominal pain earlier in the day. She has had 2 bowel movements with bright red blood. Her past medical history is notable for hyperlipidemia, hypertension, and diabetes mellitus. She takes lovastatin, hydrochlorothiazide, metformin, glyburide, and aspirin. Her temperature is 102.9°F (39.4°C), blood pressure is 101/61 mmHg, pulse is 110/min, and respirations are 22/min. On exam, she is fully alert and oriented. She is tender in the left lower quadrant. A computerized tomography (CT) scan is performed demonstrating acute diverticulitis. She is admitted and started on broad-spectrum antibiotics. 48 hours later, her urine output is significantly decreased. Her abdominal pain has improved but she has started vomiting and appears confused. She has new bilateral lower extremity edema and decreased breath sounds at the lung bases. Laboratory analysis upon admission and 48 hours later is shown below:\\n\\nAdmission:\\nHemoglobin: 11.9 g/dl\\nHematocrit: 34%\\nLeukocyte count: 11,500/mm^3\\nPlatelet count: 180,000/ mm^3\\n\\nSerum:\\nNa+: 141 mEq/L\\nCl-: 103 mEq/L\\nK+: 4.5 mEq/L\\nHCO3-: 23 mEq/L\\nBUN: 21 mg/dL\\nGlucose: 110 mg/dL\\nCreatinine: 0.9 mg/dL\\n\\n48 hours later:\\nHemoglobin: 10.1 g/dl\\nHematocrit: 28%\\nLeukocyte count: 11,500 cells/mm^3\\nPlatelet count: 195,000/ mm^3\\n\\nSerum:\\nNa+: 138 mEq/L\\nCl-: 100 mEq/L\\nK+: 5.1 mEq/L\\nHCO3-: 24 mEq/L\\nBUN: 30 mg/dL\\nGlucose: 120 mg/dL\\nCreatinine: 2.1 mg/dL\\n\\nWhich of the following findings would most likely be seen on urine microscopy? Please select one of the following: A) Hyaline casts, B) Muddy brown casts, C) Waxy casts, D) White blood cell casts.', 'output': 'B) Muddy brown casts', 'text_length': 1971, '__index_level_0__': 26841}\n",
      "Task: qa2, Sampled: 25\n",
      "{'dataset': 'medmcqa', 'split_data': 'test', 'task': 'qa2', 'instruction': 'You are given a multiple-choice medical question with four possible answers. Your task is to identify and select the single most appropriate answer. based on your medical knowledge. Provide your response as a single letter: A, B, C, or D.', 'input': 'A 50-year-old diabetic patient with asymptomatic gallstone (>3 cm) will be best treated by- Please select one of the following: A) Early surgery, B) Bile salt treatment, C) ESWL, D) Waiting till it becomes symptomatic.', 'output': 'A) Early surgery', 'text_length': 472, '__index_level_0__': 26883}\n",
      "{'dataset': 'medmcqa', 'split_data': 'test', 'task': 'qa2', 'instruction': 'You are given a multiple-choice medical question with four possible answers. Your task is to identify and select the single most appropriate answer. based on your medical knowledge. Provide your response as a single letter: A, B, C, or D.', 'input': 'All of the following take part in the pathogenesis of macularedema in diabetic retinopathy except Please select one of the following: A) Retinal pigment epithelium dysfunction, B) Oxidative stress, C) VEGF, D) Increased protein kinase - C.', 'output': 'A) Retinal pigment epithelium dysfunction', 'text_length': 518, '__index_level_0__': 26956}\n",
      "{'dataset': 'medmcqa', 'split_data': 'test', 'task': 'qa2', 'instruction': 'You are given a multiple-choice medical question with four possible answers. Your task is to identify and select the single most appropriate answer. based on your medical knowledge. Provide your response as a single letter: A, B, C, or D.', 'input': 'True about Posttraumatic fat embolism syndrome -a) Fracture mobility is a risk factor b) Associated diabetes pose a riskc) Bradycardia occursd) Thrombocytopeniae) On ABG PaO2 < 60 mm Hg on FIO2 < 0.4 Please select one of the following: A) abcd, B) bcde, C) abde, D) ade.', 'output': 'C) abde', 'text_length': 515, '__index_level_0__': 26890}\n",
      "{'dataset': 'medmcqa', 'split_data': 'test', 'task': 'qa2', 'instruction': 'You are given a multiple-choice medical question with four possible answers. Your task is to identify and select the single most appropriate answer. based on your medical knowledge. Provide your response as a single letter: A, B, C, or D.', 'input': 'A 36 weeks pregnant diabetic female has a non-reactive NST. What should be done next? Please select one of the following: A) Induction of labor, B) LSCS, C) Do NST after 1 hour, D) Proceed to biophysical profile.', 'output': 'D) Proceed to biophysical profile', 'text_length': 483, '__index_level_0__': 26891}\n",
      "{'dataset': 'medmcqa', 'split_data': 'test', 'task': 'qa2', 'instruction': 'You are given a multiple-choice medical question with four possible answers. Your task is to identify and select the single most appropriate answer. based on your medical knowledge. Provide your response as a single letter: A, B, C, or D.', 'input': '68-year-old chandu is a diabetic and presented with black, foul, smelling discharge from the nose. Examination revealed blackish discoloration of the inferior turbinate. The diagnosis is - Please select one of the following: A) Mucormycosis, B) Aspergillosis, C) Infarct of inferior turbinate, D) Foreign body.', 'output': 'A) Mucormycosis', 'text_length': 563, '__index_level_0__': 26863}\n",
      "Task: qa3, Sampled: 25\n",
      "{'dataset': 'pubmedqa', 'split_data': 'test', 'task': 'qa3', 'instruction': 'Choose the correct anser (Yes, No, or Maybe) for the given question based on the proviced context.', 'input': 'Question: Do thermal burn of palate in an elderly diabetic patient? Context: Burns of the oral mucosa may be caused by thermal, mechanical, chemical, electrical or radiation injury. Clinically, these burns can produce localised or diffuse areas of tissue damage depending on the severity and extent of the insult. Most oral thermal burns produce erosions or ulcers on the palate or tongue. A case of palatal burn in a 66-year-old diabetic patient caused by drinking hot cereal is presented. The role of diabetes in causing oral mucosal dysesthesia that predisposed the occurrence of this burn is also discussed.', 'output': 'yes', 'text_length': 712, '__index_level_0__': 27001}\n",
      "{'dataset': 'pubmedqa', 'split_data': 'test', 'task': 'qa3', 'instruction': 'Choose the correct anser (Yes, No, or Maybe) for the given question based on the proviced context.', 'input': 'Question: Is genetic variation within the APPL locus associated with metabolic or inflammatory traits in a healthy White population? Context: APPL1 (adaptor protein containing PH domain, PTB domain and leucine zipper motif 1) is the first identified cytosolic protein that directly binds to adiponectin receptors and mediates cellular responses to adiponectin. We set out to determine whether genetic variation within the APPL locus (encoding APPL1) contributes to insulin resistance, changes in lipid metabolism or inflammatory parameters in a healthy White population. We genotyped 640 healthy subjects with and without a family history of diabetes for the four single nucleotide polymorphisms (SNPs) rs6774584, rs3087684, rs17791685 and rs528035 and performed correlational analyses with metabolic and inflammatory traits. SNPs rs6774584, rs3087684, rs17791685 and rs528035 are representative of the four blocks of high linkage disequilibrium covering a 78-kb genomic locus that harbours the APPL gene. None of these SNPs correlated with anthropometric data (gender, age, body mass index, body fat, waist-hip ratio) or with family history of diabetes. Furthermore, no correlations were found with parameters of insulin sensitivity or insulin secretion. None of the SNPs was correlated with ectopic lipid content or with plasma lipids (non-esterified fatty acids, glycerol, triglycerides, total cholesterol, high-density lipoprotein-, low-density lipoprotein-cholesterol). Moreover, no correlations were detected with leucocyte measures or plasma concentrations of C-reactive protein, monocyte chemoattractant protein 1, interleukin 6 or tumour necrosis factor-alpha. Finally, diplotypes derived from these SNPs did not reveal correlations with insulin sensitivity, insulin secretion, lipid measures or inflammatory parameters either.', 'output': 'no', 'text_length': 1936, '__index_level_0__': 27026}\n",
      "{'dataset': 'pubmedqa', 'split_data': 'test', 'task': 'qa3', 'instruction': 'Choose the correct anser (Yes, No, or Maybe) for the given question based on the proviced context.', 'input': 'Question: Is stress-induced hyperglycemia , not diabetic hyperglycemia , associated with higher mortality in trauma? Context: To identify all trauma patients with diabetes and compare diabetic hyperglycemia (DH) patients with those with stress-induced hyperglycemia (SIH). SIH has been shown to result in worse outcomes after trauma. The presence of diabetes mellitus (DM) or occult DM within the cohort confounded previous studies. We identified 2 distinct populations of trauma patients with SIH or DH to determine the impact of hyperglycemia on these 2 groups. Admission glycosylated hemoglobin (HbA1c), glucose levels, and comorbidity data were collected over a 2-year period. DM was determined by patient history or admission HbA1c 6.5% or more. SIH was determined by absence of DM and admission glucose 200 mg/dL or more. Cox proportional hazards models [adjusted for age, sex, injury mechanism, and injury severity score] were used to calculate risk ratios (RRs) and associated 95% confidence intervals (CIs) for outcomes of interest. During the study period, 6852 trauma patients were evaluated, and 5117 had available glucose, HbA1c, and comorbidity data. Patients with SIH had an over twofold increase in mortality risk (RR 2.41, 95% CI 1.81-3.23), and patients with DH had a nonsignificant, near-50% increase in mortality risk (RR 1.47, 95% CI 0.92-2.36). Risk of pneumonia was similarly higher for both the DH (RR 1.49, 95% CI 1.03-2.17) and the SIH (RR 1.44, 95% CI 1.08-1.93).', 'output': 'yes', 'text_length': 1591, '__index_level_0__': 27054}\n",
      "{'dataset': 'pubmedqa', 'split_data': 'test', 'task': 'qa3', 'instruction': 'Choose the correct anser (Yes, No, or Maybe) for the given question based on the proviced context.', 'input': 'Question: Is intravenous immunoglobulin effective in patients with diabetes and with chronic inflammatory demyelinating polyneuropathy : long term follow-up? Context: Chronic inflammatory demyelinating polyneuropathy (CIDP) seems to be more common in patients with diabetes than in the general population. The long term outcome of these patients after receiving intravenous immunoglobulin is unclear and the precise optimal regimen needed has yet to be ascertained. Moreover, the influence of chronic hyperglycaemia on this neuropathy is not clear. This prospective follow-up study included all consecutive patients with diabetes with a CIDP referred to our department during the 18 months of the study. 198 consecutive patients were referred to our neuromuscular unit and exhaustively screened. 16 patients with diabetes (8%) had a demyelinating polyneuropathy fulfilling the most restrictive diagnostic criteria for CIDP. They were treated with at least one course of intravenous immunoglobulin and, if responders, retreated in case of relapse. All patients were followed for at least 40 months. Patients with diabetes with CIDP significantly improved after immunotherapy and during follow-up. The Neuropathy Impairment Score changed from 38 at presentation to 16 at the end of the follow-up. Eight patients developed distal sensory disturbances during follow-up and four of these patients complained of distal paresthesias but no neuropathic pain. Sensory disturbances were detected after 30 months (mean time) from baseline.', 'output': 'yes', 'text_length': 1629, '__index_level_0__': 26984}\n",
      "{'dataset': 'pubmedqa', 'split_data': 'test', 'task': 'qa3', 'instruction': 'Choose the correct anser (Yes, No, or Maybe) for the given question based on the proviced context.', 'input': 'Question: Are higher intakes of fish protein related to a lower risk of microalbuminuria in young Swedish type 1 diabetic patients? Context: To examine the influence of dietary intake from various protein and fat sources on the occurrence of microalbuminuria in type 1 diabetic patients. In this nested case control study, 1,150 patients with diabetes duration >5 years reported dietary habits for the previous 12 months and submitted urinary samples for the analysis of albumin excretion rate (AER). A total of 75 cases of albuminuria (overnight AER > or = 15 microg/min) were identified and compared with 225 duration-matched control subjects. Neither mean protein, fat intake, average fish protein intake (control subjects 4.56 +/- 3.83 g/day and cases 3.82 +/- 2.87 g/day; P = 0.12), nor intake of meat and vegetable protein differed between the cases of albuminuria and the control subjects. High consumers of fish protein (greater than the 75th percentile) (12 cases and 63 control subjects, mean intake 9.35 g fish protein/day, i.e., approximately 53 g fish/day) had lower odds ratios (ORs) for microalbuminuria than individuals consuming less fish protein (mean 2.72 g/day) (crude OR 0.49 and 95% CI 0.25-0.97). When adjusted for known confounding factors, such as HbA1c, mean arterial pressure, diabetes duration, age, sex, smoking, BMI, country region, and total energy, individuals with a high intake of fish protein and fish fat showed a reduction in the risk for microalbuminuria (OR 0.22 and 0.31, respectively; 95% CI 0.09-0.56 and 0.13-0.76, respectively). When fish protein and fat were adjusted for each other, a high intake of fish protein but not of fish fat was still significantly associated with a decrease in the risk for microalbuminuria.', 'output': 'yes', 'text_length': 1864, '__index_level_0__': 26994}\n",
      "Task: nli, Sampled: 25\n",
      "{'dataset': 'bionli', 'split_data': 'test', 'task': 'nli', 'instruction': \"Examine the logical relationship between the given premise and hypothesis. Determine whether the hypothesis is logically supported by the premise ('entailment') or contradicts it ('contradiction'). Select 'entailment' if the hypothesis logically follows from the premise, meaning that if the premise is true, the hypothesis must also be true. Select 'contradiction' if the hypothesis directly opposes the premise, meaning that if the premise is true, the hypothesis must be false.\", 'input': '[PRE] Diabetes mellitus (DM) is characterized by alterations in fluid balance and blood volume homeostasis. Renal interstitial hydrostatic pressure (RIHP) has been shown to play a critical role in mediating sodium and water excretion under various conditions. The objective of this study was to determine the effects of immediate and delayed initiation of insulin treatment on the restoration of the relationship between RIHP, natriuretic, and diuretic responses to acute saline volume expansion (VE) in diabetic rats. Diabetes was induced by an intraperitoneal injection of streptozotocin (STZ; 65 mg/kg body wt). Four groups of female Sprague-Dawley rats were studied: normal control group (C), untreated diabetic group (D), immediate insulin-treated diabetic group (DI; treatment with insulin for 2 wk was initiated immediately when diabetes was confirmed, which was 2 days after STZ injection), and delayed insulin-treated diabetic group (DDI; treatment with insulin for 2 wk was initiated 2 wk after STZ injection). RIHP and sodium and water excretions were measured before and during VE (5% body wt/30 min) in the four groups of anesthetized rats. VE significantly increased RIHP, fractional excretion of sodium (FE(Na)), and urine flow rate (V) in all groups of rats. Basal RIHP, RIHP response to VE (Delta RIHP), and FE(Na) and V responses to VE (Delta FE(Na) and Delta V) were significantly lower in the D group compared with the C group of rats. Delta RIHP was significantly higher in both DI and DDI groups compared with D group but was similar to that of the C group of rats. While in the DI group the Delta FE(Na) response to VE was restored, Delta FE(Na) was significantly increased in DDI compared with D group, but it remained lower than that of the C group.', 'output': 'contradiction', 'text_length': 2267, '__index_level_0__': 27126}\n",
      "{'dataset': 'bionli', 'split_data': 'test', 'task': 'nli', 'instruction': \"Analyze the relationship between the given premise and hypothesis. Classify this relationship by selecting only one of the following options: 'entailment', 'contradiction'. 'entailment': Choose this when the hypothesis logically follows from the premise. This means that if the premise is true, the hypothesis must also be true. 'contradiction': Choose this when the hypothesis directly contradicts the premise. This means that if the premise is true, the hypothesis must be false.\", 'input': '[PRE] Diabetes is featured by elevated levels of blood glucose, i.e. hyperglycemia, which might be a risk factor for hepatic fibrogenesis in patients with non-alcoholic steatohepatitis. Hepatic stellate cells (HSCs) are the major effectors during hepatic fibrogenesis. This study was designed to evaluate impacts of high levels of glucose on HSC activation, assess roles of the phytochemical curcumin in attenuating the glucose impacts, and elucidate underlying mechanisms. In this report, levels of intracellular glucose were measured. Contents and gene expression of glucose transporter-2 (GLUT2) in cell fractions were examined. Levels of cellular glutathione and oxidative stress were analyzed. We observed that high levels of glucose induced cell proliferation, type I collagen production and expression of genes relevant to HSC activation, and elevated intracellular glucose levels in cultured HSCs. Curcumin eliminated the stimulatory impacts. Curcumin abrogated the membrane translocation of GLUT2 by interrupting the p38 MAPK signaling pathway. In addition, curcumin suppressed glut2 expression by stimulating the activity of peroxisome proliferator-activated receptor-gamma (PPARγ) and de novo synthesis of glutathione.', 'output': 'entailment', 'text_length': 1720, '__index_level_0__': 27091}\n",
      "{'dataset': 'bionli', 'split_data': 'test', 'task': 'nli', 'instruction': \"Analyze the relationship between the given premise and hypothesis. Classify this relationship by selecting only one of the following options: 'entailment', 'contradiction'. 'entailment': Choose this when the hypothesis logically follows from the premise. This means that if the premise is true, the hypothesis must also be true. 'contradiction': Choose this when the hypothesis directly contradicts the premise. This means that if the premise is true, the hypothesis must be false.\", 'input': '[PRE] We have studied the in vivo and in vitro effects of Topiramate (TPM) in female Zucker diabetic fatty (ZDF) rats. After weight matching, drug treatment had a marked effect to lower fasting glucose levels of relatively normoglycemic animals as well as during an oral glucose tolerance test. The glucose clamp studies revealed a approximately 30% increased glucose disposal, increased hepatic glucose output (HGO) suppression from approximately 30 to 60%, and an increased free fatty acid suppression from 40 to 75%. Therefore, TPM treatment led to enhanced insulin sensitivity at the level of tissue glucose disposal (increased ISGDR), liver (increased inhibition of HGO), and adipose tissue (enhanced suppression of lipolysis). When soleus muscle strips of control or TPM-treated ZDF rats were studied ex vivo, insulin-stimulated glucose transport was not enhanced in the drug-treated animals. In contrast, when isolated adipocytes were studied ex vivo, a marked increase (+55%) in insulin-stimulated glucose transport was observed. In vitro treatment of muscle strips and rat adipocytes showed no effect on glucose transport in muscle with a 40% increase in insulin-stimulated adipocyte glucose transport.', 'output': 'contradiction', 'text_length': 1705, '__index_level_0__': 27120}\n",
      "{'dataset': 'bionli', 'split_data': 'test', 'task': 'nli', 'instruction': \"Examine the logical relationship between the given premise and hypothesis. Determine whether the hypothesis is logically supported by the premise ('entailment') or contradicts it ('contradiction'). Select 'entailment' if the hypothesis logically follows from the premise, meaning that if the premise is true, the hypothesis must also be true. Select 'contradiction' if the hypothesis directly opposes the premise, meaning that if the premise is true, the hypothesis must be false.\", 'input': '[PRE] Hyperglycemia was reported to enhance angiotensin (Ang) II generation in rat cardiomyocytes, and Ang II inhibition reduces cardiovascular morbidity and mortality in diabetic patients. In diabetic patients, the enhanced activation of intracellular pathways related with myocyte hypertrophy and gene expression might enhance the progression of cardiac damage. Therefore, we investigated the effects of glucose on Ang II-mediated activation of Janus-activated kinase (JAK)-2, a tyrosine kinase related with myocyte hypertrophy and cytokine and fibrogenetic growth factor overexpression, in ventricular myocytes isolated from nonfailing human hearts (n = 5) and failing human hearts (n = 8). In nonfailing myocytes, JAK2 phosphorylation was enhanced by Ang II only in the presence of high glucose (25 mmol/l) via Ang II type I (AT1) receptors (+79% vs. normal glucose, P < 0.05). JAK2 activation was prevented by inhibitors of reactive oxygen species (ROS) generation (diphenyleneiodonium [DPI], tiron, and apocynin). In myocytes isolated from failing hearts, JAK2 phosphorylation was enhanced by high glucose alone (+107%, P < 0.05). High glucose-induced JAK2 activation was blunted by both ACE inhibition (100 nmol/l ramipril) and AT1 antagonism (1 mumol/l valsartan), thus revealing that the effects are mediated by autocrine Ang II production. Inhibition of ROS generation also prevented high glucose-induced JAK2 phosphorylation.', 'output': 'entailment', 'text_length': 1926, '__index_level_0__': 27122}\n",
      "{'dataset': 'bionli', 'split_data': 'test', 'task': 'nli', 'instruction': \"Analyze the relationship between the given premise and hypothesis. Classify this relationship by selecting only one of the following options: 'entailment', 'contradiction'. 'entailment': Choose this when the hypothesis logically follows from the premise. This means that if the premise is true, the hypothesis must also be true. 'contradiction': Choose this when the hypothesis directly contradicts the premise. This means that if the premise is true, the hypothesis must be false.\", 'input': '[PRE] Exendin-4 (Ex-4), a long-acting agonist of glucagon-like peptide-1 receptor, is a novel anti-diabetic drug that prevents β-cells against various toxicities. However, the mechanism and molecules mediating the protection procession of Ex-4 are not fully understood. We investigated the protective effect of Ex-4 against lipotoxicity, mediated by a repression of sterol regulatory element-binding protein (SREBP)-1c, a regulator of genes expression involved in fat and cholesterol synthesis. To observe the effect of Ex-4, we evaluated glucose-stimulated insulin secretion (GSIS) and apoptosis in the MIN6 pancreatic β-cell line, which were cultured in DMEM medium containing 500 μM palmitate, with or without 10 nM Ex-4. We also examined the roles of SREBP-1c in lipotoxicity model by knockdown with si-RNA. Treatment with Ex-4 improved insulin secretion and survival as well as reduced SREBP-1c expression and activity in palmitate-treated MIN6 cells. This improvement was accompanied with an upregulation of PI3K/Akt signaling pathway, and LY294.002, a specific inhibitor of PI3 kinase, abrogated effects of Ex-4 on insulin secretion. Moreover, SREBP-1c in nuclei was increased by the inhibition of PI3 kinase. Lipotoxic effects of palmitate in the insulin secretion and apoptosis were significantly prevented by SREBP-1 knockdown.', 'output': 'entailment', 'text_length': 1828, '__index_level_0__': 27113}\n",
      "Task: ie, Sampled: 25\n",
      "{'dataset': 'chemdner', 'split_data': 'test', 'task': 'ie', 'instruction': 'Extract all chemical entities mentioned in the given text. The extracted entities must fall into one of the following categories: Chemical Compounds: Substances with a defined molecular structure, including organic and inorganic compounds. Examples: glucose, cholesterol, ATP, quercetin. Drugs & Pharmaceuticals: Medications and bioactive compounds used for treatment, diagnosis, or prevention of diseases. Examples: metformin, aspirin, atorvastatin, warfarin, paclitaxel. Metabolites & Bioactive Molecules: Naturally occurring molecules that play a role in biological processes. Examples: serotonin, cortisol, nitric oxide (NO), superoxide, kynurenine. Vitamins & Minerals: Essential nutrients required for biological functions. Examples: vitamin D, vitamin C, zinc, calcium, magnesium. Toxic & Environmental Chemicals: Pollutants and hazardous chemicals found in the environment. Examples: arsenic, polychlorinated biphenyls (PCB), dioxin (TCDD), bisphenol A (BPA). **Instructions:** Extract only named chemical entities that belong to the above categories. Do not extract general chemical properties (e.g., acidity, solubility) or chemical processes (e.g., oxidation, hydrolysis). Preserve the entity names as they appear in the original text, without modifications or abbreviations.Return only the extracted chemical entity names.', 'input': 'In our previous work, we found that feeding Lactobacillus johnsonii to BioBreeding diabetes-prone (BBDP) rats decreased the incidence of diabetes development. The aim of this study was to investigate host pathways affected by L. johnsonii, with specific focus on the rate-limiting enzyme of tryptophan catabolism, indoleamine 2,3-dioxygenase (IDO). Suspensions of L. johnsonii or an equal volume of vehicle were orally administered to BBDP rats. Tissue IDO was investigated using quantitative RT-PCR and Western blot, whereas tryptophan, kynurenine, and 5-hydroxytryptamine (5-HT) concentrations were quantified by HPLC and ELISA. IDO activity was also investigated using L. johnsonii culture cell-free supernatant (CFS) with affinity-purified IDO and HT-29 intestinal epithelial cells. L. johnsonii feeding resulted in a 17% reduction in serum kynurenine compared with that in vehicle-fed controls, correlating with a 1.4-fold elevation in 5-HT levels. H2O2 produced by L. johnsonii abolished IDO activity in vitro, and L. johnsonii feeding resulted in a 3.9-fold increase in ileum lumen H2O2. L. johnsonii CFS significantly reduced IDO activity in HT-29 intestinal epithelial cells (47% reduction) compared with that in vehicle-treated controls, an effect abolished by catalase treatment. These data support the role of H2O2 in commensal bacteria-host interactions and highlight the influence of commensal bacteria-derived H2O2 on host physiology.-Valladares, R., Bojilova, L., Potts, A. H., Cameron, E., Gardner, C., Lorca, G., Gonzalez, C. F. Lactobacillus johnsonii inhibits indoleamine 2,3-dioxygenase and alters tryptophan metabolite levels in BioBreeding rats.', 'output': 'tryptophan, 5-hydroxytryptamine, 5-HT, indoleamine, H2O2, kynurenine', 'text_length': 3070, '__index_level_0__': 27148}\n",
      "{'dataset': 'chemdner', 'split_data': 'test', 'task': 'ie', 'instruction': 'Extract all chemical entities mentioned in the given text. The extracted entities must fall into one of the following categories: Chemical Compounds: Substances with a defined molecular structure, including organic and inorganic compounds. Examples: glucose, cholesterol, ATP, quercetin. Drugs & Pharmaceuticals: Medications and bioactive compounds used for treatment, diagnosis, or prevention of diseases. Examples: metformin, aspirin, atorvastatin, warfarin, paclitaxel. Metabolites & Bioactive Molecules: Naturally occurring molecules that play a role in biological processes. Examples: serotonin, cortisol, nitric oxide (NO), superoxide, kynurenine. Vitamins & Minerals: Essential nutrients required for biological functions. Examples: vitamin D, vitamin C, zinc, calcium, magnesium. Toxic & Environmental Chemicals: Pollutants and hazardous chemicals found in the environment. Examples: arsenic, polychlorinated biphenyls (PCB), dioxin (TCDD), bisphenol A (BPA). **Instructions:** Extract only named chemical entities that belong to the above categories. Do not extract general chemical properties (e.g., acidity, solubility) or chemical processes (e.g., oxidation, hydrolysis). Preserve the entity names as they appear in the original text, without modifications or abbreviations.Return only the extracted chemical entity names.', 'input': 'Glucocorticoid signaling plays a critical role in regulating energy metabolism. Emerging data implicate environmental endocrine-disrupting chemicals as contributors to the obesity and diabetes epidemics. Previous studies have shown that the phenylsulfamide fungicide tolylfluanid (TF) augments glucocorticoid receptor (GR)-dependent luciferase expression in 3T3-L1 preadipocytes while modulating insulin action in primary murine and human adipocytes. Studies were performed to interrogate glucocorticoid signaling in primary adipocytes exposed to TF. TF mimicked the gene transcription profile of the murine glucocorticoid corticosterone (Cort). Cellular fractionation assays demonstrated that TF treatment promoted the activating serine phosphorylation of GR, augmenting its cytoplasmic-to-nuclear translocation as well as its enrichment at glucocorticoid response elements on the glucocorticoid-induced leucine zipper gene promoter. After acute treatment, Cort or TF promoted insulin receptor substrate-1 (IRS-1) gene and protein expression. Either treatment also enriched GR binding at an identified glucocorticoid response element in the IRS-1 gene. TF or Cort each increased insulin-stimulated lipogenesis, an effect resulting from increased lipogenic gene expression and enhanced insulin-stimulated dephosphorylation of acetyl-coenzyme A carboxylase. The augmentation of insulin-stimulated lipogenesis was mediated through a specific enhancement of Akt phosphorylation at T308. These findings support modulation of IRS-1 levels as a mechanism for glucocorticoid-mediated changes in insulin action in primary adipocytes. Albeit with less affinity than Cort, in silico analysis suggests that TF can interact with the ligand binding pocket of GR. Collectively, these studies identify TF as a structurally unique environmental glucocorticoid. Glucocorticoid signaling may thus represent a novel pathway by which environmental toxicants promote the development of metabolic diseases.', 'output': 'tolylfluanid, acetyl-coenzyme A, Cort, serine, leucine, phenylsulfamide, corticosterone', 'text_length': 3405, '__index_level_0__': 27159}\n",
      "{'dataset': 'chemdner', 'split_data': 'test', 'task': 'ie', 'instruction': 'Extract all chemical entities mentioned in the given text. The extracted entities must fall into one of the following categories: Chemical Compounds: Substances with a defined molecular structure, including organic and inorganic compounds. Examples: glucose, cholesterol, ATP, quercetin. Drugs & Pharmaceuticals: Medications and bioactive compounds used for treatment, diagnosis, or prevention of diseases. Examples: metformin, aspirin, atorvastatin, warfarin, paclitaxel. Metabolites & Bioactive Molecules: Naturally occurring molecules that play a role in biological processes. Examples: serotonin, cortisol, nitric oxide (NO), superoxide, kynurenine. Vitamins & Minerals: Essential nutrients required for biological functions. Examples: vitamin D, vitamin C, zinc, calcium, magnesium. Toxic & Environmental Chemicals: Pollutants and hazardous chemicals found in the environment. Examples: arsenic, polychlorinated biphenyls (PCB), dioxin (TCDD), bisphenol A (BPA). **Instructions:** Extract only named chemical entities that belong to the above categories. Do not extract general chemical properties (e.g., acidity, solubility) or chemical processes (e.g., oxidation, hydrolysis). Preserve the entity names as they appear in the original text, without modifications or abbreviations.Return only the extracted chemical entity names.', 'input': 'Evidence has emerged supporting a link between high glycaemic index (GI) diets and type 2 diabetes (T2D). The aim of this study was to determine if dietary GI influences the development of hyperglycaemia in C57BL/6 mice to more closely reflect T2D. Male C57BL/6 mice (n=30) were randomly divided into 3 dietary groups consisting of either standard rodent chow (4.8\\xa0% fat, 20\\xa0% protein), or a high fat (HF) diet (21-23\\xa0% fat, 19\\xa0% protein) with low GI (15.4\\xa0% starch; HF-LG) or high GI (50.5\\xa0% dextrose; HF-HG) ad libitum for 10 weeks. Body weight, blood glucose, glucose tolerance, and circulating cholesterol and triglyceride levels were measured for the duration of the study. We found that increasing the GI of a moderately HF diet induces severe hyperglycaemia and insulin resistance in C57BL/6 mice, reflective of criteria for diagnosis of T2D, whilst littermates consuming an equivalent low GI diet maintain glucose homeostasis. This study demonstrates the significant contribution of both dietary carbohydrate and fat composition in the aetiopathogenesis of T2D.', 'output': 'glucose, triglyceride, carbohydrate, dextrose, cholesterol', 'text_length': 2461, '__index_level_0__': 27177}\n",
      "{'dataset': 'chemdner', 'split_data': 'test', 'task': 'ie', 'instruction': 'Extract all chemical entities mentioned in the given text. The extracted entities must fall into one of the following categories: Chemical Compounds: Substances with a defined molecular structure, including organic and inorganic compounds. Examples: glucose, cholesterol, ATP, quercetin. Drugs & Pharmaceuticals: Medications and bioactive compounds used for treatment, diagnosis, or prevention of diseases. Examples: metformin, aspirin, atorvastatin, warfarin, paclitaxel. Metabolites & Bioactive Molecules: Naturally occurring molecules that play a role in biological processes. Examples: serotonin, cortisol, nitric oxide (NO), superoxide, kynurenine. Vitamins & Minerals: Essential nutrients required for biological functions. Examples: vitamin D, vitamin C, zinc, calcium, magnesium. Toxic & Environmental Chemicals: Pollutants and hazardous chemicals found in the environment. Examples: arsenic, polychlorinated biphenyls (PCB), dioxin (TCDD), bisphenol A (BPA). **Instructions:** Extract only named chemical entities that belong to the above categories. Do not extract general chemical properties (e.g., acidity, solubility) or chemical processes (e.g., oxidation, hydrolysis). Preserve the entity names as they appear in the original text, without modifications or abbreviations.Return only the extracted chemical entity names.', 'input': 'Selective kinin receptor agonists as cardioprotective agents in myocardial ischemia and diabetes.', 'output': '', 'text_length': 1431, '__index_level_0__': 27142}\n",
      "{'dataset': 'chemdner', 'split_data': 'test', 'task': 'ie', 'instruction': 'Extract all chemical entities mentioned in the given text. The extracted entities must fall into one of the following categories: Chemical Compounds: Substances with a defined molecular structure, including organic and inorganic compounds. Examples: glucose, cholesterol, ATP, quercetin. Drugs & Pharmaceuticals: Medications and bioactive compounds used for treatment, diagnosis, or prevention of diseases. Examples: metformin, aspirin, atorvastatin, warfarin, paclitaxel. Metabolites & Bioactive Molecules: Naturally occurring molecules that play a role in biological processes. Examples: serotonin, cortisol, nitric oxide (NO), superoxide, kynurenine. Vitamins & Minerals: Essential nutrients required for biological functions. Examples: vitamin D, vitamin C, zinc, calcium, magnesium. Toxic & Environmental Chemicals: Pollutants and hazardous chemicals found in the environment. Examples: arsenic, polychlorinated biphenyls (PCB), dioxin (TCDD), bisphenol A (BPA). **Instructions:** Extract only named chemical entities that belong to the above categories. Do not extract general chemical properties (e.g., acidity, solubility) or chemical processes (e.g., oxidation, hydrolysis). Preserve the entity names as they appear in the original text, without modifications or abbreviations.Return only the extracted chemical entity names.', 'input': 'Glycogen synthase kinase 3 (GSK-3) plays a central role in cellular energy metabolism, and dysregulation of GSK-3 activity is implicated in a variety of metabolic disorders, including obesity, type 2 diabetes, and cancer. Hence, GSK-3 has emerged as an attractive target molecule for the treatment of metabolic disorders. Therefore, this research focused on identification and characterization of a novel small-molecule GSK-3 inhibitor. Compound 1a, a structure based on 3-hydroxychromone bearing isothiazolidine-1,1-dione, was identified from chemical library as a highly potent GSK-3 inhibitor. An in vitro kinase assay utilizing a panel of kinases demonstrated that compound 1a strongly inhibits GSK-3β. The potential effects of compound 1a on the inactivation of GSK-3 were confirmed in human liver HepG2 and human embryonic kidney HEK293 cells. Stabilization of glycogen synthase and β-catenin, which are direct targets of GSK-3, by compound 1a was assessed in comparison with two other GSK-3 inhibitors: LiCl and SB-415286. In mouse 3T3-L1 preadipocytes, compound 1a markedly blocked adipocyte differentiation. Consistently, intraperitoneal administration of compound 1a to diet-induced obese mice significantly ameliorated their key symptoms such as body weight gain, increased adiposity, dyslipidemia, and hepatic steatosis due to the marked reduction of whole-body lipid level. In vitro and in vivo effects were accompanied by upregulation of β-catenin stability and downregulation of the expression of several critical genes related to lipid metabolism. From these results, it can be concluded that compound 1a, a novel small-molecule inhibitor of GSK-3, has potential as a new class of therapeutic agent for obesity treatment.', 'output': 'LiCl, isothiazolidine-1,1-dione, 3-hydroxychromone, SB-415286', 'text_length': 3132, '__index_level_0__': 27146}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd  # pandas 임포트 추가\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "# 시드 값 설정\n",
    "SEED = 42\n",
    "\n",
    "# Python의 random 모듈 시드 고정\n",
    "random.seed(SEED)\n",
    "\n",
    "# NumPy 시드 고정\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 1. 데이터셋 로드\n",
    "dataset_name = \"passionMan/diabetes_v14\"\n",
    "train_dataset = load_dataset(dataset_name, split=\"train\")\n",
    "test_dataset = load_dataset(dataset_name, split=\"test\")\n",
    "\n",
    "# 2. 중복 확인을 위한 train 데이터의 (input, output) 세트 생성\n",
    "train_pairs = set((row[\"input\"], row[\"output\"]) for row in train_dataset)\n",
    "\n",
    "# 3. 각 task별 샘플 개수 설정\n",
    "task_sample_limits = {\n",
    "    'qa1': 25,\n",
    "    'qa2': 25,\n",
    "    'qa3': 25,\n",
    "    'nli': 25,\n",
    "    're': 25,\n",
    "    'ie': 25,\n",
    "    \"summarization\": 25,\n",
    "    \"generation\": 25,\n",
    "    'alternative_diet': 25,\n",
    "    'daily_diets': 25,\n",
    "}\n",
    "default_sample_limit = 50  # 나머지 task는 100개씩 샘플링\n",
    "\n",
    "# 4. task별 샘플링 데이터 초기화\n",
    "task_sampled_data = {}\n",
    "# task_counts를 task_sample_limits로 초기화\n",
    "task_counts = {task: 0 for task in task_sample_limits}\n",
    "\n",
    "# 5. Task별 샘플링\n",
    "# 테스트 데이터셋을 셔플링하여 랜덤 샘플링 보장\n",
    "test_dataset = test_dataset.shuffle(seed=SEED)\n",
    "\n",
    "for row in test_dataset:\n",
    "    task = row[\"task\"]\n",
    "    dataset_value = row.get(\"dataset\")  # dataset 컬럼 값 확인\n",
    "    input_output_pair = (row[\"input\"], row[\"output\"])\n",
    "\n",
    "    # qa_objective 세분화\n",
    "    if task == \"qa_objective\":\n",
    "        if dataset_value == \"medqa\":\n",
    "            task = \"qa_objective_1\"  # medqa로 세분화\n",
    "        elif dataset_value == \"medmcqa\":\n",
    "            task = \"qa_objective_2\"  # medmcqa로 세분화\n",
    "        else:\n",
    "            continue  # medqa, medmcqa가 아니면 건너뛰기\n",
    "\n",
    "    # 해당 task의 샘플링 제한 확인\n",
    "    sample_limit = task_sample_limits.get(task, default_sample_limit)\n",
    "\n",
    "    # 샘플링 조건 확인\n",
    "    if task_counts.get(task, 0) < sample_limit and input_output_pair not in train_pairs:\n",
    "        if task not in task_sampled_data:\n",
    "            task_sampled_data[task] = []\n",
    "        task_sampled_data[task].append(row)\n",
    "        task_counts[task] += 1\n",
    "\n",
    "    # 모든 task의 샘플링이 완료되면 종료\n",
    "    if all(task_counts.get(task, 0) >= task_sample_limits.get(task, default_sample_limit) for task in task_sample_limits):\n",
    "        break\n",
    "\n",
    "# 6. 결과 출력 및 확인\n",
    "for task, samples in task_sampled_data.items():\n",
    "    print(f\"Task: {task}, Sampled: {len(samples)}\")\n",
    "    for sample in samples[:5]:  # 첫 5개 샘플만 출력\n",
    "        print(sample)\n",
    "\n",
    "# 7. 필요 시 샘플링된 데이터 저장\n",
    "# pandas를 사용하여 리스트의 딕셔너리를 데이터프레임으로 변환 후 Dataset으로 변환\n",
    "sampled_dataset = DatasetDict({\n",
    "    task: Dataset.from_pandas(pd.DataFrame(samples)) for task, samples in task_sampled_data.items()\n",
    "})\n",
    "\n",
    "# 저장 (필요시 주석 제거)\n",
    "# sampled_dataset.save_to_disk(\"sampled_test_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples:   8%|▊         | 21/250 [10:37<1:52:39, 29.52s/sample]"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import TextStreamer\n",
    "\n",
    "# 모델을 inference 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "# 출력 파일 설정\n",
    "output_file = \"inference_results_pmc.jsonl\"\n",
    "\n",
    "# Task별 `max_new_tokens` 설정\n",
    "task_max_new_tokens = {\n",
    "    \"alternative_diet\": 512,\n",
    "    \"daily_diets\": 1024,\n",
    "    \"dfh_info\": 256,\n",
    "    \"generation\": 2048,\n",
    "    \"ie\": 128,\n",
    "    \"nli\": 32,\n",
    "    \"qa1\": 64,\n",
    "    \"qa2\": 64,\n",
    "    \"qa3\": 64,\n",
    "    \"re\": 32,\n",
    "    \"summarization\": 1024,\n",
    "}\n",
    "\n",
    "# 새로운 프롬프트 적용\n",
    "prompt_input = (\n",
    "    'Below is an instruction that describes a task, paired with an input that provides further context.\\n'\n",
    "    'Write a response that appropriately completes the request.\\n\\n'\n",
    "    '### Instruction:\\n{instruction}\\n\\n'\n",
    "    '{input}\\n\\n'  # 기존 형식을 유지하면서 `input` 그대로 삽입\n",
    "    '### Response:'\n",
    ")\n",
    "\n",
    "# 전체 샘플 개수\n",
    "total_samples = sum(len(samples) for samples in sampled_dataset.values())\n",
    "\n",
    "# 진행 상태 표시 (`tqdm`)\n",
    "with open(output_file, 'w', encoding=\"utf-8\") as f_out:\n",
    "    with tqdm(total=total_samples, desc=\"Processing samples\", unit=\"sample\") as pbar:\n",
    "        for task, sample in sampled_dataset.items():\n",
    "            for samp in sample:\n",
    "                try:\n",
    "                    # Task별 `max_new_tokens` 설정\n",
    "                    task_name = samp.get(\"task\", \"\")\n",
    "                    max_new_tokens = task_max_new_tokens.get(task_name, 8)  # 기본값 8\n",
    "\n",
    "                    # 새로운 프롬프트 적용\n",
    "                    prompt_text = prompt_input.format(\n",
    "                        instruction=samp['instruction'],\n",
    "                        input=samp['input']\n",
    "                    )\n",
    "\n",
    "                    # 입력 토큰 생성\n",
    "                    inputs = tokenizer(\n",
    "                        [prompt_text],\n",
    "                        return_tensors=\"pt\",\n",
    "                        padding=True,  # 패딩 적용\n",
    "                    )\n",
    "\n",
    "                    # `input_ids`와 `attention_mask`만 GPU로 이동\n",
    "                    input_ids = inputs.input_ids.cuda()\n",
    "                    attention_mask = inputs.attention_mask.cuda()\n",
    "\n",
    "                    # 모델 생성\n",
    "                    output_tensor = model.generate(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        max_new_tokens=max_new_tokens,\n",
    "                        temperature=0.7,  # 답변의 다양성과 논리성 조정\n",
    "                        top_p=0.9,  # nucleus sampling\n",
    "                        top_k=50,  # Top-k 필터링\n",
    "                        repetition_penalty=1.2,  # 반복 방지\n",
    "                        do_sample=True  # 확률적 샘플링 활성화\n",
    "                    )\n",
    "\n",
    "                    # 출력 디코딩\n",
    "                    model_output = tokenizer.batch_decode(output_tensor, skip_special_tokens=True)[0]\n",
    "\n",
    "                    # `### Response:` 뒤의 텍스트 추출\n",
    "                    response_text = \"No valid response found\"\n",
    "                    response_match = re.search(r\"### Response:\\s*(.+)\", model_output, re.DOTALL)\n",
    "                    if response_match:\n",
    "                        response_text = response_match.group(1).strip()\n",
    "\n",
    "                    # 모델 출력 결과를 샘플 데이터에 추가\n",
    "                    samp['model_output'] = response_text\n",
    "\n",
    "                    # JSONL 형식으로 저장\n",
    "                    f_out.write(json.dumps(samp, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error processing sample {samp}: {str(e)}\")\n",
    "\n",
    "                # tqdm 진행 상태 업데이트\n",
    "                pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"/data/jaesung/llm_for_diabetes/src/model/inference_results_pmc.jsonl\"\n",
    "\n",
    "data = []\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3243133/1017709785.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qa_objective_df['output_label'] = qa_objective_df['output'].str.extract(r'(A\\)|B\\)|C\\)|D\\))')\n",
      "/tmp/ipykernel_3243133/1017709785.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qa_objective_df['model_output_label'] = qa_objective_df['model_output'].str.extract(r'(A\\)|B\\)|C\\)|D\\))')\n",
      "/tmp/ipykernel_3243133/1017709785.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qa_objective_df['correct'] = qa_objective_df['output_label'] == qa_objective_df['model_output_label']\n"
     ]
    }
   ],
   "source": [
    "# medqa\n",
    "\n",
    "import pandas as pd\n",
    "qa_objective_df = df[df['task']=='qa1']\n",
    "\n",
    "# 'output'와 'model_output'에서 A), B), C), D)만 추출\n",
    "qa_objective_df['output_label'] = qa_objective_df['output'].str.extract(r'(A\\)|B\\)|C\\)|D\\))')\n",
    "qa_objective_df['model_output_label'] = qa_objective_df['model_output'].str.extract(r'(A\\)|B\\)|C\\)|D\\))')\n",
    "\n",
    "# 두 컬럼 비교하여 맞은 경우를 계산\n",
    "qa_objective_df['correct'] = qa_objective_df['output_label'] == qa_objective_df['model_output_label']\n",
    "\n",
    "# Accuracy 계산\n",
    "accuracy = qa_objective_df['correct'].mean()\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3243133/2145043051.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qa_subjective_df['output_label'] = qa_subjective_df['output'].str.extract(r'(A\\)|B\\)|C\\)|D\\))')\n",
      "/tmp/ipykernel_3243133/2145043051.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qa_subjective_df['model_output_label'] = qa_subjective_df['model_output'].str.extract(r'(A\\)|B\\)|C\\)|D\\))')\n",
      "/tmp/ipykernel_3243133/2145043051.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qa_subjective_df['correct'] = qa_subjective_df['output_label'] == qa_subjective_df['model_output_label']\n"
     ]
    }
   ],
   "source": [
    "# medmcqa\n",
    "\n",
    "import pandas as pd\n",
    "qa_subjective_df = df[df['task']=='qa2']\n",
    "\n",
    "# 'output'와 'model_output'에서 A), B), C), D)만 추출\n",
    "qa_subjective_df['output_label'] = qa_subjective_df['output'].str.extract(r'(A\\)|B\\)|C\\)|D\\))')\n",
    "qa_subjective_df['model_output_label'] = qa_subjective_df['model_output'].str.extract(r'(A\\)|B\\)|C\\)|D\\))')\n",
    "\n",
    "# 두 컬럼 비교하여 맞은 경우를 계산\n",
    "qa_subjective_df['correct'] = qa_subjective_df['output_label'] == qa_subjective_df['model_output_label']\n",
    "\n",
    "# Accuracy 계산\n",
    "accuracy = qa_subjective_df['correct'].mean()\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Match Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3243133/841677399.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qa_descriptive_df['token_match_score'] = qa_descriptive_df.apply(lambda row: token_overlap(row['output'], row['model_output']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# pubmedqa\n",
    "\n",
    "def token_overlap(output, model_output):\n",
    "    # 토큰화\n",
    "    output_tokens = set(output.split())\n",
    "    model_output_tokens = set(model_output.split())\n",
    "    \n",
    "    # 공통 토큰 개수 계산\n",
    "    common_tokens = output_tokens.intersection(model_output_tokens)\n",
    "    \n",
    "    # 일치 비율 계산\n",
    "    return len(common_tokens) / len(output_tokens) if len(output_tokens) > 0 else 0\n",
    "\n",
    "qa_descriptive_df = df[df['task'] == 'qa3']\n",
    "\n",
    "# 일치 비율 계산 및 저장\n",
    "qa_descriptive_df['token_match_score'] = qa_descriptive_df.apply(lambda row: token_overlap(row['output'], row['model_output']), axis=1)\n",
    "\n",
    "# 평균 점수를 정확도로 간주\n",
    "accuracy = qa_descriptive_df['token_match_score'].mean()\n",
    "\n",
    "print(f\"Token Match Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# nli\n",
    "\n",
    "nli_df = df[df['task'] == 'nli']\n",
    "\n",
    "correct_predictions = (nli_df['output'] == nli_df['model_output']).sum()\n",
    "total_predictions = len(nli_df) \n",
    "\n",
    "nli_acc = correct_predictions / total_predictions\n",
    "\n",
    "print(nli_acc)  # bioinstruct - 0.33 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Precision: 0.0000\n",
      "Total Recall: 0.0000\n",
      "Total F1-Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_re = df[df['task'] == 're']\n",
    "\n",
    "# Precision, Recall, F1 계산 함수 (전체)\n",
    "def calculate_total_metrics(output_col, model_output_col):\n",
    "    total_true_positive = 0\n",
    "    total_false_positive = 0\n",
    "    total_false_negative = 0\n",
    "\n",
    "    for output, model_output in zip(output_col, model_output_col):\n",
    "        # ','로 구분된 문자열을 집합으로 변환\n",
    "        output_set = set(output.split(', '))\n",
    "        model_output_set = set(model_output.split(', '))\n",
    "\n",
    "        # 교집합, 정답의 크기, 모델 예측의 크기 계산\n",
    "        true_positive = len(output_set & model_output_set)\n",
    "        false_positive = len(model_output_set - output_set)\n",
    "        false_negative = len(output_set - model_output_set)\n",
    "\n",
    "        # 누적 합산\n",
    "        total_true_positive += true_positive\n",
    "        total_false_positive += false_positive\n",
    "        total_false_negative += false_negative\n",
    "\n",
    "    # 총 Precision, Recall, F1 계산\n",
    "    precision = total_true_positive / (total_true_positive + total_false_positive) if (total_true_positive + total_false_positive) > 0 else 0\n",
    "    recall = total_true_positive / (total_true_positive + total_false_negative) if (total_true_positive + total_false_negative) > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "# 메트릭 계산\n",
    "total_precision, total_recall, total_f1 = calculate_total_metrics(df_re['output'], df_re['model_output'])\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Precision: {total_precision:.4f}\")\n",
    "print(f\"Total Recall: {total_recall:.4f}\")\n",
    "print(f\"Total F1-Score: {total_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0137\n",
      "Recall: 0.0213\n",
      "F1-score: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3243133/1779761820.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ie[\"output\"] = df_ie[\"output\"].str.lower().str.split(\", \")\n",
      "/tmp/ipykernel_3243133/1779761820.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ie[\"model_output\"] = df_ie[\"model_output\"].str.lower().str.split(\", \")\n"
     ]
    }
   ],
   "source": [
    "# ie\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터프레임 예시 (df_ie 가 주어진 데이터프레임)\n",
    "df_ie = df[df['task'] == 'ie']\n",
    "\n",
    "df_ie[\"output\"] = df_ie[\"output\"].str.lower().str.split(\", \")\n",
    "df_ie[\"model_output\"] = df_ie[\"model_output\"].str.lower().str.split(\", \")\n",
    "\n",
    "# Precision, Recall, F1-score 계산 함수\n",
    "def calculate_scores(y_true, y_pred):\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    all_f1s = []\n",
    "    \n",
    "    for true_vals, pred_vals in zip(y_true, y_pred):\n",
    "        true_set = set(true_vals) if isinstance(true_vals, list) else set()\n",
    "        pred_set = set(pred_vals) if isinstance(pred_vals, list) else set()\n",
    "\n",
    "        TP = len(true_set & pred_set)  # True Positives (정답과 예측이 일치하는 것)\n",
    "        FP = len(pred_set - true_set)  # False Positives (예측했지만 정답이 아닌 것)\n",
    "        FN = len(true_set - pred_set)  # False Negatives (정답이지만 예측하지 못한 것)\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    return sum(all_precisions) / len(all_precisions), sum(all_recalls) / len(all_recalls), sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "# Precision, Recall, F1-score 계산\n",
    "precision, recall, f1 = calculate_scores(df_ie[\"output\"], df_ie[\"model_output\"])\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided context and the model's response being irrelevant and repetitive, I would evaluate the model as follows:\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response lacks coherence, completeness, and naturalness as it does not address the content of the input or provide a meaningful response to the task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided input, here is the evaluation of the model's response:\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "Explanation:\n",
      "- The model's response does not demonstrate coherence as it does not align logically with the context of the input. It simply acknowledges a comment without addressing the main topic of impaired fasting glucose among perinatally HIV-infected adolescents and youths in Dar es Salaam, Tanzania.\n",
      "- The response lacks completeness as it fails to sufficiently answer the question or provide any meaningful information related to the study discussed in the input.\n",
      "- In terms of naturalness, the response is short and generic, lacking human-like fluency or relevance to the topic at hand.\n",
      "\n",
      "Overall, the model's response falls short in terms of coherence, completeness, and naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "This response lacks any actual content to evaluate based on the provided input. Therefore, I cannot rate the model's performance on Coherence, Completeness, and Naturalness. The model did not generate a response that can be assessed based on the given metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the given context and the model's response, here is the evaluation for each metric:\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "Overall, the model's response scored poorly on all metrics as it completely failed to provide a relevant and complete answer in a natural, human-like manner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the evaluation of the model's response, here are the ratings for each metric:\n",
      "\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 4.0\n",
      "\n",
      "Overall, the model's response aligns logically with the context provided, sufficiently answers the question, and sounds relatively fluent and human-like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided information, here is the evaluation of the QA model's responses:\n",
      "\n",
      "- Coherence: 2.5\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 3.0\n",
      "\n",
      "Overall, the model's responses partially address the comments provided but lack depth and specificity. The responses appear somewhat coherent with the input context but are incomplete in addressing the specific details requested. The naturalness of the responses is reasonable, sounding polite and professional. Further improvement is needed to enhance completeness and address the specific requests for additional details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the given input and the model's response, here is the evaluation of the QA model's responses:\n",
      "\n",
      "- Coherence: 2.0\n",
      "- Completeness: 1.5\n",
      "- Naturalness: 2.0\n",
      "\n",
      "Explanation:\n",
      "\n",
      "- **Coherence (2.0)**: The model's response partially aligns with the context provided in the input by acknowledging the study's aim to identify risk factors for diabetes in chronic pancreatitis. However, there is repetition in the response which affects the coherence.\n",
      "\n",
      "- **Completeness (1.5)**: The model's response lacks completeness as it fails to provide a detailed or comprehensive answer to the input. It does not discuss specific risk factors or outcomes mentioned in the original text.\n",
      "\n",
      "- **Naturalness (2.0)**: The response is not very natural as it appears to be repetitive and does not present information in a fluent or human-like manner. The repetition of the same content negatively impacts the naturalness of the response.\n",
      "\n",
      "Overall, the model's response needs improvement in terms of coherence, completeness, and naturalness to provide a more accurate and human-like response to the input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided information, here is the evaluation for the model's response:\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response lacks coherence, completeness, and naturalness as it repeatedly provides the same instruction without generating a meaningful summary of the article.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "I would evaluate the model's response based on the given metrics as follows:\n",
      "\n",
      "- Coherence: 2.0\n",
      "The response does not align logically with the context provided in the input about the epidemiology and clinical features of infectious pathology in patients with diabetes mellitus.\n",
      "\n",
      "- Completeness: 1.5\n",
      "The response does not sufficiently answer the question in the input about the risk of community-acquired pneumonia in patients with diabetes mellitus.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "The response sounds relatively fluent and could be considered somewhat human-like in tone.\n",
      "\n",
      "Overall, the model's response lacks coherence and completeness, but it is moderately natural in terms of language flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided information, here is the evaluation of the model's responses:\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's responses did not address the input question at all, leading to a low score across all metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "**Summary Evaluation**:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 4.5\n",
      "- Naturalness: 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the evaluation of the model's response, the ratings are as follows:\n",
      "\n",
      "- Coherence: 4.0\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided input and model responses, here is the evaluation of the QA model's responses:\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model response provided (\"Thank you for your comment. We have revised the manuscript to address your concerns.\") does not align with the input question about hyperglycemia, symptoms, and symptom clusters in colorectal cancer survivors with type 2 diabetes. It lacks both coherence and completeness as it does not sufficiently answer the input question. Additionally, the response does not exhibit naturalness as it does not sound fluent or human-like. \n",
      "\n",
      "Overall, the model's response is not relevant or appropriate in the context of the input question, and it fails to meet the criteria for coherence, completeness, and naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided input and the model's responses, here is the evaluation for the QA model:\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "Overall, the model's responses are not relevant or useful in answering the questions posed by the comments. The responses lack coherence, completeness, and naturalness as they do not provide any meaningful information related to the input context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided information, here is the evaluation of the model's response for the QA task:\n",
      "\n",
      "- Coherence: 2.0\n",
      "  - The response touches on the burden of disease but fails to address the details mentioned in the input about the specific diseases, population demographics, and other key aspects related to fruit and vegetable intake.\n",
      "\n",
      "- Completeness: 1.5\n",
      "  - The response lacks completeness as it only briefly mentions the estimated deaths and DALYs without providing a comprehensive overview of the burden of disease attributable to low fruit and vegetable intake in South Africa for the specified years.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "  - The response is relatively fluent and coherent in terms of language and structure, but it lacks depth and specificity in addressing the query.\n",
      "\n",
      "Overall, the model's response falls short in coherence and completeness while achieving moderate naturalness. Additional improvements are needed to enhance the model's performance in providing accurate and detailed answers to the input query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided input, model's responses, and true answer, here is the evaluation of the QA model's responses:\n",
      "\n",
      "- Coherence: 5.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 2.0\n",
      "\n",
      "Explanation:\n",
      "1. **Coherence (5.0)**: The responses consistently address the comment made by providing the same generic statement, which aligns with the context. The responses are logically coherent with the input.\n",
      "   \n",
      "2. **Completeness (1.0)**: The responses lack completeness as they repeatedly provide a vague statement without actually addressing the specific request for more information about the compounds in SJHK. The responses are not sufficiently answering the question.\n",
      "\n",
      "3. **Naturalness (2.0)**: The responses lack variety and creativity, with the same generic phrase being repeated multiple times. This lack of originality and variation affects the naturalness of the responses, making them sound robotic and non-human-like.\n",
      "\n",
      "Overall, while the responses are coherent, they severely lack completeness and naturalness. Improvements are needed in providing more detailed and varied responses that directly address the specific requests for information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "**True Answer**:\n",
      "\n",
      "- Objective: The objective of the study was to investigate the causes of lipohypertrophy in insulin-requiring subjects with type 2 diabetes and to assess the educational deficiencies in healthcare providers regarding correct injection techniques.\n",
      "- Methods: The study surveyed 1160 insulin-requiring subjects with type 2 diabetes and conducted physical examinations to identify lipohypertrophy. Educational and injection behavior differences were analyzed between subjects with and without lipohypertrophy.\n",
      "- Results: The study revealed significant educational gaps with many patients not receiving proper training on injection techniques from healthcare providers. Patients with lipohypertrophy often relied on peers for education, highlighting the need for repeated education for doctors and nurses.\n",
      "- Conclusion: The findings emphasize the urgent need to educate healthcare professionals on correct insulin injection techniques to enhance patient knowledge and skills and prevent lipohypertrophy-related complications.\n",
      "\n",
      "Please rate each metric on a scale from 1 to 5:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 5.0\n",
      "- Naturalness: 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 점수:\n",
      "Coherence       2.600000\n",
      "Completeness    1.900000\n",
      "Naturalness     2.320000\n",
      "BLEURT          0.529392\n",
      "BERTScore_F1    0.888975\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# summarization\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT 모델 로드\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 평가 함수\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = input_text[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = model_output[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = true_output[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 점수 추출\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT 점수 계산\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT 및 BERTScore 계산\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# 점수 정규화 함수\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "qa_df = df[df['task'] == 'summarization']\n",
    "results = []\n",
    "\n",
    "for _, row in qa_df.iterrows():\n",
    "    input_text, model_output, true_output = row['input'], row['model_output'], row['output']\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # 기본값 설정\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' 컬럼이 존재하는지 확인 후 정규화 수행\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"평균 점수:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "- Completeness: 4.5\n",
      "- Naturalness: 3.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 3.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Certainly! Here is the evaluation of the QA model's response based on the given metrics:\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "Explanation:\n",
      "- **Coherence (1.0)**: The model's response lacks coherence as it repeatedly states \"I have seen your query\" without providing any meaningful information or addressing the context provided in the input.\n",
      "- **Completeness (1.0)**: The response is completely incomplete as it fails to address any of the questions or concerns raised in the input, providing no helpful information to the user.\n",
      "- **Naturalness (1.0)**: The response lacks naturalness as it consists of repetitive and nonsensical phrases that do not resemble human-like communication.\n",
      "\n",
      "Overall, the QA model's response performs poorly on all evaluated metrics, indicating a significant room for improvement in generating relevant and coherent responses.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided input and true answer, here is the evaluation of the QA model's response:\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response lacks coherence as it veers off into generic information about erectile dysfunction without directly addressing the specific questions asked in the input. It also includes repetitive and irrelevant information. In terms of completeness, the response addresses some aspects of the query but fails to directly answer the questions about diagnosis and treatment options for erectile dysfunction. Additionally, the response lacks naturalness as it feels robotic, overly verbose, and repetitive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "- Completeness: 4.5\n",
      "- Naturalness: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided metrics, here is the evaluation of the model's response:\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "Overall Assessment:\n",
      "The model's response scored low in coherence and naturalness, as it repetitively lists the patient's history without providing a clear and concise response. In terms of completeness, while the model captures some of the patient's symptoms and history, it lacks a clear and actionable treatment plan as present in the true answer. Further improvement is needed to enhance the quality of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "- Completeness: 2.5\n",
      "- Naturalness: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "- Completeness: 2.5\n",
      "- Naturalness: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 3.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the given input and the model's response, here is the evaluation:\n",
      "\n",
      "- Coherence: 3.0\n",
      "- Completeness: 2.5\n",
      "- Naturalness: 2.5\n",
      "\n",
      "The model's response shows moderate coherence with some alignment to the symptoms described in the input. However, the response lacks completeness in addressing all the specific details mentioned by the patient. Additionally, the response appears somewhat robotic and lacks the natural flow of human-like language.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "- Completeness: 1.5\n",
      "- Naturalness: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5\n",
      "- Completeness: 1.5\n",
      "- Naturalness: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 점수:\n",
      "Coherence       3.020000\n",
      "Completeness    2.700000\n",
      "Naturalness     2.580000\n",
      "BLEURT          0.542391\n",
      "BERTScore_F1    0.614151\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# generation\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT 모델 로드\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 평가 함수\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = input_text[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = model_output[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = true_output[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 점수 추출\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT 점수 계산\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT 및 BERTScore 계산\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# 점수 정규화 함수\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "qa_df = df[df['task'] == 'generation']\n",
    "results = []\n",
    "\n",
    "for _, row in qa_df.iterrows():\n",
    "    input_text, model_output, true_output = row['input'], row['model_output'], row['output']\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # 기본값 설정\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' 컬럼이 존재하는지 확인 후 정규화 수행\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"평균 점수:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating daily diets: 100%|██████████| 21/21 [00:20<00:00,  1.03it/s]\n",
      "Evaluating alternative diets: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Diets Average Scores:\n",
      "Coherence               3.761905\n",
      "Completeness            3.000000\n",
      "Naturalness             3.880952\n",
      "Nutritional Adequacy    3.000000\n",
      "Caloric Balance         3.309524\n",
      "dtype: float64\n",
      "\n",
      "Alternative Diets scores not available:\n",
      "Missing columns: ['Improvement', 'Suitability']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# daily diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output, task_type):\n",
    "    input_text = input_text[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = model_output[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = true_output[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    if task_type == \"daily_diets\":\n",
    "        prompt = f\"\"\"\n",
    "        You are tasked with evaluating the quality of a meal recommendation model's responses based on the following metrics:\n",
    "        1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "        2. **Completeness**: Does the model's response sufficiently answer the input request?\n",
    "        3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "        4. **Nutritional Adequacy**: Does the meal align with the nutritional goals in the input, considering reasonable flexibility and practical applicability in real-life scenarios?\n",
    "        5. **Caloric Balance**: Are the recommended meals well-balanced in terms of calories?\n",
    "\n",
    "        **Input**:\n",
    "        {input_text}\n",
    "\n",
    "        **Model's Response**:\n",
    "        {model_output}\n",
    "\n",
    "        **True Answer**:\n",
    "        {true_output}\n",
    "\n",
    "        Please rate each metric on a scale from 1 to 5. \n",
    "        Example response format:\n",
    "        - Coherence: X.X\n",
    "        - Completeness: X.X\n",
    "        - Naturalness: X.X\n",
    "        - Nutritional Adequacy: X.X\n",
    "        - Caloric Balance: X.X\n",
    "        \"\"\"\n",
    "    elif task_type == \"alternative_diets\":\n",
    "        prompt = f\"\"\"\n",
    "        You are tasked with evaluating the quality of a meal recommendation model's responses based on the following metrics:\n",
    "        1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "        2. **Completeness**: Does the model's response sufficiently answer the input request?\n",
    "        3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "        4. **Improvement**: Does the recommended meal address the shortcomings of the previous meal?\n",
    "        5. **Suitability**: Is the recommended meal suitable for a diabetes patient?\n",
    "\n",
    "        **Input**:\n",
    "        {input_text}\n",
    "\n",
    "        **Model's Response**:\n",
    "        {model_output}\n",
    "\n",
    "        **True Answer**:\n",
    "        {true_output}\n",
    "\n",
    "        Please rate each metric on a scale from 1 to 5. \n",
    "        Example response format:\n",
    "        - Coherence: X.X\n",
    "        - Completeness: X.X\n",
    "        - Naturalness: X.X\n",
    "        - Improvement: X.X\n",
    "        - Suitability: X.X\n",
    "        \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for meal recommendation models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# 점수 추출 함수\n",
    "def extract_scores(evaluation, task_type):\n",
    "    if evaluation is None:\n",
    "        if task_type == \"daily_diets\":\n",
    "            return {\n",
    "                \"Coherence\": 0.0,\n",
    "                \"Completeness\": 0.0,\n",
    "                \"Naturalness\": 0.0,\n",
    "                \"Nutritional Adequacy\": 0.0,\n",
    "                \"Caloric Balance\": 0.0\n",
    "            }\n",
    "        elif task_type == \"alternative_diets\":\n",
    "            return {\n",
    "                \"Coherence\": 0.0,\n",
    "                \"Completeness\": 0.0,\n",
    "                \"Naturalness\": 0.0,\n",
    "                \"Improvement\": 0.0,\n",
    "                \"Suitability\": 0.0\n",
    "            }\n",
    "\n",
    "    scores = {}\n",
    "    if task_type == \"daily_diets\":\n",
    "        metrics = [\"Coherence\", \"Completeness\", \"Naturalness\", \"Nutritional Adequacy\", \"Caloric Balance\"]\n",
    "    elif task_type == \"alternative_diets\":\n",
    "        metrics = [\"Coherence\", \"Completeness\", \"Naturalness\", \"Improvement\", \"Suitability\"]\n",
    "\n",
    "    for metric in metrics:\n",
    "        match = re.search(fr\"{metric}: (\\d\\.\\d)\", evaluation)\n",
    "        scores[metric] = float(match.group(1)) if match else 0.0\n",
    "\n",
    "    return scores\n",
    "\n",
    "results = []\n",
    "\n",
    "daily_df = df[(df['task'] == 'daily_diets') & (df['output'].str.contains('\"Breakfast\"'))]\n",
    "\n",
    "for _, row in tqdm(daily_df.iterrows(), total=len(daily_df), desc=\"Evaluating daily diets\"):\n",
    "    evaluation = evaluate_with_gpt4(row['input'], row['model_output'], row['output'], \"daily_diets\")\n",
    "    scores = extract_scores(evaluation, \"daily_diets\")\n",
    "    results.append({**row.to_dict(), **scores})\n",
    "\n",
    "alternative_df = df[df['task'] == 'alternative_diets']\n",
    "\n",
    "for _, row in tqdm(alternative_df.iterrows(), total=len(alternative_df), desc=\"Evaluating alternative diets\"):\n",
    "    evaluation = evaluate_with_gpt4(row['input'], row['model_output'], row['output'], \"alternative_diets\")\n",
    "    scores = extract_scores(evaluation, \"alternative_diets\")\n",
    "    results.append({**row.to_dict(), **scores})\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "if \"Nutritional Adequacy\" in evaluation_df.columns and \"Caloric Balance\" in evaluation_df.columns:\n",
    "    daily_avg = evaluation_df[evaluation_df['task'] == 'daily_diets'][[\n",
    "        \"Coherence\", \"Completeness\", \"Naturalness\", \n",
    "        \"Nutritional Adequacy\", \"Caloric Balance\"\n",
    "    ]].mean()\n",
    "    print(\"Daily Diets Average Scores:\")\n",
    "    print(daily_avg)\n",
    "\n",
    "if \"Improvement\" in evaluation_df.columns and \"Suitability\" in evaluation_df.columns:\n",
    "    alternative_avg = evaluation_df[evaluation_df['task'] == 'alternative_diets'][[\n",
    "        \"Coherence\", \"Completeness\", \"Naturalness\", \n",
    "        \"Improvement\", \"Suitability\"\n",
    "    ]].mean()\n",
    "    print(\"\\nAlternative Diets Average Scores:\")\n",
    "    print(alternative_avg)\n",
    "else:\n",
    "    missing_columns = [col for col in [\"Improvement\", \"Suitability\"] if col not in evaluation_df.columns]\n",
    "    print(\"\\nAlternative Diets scores not available:\")\n",
    "    print(f\"Missing columns: {missing_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating alternative diets:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating alternative diets: 100%|██████████| 25/25 [00:23<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alternative Diets Average Scores:\n",
      "Coherence       4.32\n",
      "Completeness    4.00\n",
      "Naturalness     4.00\n",
      "Improvement     3.32\n",
      "Suitability     3.98\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# alternative diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output, task_type):\n",
    "\n",
    "    input_text = input_text[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = model_output[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = true_output[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    if task_type == \"daily_diets\":\n",
    "        prompt = f\"\"\"\n",
    "        You are tasked with evaluating the quality of a meal recommendation model's responses based on the following metrics:\n",
    "        1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "        2. **Completeness**: Does the model's response sufficiently answer the input request?\n",
    "        3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "        4. **Nutritional Adequacy**: Does the meal response meet the nutritional goals mentioned in the input?\n",
    "        5. **Caloric Balance**: Are the recommended meals well-balanced in terms of calories?\n",
    "\n",
    "        **Input**:\n",
    "        {input_text}\n",
    "\n",
    "        **Model's Response**:\n",
    "        {model_output}\n",
    "\n",
    "        **True Answer**:\n",
    "        {true_output}\n",
    "\n",
    "        Please rate each metric on a scale from 1 to 5. \n",
    "        Example response format:\n",
    "        - Coherence: X.X\n",
    "        - Completeness: X.X\n",
    "        - Naturalness: X.X\n",
    "        - Nutritional Adequacy: X.X\n",
    "        - Caloric Balance: X.X\n",
    "        \"\"\"\n",
    "    elif task_type == \"alternative_diet\":\n",
    "        prompt = f\"\"\"\n",
    "        You are tasked with evaluating the quality of a meal recommendation model's responses based on the following metrics:\n",
    "\n",
    "        1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "        2. **Completeness**: Does the model's response sufficiently answer the input request?\n",
    "        3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "        4. **Improvement**: Assume that the recommended alternative meal is an improvement over the previous meal. Evaluate how effectively it builds upon and enhances the previous meal, even if the changes are small or subtle.\n",
    "        5. **Suitability**: Is the recommended meal suitable for a diabetes patient?\n",
    "\n",
    "        **Input**:\n",
    "        {input_text}\n",
    "\n",
    "        **Model's Response**:\n",
    "        {model_output}\n",
    "\n",
    "        **True Answer**:\n",
    "        {true_output}\n",
    "\n",
    "        Please rate each metric on a scale from 1 to 5. \n",
    "        Example response format:\n",
    "        - Coherence: X.X\n",
    "        - Completeness: X.X\n",
    "        - Naturalness: X.X\n",
    "        - Improvement: X.X\n",
    "        - Suitability: X.X\n",
    "        \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for meal recommendation models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "def extract_scores(evaluation, task_type):\n",
    "    if evaluation is None:\n",
    "        if task_type == \"daily_diets\":\n",
    "            return {\n",
    "                \"Coherence\": 0.0,\n",
    "                \"Completeness\": 0.0,\n",
    "                \"Naturalness\": 0.0,\n",
    "                \"Nutritional Adequacy\": 0.0,\n",
    "                \"Caloric Balance\": 0.0\n",
    "            }\n",
    "        elif task_type == \"alternative_diet\":\n",
    "            return {\n",
    "                \"Coherence\": 0.0,\n",
    "                \"Completeness\": 0.0,\n",
    "                \"Naturalness\": 0.0,\n",
    "                \"Improvement\": 0.0,\n",
    "                \"Suitability\": 0.0\n",
    "            }\n",
    "\n",
    "    scores = {}\n",
    "    if task_type == \"daily_diets\":\n",
    "        metrics = [\"Coherence\", \"Completeness\", \"Naturalness\", \"Nutritional Adequacy\", \"Caloric Balance\"]\n",
    "    elif task_type == \"alternative_diet\":\n",
    "        metrics = [\"Coherence\", \"Completeness\", \"Naturalness\", \"Improvement\", \"Suitability\"]\n",
    "\n",
    "    for metric in metrics:\n",
    "        match = re.search(fr\"{metric}: (\\d\\.\\d)\", evaluation)\n",
    "        scores[metric] = float(match.group(1)) if match else 0.0\n",
    "\n",
    "    return scores\n",
    "\n",
    "results = []\n",
    "\n",
    "alternative_df = df[df['task'] == 'alternative_diet']\n",
    "\n",
    "for _, row in tqdm(alternative_df.iterrows(), total=len(alternative_df), desc=\"Evaluating alternative diets\"):\n",
    "    evaluation = evaluate_with_gpt4(row['input'], row['model_output'], row['output'], \"alternative_diet\")\n",
    "    scores = extract_scores(evaluation, \"alternative_diet\")\n",
    "    results.append({**row.to_dict(), **scores})\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "if all(col in evaluation_df.columns for col in [\"Improvement\", \"Suitability\"]):\n",
    "    alternative_avg = evaluation_df[[\n",
    "        \"Coherence\", \"Completeness\", \"Naturalness\", \n",
    "        \"Improvement\", \"Suitability\"\n",
    "    ]].mean()\n",
    "    print(\"\\nAlternative Diets Average Scores:\")\n",
    "    print(alternative_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>servings</th>\n",
       "      <th>steps</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition_facts</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark</td>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark: Dive into ...</td>\n",
       "      <td>10 min</td>\n",
       "      <td>4 hr</td>\n",
       "      <td>6 Servings</td>\n",
       "      <td>['Cover a freezer-safe tray with parchment pap...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...</td>\n",
       "      <td>{'Servings': '6 Servings', 'Serving Size': '1 ...</td>\n",
       "      <td>[{'label': 'Plain Nonfat Greek yogurt', 'us_me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maple-Pumpkin Spice Oatmeal Cookies</td>\n",
       "      <td>Description not found</td>\n",
       "      <td>10 min</td>\n",
       "      <td>25 min</td>\n",
       "      <td>14 Servings</td>\n",
       "      <td>['Preheat the oven to 350 degrees F. Line two ...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...</td>\n",
       "      <td>{'Servings': '14 Servings', 'Serving Size': '1...</td>\n",
       "      <td>[{'label': 'old-fashioned rolled oats', 'us_me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0   Raspberry Swirl Frozen Yogurt Bark   \n",
       "1  Maple-Pumpkin Spice Oatmeal Cookies   \n",
       "\n",
       "                                         description prep_time cook_time  \\\n",
       "0  Raspberry Swirl Frozen Yogurt Bark: Dive into ...    10 min      4 hr   \n",
       "1                              Description not found    10 min    25 min   \n",
       "\n",
       "      servings                                              steps  \\\n",
       "0   6 Servings  ['Cover a freezer-safe tray with parchment pap...   \n",
       "1  14 Servings  ['Preheat the oven to 350 degrees F. Line two ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...   \n",
       "1  ['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...   \n",
       "\n",
       "                                     nutrition_facts  \\\n",
       "0  {'Servings': '6 Servings', 'Serving Size': '1 ...   \n",
       "1  {'Servings': '14 Servings', 'Serving Size': '1...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  [{'label': 'Plain Nonfat Greek yogurt', 'us_me...  \n",
       "1  [{'label': 'old-fashioned rolled oats', 'us_me...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfh = pd.read_csv(\"/data/jaesung/llm_for_diabetes/src/data/data2_daily_diets/diabetes_food_hub_new_nutri_facts.csv\")\n",
    "dfh.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:27<00:00,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results for Each Row ===\n",
      "Row Index: 0\n",
      "Output Scores: {'Breakfast': {'score': 1.2832821300563242, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': 0.1844070961718014, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': 0.8727017632030825, 'grade': 'B'}, 'Lunch': {'score': -0.13559683963271407, 'grade': 'B'}, 'Dinner': {'score': 0.12827070932539675, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 1\n",
      "Output Scores: {'Breakfast': {'score': 0.27903677232536306, 'grade': 'B'}, 'Lunch': {'score': 1.2434792311769467, 'grade': 'B'}, 'Dinner': {'score': 0.12827070932539675, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': 1.210600194254846, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': 0.12827070932539675, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 2\n",
      "Output Scores: {'Breakfast': {'score': -0.06054961667206582, 'grade': 'B'}, 'Lunch': {'score': 1.4849885674520331, 'grade': 'B'}, 'Dinner': {'score': 0.12827070932539675, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -0.34868400536376987, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': -0.13559683963271407, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 3\n",
      "Output Scores: {'Breakfast': {'score': -5.211711711711713, 'grade': 'A'}, 'Lunch': {'score': -0.6524003743136113, 'grade': 'B'}, 'Dinner': {'score': 1.210600194254846, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -0.34868400536376987, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': 0.27903677232536306, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 4\n",
      "Output Scores: {'Breakfast': {'score': 0.08622999129328224, 'grade': 'B'}, 'Lunch': {'score': 5.048513302034429, 'grade': 'C'}, 'Dinner': {'score': 0.021039548778313044, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -0.34868400536376987, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': 0.659521337091431, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 5\n",
      "Output Scores: {'Breakfast': {'score': 1.934614824523082, 'grade': 'B'}, 'Lunch': {'score': -0.13559683963271407, 'grade': 'B'}, 'Dinner': {'score': 0.7137387880113759, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -0.41280659310399087, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': 3.7777777777777803, 'grade': 'C'}}\n",
      "\n",
      "Row Index: 6\n",
      "Output Scores: {'Breakfast': {'score': 0.912467700258398, 'grade': 'B'}, 'Lunch': {'score': -0.8293254408681712, 'grade': 'B'}, 'Dinner': {'score': 0.12827070932539675, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -0.34868400536376987, 'grade': 'B'}, 'Lunch': {'score': 1.210600194254846, 'grade': 'B'}, 'Dinner': {'score': 0.12827070932539675, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 7\n",
      "Output Scores: {'Breakfast': {'score': 0.42270531400966216, 'grade': 'B'}, 'Lunch': {'score': 0.8727017632030825, 'grade': 'B'}, 'Dinner': {'score': -0.27594371081766056, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': 1.210600194254846, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': -0.36950770646422804, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 8\n",
      "Output Scores: {'Breakfast': {'score': 0.8727017632030825, 'grade': 'B'}, 'Lunch': {'score': 0.5100293542074366, 'grade': 'B'}, 'Dinner': {'score': -0.36950770646422804, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -5.636214630779849, 'grade': 'A'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': 0.659521337091431, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 9\n",
      "Output Scores: {'Breakfast': {'score': -2.0825661036928644, 'grade': 'A'}, 'Lunch': {'score': 3.7777777777777803, 'grade': 'C'}, 'Dinner': {'score': 0.12827070932539675, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': 0.1844070961718014, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': 0.1844070961718014, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 10\n",
      "Output Scores: {'Breakfast': {'score': -0.41280659310399087, 'grade': 'B'}, 'Lunch': {'score': 0.2462391862198252, 'grade': 'B'}, 'Dinner': {'score': -0.3906122681790034, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': 1.210600194254846, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': 0.1844070961718014, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 11\n",
      "Output Scores: {'Breakfast': {'score': 0.12827070932539675, 'grade': 'B'}, 'Lunch': {'score': 3.991531435665514, 'grade': 'C'}, 'Dinner': {'score': 10.100156494522693, 'grade': 'D'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -0.34868400536376987, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': 1.210600194254846, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 12\n",
      "Output Scores: {'Breakfast': {'score': 0.8367122426528368, 'grade': 'B'}, 'Lunch': {'score': -0.4020340890818459, 'grade': 'B'}, 'Dinner': {'score': -0.13559683963271407, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': 1.210600194254846, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': -0.13559683963271407, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 13\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 14\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 15\n",
      "Output Scores: {'Breakfast': {'score': 0.8727017632030825, 'grade': 'B'}, 'Lunch': {'score': -0.4266791593180477, 'grade': 'B'}, 'Dinner': {'score': -0.36950770646422804, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -0.13559683963271407, 'grade': 'B'}, 'Lunch': {'score': 0.1844070961718014, 'grade': 'B'}, 'Dinner': {'score': 0.12827070932539675, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 16\n",
      "Output Scores: {'Breakfast': {'score': -0.3739171323675692, 'grade': 'B'}, 'Lunch': {'score': 0.25068770677669977, 'grade': 'B'}, 'Dinner': {'score': -1.5227480566986737, 'grade': 'A'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -0.31896724934699616, 'grade': 'B'}, 'Lunch': {'score': 0.18546853989891976, 'grade': 'B'}, 'Dinner': {'score': -0.13559683963271407, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 17\n",
      "Output Scores: {'Breakfast': {'score': 2.357681755829904, 'grade': 'C'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': 0.1844070961718014, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -0.34868400536376987, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': -3.2384529126307444, 'grade': 'A'}}\n",
      "\n",
      "Row Index: 18\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 19\n",
      "Output Scores: {'Breakfast': {'score': 0.7137387880113759, 'grade': 'B'}, 'Lunch': {'score': -0.11996228751547866, 'grade': 'B'}, 'Dinner': {'score': 1.4849885674520331, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -5.636214630779849, 'grade': 'A'}, 'Lunch': {'score': 0.659521337091431, 'grade': 'B'}, 'Dinner': {'score': -0.36950770646422804, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 20\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 21\n",
      "Output Scores: {'Breakfast': {'score': -0.31896724934699616, 'grade': 'B'}, 'Lunch': {'score': 0.037248942130043594, 'grade': 'B'}, 'Dinner': {'score': -2.6285387892530747, 'grade': 'A'}}\n",
      "Model Output Scores: {'Breakfast': {'score': 0.1844070961718014, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': -0.11996228751547866, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 22\n",
      "Output Scores: {'Breakfast': {'score': 0.4852935434116248, 'grade': 'B'}, 'Lunch': {'score': 0.7137387880113759, 'grade': 'B'}, 'Dinner': {'score': 0.12827070932539675, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': 1.210600194254846, 'grade': 'B'}, 'Lunch': {'score': -0.13559683963271407, 'grade': 'B'}, 'Dinner': {'score': 0.12827070932539675, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 23\n",
      "Output Scores: {'Breakfast': {'score': 0.8727017632030825, 'grade': 'B'}, 'Lunch': {'score': 0.5100293542074366, 'grade': 'B'}, 'Dinner': {'score': -0.36950770646422804, 'grade': 'B'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -0.31896724934699616, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': 0.1844070961718014, 'grade': 'B'}}\n",
      "\n",
      "Row Index: 24\n",
      "Output Scores: {'Breakfast': {'score': -0.5334085274869877, 'grade': 'B'}, 'Lunch': {'score': -0.34868400536376987, 'grade': 'B'}, 'Dinner': {'score': -1.6295609152752002, 'grade': 'A'}}\n",
      "Model Output Scores: {'Breakfast': {'score': -0.34868400536376987, 'grade': 'B'}, 'Lunch': {'score': 0.12827070932539675, 'grade': 'B'}, 'Dinner': {'score': -0.34868400536376987, 'grade': 'B'}}\n",
      "\n",
      "=== Overall Averages ===\n",
      "Output Average Nutri-Score: 0.4117810220807128\n",
      "Model Output Average Nutri-Score: -0.012445191418042765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# daily diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return all(key in data for key in ['Breakfast', 'Lunch', 'Dinner'])\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # 과일/채소 비율을 100g 기준으로 변환\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data) if isinstance(data, (int, float, str)) else default\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # 전체 무게 계산\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g 기준으로 성분 정규화\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_meal_nutri_score(meal_data, dfh):\n",
    "    meal_scores = {}\n",
    "\n",
    "    for meal, title in meal_data.items():\n",
    "        matched_row = find_most_similar_row(title, dfh)\n",
    "        if matched_row is None:\n",
    "            continue\n",
    "\n",
    "        nutrition_facts = matched_row['nutrition_facts']\n",
    "        ingredients = matched_row['ingredients']\n",
    "        score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "\n",
    "        if score is None:\n",
    "            print(f\"Warning: Nutri-Score calculation failed for meal '{meal}' with title '{title}'.\")\n",
    "            grade = \"N/A\"\n",
    "        else:\n",
    "            grade = get_nutri_score_grade(score)\n",
    "\n",
    "        meal_scores[meal] = {'score': score, 'grade': grade}\n",
    "\n",
    "    return meal_scores\n",
    "\n",
    "def calculate_scores_with_comparison(df, dfh):\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        output_scores = {}\n",
    "        model_scores = {}\n",
    "        if is_valid_meal_structure(row.get('output', '')):\n",
    "            output_data = json.loads(row['output'])\n",
    "            output_scores = calculate_meal_nutri_score(output_data, dfh)\n",
    "        if is_valid_meal_structure(row.get('model_output', '')):\n",
    "            model_data = json.loads(row['model_output'])\n",
    "            model_scores = calculate_meal_nutri_score(model_data, dfh)\n",
    "        results.append({'row_index': idx, 'output_scores': output_scores, 'model_scores': model_scores})\n",
    "    return results\n",
    "\n",
    "def calculate_average_scores(results):\n",
    "    \"\"\"\n",
    "    Calculate the average Nutri-Scores for outputs and model outputs.\n",
    "    \"\"\"\n",
    "    output_total_score = 0\n",
    "    model_total_score = 0\n",
    "    output_count = 0\n",
    "    model_count = 0\n",
    "\n",
    "    for result in results:\n",
    "        # Extract output scores\n",
    "        for meal, score_data in result['output_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                output_total_score += score_data['score']\n",
    "                output_count += 1\n",
    "\n",
    "        # Extract model scores\n",
    "        for meal, score_data in result['model_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                model_total_score += score_data['score']\n",
    "                model_count += 1\n",
    "\n",
    "    # Calculate averages\n",
    "    output_avg = output_total_score / output_count if output_count > 0 else None\n",
    "    model_avg = model_total_score / model_count if model_count > 0 else None\n",
    "\n",
    "    return output_avg, model_avg\n",
    "\n",
    "\n",
    "# 'daily_diets' task Nutri-Score calculation\n",
    "filtered_df = df[df['task'] == 'daily_diets']\n",
    "results = calculate_scores_with_comparison(filtered_df, dfh)\n",
    "\n",
    "# Calculate overall averages\n",
    "output_avg, model_avg = calculate_average_scores(results)\n",
    "\n",
    "# Print results\n",
    "print(\"=== Results for Each Row ===\")\n",
    "for result in results:\n",
    "    print(f\"Row Index: {result['row_index']}\")\n",
    "    print(f\"Output Scores: {result['output_scores']}\")\n",
    "    print(f\"Model Output Scores: {result['model_scores']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== Overall Averages ===\")\n",
    "print(f\"Output Average Nutri-Score: {output_avg}\")\n",
    "print(f\"Model Output Average Nutri-Score: {model_avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:33<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Average Nutri-Score: 0.4576467924666062\n",
      "Model Output Average Nutri-Score: 0.9385360360104872\n",
      "{'row_index': 50, 'output_score': -0.5456349206349205, 'model_output_score': -0.2137724271482232}\n",
      "{'row_index': 51, 'output_score': 0.32153783832762994, 'model_output_score': -1.8280321920168663}\n",
      "{'row_index': 52, 'output_score': 1.2495974235104654, 'model_output_score': 0.08622999129328224}\n",
      "{'row_index': 53, 'output_score': -0.2137724271482232, 'model_output_score': -1.8280321920168663}\n",
      "{'row_index': 54, 'output_score': 0.09538432905267075, 'model_output_score': 0.08622999129328224}\n",
      "{'row_index': 55, 'output_score': 0.09538432905267075, 'model_output_score': 0.04485645933014354}\n",
      "{'row_index': 56, 'output_score': -4.595731219412345, 'model_output_score': 3.005339996080737}\n",
      "{'row_index': 57, 'output_score': 0.32153783832762994, 'model_output_score': 0.9751322751322751}\n",
      "{'row_index': 58, 'output_score': -0.04938140184041795, 'model_output_score': 0.08622999129328224}\n",
      "{'row_index': 59, 'output_score': -0.3771852609061912, 'model_output_score': 8.479166666666668}\n",
      "{'row_index': 60, 'output_score': 0.6509013861955051, 'model_output_score': 0.08622999129328224}\n",
      "{'row_index': 61, 'output_score': -0.3154319831908299, 'model_output_score': 0.08622999129328224}\n",
      "{'row_index': 62, 'output_score': -1.8280321920168663, 'model_output_score': 0.08622999129328224}\n",
      "{'row_index': 63, 'output_score': 0.08814244409039951, 'model_output_score': -0.2137724271482232}\n",
      "{'row_index': 64, 'output_score': -1.8280321920168663, 'model_output_score': 1.0389211034967496}\n",
      "{'row_index': 65, 'output_score': -0.08572926025756211, 'model_output_score': 1.0389211034967496}\n",
      "{'row_index': 66, 'output_score': 1.0389211034967496, 'model_output_score': 0.08622999129328224}\n",
      "{'row_index': 67, 'output_score': 3.005339996080737, 'model_output_score': 0.9751322751322751}\n",
      "{'row_index': 68, 'output_score': -0.04938140184041795, 'model_output_score': -1.8280321920168663}\n",
      "{'row_index': 69, 'output_score': -0.08572926025756211, 'model_output_score': -0.2137724271482232}\n",
      "{'row_index': 70, 'output_score': 3.005339996080737, 'model_output_score': 10.288530465949819}\n",
      "{'row_index': 71, 'output_score': 1.8030071355759434, 'model_output_score': 1.0389211034967496}\n",
      "{'row_index': 72, 'output_score': 10.288530465949819, 'model_output_score': 1.0389211034967496}\n",
      "{'row_index': 73, 'output_score': 0.5535285495992766, 'model_output_score': 0.08622999129328224}\n",
      "{'row_index': 74, 'output_score': -1.1019415041528768, 'model_output_score': 0.9751322751322751}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# alternative diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return isinstance(data, dict)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # 과일/채소 비율을 100g 기준으로 변환\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # 전체 무게 계산\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g 기준으로 성분 정규화\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_scores_with_comparison_no_meals(df, dfh):\n",
    "    results = []\n",
    "    output_scores_list = []\n",
    "    model_output_scores_list = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            output_text = row.get('output', '')\n",
    "            if output_text:\n",
    "                matched_row = find_most_similar_row(output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    output_scores_list.append(output_score)\n",
    "                else:\n",
    "                    output_score = None\n",
    "\n",
    "            model_output_text = row.get('model_output', '')\n",
    "            if model_output_text:\n",
    "                matched_row = find_most_similar_row(model_output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    model_output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    model_output_scores_list.append(model_output_score)\n",
    "                else:\n",
    "                    model_output_score = None\n",
    "\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': output_score,\n",
    "                'model_output_score': model_output_score\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': None,\n",
    "                'model_output_score': None\n",
    "            })\n",
    "\n",
    "    final_output_avg = sum(output_scores_list) / len(output_scores_list) if output_scores_list else None\n",
    "    final_model_output_avg = sum(model_output_scores_list) / len(model_output_scores_list) if model_output_scores_list else None\n",
    "\n",
    "    print(f\"Output Average Nutri-Score: {final_output_avg}\")\n",
    "    print(f\"Model Output Average Nutri-Score: {final_model_output_avg}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Execution\n",
    "filtered_df = df[df['task'] == 'alternative_diet']\n",
    "results = calculate_scores_with_comparison_no_meals(filtered_df, dfh)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meal_kernel",
   "language": "python",
   "name": "meal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
