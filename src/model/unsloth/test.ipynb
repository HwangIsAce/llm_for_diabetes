{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-16 11:09:30 __init__.py:190] Automatically detected platform cuda.\n",
      "INFO 02-16 11:09:39 config.py:542] This model supports multiple tasks: {'classify', 'embed', 'score', 'generate', 'reward'}. Defaulting to 'generate'.\n",
      "INFO 02-16 11:09:39 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='BatsResearch/bonito-v1', speculative_config=None, tokenizer='BatsResearch/bonito-v1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=BatsResearch/bonito-v1, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 02-16 11:09:40 cuda.py:230] Using Flash Attention backend.\n",
      "INFO 02-16 11:09:41 model_runner.py:1110] Starting to load model BatsResearch/bonito-v1...\n",
      "INFO 02-16 11:09:41 weight_utils.py:252] Using model weights format ['*.bin']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e284834a94b249b3952d6151bc86971f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pt checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-16 11:09:54 model_runner.py:1115] Loading model weights took 13.4967 GB\n",
      "INFO 02-16 11:09:57 worker.py:267] Memory profiling takes 2.94 seconds\n",
      "INFO 02-16 11:09:57 worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB\n",
      "INFO 02-16 11:09:57 worker.py:267] model weights take 13.50GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 3.38GiB; the rest of the memory reserved for KV Cache is 18.48GiB.\n",
      "INFO 02-16 11:09:57 executor_base.py:110] # CUDA blocks: 9462, # CPU blocks: 2048\n",
      "INFO 02-16 11:09:57 executor_base.py:115] Maximum concurrency for 32768 tokens per request: 4.62x\n",
      "INFO 02-16 11:09:59 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-16 11:10:16 model_runner.py:1562] Graph capturing finished in 17 secs, took 0.87 GiB\n",
      "INFO 02-16 11:10:16 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 22.37 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ab397279ef467e888f26ee2890fcac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 10/10 [00:01<00:00,  5.84it/s, est. speed input: 654.43 toks/s, output: 312.91 toks/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f8d6b4aa0742859a97b8ab3682178e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03901814ebe041ff8d343b3a5c661305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bonito import Bonito\n",
    "from vllm import SamplingParams\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Initialize the Bonito model\n",
    "bonito = Bonito(\"BatsResearch/bonito-v1\")\n",
    "\n",
    "# load dataset with unannotated text\n",
    "unannotated_text = load_dataset(\n",
    "    \"BatsResearch/bonito-experiment\",\n",
    "    \"unannotated_contract_nli\"\n",
    ")[\"train\"].select(range(10))\n",
    "\n",
    "# Generate synthetic instruction tuning dataset\n",
    "sampling_params = SamplingParams(max_tokens=256, top_p=0.95, temperature=0.5, n=1)\n",
    "synthetic_dataset = bonito.generate_tasks(\n",
    "    unannotated_text,\n",
    "    context_col=\"input\",\n",
    "    task_type=\"qa\",\n",
    "    sampling_params=sampling_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Recipient is given a written agreement with the Discloser',\n",
       " 'to prevent disclosure of confidential information',\n",
       " '5',\n",
       " 'The name of the United Nations is protected by law',\n",
       " 'receive data',\n",
       " 'to protect confidential information',\n",
       " 'yes',\n",
       " 'to protect confidential information',\n",
       " 'The Recipient cannot be precluded from disclosing the Confidential Information because the Recipient is not in breach of any obligation as to confidentiality.',\n",
       " 'to define confidential information']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_dataset['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.3 Provided that the Recipient has a written agreement with the following persons or entities requiring them to treat the Confidential Information in accordance with this Agreement, the Recipient may disclose the Confidential Information to: 2.3.1  Any other party with the Discloser’s prior written consent; and 2.3.2 the Recipient’s employees, officials, representatives and agents who have a strict need to know the contents of the Confidential Information, and employees, officials, representatives and agents of any legal entity that it controls, controls it, or with which it is under common control, who have a similar need to know the contents of the Confidential Information, provided that, for these purposes a controlled legal entity means:',\n",
       " '5. All Confidential Information in any form and any medium, including all copies thereof, disclosed to the Recipient shall be returned to UNHCR or destroyed:  (a) if a business relationship is not entered into with UNHCR on or before the date which is three (3) months after the date both Parties have signed the Agreement; or',\n",
       " '4. Nothing in this Agreement is to be construed as granting the Recipient, by implication or otherwise, any right whatsoever with respect to the Confidential Information or part thereof.',\n",
       " '11. The Recipient shall not advertise or otherwise make public the fact that it has a confidential relationship with UNHCR, nor shall the Recipient, in any manner whatsoever use the name, emblem, or official seal of the United Nations or UNHCR, or any abbreviation of the name of the United Nations or UNHCR in connection with its business or otherwise.',\n",
       " '1. “Confidential Information”, whenever used in this Agreement, shall mean any data, document, specification and other information or material, that is delivered or disclosed by UNHCR to the Recipient in any form whatsoever, whether orally, visually in writing or otherwise (including computerized form), and that, at the time of disclosure to the Recipient, is designated as confidential.',\n",
       " '1. “Confidential Information”, whenever used in this Agreement, shall mean any data, document, specification and other information or material, that is delivered or disclosed by UNHCR to the Recipient in any form whatsoever, whether orally, visually in writing or otherwise (including computerized form), and that, at the time of disclosure to the Recipient, is designated as confidential.',\n",
       " 'Either Party may terminate the working relationship contemplated by this Agreement by providing written notice to the other, provided, however, that the obligations and restrictions hereunder regarding the Confidential Information shall remain effective following any such termination or any other termination or expiration of this Agreement.',\n",
       " 'The Recipient shall not be precluded from disclosing the Confidential Information that is  (i) obtained by the Recipient without restriction from a third party who is not in breach of any obligation as to confidentiality to the owner of such Confidential Information or any other person, or  (ii) disclosed by the Discloser to a third party without any obligation of confidentiality, or  (iii) previously known by the Recipient, or  (iv) at any time is developed by the Recipient completely independently of any disclosures hereunder.',\n",
       " 'The Recipient shall not be precluded from disclosing the Confidential Information that is  (i) obtained by the Recipient without restriction from a third party who is not in breach of any obligation as to confidentiality to the owner of such Confidential Information or any other person, or',\n",
       " '1. “Confidential Information”, whenever used in this Agreement, shall mean any data, document, specification and other information or material, that is delivered or disclosed by UNHCR to the Recipient in any form whatsoever, whether orally, visually in writing or otherwise (including computerized form), and that, at the time of disclosure to the Recipient, is designated as confidential.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unannotated_text['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env_kernel",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
