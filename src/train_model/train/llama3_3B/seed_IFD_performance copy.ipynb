{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# \n",
    "file_paths = [\n",
    "    \"/data/jaesung/llm_for_diabetes/src/trial8/train/llama3_8B/response/real_seed_IFD.jsonl\",\n",
    "    # \"/data/jaesung/llm_for_diabetes/src/trial/CoT_collection/model_response/test_1.jsonl\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "# medqa\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "qa1 = df[df['task'] == 'qa1']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(qa1)\n",
    "\n",
    "for _, row in qa1.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.1800\n"
     ]
    }
   ],
   "source": [
    "# medmcqa\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "qa2 = df[df['task'] == 'qa2']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(qa2)\n",
    "\n",
    "for _, row in qa2.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.7100\n"
     ]
    }
   ],
   "source": [
    "# pubmedqa\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "qa3 = df[df['task'] == 'qa3']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(qa3)\n",
    "\n",
    "for _, row in qa3.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.2200\n"
     ]
    }
   ],
   "source": [
    "# bionli\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "nli = df[df['task'] == 'nli']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(nli)\n",
    "\n",
    "for _, row in nli.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating drug/effect pairs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 22434.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Drug/Effect Pair Evaluation (Strict Match, cleaned)\n",
      "‚úÖ Precision: 0.3434\n",
      "‚úÖ Recall   : 0.3400\n",
      "‚úÖ F1 Score : 0.3417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_drug_effect_clean(text):\n",
    "    \"\"\"\n",
    "    output ÎòêÎäî model_output_32ÏóêÏÑú drugÏôÄ effect Í∞íÏùÑ Ï∂îÏ∂úÌïòÍ≥†,\n",
    "    \\nÏù¥ÎÇò ÌäπÏàò ÌÜ†ÌÅ∞ Ïù¥ÌõÑÏùò ÏÑ§Î™ÖÏùÄ Ï†úÍ±∞ÌïúÎã§.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return {\"drug\": None, \"effect\": None}\n",
    "    \n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # drug Ï∂îÏ∂ú\n",
    "    drug_match = re.search(r'drug:\\s*([^,\\n|<]+)', text)\n",
    "    drug = drug_match.group(1).strip() if drug_match else None\n",
    "\n",
    "    # effect Ï∂îÏ∂ú\n",
    "    effect_match = re.search(r'effect:\\s*([^\\n|<]+)', text)\n",
    "    effect = effect_match.group(1).strip() if effect_match else None\n",
    "\n",
    "    return {\"drug\": drug, \"effect\": effect}\n",
    "\n",
    "# ‚úÖ 're2' taskÎßå ÌïÑÌÑ∞ÎßÅ\n",
    "re_df = df[df['task'] == 're2'].reset_index(drop=True)\n",
    "\n",
    "# ‚úÖ ÌÜµÍ≥Ñ Î≥ÄÏàò Ï¥àÍ∏∞Ìôî\n",
    "true_positive, false_positive, false_negative = 0, 0, 0\n",
    "\n",
    "# ‚úÖ ÌèâÍ∞Ä Î£®ÌîÑ\n",
    "for _, row in tqdm(re_df.iterrows(), total=len(re_df), desc=\"Evaluating drug/effect pairs\"):\n",
    "    true_vals = extract_drug_effect_clean(row['output'])\n",
    "    pred_vals = extract_drug_effect_clean(row['model_output_32'])\n",
    "\n",
    "    if true_vals[\"drug\"] and true_vals[\"effect\"]:\n",
    "        if true_vals == pred_vals:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "            if pred_vals[\"drug\"] or pred_vals[\"effect\"]:\n",
    "                false_positive += 1\n",
    "    elif pred_vals[\"drug\"] or pred_vals[\"effect\"]:\n",
    "        false_positive += 1\n",
    "\n",
    "# ‚úÖ ÏßÄÌëú Í≥ÑÏÇ∞\n",
    "precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# ‚úÖ Ï∂úÎ†•\n",
    "print(\"\\nüìä Drug/Effect Pair Evaluation (Strict Match, cleaned)\")\n",
    "print(f\"‚úÖ Precision: {precision:.4f}\")\n",
    "print(f\"‚úÖ Recall   : {recall:.4f}\")\n",
    "print(f\"‚úÖ F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 'ie' ÌÉúÏä§ÌÅ¨ ÌïÑÌÑ∞ÎßÅ\n",
    "ie = df[df['task'] == 'ie'].copy()\n",
    "\n",
    "# Î¨∏ÏûêÏó¥ ÌòïÌÉúÎ•º ÏïàÏ†ÑÌïòÍ≤å Î¶¨Ïä§Ìä∏Î°ú ÌååÏã±ÌïòÎäî Ìï®Ïàò\n",
    "def safe_eval(val):\n",
    "    if isinstance(val, list):  \n",
    "        return [str(i).strip().lower() for i in val]\n",
    "    elif isinstance(val, str) and val.strip():  \n",
    "        try:\n",
    "            parsed = ast.literal_eval(val)\n",
    "            if isinstance(parsed, list):\n",
    "                return [str(i).strip().lower() for i in parsed]\n",
    "            else:\n",
    "                return [str(parsed).strip().lower()]\n",
    "        except:\n",
    "            return [val.strip().lower()]\n",
    "    return []\n",
    "\n",
    "# outputÍ≥º model_output Î™®Îëê Î¶¨Ïä§Ìä∏ ÌòïÌÉúÎ°ú ÌååÏã±\n",
    "ie[\"output\"] = ie[\"output\"].apply(safe_eval)\n",
    "ie[\"model_output_32\"] = ie[\"model_output_32\"].apply(safe_eval)\n",
    "\n",
    "# Precision, Recall, F1-score Í≥ÑÏÇ∞ Ìï®Ïàò\n",
    "def calculate_scores(y_true, y_pred):\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for true_vals, pred_vals in zip(y_true, y_pred):\n",
    "        if not true_vals and not pred_vals:\n",
    "            all_precisions.append(1.0)\n",
    "            all_recalls.append(1.0)\n",
    "            all_f1s.append(1.0)\n",
    "            continue\n",
    "\n",
    "        true_count = Counter(true_vals)\n",
    "        pred_count = Counter(pred_vals)\n",
    "\n",
    "        TP = sum(min(true_count[k], pred_count[k]) for k in true_count.keys() & pred_count.keys())\n",
    "        FP = sum(pred_count[k] - true_count.get(k, 0) for k in pred_count.keys())\n",
    "        FN = sum(true_count[k] - pred_count.get(k, 0) for k in true_count.keys())\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    return sum(all_precisions) / len(all_precisions), sum(all_recalls) / len(all_recalls), sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "def calculate_scores_ignore_duplicates(y_true, y_pred):\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for true_vals, pred_vals in zip(y_true, y_pred):\n",
    "        true_set = set(true_vals)\n",
    "        pred_set = set(pred_vals)\n",
    "\n",
    "        TP = len(true_set & pred_set)\n",
    "        FP = len(pred_set - true_set)\n",
    "        FN = len(true_set - pred_set)\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    return sum(all_precisions) / len(all_precisions), sum(all_recalls) / len(all_recalls), sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "\n",
    "# Ï†êÏàò Í≥ÑÏÇ∞\n",
    "precision, recall, f1 = calculate_scores_ignore_duplicates(ie[\"output\"], ie[\"model_output_32\"])\n",
    "\n",
    "# Ï∂úÎ†•\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response accurately reflects the coherent sequence of interactions between the doctor and the patient. It maintains logical alignment with the context provided, recapitulating the entire dialogue effectively.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - The model simply mirrors the interaction verbatim without transforming it into a concise, integrated answer as the True Answer does. While the response is detailed, it is not in the expected format of a summarization or transformation as seen in the True Answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response, being a direct replay of the dialogue, sounds fluent and human-like. The conversational flow is preserved, making it sound natural in the context of a dialogue summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The response mostly aligns with the context and captures the major aspects of the conversation. However, it does not include some details, such as specific patient demographics, which are present in the true answer.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - While the model's response covers most of the symptoms, history, examination findings, and diagnostic results, it misses certain demographic details, some examination results, and the fact that there is a working diagnosis. Other detailed historical facts like the patient's Cameroonian origin and the specific hospital are also absent.\n",
      "  \n",
      "- Naturalness: 4.7\n",
      "  - The response is generally fluent and human-like but slightly mechanical in listing the information, lacking some of the natural structure present in a typical clinical note, such as those related to demographic details or specific conclusions drawn from data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is coherent with the context provided. It correctly identifies the diagnosis of high-risk PTCL, NOS, and mentions the treatment with modified chemotherapy. However, it omits some details such as the patient's specific symptoms and medical history, which were part of the preceding conversation.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The response covers the main outcome about the diagnosis and the proposed treatment plan but lacks specificity in some areas. It does not include critical laboratory and biopsy findings or mention the patient's medical history, which could provide a more complete picture of the case.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The model's response is fairly natural and human-like. It conveys information in a clear and understandable manner, although it is slightly repetitive in stating the diagnosis's high-risk nature, which affects its flow. Overall, it accurately reflects how a doctor might communicate such information to a patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response is generally coherent and aligns logically with the context provided in the input. The summary covers the main points of the doctor-patient conversation and reflects the doctor's concerns and actions. However, the conclusion about being unable to save the patient is missing, which affects the coherence.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The model's response captures most of the main elements of the conversation, including symptoms, vital signs, examination findings, and the need for further tests and treatment. However, it lacks details about the outcome of the case, specifically the inability to save the patient and the need to discuss next steps with the family.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The model's response is fluent and human-like in its summary of the conversation. It uses appropriate clinical language and maintains a professional tone that would be expected in a medical setting. The language is clear and direct, resembling how a clinician might write a clinical note.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the information provided in the input dialogue. It accurately reflects the progression of the patient's medical situation and the treatment steps taken.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response is mostly complete but simplifies some of the details found in the true answer. It captures the key points of the treatment process but omits certain details like the patient's age, diabetes, hypertension, and the specific doses of teriparatide and elemental calcium.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The language used in the model's response is fluent and human-like, maintaining a clinical tone appropriate for medical summaries. However, it could be slightly further improved with more nuanced language for higher naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is almost entirely coherent with the context provided. However, it inaccurately mentions that the patient had difficulty breathing, which the patient denied.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model's response covers most key points, including symptoms, medical and dental history, lifestyle, and previous treatments. It lacks specific details such as the patient's occupation and family status, but these are not crucial to the medical analysis being summarized.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response is fluent, well-structured, and resembles a human-like summary of the conversation. It logically organizes information without awkward phrasing or grammatical errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 4.5\n",
      "- Naturalness: 5.0\n",
      "\n",
      "**Explanation:**\n",
      "- **Coherence (5.0):** The model's response is coherent as it perfectly mirrors the interaction between the doctor and the patient. It provides a detailed account of the conversation and logically aligns with the context given in the input without introducing any errors or contradictions.\n",
      "- **Completeness (4.5):** While the model's response encapsulates most of the key details from the conversation, it primarily replicates the interaction rather than summarizing the scenario effectively or explicitly outlining the complete diagnosis and treatment plan. It doesn't extract specific details such as the patient's age or the mention of normal liver and renal functions which are found in the \"True Answer.\"\n",
      "- **Naturalness (5.0):** The dialogue generated by the model is fluid and mimics a natural human conversation. The exchange between the doctor and the patient is structured in a way that feels authentic and maintains a professional tone throughout the interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is generally coherent with the context provided. It logically follows the sequence of events discussed between the doctor and the patient. However, there is a minor discrepancy as it doesn't mention some of the details like her blood pressure during the hospital admission or the sequential occurrence of the seizures, which are relevant to the case progression.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The model's response is mostly complete in terms of capturing the key points of the provided dialogue. It covers the patient's history, initial diagnosis, and transfer to the ICU. However, it fails to detail the progression of events, particularly the timing and nature of the seizures and the context of the initial admission, which are present in the true answer.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The model's response is very natural and fluent. It reads like a summary that a medical professional might provide, maintaining a clinical and human-like tone. The sentence structure and vocabulary are appropriate for the context, enhancing the overall readability and professionalism.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "    - The model's response claims to summarize the conversation, but it offers very little specific information related to the conversation content. It lacks the logical flow and factuality seen in the true answer.\n",
      "- Completeness: 1.5\n",
      "    - The response is very general and does not address specific symptoms, conditions, or medical history mentioned in the input. Important details are missing, such as the diagnosis of pneumonia, acute kidney injury, and treatment specifics. It fails to deliver a comprehensive answer based on the input context.\n",
      "- Naturalness: 3.0\n",
      "    - The language used by the model is fluent and human-like, but it's too generic and lacks the detail expected from a clinical note derived from the detailed conversation provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the dialogue provided in the input. It accurately reflects the sequence of events and the medical condition discussed by the doctor and patient. However, the mention of death in the dialogue as part of a \"clinical note\" is unconventional, hence a slight deduction.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model sufficiently answers the context by summarizing the progression of the patient's condition and death. However, it misses some details present in the true answer, such as the exact timing of the surgical site infection (\"about 3 weeks after surgery\"). The model doesn't explicitly mention the age of the patient nor the specific diagnosis timeline related to the surgery.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and mostly human-like. It is structured in a manner typical of clinical notes. However, the bizarre inclusion of a message of death in such a formal document without further supportive context (unlike casual conversation) slightly diminishes its natural feel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically follows from the input context. It summarizes the events and details correctly. The only minor issue is that it doesn't explicitly address the patient's emotional responses, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model's response captures most of the critical details from the conversation, including symptoms, medical history, initial treatment, and transfer plans. However, it omits a more explicit explanation of medical terms like \"rotated film\" and \"inferoposterior STEMI,\" which would enhance understanding.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "  - While the response retains a professional tone and fluency, it lacks the conversational elements found in human interactions. The repetition of facts and slightly robotic structure make it less human-like. A more seamless integration of dialogues would improve naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns with the context provided in the input. It accurately reflects the dialogue between the doctor and the patient, maintaining consistency with the sequence of events and medical details.\n",
      "\n",
      "- Completeness: 5.0  \n",
      "  The model's response sufficiently answers the question as it provides a detailed account of each presentation, including significant medical events, treatments received, and outcomes. It encompasses all the key information conveyed in the true answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The dialogue in the model's response is fluent and sounds human-like. It maintains a conversational tone and structure consistent with a doctor-patient interaction, using appropriate language and phrasing throughout the exchange.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response accurately follows the dialogue provided in the input. Each part of the patient's history and symptoms aligns logically with the context and prior questions from the doctor.\n",
      "\n",
      "- Completeness: 5.0\n",
      "  - The model's response thoroughly addresses all the details mentioned throughout the dialogue. It covers the patient's medical history, symptoms, lab work, differential diagnosis, and treatment results in detail, matching the true answer provided.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The dialogue flows naturally and maintains a human-like conversational tone. The language used is clear and fluent, suitable for a patient-doctor interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context provided and summarizes the key points of the doctor's conversation with the patient and family. However, it doesn't capture the entire interaction, particularly the doctor's apology and family's response are missing. \n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the model summarizes the medical history and related changes during surgery, it lacks specifics about the patient's death, such as family communication and emotional aspects present in the conversation.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and sounds human-like, articulating the situation clearly and cohesively. However, it reads more like a clinical note than a natural conversation, which impacts the perceived naturalness slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "\n",
      "The model's response is logically aligned with the context provided. It accurately synthesizes the information exchanged between the doctor and patient, maintaining consistency with the provided dialogue.\n",
      "\n",
      "- Completeness: 4.5\n",
      "\n",
      "The model's response is mostly complete, capturing the essential details discussed in the interaction. However, it omits specific contextual details about the mother's condition becoming apparent through recurrent mucosal candidiasis and mild postprandial hyperglycaemia, as well as the father remaining asymptomatic after his diagnosis.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The model's response is fluently written in a natural and human-like clinical note format. While it's fairly formal, this style is appropriate given the clinical context and matches expectations for a report of this nature. Minimal awkward phrasing enhances its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is coherent in summarizing the dialogue between the doctor and the patient. However, it lacks some specific details present in the true answer, such as the exact size of the mass and the patient's intermittent dysphagia for solids.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model provides a well-rounded answer that covers most aspects from the input conversation. It captures the primary medical findings, procedures, and patient instructions. However, it misses the patient's demographic details and the specific measurement of the thyroid mass, which are present in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds human-like. It uses terminology and sentence structures that match natural conversation, particularly in a clinical setting. There are little to no awkward expressions or phrasing issues.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 2.0**  \n",
      "  The model's response demonstrates significant incoherence with the provided context. It incorrectly identifies the patient as a male and fails to mention crucial details like the patient's background and gender, which were clearly outlined in the input.\n",
      "\n",
      "- **Completeness: 2.5**  \n",
      "  Though the model captures some elements of the patient's medical history related to HCV, it lacks critical details that are necessary for a complete understanding. It misses other essential parts of the patient history such as age, gender, diabetes diagnosis, the effectiveness of treatment, specific test results, and the cessation of the previous treatment due to side effects.\n",
      "\n",
      "- **Naturalness: 4.0**  \n",
      "  The model's response is generally fluent and reads in a human-like manner. However, the inaccuracies and missing details somewhat affect the perception of naturalness because a human responding accurately would include these relevant details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response mostly aligns with the context provided in the input, correctly summarizing the patient's medical history, the diagnostic and therapeutic procedures they underwent, and the loss to follow-up status. However, it inaccurately mentions urinary symptoms as a chief complaint, which the patient explicitly denied experiencing.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response covers most of the key details from the input, such as the patient's medical history, the suspicion of renal cell carcinoma, the biopsy, the nephrectomy, and subsequent follow-up issues. However, it mistakenly states that urinary symptoms were attributed to the renal mass, which was not mentioned in the input.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The clinical note is well-written, fluent, and human-like. It adheres to the formal tone typical in medical documentation, maintaining clarity and comprehensibility. Yet, the slight error regarding urinary symptoms slightly impacts the perceived accuracy and reliability.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response is coherent with the context provided in the input. It follows the dialog sequence accurately and maintains the logical flow of questions and answers in a conversation between a doctor and a patient. However, some details such as the age of the patient and specific details about the renal ultrasound are missing.\n",
      "\n",
      "- **Completeness: 3.5**  \n",
      "  The model's response is mostly complete but lacks some specific details present in the true answer, such as the age of the patient, the specific finding of the duplicated collecting system with mild prominence, and the need for water to stimulate diuresis after the water deprivation test. These omissions somewhat reduce the completeness of the response.\n",
      "\n",
      "- **Naturalness: 5.0**  \n",
      "  The model's response sounds fluent and human-like. The dialogue uses natural language and the interactions follow a realistic pattern for a medical consultation. The responses are well-constructed and align with the typical communication style you'd expect in such a setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 3.5\n",
      "\n",
      "Explanation:\n",
      "- **Coherence**: The model's response is relatively coherent with the structure of a medical note, but it's essentially just a repetition of the input conversation without synthesizing the information or organizing it clearly into a structured note. It doesn't effectively transform the direct dialogue into a coherent clinical summary.\n",
      "  \n",
      "- **Completeness**: The model repeats the conversation nearly verbatim without adding synthesized conclusions or additional contextual information that is customary in a clinical note, such as age or location details mentioned in the true answer. It also lacks the specific details about the progression and severity of the disease and the treatment mentioned in the true note.\n",
      "\n",
      "- **Naturalness**: While the model's response maintains the directness and fluency of the patient-doctor dialogue, it does not exhibit the natural language typical of structured clinical notes. It misses the professional tone and summarization typical of such notes, despite the individual parts being fluently written.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response contains a repetition of the dialogue instead of a summarized or structured clinical note. This repetition makes the response logically misaligned with what would be expected from a clinical note, which should concisely compile and synthesize the information provided in the dialogue. However, the repeated dialogue does match the original context.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "While the model's response includes much of the dialogue, it lacks the structured summary form expected in a clinical note. The dialogue format doesn't allow for an easy extraction of key points, such as timing of symptoms, treatment details, or any other follow-up necessary. There's no mention of the conclusion about the patient's stable condition or follow-up plans, which are crucial for completeness.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The text itself is fluent, and each individual portion of dialogue sounds natural and human-like. However, the expected form for a clinical note is not met, slightly lowering its score in terms of natural use for the context required. Nonetheless, the language used is grammatically correct and competently mirrors authentic human dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "  - The model's response is mostly coherent with the context provided, accurately mentioning key details such as chromosome 1q21.1 deletion syndrome, dextrocardia, atrial septal defect, and SIADH. However, it introduces Dr. Smith, which is inconsistent with the previous conversation, and there is some generalization in the explanation of test results without addressing some specific results like the elevated plasma AVP level.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The response covers most aspects of the medical condition discussed in the input, including the cardiac findings, kidney function, hormonal levels, and chromosome deletion syndrome. It also mentions discussing the condition with the patient's mother. However, the degree of detail could be improved by including additional specifics from the input, such as the exact test values for clearer elaboration.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The model's response is generally fluent and uses language that is natural and human-like. The tone is empathetic and professional, resembling how a doctor might communicate information to a patient. The main issue affecting naturalness is the inconsistency with the doctor's identity (introduction of Dr. Smith), which can slightly disrupt the dialogue's flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response generally aligns with the input context, providing a structured overview of the conversation between the doctor and patient. However, it lacks specific details and nuances present in the input, which slightly affects its coherence.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The response covers key aspects of the patient's condition, history, and the doctor's recommendations but omits detailed specifics such as the age of the patient and certain procedural outcomes included in the true answer. This impacts the completeness by not fully reflecting all critical details of the conversation.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model presents the information in a fluent, organized, and human-like manner. However, the summary's repetitive structure (e.g., \"is that correct?\") and limited variation in language might slightly reduce the overall naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response generally aligns with the context, capturing the main topics discussed in the doctor-patient conversation. However, it lacks specific details and provides a high-level summary, which may impact logical continuity.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model's response captures the overall flow of the conversation and mentions key aspects like medical history, diagnosis, and treatment. However, it omits specific details that were present in the true answer, such as specific test results, medication changes, and detailed observations from the examination. \n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The model's response is fluent and reads like a structured clinical note, which is appropriate for the scenario. It sounds professional and human-like, but it could benefit from more detailed and conversational elements to fully match the intricacy of the original conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "  The model's response logically aligns with the context provided in the input. It captures the essential details of the conversation between the doctor and patient, including the patient's symptoms, diagnosis, treatment, and history. However, there are some inaccuracies in the voice and perspective, as it shifts from third-person to first-person, which affects overall coherence slightly.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "  The model's response includes detailed information about the patient's condition, treatment, and a summary of the conversation, but it misses some specific details from the true answer, such as the mention of allopurinol and specific laboratory test results. Additionally, the model inaccurately shifts the roles, where the patient appears to prescribe medication instead of the doctor, affecting the completeness.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "\n",
      "  The response lacks a full natural flow due to the shift in perspective where the patient seems to write as if they are the doctor. The language used is mostly clear and fluent, but this shift impacts the naturalness significantly because it creates an unnatural recounting of the events where the patient seems to give medical directives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response provides a general overview of the conversation but lacks detail on specific dialogue exchanges. It doesn't directly align with the specific information exchanged between the doctor and patient, such as the symptoms, test results, and medical history. Instead, it offers an abstract interpretation.\n",
      "  \n",
      "- Completeness: 2.5\n",
      "  - The model's response fails to cover specific details present in the conversation, such as the mention of the MMR vaccine, the absence of diabetes, the specific electrodiagnostic findings, and the prescribed follow-up. It offers only a high-level summary rather than a detailed account, making it insufficient in context.\n",
      "  \n",
      "- Naturalness: 4.0\n",
      "  - The model's language is fluent and reads like a coherent narrative summary. However, it lacks the specificity and directness expected in a natural dialogue response, which slightly impacts the perception of naturalness in this context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 4.5\n",
      "\n",
      "**Evaluation Explanation:**\n",
      "\n",
      "- **Coherence (4.5):**\n",
      "  The model's response is coherent as it logically follows the sequence of the dialogue and aligns well with the context of the Q&A session provided. It maintains the conversational flow by mirroring the interaction accurately.\n",
      "\n",
      "- **Completeness (3.0):**\n",
      "  The model repeats the dialogue almost verbatim from the input but doesn't consolidate the information into a concise summary. It fails to capture some details like the patient's employment and body mass index present in the true answer, leading to an incomplete representation of the situation.\n",
      "\n",
      "- **Naturalness (4.5):**\n",
      "  The response is naturally structured and reads fluently, resembling a realistic conversation between a doctor and a patient. The interaction is human-like and follows expected conversational norms. However, it does not exhibit the natural variation expected in a summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "The model's response is coherent and logically aligns with the context provided in the input. It accurately summarizes the sequence of medical procedures and outcomes discussed between the doctor and patient.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "The model's response sufficiently answers the provided context by including key details about the procedures and outcomes. However, it lacks minor details such as the patient's age and specific descriptors like \"tight LAD lesion\" mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "The model's response is fluent and human-like. It maintains a professional and clinical tone appropriate for the context of a medical discussion. Slight improvements in conciseness or addressing patient reactions might enhance naturalness further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 3.5\n",
      "\n",
      "**Evaluation Explanation**:\n",
      "\n",
      "1. **Coherence (3.0)**: The model's response gives a general summary of a doctor-patient interaction without specific reference to the details presented in the input. While the response is structured logically and acknowledges elements like medical history, symptoms, and treatment, it lacks specific alignment with the nuances of the provided conversation, such as the mention of anxiety disorder and detailed examination results.\n",
      "\n",
      "2. **Completeness (2.0)**: The response is incomplete as it omits many specific details critical to a comprehensive understanding of the case. The patient‚Äôs specific symptoms, diagnoses, treatments, and the progression with family medicine specialists, as discussed in the input, are not addressed in sufficient detail.\n",
      "\n",
      "3. **Naturalness (3.5)**: The response sounds moderately fluent and human-like, maintaining a clear, structured narrative typical of clinical notes. However, it could benefit from more detail and specificity to enhance naturalness and comprehension.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model‚Äôs response is coherent with the context provided. It captures the essential elements of the patient's condition and treatment as outlined in the dialogue between the doctor and the patient.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model‚Äôs response sufficiently answers the question in terms of details regarding symptoms, diagnosis, and treatment. However, it lacks some specific details mentioned in the true answer, such as age, exact blood pressure values during the hypertensive crises, and specific information about the CT-angiography.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The model‚Äôs response is fluent and human-like. It reads like a typical summary that a patient might provide to a doctor, reflecting both gratitude and an understanding of the medical situation. However, it slightly lacks the informal tone that might be expected in a patient's rephrasing compared to the formal narrative presented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response maintains strong coherence with the input. It accurately captures the patient's history of type-1 diabetes and the issues with glycemic control, compliance, and the subsequent complications such as diabetic retinopathy and renal vascular issues. It correctly mentions islet cell transplantation as a proposed solution and identifies the change in mental state. The main inconsistency is the change of gender in the narrative, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The model's response satisfactorily covers the key elements in the input: the patient's history of diabetes, treatment regimens, current medical complications, and the subsequent mental health changes. However, it lacks some specific details, such as the patient's age and the detailed history of treatment regimens provided in the input and true answer. These omissions affect the completeness slightly, but the core elements are present.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "\n",
      "The model's response is articulated fluently and describes the patient's condition in a human-like manner. The language used is clear and straightforward, maintaining a professional tone consistent with the context of a medical discussion. There is a minor deduction for the occasional awkward phrasing which slightly detracts from the overall naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌèâÍ∑† Ï†êÏàò:\n",
      "Coherence       4.112903\n",
      "Completeness    3.596774\n",
      "Naturalness     4.400000\n",
      "BLEURT          0.530179\n",
      "BERTScore_F1    0.533574\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# summarization\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "summarization = df[df['task'] == 'summarization']\n",
    "results = []\n",
    "\n",
    "for _, row in summarization.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "    - The model's response logically aligns with the context provided. It correctly identifies the high blood sugar levels and emphasizes the importance of dietary and lifestyle changes in managing diabetes.\n",
      "    \n",
      "- Completeness: 3.5\n",
      "    - The response provides a good general overview of managing diabetes through diet and lifestyle. However, it lacks specific diet recommendations and an additional medication suggestion that was present in the true answer (e.g., Tablet Volibo 0.2 mg). The model also doesn't specify a follow-up plan, which impacts completeness.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "    - The response is very fluent and human-like, with polite expressions and a clear structure. It sounds professional and would be appropriate for a professional healthcare response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context provided in the input by addressing the concern about insulin levels and potential diabetes development. However, it suggests insulin resistance without adequately considering the provided healthy lifestyle details.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model covers several potential causes related to the lab results and offers advice on lifestyle management. However, it fails to fully address the specific concern about pancreatic cancer and the decreased insulin level explanation related to beta cell exhaustion.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and resembles a human-like conversation. It acknowledges the user's concerns and provides advice in a professional and empathetic manner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided, recognizing the need for professional consultation due to the complexity of the condition and differing medical opinions. It suggests consulting a specialist, which is a logical step in this scenario.\n",
      "  \n",
      "- Completeness: 3.5  \n",
      "  The response provides general advice to consult an ophthalmologist but lacks specific information or guidance on choosing between the two proposed treatment options. It doesn't directly address the specific courses of action suggested by the two other doctors, which could help the user in making an informed decision.\n",
      "  \n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, with a polite and empathetic tone that suits the context of providing medical guidance. The language used is clear and natural, closely resembling how a real human might respond in a professional setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context and provides relevant information on potential causes for erectile dysfunction, such as hormonal imbalance and poor blood circulation.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response suggests seeing a doctor and offers some home remedies, which provides a reasonable starting point for addressing the issue. However, it lacks detailed suggestions for alternative medications as found in the true answer and does not inquire about additional conditions like diabetes or hypertension.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and reads naturally, resembling how a human doctor might professionally advise a patient on this sensitive issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response provides a coherent explanation regarding the relationship between diabetes and gum problems. It discusses gum disease as a common issue for individuals with diabetes, which aligns logically with the context provided. However, it somewhat overgeneralizes by implying a direct connection between diabetes and the observed symptoms without requesting further information, like images, for a more accurate assessment.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model's response is somewhat complete but lacks the specificity that a healthcare professional would likely seek. While it provides a potential explanation and suggests further action (visiting a dentist for proper diagnosis and treatment), it doesn't directly address the need for more information or the option of sending images for review. The true answer indicates a step in diagnosis that the model's response omitted.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is fluent and constructed in a human-like manner, providing information in a clear and logical sequence. It reads like a thoughtful reply from a healthcare professional, using a polite tone and offering actionable advice. However, it slightly repeats information about plaque buildup and gum disease, which could sound redundant to a reader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5  \n",
      "  The model's response touches on some issues related to joint pain but introduces osteoarthritis as the primary concern, which does not align precisely with the context provided by the user, who indicated a diagnosis of frozen shoulder. The advice for osteoarthritis deviates from addressing the specific context of frozen shoulder.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  The response lacks detailed advice specific to treating frozen shoulder, such as emphasizing physiotherapy or recommending specific medications that align with those referred to in the input. It provides a general perspective applicable to osteoarthritis rather than directly addressing the user's current diagnosis and suggested treatments.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response is articulated in a fluent and human-like manner. It uses a professional and empathetic tone, which is appropriate for a patient-doctor communication. However, the misalignment in technical accuracy slightly affects its perceived naturalness from the perspective of understanding the problem correctly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It identifies and expands on the patient's condition with regards to their blood sugar readings and potential complications, demonstrating a clear understanding of the diabetes management context.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model's response acknowledges the need for lifestyle changes and medication but lacks specificity in terms of the detailed drug and dietary recommendations requested by the patient. It does not provide a specific diet plan or medication adjustment, such as the inclusion of Tablet Volibo from the true answer, which would be beneficial to make the response more complete.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent, human-like, and provides a compassionate tone. It uses clear language and structures the advice in a way that sounds professional, though somewhat generic in terms of personalized instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "The model's response logically aligns with the context by accurately identifying type 2 diabetes and fatty liver disease based on the provided information. It also correctly mentions the presence of fibroids in the uterus. However, there is an assumption regarding non-alcoholic fatty liver disease, which while a reasonable inference, is not explicitly stated in the input.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "The response provides a comprehensive interpretation of the given medical conditions and offers a general management plan, which aligns well with the input request to interpret the report. However, it lacks specific advice on consulting a general surgeon for fibroid management, as included in the true answer, indicating slight incompleteness.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "The response is fluent, well-structured, and sounds natural and human-like. It maintains an empathetic and professional tone appropriate for a medical communication, thus scoring high on naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.5\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence**: The model's response logically aligns with the context provided. It recognizes the symptom (burning sensation) and mentions potential causes that match the true answer, such as neuropathy and diabetes. However, it lacks some specific details included in the true answer.\n",
      "- **Completeness**: The response provides a general potential cause but lacks the depth and specifics of the true answer, such as the mention of cervical spine issues and the suggestion for specific tests and treatments. Therefore, it is somewhat complete but could be more encompassing.\n",
      "- **Naturalness**: The response is fluent and human-like. It reads naturally and maintains a professional and empathetic tone in addressing the user's concern.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0 - The model's response aligns well with the context provided in the input, acknowledging the user's previous diagnosis and current concern about medication.\n",
      "- Completeness: 4.5 - The response provides a thorough explanation of the importance of managing diabetes and suggests consulting a healthcare professional. However, it does not address the user's HbA1c report directly.\n",
      "- Naturalness: 5.0 - The response is fluent and reads like a response you would expect from a healthcare professional, maintaining a human-like tone throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response generally aligns with the symptoms described, focusing on potential issues with eye muscles and alignment which relate to double vision. However, the explanation doesn't strongly tie into all the specifics mentioned, such as the changes related to adjusting head position or pulling the eyelid.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The response offers some possible explanations and general advice (such as home remedies and the suggestion of a thorough eye exam), but it lacks a deeper exploration into the specific details like the user experiencing vision improvement by adjusting head position or eyelid position. It also doesn't tie into the context of starting the Keto diet or recent travel.\n",
      "  \n",
      "- Naturalness: 4.0\n",
      "  - The language is generally fluent and sounds natural. The suggestions and empathetic tone match the expectations of a doctor-patient communication, though it might slightly feel more like a typical response template rather than personalized advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It addresses the medical concerns related to the foreskin and suggests applying an antibiotic ointment, which is a relevant and reasonable suggestion. It also advises consulting a doctor if there's no improvement, which aligns with standard medical advice.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model provides a fairly complete answer, suggesting the continued use of Aspoline and adding an antibiotic ointment for potential infection. It also recommends consulting a doctor if the condition persists. However, it could have been more comprehensive by acknowledging and addressing the symptoms of burning sensation more specifically or offering additional reassurance or interim steps.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, with polite language and clear instructions. It reads like a conversation with a concerned healthcare provider, maintaining a professional yet empathetic tone, thus sounding natural. However, slight improvements in empathy or reassurance could enhance the naturalness even further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  *Explanation*: The model's response aligns well with the context, addressing the patient's concerns about managing their condition and offering general advice. However, it misses specific mentions of PAD treatments, such as medications or specific surgical procedures.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  *Explanation*: While the response offers general advice on lifestyle changes and the importance of prevention, it lacks specificity in addressing the question about preventive surgery and other detailed medical options like particular drugs or specific procedures, which is provided in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  *Explanation*: The response is fluent and human-like, displaying empathy and reassurance. The tone is conversational and appropriate for a patient query, but it can be slightly more concise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The response logically follows the context provided. It acknowledges the patient's concern about weight loss and provides a plausible explanation related to diabetes. The only slight detractor is the model mentions diabetic ketoacidosis a bit prematurely without knowing the full extent of the user's symptoms.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response is mostly complete as it offers a potential explanation for the weight loss and suggests possible actions to take. However, it could mention other potential causes of weight loss in diabetic patients and emphasize the importance of a direct consultation with a healthcare provider beyond just checking for ketoacidosis.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluently written and sounds human-like, being polite and informative. It provides detailed advice naturally, though it could be slightly improved by offering a more personalized closing comment to enhance empathy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "    The model's response is generally coherent, as it mentions the patient's age and diabetes management, acknowledges the normal test results, and suggests discussing chest pain with a doctor. However, it doesn't specifically address the CT angiogram or provide any detailed information related to the potential heart condition.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "    The response lacks completeness because it doesn't directly advise on what medication to take to avoid a future heart attack, which was the main inquiry. Additionally, it doesn't provide specific suggestions regarding potential treatments like Antiplatelet Statin combinations or evaluations such as echo or TMT testing. Instead, it focuses primarily on general lifestyle advice.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "    The model‚Äôs response is quite natural and sounds fluent and human-like. It exhibits a friendly tone and standard conversational style, which makes it approachable and easy to understand. However, the conversational tone might slightly detract from the more technical aspects expected from a medical professional‚Äôs advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response somewhat aligns with the context provided and accurately identifies PCOS as a potential concern, linking it to several symptoms mentioned. However, it incorrectly states that sickle cell trait can lead to chronic constipation, which lacks direct support from common medical understanding. Additionally, it overlooks other possible causes of symptoms like hyperthyroidism, which are identified in the true answer.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The response covers several aspects of the symptoms and provides some potential connections to PCOS, but it misses important issues identified in the true answer, such as hyperthyroidism and specific treatments. The model provides general recommendations but not the detailed guidelines or potential interventions found in the true response.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and sounds human-like, articulating concerns and suggestions in a personable manner. It uses empathetic and professional language typical of doctor-patient communication. However, the accuracy of the content could enhance its naturalness by reinforcing the credibility of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response does not align well with the context provided. The input is about an eye condition related to diabetes (as indicated by the OCT report), but the model incorrectly discusses Accentrix as a diabetes medication primarily used to control blood sugar. Accentrix is actually a treatment for eye conditions like diabetic macular edema, which is more relevant to the context.\n",
      "\n",
      "- Completeness: 1.5  \n",
      "  The response fails to address the main query properly. The model does not discuss the results of the OCT report or the specific role of Accentrix in treating diabetic macular edema, which is the condition indicated by the report.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  Although the response is not accurate regarding the context, it is fluently written and sounds human-like in its phrasing and tone. However, minor deductions are due to slight factual inaccuracies that could cause reader confusion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response logically aligns with parts of the context; it addresses the concern about the swelling and mentions the possibility of surgery. However, it does not address some specific details such as the possibility of cellulitis or the previous doctor's remarks.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The model provides a general suggestion to consult with a healthcare professional and considers surgery as a possibility. However, it lacks specific guidance or insight into the condition, such as the potential for cellulitis, medications, or the rationale for the suggested surgery. It doesn't sufficiently answer questions about the doctor's possible reasons for surgery or provide a nuanced second opinion.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and human-like, with a polite tone and clear expression. It addresses the user's concerns in a reassuring manner and maintains a conversational style throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is coherent with the input and logically aligns with the context. It acknowledges the user's concerns and provides a structured response indicating potential reasons for anxiety and suggesting solutions.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The response is fairly complete, providing several practical suggestions including seeing a professional, practicing relaxation techniques, and considering medication. However, it could have included more specific information on potential biochemical factors that might cause severe anxiety, similar to what is mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "  - The model's response is quite fluent and human-like. It uses a conversational tone and provides recommendations in a reassuring and professional manner, similar to how a healthcare provider might respond in a real conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response is coherent as it logically aligns with the context provided in the input. It addresses the potential causes of cloudy vision, including dry eyes, in alignment with the user‚Äôs experience and medical history. However, it could have benefited from a brief acknowledgment of the specific conditions mentioned, like cataracts or the vitrectomy.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - The response offers a reasonable exploration of possible causes of the vision issues, suggesting dry eyes and other potential factors like cataracts, which were mentioned in the query. However, it does not explore some additional specifics like the impact of the vitrectomy and cataract surgery context, or suggestions about the eye not closing properly, which might have offered a more complete answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  - The language used in the model's response is fluent and mostly human-like, replicating the style typical of a medical professional. The introduction and explanation are clear, although using a more personalized touch or simple language might enhance the natural conversational flow seen in real-world doctor-patient dialogues.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It acknowledges the concern about mild LVH, offers reassurance, and suggests further monitoring and consulting with a doctor, which is consistent with the input context.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model's response is somewhat complete but lacks some specific information and depth compared to the true answer. It doesn't address some potential diagnoses or provide a broader scope of possible explanations for the user's symptoms, such as athlete-related LVH or the nature of sinus tachycardia.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and human-like, maintaining a professional yet comforting tone suitable for a medical discussion. It conveys empathy and offers general advice, contributing to its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response provides general advice on managing diabetes with mention of following a strict diet, monitoring blood sugar levels, and regular consultations, which aligns somewhat with the context. However, it introduces new medications like atenolol, irrelevant to the concerns about changing diabetes medications. It also misses specific concerns about the sodium glucose transporter, kidney damage, and the fear of weight gain mentioned in the context.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The response lacks a direct address of the patient's specific queries regarding concerns about weight gain with sulfonylurea, ineffectiveness of acarbose and voglibose, the safety of sodium glucose transporter, and the implications of using slow-release insulin injections. Thus, it does not sufficiently answer the specific questions raised by the patient.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The model's response is generally fluent and structured in a professional and human-like manner, appropriate for a medical consultation. However, specifics of the patient's situation and direct engagement with their specific concerns are insufficient, impacting the overall naturalness slightly.\n",
      "\n",
      "**Summary**: The model needs improvement in directly addressing the patient's specific concerns and ensuring all content directly aligns with the patient's context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response logically aligns with the context provided in the input. It identifies that the user is experiencing flat foot and foot pain, and gives a thorough discussion on flat feet, their causes, and general treatment options. However, it doesn't address the specific areas of pain mentioned (lateral and medial side of the heel), and it overlooks the current pain relief aspect, which affects coherence with the specific context.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "While the model's response provides an extensive overview of flat feet and potential treatment plans, it lacks specific guidance related to the user's immediate concern of pain management and does not address the potential need for diagnostic tests like X-rays or blood work. It also does not mention immediate steps such as the use of NSAIDs for pain relief, which are suggested in the true answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is well-written and sounds fluent and human-like. It uses an informative and caring tone, typical of a medical professional's advice. However, the repetition at the end and the lack of specific attention to the user's unique details slightly detract from the natural flow of a personalized medical response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5  \n",
      "  The model's response does mention a SOL and considers the possibility of liver cancer, which aligns with the input. However, it overlooks the specific mention of a hemangioma by the radiologist, which is essential to interpreting the context accurately. This oversight affects the logical alignment of the response with the information provided.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  The response does not fully address the request for guidance on further procedures. It misses details about the conservative management of the hemangioma, including follow-up ultrasounds and potential treatment options, which are crucial given the nature of the diagnosis. It also does not consider the mentioned results like the AFP and serum ferritin in the context of the patient's entire health profile, such as the hemangioma nature.\n",
      "\n",
      "- Naturalness: 3.5  \n",
      "  The language of the model's response appears fluent and understandable. However, the suggestion of consulting a hepatologist due to a possible cancer diagnosis without addressing or acknowledging the radiologist's findings about the hemangioma reduces the perception of expertise, slightly affecting its human-like quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response generally aligns with the context, focusing on obstructive sleep apnea (OSA) as a significant health issue for the patient. However, it claims the MR brain and CT thorax imaging findings are \"consistent with OSA,\" which is not directly accurate. It also suggests symptoms like snoring and daytime sleepiness without context from the input. \n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response somewhat addresses the query about the connection between sleep apnea and the brain changes, suggesting CPAP therapy as part of the treatment. However, it does not mention the irreversibility of the brain changes, nor does it address other contributing factors like high blood pressure, making it incomplete compared to the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The language is fluent and human-like, with appropriate transitions and a professional tone. It reads naturally as if written by a human doctor. However, the repetitive conclusion and over-reliance on general advice detract slightly from its perceived expertise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "    The model's response aligns with the context of the input to a reasonable extent. It discusses the recall of metformin and reassures the user about its safety, which is in line with the concerns raised in the input. However, the model does not address the critical issue of high blood sugar levels mentioned in the input, which slightly affects coherence with the user‚Äôs full context.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "    The model's response does not fully answer the question. While it addresses the worry about metformin's recall, it does not provide alternative medications or suggestions to manage the user's high blood sugar levels. The user seeks an alternative to metformin and guidance on managing their diabetes, which is not fully provided in the response.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "    The response is fluent and sounds human-like. The language used is polite and professional, and it appropriately uses medical context to reassure the user. However, there is a slight lack of personal touch and engagement compared to what might be expected in a more tailored, human-like response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response suggests \"facial flushing\" as a possible explanation for the burning sensation. However, this suggestion does not coherently align with the symptoms described in the input, which does not mention facial flushing but rather a burning sensation on the head. The true answer provides more plausible explanations like vitamin deficiency or a neurological cause.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The response does not sufficiently address the potential causes of the burning sensation as it focuses on facial flushing, which seems unrelated to the described symptom. Additional potential causes, such as vitamin deficiencies or neurological issues mentioned in the true answer, are missing, rendering the response incomplete.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is written in a fluent and polite manner consistent with a human-like tone that one might expect from a healthcare professional. It effectively maintains a conversational style, which contributes to its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model‚Äôs response is mostly coherent with the context given by the user. It correctly identifies the condition as a fungal infection common in warm, humid environments and logically connects the prescribed treatments with the symptoms.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response does cover several potential treatments and preventive measures for fungal infections, it does not address the potential issue of a resistant strain of fungus, which the true answer highlights by suggesting Terbinafine. Additionally, there is no mention of discontinuing steroid creams. These omissions limit the completeness of the advice for achieving a \"permanent cure.\"\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response sounds fluent and human-like, maintaining a conversational tone that is typical in human communication between a doctor and patient. The language is easy to understand, and the advice is structured clearly, fostering a reassuring interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided, acknowledging the patient's concerns and referencing their age and health conditions. However, it doesn‚Äôt specifically address emphysema or the use of anesthesia in detail.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model acknowledges the patient‚Äôs health conditions and reassures them about consulting a doctor, it lacks specific advice about anesthesia and surgical risks, which are the primary concerns of the patient.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and human-like, displaying empathy and understanding, which is appropriate for a healthcare context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response aligns well with the context provided. It addresses the user's concerns about anxiety, bloating, and constipation, while considering the patient's existing conditions like coronary artery disease and diabetes. However, it doesn't specifically link or relate the stomach symptoms to the medications or existing conditions as the True Answer does, which slightly impacts coherence.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - While the model provides a broad perspective on managing anxiety and heart health, it lacks specific recommendations concerning the user's medication dosages and does not directly address the potential side effects of Mirtazapine as mentioned in the True Answer. It covers many aspects generally but misses some personalized considerations that are crucial given the input context.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent, well-phrased, and reads naturally like advice from a healthcare professional. It conveys empathy and offers general guidance effectively, though it could include more personal touches or specific advice to enhance relatability.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "The model's response mentions \"delirium tremens,\" which may not be directly related to the symptoms described (sudden jerks). Delirium tremens is typically associated with alcohol withdrawal, which is not mentioned in the input. Thus, the response doesn't logically align with the context provided, indicating a lack of coherence.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "The model suggests consulting with a doctor, which is a valid general recommendation, but it doesn't specifically address the question about the likelihood of the jerks returning or consider the full medical history (including Alzheimer's, diabetes, and thyroid conditions) mentioned in the input. Therefore, it does not sufficiently answer the question.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "The model's response is relatively fluent and human-like, although it uses some technical terms that might not be familiar to all users. It clearly communicates the need to consult a healthcare professional, which maintains a conversational tone. \n",
      "\n",
      "Overall, while the response sounds natural, it lacks coherence and completeness in addressing the specific medical concerns presented in the input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided by addressing the concerns regarding the mother's diabetes and hemoglobin levels. It identifies the potential causes of fluctuations and suggests general strategies for management. However, it lacks specific reference to the individual medical circumstances mentioned in the input, such as the specific medicines and reports attached.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The response addresses the broad issues of blood sugar and hemoglobin level management and mentions a few general solutions. However, it does not provide specific medication recommendations or refer to the individual medical treatment, as seen in the true answer. Hence, it is less complete in directly answering the user's request regarding specific steps and medicine types.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The model's response is fluent and human-like. It presents information in a clear, professional tone, appropriate for a healthcare conversation. The language and structure are consistent with how a doctor might communicate in writing, but it could benefit from more personalized details to fully emulate a conversation with a healthcare provider.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the context provided in the input. It acknowledges the elevated TSH level and normal T3 and T4 levels, which are crucial to diagnosing thyroid issues. However, it could improve by explicitly differentiating between overt and subclinical hypothyroidism.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model provides a good initial assessment and suggests further testing for confirmation, which is relevant. However, it misses discussing the concept of subclinical hypothyroidism and that treatment may not be immediately necessary without symptoms, which the true answer addresses.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and sounds human-like. It uses a supportive tone and provides practical advice in a clear manner, enhancing its naturalness for the user.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0 \n",
      "  - The model's response logically aligns with the context. It correctly identifies potential complications such as blood clots and mentions the importance of evaluation by a vascular surgeon, which is coherent with the descriptions provided in the input. However, it assumes issues that may not be entirely indicated or confirmed by the information given.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The response addresses some critical aspects such as the need for evaluation by a vascular surgeon and the possibility of amputation but lacks detailed advice specifically tailored to address all the unique conditions described, particularly the role of Doppler tests. It also omits addressing the question about the leg swelling and the prolonged antibiotic use more thoroughly.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The language used is fluent and sounds human-like. The response is clear, empathetic, and professional in providing advice. It reads naturally, although it could be more comprehensive in covering all nuances of the condition described in the input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "    The model's response is generally coherent with the input context. It addresses the skin issue experienced by a diabetic, mentioning hyperpigmentation as a potential condition, which fits the description of darkened skin. However, it does not consider localized factors like footwear friction, which is a significant aspect of the user's situation.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "    The response provides a partial answer by mentioning potential treatments like hydroquinone or azelaic acid and suggesting consulting a dermatologist. However, it does not mention other possible causes like frictional hyperkeratosis or acanthosis nigricans, which are relevant in this specific scenario. It also misses the specific treatment advice offered in the True Answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "    The response is fluent and sounds fairly human-like. It uses clear, professional language and maintains a tone consistent with a medical professional, making it quite natural for the context of a medical query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent with the input and provides a logical interpretation of the symptoms described, offering possible reasons such as medical conditions or lifestyle factors affecting sexual performance.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response addresses potential causes and suggests steps like medical evaluation and lifestyle changes. However, it doesn't mention specific tests like blood sugar or hormonal checks, which are highlighted in the true answer. Including these details would have improved completeness.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The model's response is fluent, polite, and human-like. It acknowledges the user's concern and provides comprehensive information in a respectful and professional manner, akin to how a healthcare provider might converse.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It correctly identifies that the non-functioning of the right leg and hand could be due to a serious vascular issue, which is plausible given the input about the MRI scan results.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model acknowledges the need for medical attention but does not fully address the question regarding the possibility of restoring the function of the leg and hand. It lacks the specific details or explanations that could be provided, such as potential recovery scenarios or further diagnostic steps.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and human-like. It uses comforting and understanding language, creating a natural tone. However, it could be slightly improved by directly addressing the question more thoroughly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context. It acknowledges the father's health issues, including diabetes and chest pain, and suggests seeing a cardiologist, which is appropriate given the symptoms. However, it doesn't specifically identify the possibility of angina, which would align more closely with the symptoms described.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response covers general recommendations like managing diabetes and monitoring heart health, it doesn't provide specific remedies or medications, nor does it mention heart conditions like angina outright. The response lacks detailed suggestions or further questions that could lead to a more personalized and complete answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent, polite, and human-like in tone. It is professionally written and sounds like a response one might expect from a healthcare provider. The language is clear and respectful, making it sound natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the context provided. It addresses the concern about the son's blood sugar levels in response to the symptoms described and appropriately considers the potential implications. \n",
      "\n",
      "- Completeness: 4.5\n",
      "\n",
      "The model's response sufficiently answers the question by confirming that the blood sugar levels are within the normal range for a child of that age and suggests follow-up actions, including consulting a pediatric endocrinologist. It also provides advice on maintaining a healthy lifestyle and monitoring sugar levels, which adds completeness to the advice given.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The response is fluent and human-like, mimicking a considerate and communicative style a doctor might use. It‚Äôs compassionate, reassuring, and clear, making it sound very natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It mentions relevant aspects such as examining genitals, blood tests, and considering medical history, which are pertinent to assessing erectile dysfunction. However, it is slightly general and could benefit from a bit more specificity, which the true answer provides.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response covers the basic steps involved in the examination and potential next steps regarding erectile dysfunction. It mentions examining genitals and internal organs, blood tests, and medical history. Nonetheless, it lacks some of the more specific procedures mentioned in the true answer, such as the penile Doppler, skin retraction check, and nerve conduction tests.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is fluent and human-like. It maintains a polite and reassuring tone typical of a conversation with a healthcare provider, which enhances its naturalness. The response is well-structured and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the input's context. It acknowledges the user's depression and the importance of seeking professional help. However, it slightly lacks specificity regarding the critical point of suicidal thoughts, which could be addressed more directly.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides a general direction by encouraging professional help, which is crucial. However, it lacks depth by not addressing the severity of suicidal thoughts explicitly or offering a concrete action plan compared to the true answer, which emphasizes immediate action and suggests possible treatments and assessments.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and human-like. The tone is empathetic, supportive, and appropriate for the situation, thus scoring high on naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response logically aligns with the context of experiencing nerve pain, as it acknowledges the symptom and suggests consulting a healthcare professional as a reasonable next step. However, it lacks the specifics present in the true answer about potential causes and diagnostic approaches.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  - While the response identifies that the symptom could be linked to various conditions and suggests seeing a healthcare professional, it does not delve into specific potential causes, diagnostic tests, or immediate relief strategies mentioned in the true answer, which might be considered important for a comprehensive response.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  - The model's response is fluent and sounds human-like. It uses natural language and provides a professional and empathetic tone, appropriate for a medical context. It effectively communicates the necessity of consulting a healthcare professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The response logically aligns with the context in terms of addressing frequent urination and suggesting seeing a doctor. However, it does not directly address the concern about feeling aroused when the bladder is full, leading to a slight misalignment with the context.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - The response suggests consulting a doctor, addressing the concern of frequent urination, but lacks a focus on the erotic sensation the user experiences when their bladder is full. It also doesn‚Äôt mention the possibility of impaired sugar control as the true answer does.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The model's response is fluent and sounds human-like, using appropriate conversational language. However, it slightly lacks personalization in addressing the user's particular experience regarding getting aroused, which affects the overall naturalness slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "  - The model's response is somewhat coherent as it acknowledges the symptoms described in the input and suggests consulting a doctor for evaluation. However, it doesn't directly address all specific symptoms mentioned, such as the burning sensation or the intermittent nature of the issue.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The response is incomplete because it does not provide a potential explanation for the symptoms or advice besides consulting a doctor. It does not leverage the information provided in the input or suggest any immediate steps or tests that have already been done, such as the uroflowmetry test.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The response is fairly natural and fluent, closely resembling a typical interaction one might have with a healthcare professional advising a patient to seek further consultation. However, it slightly lacks detail and personalization, which could enhance its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is logically consistent with the context provided. It addresses the concern about the bitter taste and connects it to potential causes, such as the steroids and other medications the mother is taking.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model provides a thorough explanation of potential causes for the side effects and suggests contacting a doctor for adjustments, which sufficiently addresses the question about the bitter taste and side effects. However, it suggests switching medications without acknowledging that such decisions should be made by a healthcare professional, possibly slightly reducing the completeness.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent and generally human-like, using polite language and providing a structured explanation. However, there are minor repetitions regarding consulting a doctor, which slightly affect the natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 3.0** - The model provides coherent advice on managing pain which aligns with the general context of addressing finger pain. However, it does not address the specific details mentioned in the input, such as the lack of swelling and the severe nature of the pain. \n",
      "\n",
      "- **Completeness: 2.0** - While the model offers general pain management tips, it fails to sufficiently address potential underlying causes or provide a comprehensive response that explores possible diagnoses. The true answer indicates potential causes like neuralgia and discusses diagnostic steps, which are absent in the model's response.\n",
      "\n",
      "- **Naturalness: 4.0** - The language used in the model's response is fluent and human-like. It conveys empathy and provides clear instructions, making it sound natural. However, the overly generic tone slightly detracts from the conversational naturalness expected in a medical consultation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response is generally coherent with the context provided and acknowledges the concern about the quality of the biopsy material. However, it somewhat misinterprets the significance of the fibrino-leukocytic consistency and its implications for diagnosis, which can lead to a misalignment with the context.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response provides a general overview of myelodysplastic syndrome and acknowledges the insufficient biopsy material. It touches upon refractory anemia with excess blasts but does not delve deeply into explaining the significance of the fibrino-leukocytic nature or the next steps regarding the biopsy quality issue, which is addressed in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The language used in the response is fluent and expresses empathy and understanding in a human-like manner. The advice to seek further diagnosis and potentially a second opinion feels natural and supportive, contributing positively to this metric.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response is partially coherent with the context. It correctly addresses the importance of wound care in diabetic patients but does not directly address what might happen to the foot in the future, given the specific context and symptoms such as discoloration.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response gives general advice, which applies to caring for a diabetic wound, but it does not provide a specific answer to the future implications for the foot, such as mentioning the possibility of a fracture, the process of bruising healing, or the importance of monitoring the discoloration.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response is generally fluent and follows a natural structure you'd expect from human communication. However, there is a minor redundancy with the phrase \"signs of infection or infection,\" which slightly impacts its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the input, recognizing the recurrence of the infection and suggesting that it is linked to the underlying diabetes condition. It also offers advice consistent with such situations (antifungal cream, using lubricants, contacting a doctor), which shows comprehension of the context.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model addresses possible reasons for recurrence and provides some recommendations, it does not fully explain the potential role of poorly controlled blood sugar levels in recurrence or the necessity for a partner's evaluation and treatment as mentioned in the true answer. Additionally, it doesn't emphasize completing a full course of treatment this time compared to the true answer.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent, polite, and human-like. It communicates clearly and offers advice in a caring tone, which maintains professionalism appropriate for a medical response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It acknowledges the user's concern about health after touching a used needle and reassures the user that not being pierced reduces the risk of contracting HIV. However, it inaccurately suggests that a cold could be related to the \"injury,\" which may create confusion, as a mere touch is not an injury.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response does address the main concern about the risk of HIV transmission. However, it lacks detail compared to the true answer. It doesn't discuss the implications of the needle's use, inquire about the HIV status of the person with the needle, or suggest a testing timeline, reducing completeness.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response is mostly fluent and human-like, using polite and reassuring language. However, the phrase \"result of the injury you sustained\" is somewhat awkward in this context since no injury was sustained, impacting naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is generally coherent and logically aligns with the context. It addresses the glucose levels and HbA1c in the context of diabetes concerns. However, it incorrectly interprets the information, particularly by stating that the HbA1c of 6.2 indicates living with diabetes for some time, which could be misleading as it is in the pre-diabetes range.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a substantial amount of information, discussing the potential for pre-diabetes and offering general advice on lifestyle changes and consulting a primary care physician. However, the suggestion of the HbA1c level indicating existing diabetes without further clarification could be deemed incomplete or inaccurate information.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is well-written, fluent, and sounds human-like. It uses friendly and reassuring language that one would expect from a healthcare professional. There are no significant grammatical or stylistic errors. The only minor aspect that affects naturalness is the slightly inaccurate interpretation of the medical information, which impacts overall trust in the naturalness of a professional medical response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "  The model's response logically aligns with the context provided in the input. It acknowledges the HbA1c levels and suggests lifestyle modifications and supplements. However, it does not address any specifics about the user's past or current treatment for diabetes, as the input does not provide this information.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "  The model's response provides some information on lifestyle changes and suggests specific supplements (cinnamon, chromium, and alpha-lipoic acid). However, it lacks detail compared to the True Answer, which provides extensive recommendations on diet, exercise, and additional supplements. The model's response could be more comprehensive by mentioning these aspects and advising on lifestyle changes with specific instructions or dietary advice.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "  The response is fluent and sounds human-like. It uses polite language, acknowledges the user's initiative to manage diabetes, and advises consulting a doctor before starting new supplements, which feels natural in a healthcare context. The language is straightforward and easy to understand, contributing to a more conversational tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model‚Äôs response is logically aligned with the context provided. It accurately reflects the symptoms and medications mentioned and offers a relevant suggestion to consult a physician.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response sufficiently addresses the main concern by recommending a consultation with a healthcare provider. However, it lacks specific guidance on the current condition beyond suggesting professional consultation.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The language used is fluent and professional, resembling that of a human healthcare provider. The model‚Äôs expression of empathy and concern is appropriately human-like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided, discussing the grandfather's age, diabetes, and heart condition. It suggests cautious consideration between angioplasty and bypass surgery, reflecting the decision-making process the doctors might be undertaking.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the model's response covers the basic considerations (age, diabetes, heart condition), it lacks specific details found in the true answer, such as the recommendation against angioplasty for someone over 80, the patient‚Äôs low ejection fraction, and the explanation of minimally invasive bypass surgery. These details are critical for making a well-informed decision.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and human-like. It maintains a professional tone and offers general advice to consult specialists, similar to how a healthcare professional might communicate while remaining accessible and empathetic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response logically aligns with the context provided and addresses the main issue of high blood pressure and the problems associated with diuretics. It suggests considering ACE inhibitors or ARBs, which is coherent with the need for non-diuretic options.\n",
      "\n",
      "- **Completeness: 3.5**  \n",
      "  While the model suggests some non-diuretic medication options and lifestyle changes, it doesn't cover all the possibilities presented in the true answer, such as specific medication names like beta-blockers (Metoprolol, Atenolol, Nebivolol), Hydralazine, or alpha-blockers. It does, however, touch on other suggestions like lifestyle modifications.\n",
      "\n",
      "- **Naturalness: 4.8**  \n",
      "  The response is very fluent and human-like, using a conversational tone and polite language. The model provides empathetic responses and encourages discussing the issue with a doctor, which enhances its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response does not logically align with the context provided. The user has already mentioned having normal blood work and tests, including diabetes checks. The model's suggestion to conduct tests for diabetes and cholesterol does not account for the already ruled-out conditions.\n",
      "  \n",
      "- Completeness: 1.5  \n",
      "  The response does not sufficiently answer the question. It fails to provide any new or relevant suggestions considering the exhaustive testing already done as described in the input. It should suggest further investigative steps, similar to those mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 3.0  \n",
      "  The response is somewhat fluent and human-like, but the generic advice given detracts from its naturalness in this specific context. The tone is appropriate, but the advice lacks personalization based on the provided information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context provided, advising appropriate steps for managing symptoms related to typhoid, diabetes, and a blood clot. However, it lacks specific focus on the immediate concern of a headache potentially related to the blood clot, which is emphasized in the true answer.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the response covers general advice and supportive steps in detail, it misses the crucial aspect of consulting a neurosurgeon for the severe headache due to the blood clot, which is an important part of the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent, human-like, and empathetic. It communicates care effectively, although it could be improved by focusing more on the severity of the situation specific to the headache.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent with the context as it acknowledges the prolonged issue with jock itch and the use of medications. It also offers logical advice related to seeing a dermatologist and maintaining hygiene. However, it does not directly address any potential underlying health issues like diabetes, which the True Answer does.\n",
      "  \n",
      "- Completeness: 3.5  \n",
      "  While the model suggests visiting a dermatologist for stronger medication and offers some lifestyle advice, it doesn't provide specific alternative medications or a follow-up plan. It lacks in covering potential underlying health issues that might contribute to persistent symptoms, such as diabetes, which the True Answer explores.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is highly fluent and resembles natural human-like communication. It uses polite language and expresses empathy, making it sound conversational and considerate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context and provides relevant information about the need for a biopsy due to the potential benign or malignant nature of the nasal polyp. \n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The response provides a comprehensive answer addressing the necessity of a biopsy and potential outcomes, but it lacks the specificity about risks associated with surgery in patients above 40 and doesn't explicitly discuss conditions such as BP or diabetes which are mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "  - The response is fluent, human-like, and empathetic. It provides a clear explanation and closing remarks that make it sound like a natural conversation from a medical professional.\n",
      "\n",
      "Overall, the model performs well in maintaining coherence and naturalness, with slight room for improvement in completeness regarding specific risk factors mentioned in the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The response logically aligns with the context provided in the input. It addresses the concern of elevated serum creatinine and triglyceride levels, as well as the HbA1c level, which are all mentioned in the input.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides a general overview but lacks specific advice on potential actions, such as restarting medications, which the true answer suggests. It misses discussing the risks of not being on medication and advising consulting a specialist directly.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response sounds fluent and human-like. It appears polite and uses appropriate medical language for the context while maintaining clarity and sensitivity to the user's situation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response presents correct information regarding the blood glucose and blood pressure levels being within normal ranges, but it inaccurately refers to the FBS value as normal when it is high. It also claims that heart rate is not an issue, disregarding potential changes from medication adjustments. Some contradictions to the input and the true answer, such as continuing with Metformin ER twice daily, which can be fine but lacks proper explanation provided in the true answer.\n",
      "  \n",
      "- Completeness: 2.5\n",
      "  - The response does not fully address concerns about switching from Prolomet XL to Tazloc-H and does not provide thorough guidance on monitoring or adjusting medications based on heart rate or glucose levels. It also omits information about evaluating blood sugar readings after starting diabetes medication, which is covered in the true answer.\n",
      "  \n",
      "- Naturalness: 4.0\n",
      "  - The model's response is fairly natural and polite, offering a fluent, human-like manner of communication. However, it uses some medical terms without sufficiently explaining them for patient understanding, which slightly affects naturalness in a patient-doctor context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context by addressing the symptoms and potential causes (lipomatosis, infections, low sedimentation rate) mentioned in the input. However, it does not fully incorporate all aspects such as the stiffness and rigidity in the left arm.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model provides a broad perspective and suggests a consultation with a healthcare professional, it lacks detailed exploration of certain symptoms like numbness or erectile issues and does not make suggestions for further tests or possible conditions like the True Answer does.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and human-like, employing an empathetic tone appropriate for a healthcare setting. It could be slightly more concise to improve readability, but overall it maintains a professional and caring tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent with the input. It acknowledges the blood sugar reading and provides general advice related to blood sugar management.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the model addresses the blood sugar reading, it does not directly answer whether or not the person is diabetic. A more complete response would discuss blood sugar thresholds for diabetes diagnosis or refer to a healthcare provider for diagnosis.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds human-like, with a polite and empathetic tone that is expected in a conversation with a healthcare professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context provided, discussing the issue of ingrown nails and recommending potential treatments. However, it slightly misses specific details that could improve coherence, such as addressing past attempts at solving the issue.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model provides a broad range of general advice for managing ingrown nails but does not address the user's specific context, such as the previous surgical intervention and the duration of the issue. It also does not mention checking for related health issues, such as diabetes, which could be relevant given the recurrence.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and human-like, with a compassionate tone and clear instructions, making it easy to read and understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response lacks coherence with the individual's specific symptoms detailed in the input. Instead of discussing symptoms like sensation in the index finger and chest discomfort, the response generally focuses on post-heart attack discomfort, which doesn't align with the context given that no recent heart attack was mentioned.\n",
      "\n",
      "- Completeness: 1.5  \n",
      "  The model's response does not sufficiently address the question about the potential causes of the specific symptoms of finger sensation and chest discomfort as described. It instead discusses general post-heart attack issues, missing possible neurological explanations or other direct investigations that could be relevant.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response is fluent and human-like. Despite the lack of coherence and completeness, the language used is clear and natural, resembling how a medical professional might communicate general information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided in the input. It addresses the concern about the elevated CRP level and provides a possible explanation related to infection or inflammation, which is coherent with medical knowledge.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The model's response sufficiently answers the question about the high CRP level by explaining that it might indicate an infection or inflammation. However, it doesn't directly address the pain in the joints or the inability to lift the shoulder, which would add completeness to the response.\n",
      "  \n",
      "- Naturalness: 4.8\n",
      "  - The model's response sounds very fluent and human-like, with polite language and a clear structure. It resembles how a human doctor might respond to a similar query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "\n",
      "The model's response is somewhat coherent, as it acknowledges the symptoms and discusses lab results such as CBC, fasting blood sugar, and HbA1c. However, it incorrectly interprets a fasting blood sugar of 74 as \"slightly high,\" which is misleading given that 74 is generally considered a normal fasting glucose level. Furthermore, the response does not adequately address menopause or its potential link to the symptoms.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "While the model's response addresses some aspects of the lab results and suggests consulting a healthcare professional, it lacks detail on potential causes specifically related to menopause and hormonal imbalances. The model misses discussing possible tests like FSH, LH, estradiol, or other relevant conditions such as hypertension, thyroid issues, or Vitamin D3 deficiency that were mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The model's response is mostly fluent and human-like, expressing empathy and providing general advice in a manner that feels conversational. However, there is an incorrect medical interpretation regarding blood sugar levels, which affects the overall naturalness in terms of accuracy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is coherent with the input context. It acknowledges the concerns regarding the father-in-law's health, mentions the existing health conditions, and considers the difficulty in placing an AV fistula due to the partial amputation. However, it slightly lacks in terms of addressing the detailed options and alternatives for an AV fistula placement as depicted in the true answer.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The response covers the necessity of consulting a nephrologist and discusses the possible challenges with fistula placement due to the father's condition. However, it doesn't provide as many specific alternatives and details as the true answer does, which mentions various types of fistulas and other sites, as well as the option of using a central line. \n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response sounds fluent, polite, and human-like. It uses a natural conversational tone, reassuring the inquirer and suggesting further consultation, which makes it easy to read and understand. However, it could be slightly improved by providing more detailed medical options that are mentioned in the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "  The model's response is generally coherent and aligns logically with the context of the input. It addresses the mild concentric LVH condition in the context of obesity, which is a relevant factor mentioned in the input. However, it does not thoroughly consider all factors contributing to LVH, such as the patient's medical history with regard to alcohol and smoking cessation.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "  While the response touches upon the role of obesity in LVH and suggests practical steps involving diet and exercise, it does not fully cover other aspects of the patient's condition, including the recent changes in smoking habits and current medication usage. The model's response lacks specific advice on how these might interact with the treatment of LVH or why consulting a doctor is crucial, unlike the true answer which suggests a follow-up with a cardiologist.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "  The response is quite fluent and sounds human-like. It employs a compassionate and considerate tone, as might be expected from a healthcare provider. The use of phrases like \"thank you for your query\" and \"best wishes\" enhances the naturalness and overall communication style.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "\n",
      "The model's response does not logically align with the context provided in the input. It repeats the same information about medications without addressing the specific concerns mentioned, such as potential bad interactions or unnecessary medications.\n",
      "\n",
      "- Completeness: 1.0\n",
      "\n",
      "The model's response fails to sufficiently answer the question in the input. It does not provide any guidance on potential bad interactions or which medications might be unnecessary, nor does it address TB treatment concerns.\n",
      "\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response lacks fluency and does not sound human-like due to excessive repetition of the same sentences about medications. This diminishes clarity and readability.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response logically aligns with the context provided in the input. It acknowledges the patient's conditions (diabetes, jaundice, hepatitis E, and the positive ANA result) and suggests potential complications. However, it could be slightly more accurate regarding the nature of Hepatitis E, which generally is not considered life-threatening.\n",
      "\n",
      "- **Completeness: 3.5**  \n",
      "  The model's response addresses the central concern about complications and acknowledges the need to consult a healthcare professional and manage diabetes. However, it lacks details provided in the true answer, such as the typical non-life-threatening nature of Hepatitis E, dietary recommendations, and information on the potential for false-positive ANA results.\n",
      "\n",
      "- **Naturalness: 4.8**  \n",
      "  The response is fluent, polite, and human-like in its tone and structure. It effectively communicates concern and emphasizes the importance of consulting a healthcare professional, making it sound like advice from a human doctor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The response logically aligns with the context provided, offering potential causes for the knee pain and suggesting further medical consultation and treatment options based on the details shared by the user. There is a slight discordance regarding the user already consulting an orthopedician, and suggesting consulting again might seem redundant. However, it is still coherent within the context of seeking further medical advice.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The response provides a possible explanation for the knee pain and suggests steps for treatment and further evaluation, which sufficiently covers the user's query. However, it could further improve by acknowledging the fact that the user had already consulted an orthopedician and that further exploration is necessary.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "  - The language used is fluent and human-like, with appropriate empathy and clarity. It addresses the user directly and provides suggestions in a conversational manner, making the response seem natural and reassuring.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the input by addressing the presence of a 9 mm gallstone and offers reasonable next steps, such as consulting a specialist and monitoring cholesterol levels. However, it does not acknowledge the possibility that the gallstone may not be causing the pain, missing some context from the original input.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response covers several relevant aspects such as consulting a gastroenterologist, maintaining a healthy lifestyle to prevent recurrence, and managing cholesterol. However, it misses important details from the true answer, such as the possibility that the gallstone may be asymptomatic and other potential causes of the pain. It also fails to ask for more specific information about the pain.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent, polite, and generally sounds human-like. It communicates clearly and uses professional language suitable for a medical consultation. However, a slight deduction is due to the lack of personalized engagement, which could be improved by asking more specific questions about the patient's symptoms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the input context. It correctly distinguishes between early bronchiectatic changes and bronchiectasis and provides an insight into the progression and management of the condition. However, it fails to mention the atelectasis diagnosis present in the true answer.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model's response adequately explains the difference between early bronchiectatic changes and bronchiectasis and offers guidance on treatment and prognosis. However, it does not address the suggestion of performing specific tests like sputum Gram staining, AFB staining, and fungal staining mentioned in the true answer. Additionally, the model does not consider the combination of medications suggested in the true answer or provide reassurance about life expectancy as specifically as the true answer does.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response is fluent and sounds human-like. It uses clear, professional language appropriate for a medical inquiry and offers a comprehensive explanation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response maintains coherence in that it addresses general management of diabetes and related pain. However, it lacks direct alignment with some specific details provided, such as the context of the gallbladder removal and specific medications which could be influencing her symptoms like abdominal pain and burning sensation. \n",
      "\n",
      "- Completeness: 2.5  \n",
      "  While the response generally addresses seeking medical advice and mentions managing diabetes, it does not provide a comprehensive answer to the presented symptoms of abdominal pain and burning sensation. The response also omits discussion on stool issues or suggested specific treatments, missing key aspects of the problem described in the input.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The language used is fluent and human-like. It offers polite, understandable advice, typical of a professional tone one would expect from a healthcare provider. However, the response could include more empathy or personalization to improve naturalness further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "  - The model's response partially aligns with the context but does not explicitly address all the specific details mentioned in the input, such as the concern about brain infection and the specific questions about acetyl carnitine and choline. It acknowledges the presence of meningioma and atrophy but lacks depth in connecting these with the specific symptoms and questions presented.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The response fails to fully answer all the user's questions, especially regarding the causes of the MRI findings and the effects of supplements like acetyl carnitine. While the general advice to consult a healthcare professional is sound, it doesn't provide enough direct information regarding the user's inquiry about possible infection and other potential causes.\n",
      "  \n",
      "- Naturalness: 4.5\n",
      "  - The language in the response is fluent and reads naturally. It uses a professional and empathetic tone, typical of human interaction in healthcare. The model effectively presents a human-like response in terms of expressing understanding and concern.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context of the input. It addresses the user's concerns about unexpected bleeding, discusses potential causes such as hormonal changes, and suggests seeking medical consultation, which aligns with typical healthcare advice for these symptoms.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The response provides a thorough answer by discussing several possible causes of the bleeding, such as the start of a menstrual cycle, hormonal imbalance, and the possibility of STIs. However, it could have been more complete by mentioning specific diagnostic tests like a blood hCG test for ruling out pregnancy or a physical examination for a vaginal tear, as included in the true answer. \n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent and sounds quite human-like. It uses a professional yet conversational tone appropriate for a doctor-patient interaction, making it seem genuine and reassuring. Minor adjustments in phrasing could make it sound slightly more natural, particularly by reducing some repetition and making concise statements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model‚Äôs response logically aligns with the context provided. It acknowledges the patient's current treatment and suggests consulting a dermatologist for further evaluation, which is a coherent step given the uncertainty surrounding the condition.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response addresses the immediate need for further evaluation and suggests practical home care measures. However, it lacks depth in exploring possible causes or conditions like candidal balanitis or other infections indicated in the true answer. Specifically, it doesn't provide warnings against using certain treatments that might worsen the condition, nor does it probe for more information which could help refine the diagnosis.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The language used in the model's response is fluent and human-like, making it easy to read and understand. There is a polite and empathetic tone, though some of the phrasing, like \"you can try some home remedies,\" feels slightly informal for a medical professional response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response aligns with the context given in terms of addressing the concerns about medications and their effects on weight. However, it assumes that the patient is taking medications that stimulate insulin release, which may not be entirely accurate based on the input provided.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response provides some general advice on lifestyle changes and suggests discussing medication options with a doctor, but it does not address the specific concerns mentioned about sodium glucose transporters and slow-release insulin, nor does it propose any alternative medications that avoid weight gain. \n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The language used in the response is fluent, polite, and human-like, making it easy to read and understand. It acknowledges the patient's concerns empathetically and provides general guidance naturally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.0**  \n",
      "  The model's response logically aligns with the context provided. It addresses the medical conditions and dietary concerns mentioned, such as diabetes, high blood pressure, and specific dietary restrictions. However, there is a slight misalignment when it suggests ensuring enough potassium and urate intake, which contradicts the request for low potassium and low urate.\n",
      "\n",
      "- **Completeness: 3.5**  \n",
      "  The response gives a general overview of dietary considerations like protein intake and limiting phosphorus but lacks specificity regarding how often the patient can consume fish and chicken. It doesn't adequately address the input's question about frequency of consuming non-vegetarian foods.\n",
      "\n",
      "- **Naturalness: 4.5**  \n",
      "  The response is fluent and sounds human-like. It uses polite and encouraging language, making it sound like a conversation with a health professional. The suggestion to consult a registered dietitian adds to the naturalness. However, the repetitive mention of potassium and urate needs refinement for precision in medical advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The response is generally coherent and logically aligns with the context provided in the input. However, there is a slight inaccuracy in the interpretation of the HbA1c result. The model mentions that the HbA1c result indicates a risk for prediabetes, whereas the result of 4.8 is typically considered normal rather than indicative of prediabetes.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a comprehensive set of suggestions for managing blood sugar levels and reducing the risk of developing diabetes. It covers lifestyle changes and regular check-ups but does not adequately address the main concern about whether there is a current need for stress over the test results.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is mostly fluent and human-like, with friendly and supportive language. There are some minor repeated phrases which slightly detract from the flow but overall, it is natural-sounding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It addresses the significant artery blockage and discusses potential treatments and considerations surrounding the suggested stent procedure.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a comprehensive discussion on the matter, though it could be more direct in strongly advising stenting in cases with high blockage percentages, as was emphasized in the true answer. It does mention lifestyle changes and medications as alternative options, albeit more as general advice rather than specific to the current condition.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and human-like, displaying a caring tone with language and structure that is intuitive and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and logically aligned with the context provided. It acknowledges the pain and suggests visiting a urologist for a thorough evaluation. However, it could have been more specific by mentioning factors related to diabetes management, considering the patient's age and medication.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response recommends seeing a urologist, which is a good start for addressing the issue. However, it lacks specifics that could be important, such as the potential causes of the pain like tight frenulum, partial phimosis, or Peyronie's disease, as mentioned in the true answer. Including a potential connection to the existing medical condition (like diabetes) would have made it more complete.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The language is fluent and human-like. The response is polite and uses professional language appropriate for a doctor-patient interaction, contributing to its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5\n",
      "\n",
      "The model's response is somewhat aligned with the context provided in the input as it addresses both the fever and the diabetes. However, it fails to take into account the specifics that the fever's cause is undetermined and that the blood reports are negative. The suggestion of antibiotics without proper diagnosis lacks coherence with the context provided, which mentions that the cause hasn't been identified.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The response provides an answer, but it is lacking in complexity and necessary medical guidance, particularly regarding the unexplained nature of the fever and the need for further diagnostic testing. While it suggests some antibiotics and maintains the current diabetes treatment, it doesn't cover essential diagnostic steps or considerations about the sugar level inconsistencies. The evaluation of the fever is particularly lacking.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "The response is fairly fluent and human-like in its language. It uses understandable terms and provides a structure that resembles an advisable suggestion. However, there are minor fluency issues, such as repetitive statements and slight awkwardness in phrasing (\"the treatment of fever is giving antibiotics\"). Overall, it sounds reasonably natural for a model response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the input context. It acknowledges the symptoms described and suggests potential causes such as stress and vitamin deficiency, which are relevant considerations based on the provided details. However, it could have specifically mentioned more potential medical causes like those in the True Answer, such as thyroid issues or diabetes, to be more precise.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response offers general advice on managing symptoms and emphasizes the importance of consulting a doctor for further evaluation. However, it lacks specific recommendations for medical tests or possible specific conditions that could explain the symptoms, which are present in the True Answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent, conversational, and human-like. It provides an empathetic tone and offers advice in a manner typical of a human medical professional responding to a patient's concerns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and logically aligns with the context provided. It addresses the questions about medication, lifestyle factors, and the importance of consulting a doctor, which is consistent with the user's concerns.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response covers several aspects such as medication, family history, and lifestyle factors, it does not address all specific questions the user asked, such as the reasons behind persistent high cholesterol levels and whether specific medication side effects could occur. It provides a general answer without delving into possible hereditary factors or specific lifestyle changes.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response reads very fluently and sounds human-like. The language is polite, supportive, and reassuring, maintaining a conversational tone throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It addresses the symptom of a slow urine stream and considers possible causes such as urinary retention, but rules out prostate enlargement based on the scan results mentioned in the input, which shows a good understanding of the context.\n",
      "  \n",
      "- Completeness: 4.0  \n",
      "  The model provides a satisfactory response by suggesting possible causes for the symptoms and recommending consultation with a healthcare provider, which directly addresses the user's concerns. However, it does not utilize the attached scan reports directly or suggest any lifestyle changes or immediate actions the user might take, which could enhance the completeness.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, with a professional tone suitable for a medical inquiry. The language is clear and without errors, making it easy to read and understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5 \n",
      "\n",
      "The model's response is mostly coherent with the input context. It acknowledges the user's situation and provides an explanation of how the menstrual cycle could potentially affect blood glucose levels. However, it strongly implies that the menstrual cycle can lead to higher glucose readings, whereas the impact is usually negligible for fasting glucose tests.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response addresses the concern about the influence of menstrual cycle on glucose test results and reassures the user. However, it could be improved by suggesting consulting a healthcare professional for personalized advice or mentioning that variances in glucose levels during menstruation are typically minor.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The response is fluent and human-like. It is polite, uses a conversational tone, and provides reassurance, which makes it sound quite natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 4.8\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence**: The model's response is logically aligned with the context, acknowledging the patient's existing conditions and the concern over a high WBC count. However, it doesn't specifically address the potential link to the stent implementation, which could also be relevant.\n",
      "  \n",
      "- **Completeness**: The response provides a general explanation and suggests seeing a doctor, which is appropriate. However, it could be more complete by including potential causes related to the recent stent implementation or suggesting a specific type of specialist to consult (e.g., a hematologist, as noted in the true answer).\n",
      "\n",
      "- **Naturalness**: The language used is fluent and human-like, with a friendly and professional tone. The response reads smoothly and addresses the patient's health concerns empathetically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0  \n",
      "  The model's response is not coherent with the user's specific question about whether to choose circumcision or frenuloplasty. Instead, it diverges into an unrelated discussion about Peyronie's disease, which is not mentioned in the user's context.  \n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The response does not address the user's main question about which surgical procedure to choose (circumcision or frenuloplasty). It fails to provide any guidance on the specific medical issue presented by the user.  \n",
      "\n",
      "- Naturalness: 2.5  \n",
      "  While the response sounds somewhat fluent, it includes repetitions and tangential information that reduce its perceived naturalness and relevance to the actual question posed by the user.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided. It acknowledges the user's concerns and the high readings, and suggests seeing a healthcare professional for a more definitive diagnosis. However, it could have been more specific about the next steps like the true answer did.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The response sufficiently addresses the user's situation by acknowledging the family history and expressing the need for professional evaluation. However, it lacks specific advice on the tests mentioned in the true answer (e.g., HbA1c, FBS, PPBS).\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The response is fluent, polite, and human-like. It maintains a conversational tone and appropriately expresses empathy for the user's concern.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model‚Äôs response is logically coherent with the context of the input question. It addresses the main topic of factors that can enhance the chances of getting pregnant.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response covers several aspects, such as maintaining a healthy lifestyle, managing stress, and taking prenatal vitamins. However, it lacks certain specific details mentioned in the True Answer, such as checking blood count, rubella immunity, etc., and advice for those above certain ages or with specific medical histories.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The language used in the model's response is fluent and sounds human-like. The response is polite, informative, and structured in a way that is typical of a conversation with a physician.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response aligns with the context to some extent, addressing the concern about prostate pain during ejaculation. However, it misses some critical potential medical causes and evaluates the situation as merely physiological without considering other possibilities mentioned in the true answer.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  While the response somewhat addresses the issue, it does not sufficiently cover the potential causes of painful ejaculation. The true answer provides a detailed list of potential medical inquiries and considerations that the model's response lacks.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The model's response is fairly natural and human-like, with a reassuring tone typical of a healthcare professional trying to comfort a concerned individual. However, some repetitiveness could be streamlined to improve fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  - The model's response logically addresses the issue of miscarriages by mentioning that they can be common and unexplained, and it suggests seeking advice from a doctor. However, it doesn't directly engage with the specific context of having two miscarriages within a year.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  - While the response suggests talking to a doctor, it lacks detail compared to the true answer, which provides specific steps and investigations to consider. The model's response doesn't sufficiently answer why the miscarriages might have occurred or what specific actions to take next.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  - The response is fluent, polite, and resembles a human-like interaction. It uses a conversational tone that would be acceptable in a real-life interaction with a professional. However, it could sound slightly more personalized to the context provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "\n",
      "The model's response does not logically align with the context completely. It inaccurately assumes a high risk based on being overweight and sedentary, which contradicts the input that specifies the individual is an active marathon runner who engages in strength training. Furthermore, the model does not address the context's mention of vitamin D levels.\n",
      "\n",
      "- Completeness: 1.5\n",
      "\n",
      "The model's response fails to address the main concern regarding recommended precautions or preventive measures in relation to the test results. Specifically, it overlooks the slightly borderline vitamin D levels, which was highlighted as part of the true answer's focus.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "The model's response is fluent and human-like, maintaining a professional and polite tone. However, the advice given is generic and partially irrelevant to the context, which reduces its perceived naturalness slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response is logically aligned with the context. It acknowledges the user's concerns about blood sugar levels and provides relevant suggestions for managing high levels. It does mention that consulting a doctor is crucial, which is aligned with typical medical advice.\n",
      "\n",
      "- **Completeness: 3.5**  \n",
      "  While the model provides useful general advice on lifestyle modifications to control blood sugar levels, it lacks specific medical insights and tests (e.g., HBA1c, retinopathy screening) mentioned in the True Answer. The response doesn't address the specific query about whether fasting is safe but provides general guidance for handling high blood sugar.\n",
      "\n",
      "- **Naturalness: 4.8**  \n",
      "  The response is fluent, human-like, and empathetic. It maintains a conversational and supportive tone throughout, making it easy to understand and engaging for the user. The suggestions are clear and articulated well, contributing to its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response does have some logical alignment with the context, addressing the concern about elevated blood sugar levels. However, it mistakenly mentions that blood sugar levels have been normal for the past six months, which is incorrect according to the input.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The response gives general advice on managing blood sugar levels through lifestyle changes and consulting a doctor. However, it lacks specific advice on target sugar levels or detailed next steps, like seeing a diabetologist, which would be more actionable for the user.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The response is fluent and reads naturally, resembling how a human might respond to such a query. However, some parts feel repetitive and lack specific insight.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context of the query. It identifies plantar fasciitis as a potential diagnosis, which is consistent with the symptoms described. However, it does not mention the lack of X-ray examination which might be expected given the user's note about enclosed X-rays.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response identifies plantar fasciitis and provides general advice on managing the condition, but it lacks specific treatment recommendations such as medication (Piroxicam, Rabeprazole, etc.) mentioned in the true answer. It also fails to mention the need for a follow-up consultation for a more detailed treatment plan.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The language used in the model's response is fluent and human-like. It is polite and structured in a way that is characteristic of a professional response from a healthcare provider.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It acknowledges the user's concern and evaluates potential causes for the sharp pain below the left breast, including both benign and serious conditions. However, it doesn't engage in any interactive questioning that might better tailor its analysis to the specific details of the individual case.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response covers a broad range of possible causes for the pain, which can provide value in terms of understanding potential issues. Nevertheless, it lacks follow-up questions that are present in the \"True Answer\" that might refine the diagnosis or provide more personalized advice.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds human-like, maintaining a professional tone suited for a healthcare context. It provides explanations and recommendations appropriately. The structured listing of possible conditions adds to its professionalism, though the list-like structure might slightly reduce conversational flow for some readers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response is somewhat coherent as it addresses the elevated CRP levels and suggests possible inflammatory conditions like rheumatoid arthritis or inflammatory bowel disease. However, it doesn't directly link these conditions to the specific symptoms and context provided by the user, such as IBS, anxiety, or allergic rhinitis.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The response partially answers why CRP can be elevated without a high ESR, suggesting an inflammatory condition could be the cause. However, it lacks specific details from the true answer and doesn't address potential causes like allergic rhinitis or anxiety related to the existing health conditions.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and human-like, offering empathetic advice and suggesting lifestyle changes. The language used is friendly and relatable, resembling how a human doctor might respond in writing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌèâÍ∑† Ï†êÏàò:\n",
      "Coherence       3.930000\n",
      "Completeness    3.200000\n",
      "Naturalness     4.463000\n",
      "BLEURT          0.636955\n",
      "BERTScore_F1    0.410878\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# generation\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "generation = df[df['task'] == 'generation']\n",
    "results = []\n",
    "\n",
    "for _, row in generation.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column BLEURT not found in DataFrame. Skipping normalization.\n",
      "Warning: Column BERTScore_F1 not found in DataFrame. Skipping normalization.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Coherence', 'Completeness', 'Naturalness', 'BLEURT', 'BERTScore_F1'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 147\u001b[0m\n\u001b[1;32m    144\u001b[0m evaluation_df \u001b[38;5;241m=\u001b[39m normalize_scores(evaluation_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEURT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m evaluation_df \u001b[38;5;241m=\u001b[39m normalize_scores(evaluation_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore_F1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m average_scores \u001b[38;5;241m=\u001b[39m evaluation_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoherence\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleteness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaturalness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEURT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore_F1\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÌèâÍ∑† Ï†êÏàò:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(average_scores)\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Coherence', 'Completeness', 'Naturalness', 'BLEURT', 'BERTScore_F1'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# daily_diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "daily = df[df['task'] == 'daily_diets']\n",
    "results = []\n",
    "\n",
    "for i, row in daily.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_outpu_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Evaluation {i+1} result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌèâÍ∑† Ï†êÏàò:\n",
      "Coherence       3.223577\n",
      "Completeness    2.880081\n",
      "Naturalness     3.008130\n",
      "BLEURT          0.488236\n",
      "BERTScore_F1    0.627131\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# alternative_diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "alternative = df[df['task'] == 'alternative_diet']\n",
    "results = []\n",
    "\n",
    "for _, row in alternative.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Evaluation {i+1} result:\\n{evaluation}\")\n",
    "            \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>servings</th>\n",
       "      <th>steps</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition_facts</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark</td>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark: Dive into ...</td>\n",
       "      <td>10 min</td>\n",
       "      <td>4 hr</td>\n",
       "      <td>6 Servings</td>\n",
       "      <td>['Cover a freezer-safe tray with parchment pap...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...</td>\n",
       "      <td>{'Servings': '6 Servings', 'Serving Size': '1 ...</td>\n",
       "      <td>[{'label': 'Plain Nonfat Greek yogurt', 'us_me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maple-Pumpkin Spice Oatmeal Cookies</td>\n",
       "      <td>Description not found</td>\n",
       "      <td>10 min</td>\n",
       "      <td>25 min</td>\n",
       "      <td>14 Servings</td>\n",
       "      <td>['Preheat the oven to 350 degrees F. Line two ...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...</td>\n",
       "      <td>{'Servings': '14 Servings', 'Serving Size': '1...</td>\n",
       "      <td>[{'label': 'old-fashioned rolled oats', 'us_me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0   Raspberry Swirl Frozen Yogurt Bark   \n",
       "1  Maple-Pumpkin Spice Oatmeal Cookies   \n",
       "\n",
       "                                         description prep_time cook_time  \\\n",
       "0  Raspberry Swirl Frozen Yogurt Bark: Dive into ...    10 min      4 hr   \n",
       "1                              Description not found    10 min    25 min   \n",
       "\n",
       "      servings                                              steps  \\\n",
       "0   6 Servings  ['Cover a freezer-safe tray with parchment pap...   \n",
       "1  14 Servings  ['Preheat the oven to 350 degrees F. Line two ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...   \n",
       "1  ['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...   \n",
       "\n",
       "                                     nutrition_facts  \\\n",
       "0  {'Servings': '6 Servings', 'Serving Size': '1 ...   \n",
       "1  {'Servings': '14 Servings', 'Serving Size': '1...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  [{'label': 'Plain Nonfat Greek yogurt', 'us_me...  \n",
       "1  [{'label': 'old-fashioned rolled oats', 'us_me...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfh = pd.read_csv(\"/data/jaesung/llm_for_diabetes/src/data/data2_daily_diets/diabetes_food_hub_new_nutri_facts.csv\")\n",
    "dfh.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [00:00<00:00, 22063.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results for Each Row ===\n",
      "Row Index: 661\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 662\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 663\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 664\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 665\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 666\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 667\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 668\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 669\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 670\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 671\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 672\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 673\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 674\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 675\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 676\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 677\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 678\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 679\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 680\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 681\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 682\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 683\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 684\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 685\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 686\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 687\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 688\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 689\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 690\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 691\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 692\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 693\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 694\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 695\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 696\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 697\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 698\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 699\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 700\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 701\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 702\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 703\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 704\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 705\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 706\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 707\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 708\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 709\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 710\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 711\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 712\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 713\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 714\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 715\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 716\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 717\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 718\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 719\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 720\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 721\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 722\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 723\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 724\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 725\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 726\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 727\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 728\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 729\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 730\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 731\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 732\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 733\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 734\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 735\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 736\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 737\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 738\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 739\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 740\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 741\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 742\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 743\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 744\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 745\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 746\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 747\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 748\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 749\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 750\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 751\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 752\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 753\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 754\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 755\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 756\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 757\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 758\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 759\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 760\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 761\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 762\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 763\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 764\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 765\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 766\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 767\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 768\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 769\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 770\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 771\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 772\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 773\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 774\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 775\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 776\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 777\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 778\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 779\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 780\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 781\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 782\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 783\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 784\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 785\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 786\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 787\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 788\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 789\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 790\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 791\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 792\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 793\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 794\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 795\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 796\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 797\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 798\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 799\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 800\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 801\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 802\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 803\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 804\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 805\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 806\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 807\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 808\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 809\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 810\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 811\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 812\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 813\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 814\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 815\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 816\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 817\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 818\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 819\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 820\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 821\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 822\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 823\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 824\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 825\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 826\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 827\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 828\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 829\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 830\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 831\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 832\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 833\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 834\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 835\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 836\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 837\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 838\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 839\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 840\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 841\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 842\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 843\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 844\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 845\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 846\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 847\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 848\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 849\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 850\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 851\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 852\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 853\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 854\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 855\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 856\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 857\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 858\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 859\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 860\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 861\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 862\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 863\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 864\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 865\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 866\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 867\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 868\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 869\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 870\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 871\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 872\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 873\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 874\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 875\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 876\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 877\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 878\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 879\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 880\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 881\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 882\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 883\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 884\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 885\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 886\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 887\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 888\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 889\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 890\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 891\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 892\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 893\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 894\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 895\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 896\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 897\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 898\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 899\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 900\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 901\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 902\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 903\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 904\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 905\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 906\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 907\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 908\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 909\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 910\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 911\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 912\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 913\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 914\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 915\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 916\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 917\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 918\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 919\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 920\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 921\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 922\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 923\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 924\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 925\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 926\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 927\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 928\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 929\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 930\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 931\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 932\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 933\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 934\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "=== Overall Averages ===\n",
      "Output Average Nutri-Score: None\n",
      "Model Output Average Nutri-Score: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# daily diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return all(key in data for key in ['Breakfast', 'Lunch', 'Dinner'])\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # Í≥ºÏùº/Ï±ÑÏÜå ÎπÑÏú®ÏùÑ 100g Í∏∞Ï§ÄÏúºÎ°ú Î≥ÄÌôò\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data) if isinstance(data, (int, float, str)) else default\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # Ï†ÑÏ≤¥ Î¨¥Í≤å Í≥ÑÏÇ∞\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g Í∏∞Ï§ÄÏúºÎ°ú ÏÑ±Î∂Ñ Ï†ïÍ∑úÌôî\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_meal_nutri_score(meal_data, dfh):\n",
    "    meal_scores = {}\n",
    "\n",
    "    for meal, title in meal_data.items():\n",
    "        matched_row = find_most_similar_row(title, dfh)\n",
    "        if matched_row is None:\n",
    "            continue\n",
    "\n",
    "        nutrition_facts = matched_row['nutrition_facts']\n",
    "        ingredients = matched_row['ingredients']\n",
    "        score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "\n",
    "        if score is None:\n",
    "            print(f\"Warning: Nutri-Score calculation failed for meal '{meal}' with title '{title}'.\")\n",
    "            grade = \"N/A\"\n",
    "        else:\n",
    "            grade = get_nutri_score_grade(score)\n",
    "\n",
    "        meal_scores[meal] = {'score': score, 'grade': grade}\n",
    "\n",
    "    return meal_scores\n",
    "\n",
    "def calculate_scores_with_comparison(df, dfh):\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        output_scores = {}\n",
    "        model_scores = {}\n",
    "        if is_valid_meal_structure(row.get('output', '')):\n",
    "            output_data = json.loads(row['output'])\n",
    "            output_scores = calculate_meal_nutri_score(output_data, dfh)\n",
    "        if is_valid_meal_structure(row.get('model_output_512', '')):\n",
    "            model_data = json.loads(row['model_output_512'])\n",
    "            model_scores = calculate_meal_nutri_score(model_data, dfh)\n",
    "        results.append({'row_index': idx, 'output_scores': output_scores, 'model_scores': model_scores})\n",
    "    return results\n",
    "\n",
    "def calculate_average_scores(results):\n",
    "    \"\"\"\n",
    "    Calculate the average Nutri-Scores for outputs and model outputs.\n",
    "    \"\"\"\n",
    "    output_total_score = 0\n",
    "    model_total_score = 0\n",
    "    output_count = 0\n",
    "    model_count = 0\n",
    "\n",
    "    for result in results:\n",
    "        # Extract output scores\n",
    "        for meal, score_data in result['output_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                output_total_score += score_data['score']\n",
    "                output_count += 1\n",
    "\n",
    "        # Extract model scores\n",
    "        for meal, score_data in result['model_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                model_total_score += score_data['score']\n",
    "                model_count += 1\n",
    "\n",
    "    # Calculate averages\n",
    "    output_avg = output_total_score / output_count if output_count > 0 else None\n",
    "    model_avg = model_total_score / model_count if model_count > 0 else None\n",
    "\n",
    "    return output_avg, model_avg\n",
    "\n",
    "\n",
    "# 'daily_diets' task Nutri-Score calculation\n",
    "filtered_df = df[df['task'] == 'daily_diets']\n",
    "results = calculate_scores_with_comparison(filtered_df, dfh)\n",
    "\n",
    "# Calculate overall averages\n",
    "output_avg, model_avg = calculate_average_scores(results)\n",
    "\n",
    "# Print results\n",
    "print(\"=== Results for Each Row ===\")\n",
    "for result in results:\n",
    "    print(f\"Row Index: {result['row_index']}\")\n",
    "    print(f\"Output Scores: {result['output_scores']}\")\n",
    "    print(f\"Model Output Scores: {result['model_scores']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== Overall Averages ===\")\n",
    "print(f\"Output Average Nutri-Score: {output_avg}\")\n",
    "print(f\"Model Output Average Nutri-Score: {model_avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/246 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 158/246 [03:34<01:46,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error identifying fruits and vegetables: unterminated string literal (detected at line 1) (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 207/246 [04:37<00:40,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Total weight is zero. Skipping calculation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 246/246 [05:27<00:00,  1.33s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 216\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# Execution\u001b[39;00m\n\u001b[1;32m    215\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malternative_diet\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 216\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_scores_with_comparison_no_meals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Cell \u001b[0;32mIn[32], line 207\u001b[0m, in \u001b[0;36mcalculate_scores_with_comparison_no_meals\u001b[0;34m(df, dfh)\u001b[0m\n\u001b[1;32m    200\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    201\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_index\u001b[39m\u001b[38;5;124m'\u001b[39m: idx,\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         })\n\u001b[1;32m    206\u001b[0m final_output_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(output_scores_list) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(output_scores_list) \u001b[38;5;28;01mif\u001b[39;00m output_scores_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m final_model_output_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_output_scores_list\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(model_output_scores_list) \u001b[38;5;28;01mif\u001b[39;00m model_output_scores_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Average Nutri-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_output_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Output Average Nutri-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_model_output_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# alternative diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return isinstance(data, dict)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # Í≥ºÏùº/Ï±ÑÏÜå ÎπÑÏú®ÏùÑ 100g Í∏∞Ï§ÄÏúºÎ°ú Î≥ÄÌôò\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # Ï†ÑÏ≤¥ Î¨¥Í≤å Í≥ÑÏÇ∞\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g Í∏∞Ï§ÄÏúºÎ°ú ÏÑ±Î∂Ñ Ï†ïÍ∑úÌôî\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_scores_with_comparison_no_meals(df, dfh):\n",
    "    results = []\n",
    "    output_scores_list = []\n",
    "    model_output_scores_list = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            output_text = row.get('output', '')\n",
    "            if output_text:\n",
    "                matched_row = find_most_similar_row(output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    output_scores_list.append(output_score)\n",
    "                else:\n",
    "                    output_score = None\n",
    "\n",
    "            model_output_text = row.get('model_output_512', '')\n",
    "            if model_output_text:\n",
    "                matched_row = find_most_similar_row(model_output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    model_output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    model_output_scores_list.append(model_output_score)\n",
    "                else:\n",
    "                    model_output_score = None\n",
    "\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': output_score,\n",
    "                'model_output_score': model_output_score\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': None,\n",
    "                'model_output_score': None\n",
    "            })\n",
    "\n",
    "    final_output_avg = sum(output_scores_list) / len(output_scores_list) if output_scores_list else None\n",
    "    final_model_output_avg = sum(model_output_scores_list) / len(model_output_scores_list) if model_output_scores_list else None\n",
    "\n",
    "    print(f\"Output Average Nutri-Score: {final_output_avg}\")\n",
    "    print(f\"Model Output Average Nutri-Score: {final_model_output_avg}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Execution\n",
    "filtered_df = df[df['task'] == 'alternative_diet']\n",
    "results = calculate_scores_with_comparison_no_meals(filtered_df, dfh)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env_kernel",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
