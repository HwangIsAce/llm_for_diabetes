{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# \n",
    "file_paths = [\n",
    "    \"/data/jaesung/llm_for_diabetes/src/trial8/train/llama3_8B/response/real_seed_IFD.jsonl\",\n",
    "    # \"/data/jaesung/llm_for_diabetes/src/trial/CoT_collection/model_response/test_1.jsonl\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.4700\n"
     ]
    }
   ],
   "source": [
    "# medqa\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드 (API 키 설정)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turbo를 사용하여 true_answer와 model_answer가 같은 의미인지 판별\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT 응답이 YES면 정답 처리\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # 오류 발생 시 오답 처리\n",
    "\n",
    "# 데이터 로드 및 필터링\n",
    "qa1 = df[df['task'] == 'qa1']\n",
    "\n",
    "# 정답 판별 수행\n",
    "correct_count = 0\n",
    "total_count = len(qa1)\n",
    "\n",
    "for _, row in qa1.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy 계산\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.5200\n"
     ]
    }
   ],
   "source": [
    "# medmcqa\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드 (API 키 설정)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turbo를 사용하여 true_answer와 model_answer가 같은 의미인지 판별\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT 응답이 YES면 정답 처리\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # 오류 발생 시 오답 처리\n",
    "\n",
    "# 데이터 로드 및 필터링\n",
    "qa2 = df[df['task'] == 'qa2']\n",
    "\n",
    "# 정답 판별 수행\n",
    "correct_count = 0\n",
    "total_count = len(qa2)\n",
    "\n",
    "for _, row in qa2.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy 계산\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.7200\n"
     ]
    }
   ],
   "source": [
    "# pubmedqa\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드 (API 키 설정)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turbo를 사용하여 true_answer와 model_answer가 같은 의미인지 판별\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT 응답이 YES면 정답 처리\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # 오류 발생 시 오답 처리\n",
    "\n",
    "# 데이터 로드 및 필터링\n",
    "qa3 = df[df['task'] == 'qa3']\n",
    "\n",
    "# 정답 판별 수행\n",
    "correct_count = 0\n",
    "total_count = len(qa3)\n",
    "\n",
    "for _, row in qa3.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy 계산\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.3900\n"
     ]
    }
   ],
   "source": [
    "# bionli\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드 (API 키 설정)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turbo를 사용하여 true_answer와 model_answer가 같은 의미인지 판별\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT 응답이 YES면 정답 처리\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # 오류 발생 시 오답 처리\n",
    "\n",
    "# 데이터 로드 및 필터링\n",
    "nli = df[df['task'] == 'nli']\n",
    "\n",
    "# 정답 판별 수행\n",
    "correct_count = 0\n",
    "total_count = len(nli)\n",
    "\n",
    "for _, row in nli.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy 계산\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating drug/effect pairs: 100%|██████████| 100/100 [00:00<00:00, 22489.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Drug/Effect Pair Evaluation (Strict Match, cleaned)\n",
      "✅ Precision: 0.3400\n",
      "✅ Recall   : 0.3400\n",
      "✅ F1 Score : 0.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_drug_effect_clean(text):\n",
    "    \"\"\"\n",
    "    output 또는 model_output_32에서 drug와 effect 값을 추출하고,\n",
    "    \\n이나 특수 토큰 이후의 설명은 제거한다.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return {\"drug\": None, \"effect\": None}\n",
    "    \n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # drug 추출\n",
    "    drug_match = re.search(r'drug:\\s*([^,\\n|<]+)', text)\n",
    "    drug = drug_match.group(1).strip() if drug_match else None\n",
    "\n",
    "    # effect 추출\n",
    "    effect_match = re.search(r'effect:\\s*([^\\n|<]+)', text)\n",
    "    effect = effect_match.group(1).strip() if effect_match else None\n",
    "\n",
    "    return {\"drug\": drug, \"effect\": effect}\n",
    "\n",
    "# ✅ 're2' task만 필터링\n",
    "re_df = df[df['task'] == 're2'].reset_index(drop=True)\n",
    "\n",
    "# ✅ 통계 변수 초기화\n",
    "true_positive, false_positive, false_negative = 0, 0, 0\n",
    "\n",
    "# ✅ 평가 루프\n",
    "for _, row in tqdm(re_df.iterrows(), total=len(re_df), desc=\"Evaluating drug/effect pairs\"):\n",
    "    true_vals = extract_drug_effect_clean(row['output'])\n",
    "    pred_vals = extract_drug_effect_clean(row['model_output_32'])\n",
    "\n",
    "    if true_vals[\"drug\"] and true_vals[\"effect\"]:\n",
    "        if true_vals == pred_vals:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "            if pred_vals[\"drug\"] or pred_vals[\"effect\"]:\n",
    "                false_positive += 1\n",
    "    elif pred_vals[\"drug\"] or pred_vals[\"effect\"]:\n",
    "        false_positive += 1\n",
    "\n",
    "# ✅ 지표 계산\n",
    "precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# ✅ 출력\n",
    "print(\"\\n📊 Drug/Effect Pair Evaluation (Strict Match, cleaned)\")\n",
    "print(f\"✅ Precision: {precision:.4f}\")\n",
    "print(f\"✅ Recall   : {recall:.4f}\")\n",
    "print(f\"✅ F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 'ie' 태스크 필터링\n",
    "ie = df[df['task'] == 'ie'].copy()\n",
    "\n",
    "# 문자열 형태를 안전하게 리스트로 파싱하는 함수\n",
    "def safe_eval(val):\n",
    "    if isinstance(val, list):  \n",
    "        return [str(i).strip().lower() for i in val]\n",
    "    elif isinstance(val, str) and val.strip():  \n",
    "        try:\n",
    "            parsed = ast.literal_eval(val)\n",
    "            if isinstance(parsed, list):\n",
    "                return [str(i).strip().lower() for i in parsed]\n",
    "            else:\n",
    "                return [str(parsed).strip().lower()]\n",
    "        except:\n",
    "            return [val.strip().lower()]\n",
    "    return []\n",
    "\n",
    "# output과 model_output 모두 리스트 형태로 파싱\n",
    "ie[\"output\"] = ie[\"output\"].apply(safe_eval)\n",
    "ie[\"model_output_32\"] = ie[\"model_output_32\"].apply(safe_eval)\n",
    "\n",
    "# Precision, Recall, F1-score 계산 함수\n",
    "def calculate_scores(y_true, y_pred):\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for true_vals, pred_vals in zip(y_true, y_pred):\n",
    "        if not true_vals and not pred_vals:\n",
    "            all_precisions.append(1.0)\n",
    "            all_recalls.append(1.0)\n",
    "            all_f1s.append(1.0)\n",
    "            continue\n",
    "\n",
    "        true_count = Counter(true_vals)\n",
    "        pred_count = Counter(pred_vals)\n",
    "\n",
    "        TP = sum(min(true_count[k], pred_count[k]) for k in true_count.keys() & pred_count.keys())\n",
    "        FP = sum(pred_count[k] - true_count.get(k, 0) for k in pred_count.keys())\n",
    "        FN = sum(true_count[k] - pred_count.get(k, 0) for k in true_count.keys())\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    return sum(all_precisions) / len(all_precisions), sum(all_recalls) / len(all_recalls), sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "def calculate_scores_ignore_duplicates(y_true, y_pred):\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for true_vals, pred_vals in zip(y_true, y_pred):\n",
    "        true_set = set(true_vals)\n",
    "        pred_set = set(pred_vals)\n",
    "\n",
    "        TP = len(true_set & pred_set)\n",
    "        FP = len(pred_set - true_set)\n",
    "        FN = len(true_set - pred_set)\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    return sum(all_precisions) / len(all_precisions), sum(all_recalls) / len(all_recalls), sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "\n",
    "# 점수 계산\n",
    "precision, recall, f1 = calculate_scores_ignore_duplicates(ie[\"output\"], ie[\"model_output_32\"])\n",
    "\n",
    "# 출력\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0 \n",
      "  - The model's response logically aligns with the context provided in the input. It accurately summarizes the patient's medical history and current condition as discussed by the doctor and the patient.\n",
      "  \n",
      "- Completeness: 4.5\n",
      "  - The model's response sufficiently answers the question by encapsulating most key elements of the patient's condition described in the dialogue. However, it could include additional specific details such as the patient's profound impairment in attention and short-term memory, and facets like facetiousness and inappropriate jocularity, which are noted in the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response is fluent and human-like, presenting the information in a clear and structured manner similar to a medical report.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model details align logically and are consistent with the context provided in the doctor-patient conversation. It accurately captures the diagnosis, patient history, examination findings, investigations, and the proposed management plan.\n",
      "  \n",
      "- Completeness: 4.5\n",
      "  - The response captures most of the key details from the input context, including symptoms, medical history, examination, investigations, and management plan. However, it lacks the demographic detail of the patient (such as age and regional background) and the emergency management specifics provided in the true answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The model's response is clear and structured but reads more like a medical report than a natural conversation. While fluent and precise, it lacks elements of conversational language, which slightly impacts the human-like quality of naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response captures the logical flow and aligns well with the context of the doctor-patient conversation. However, minor details, such as specific phenotypic markers and the physical examination findings, are not mentioned, which slightly affects the coherence.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response is mostly complete and covers the main points, such as the symptoms, medical history, test results, diagnosis, and treatment plan. Nevertheless, it lacks some specifics, like the detailed phenotype of lymphocytes and the exact nature of the treatment plan, which reduces the completeness slightly.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds natural. It maintains a professional tone consistent with a medical setting, making it sound human-like. There are no awkward or unclear phrases, contributing to its high naturalness rating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 5.0**  \n",
      "  The model's response logically aligns with the context provided in the input. It accurately captures the sequence of events, symptoms, medical history, diagnostic steps, and the unfortunate outcome, all of which were discussed in the original dialogue.\n",
      "\n",
      "- **Completeness: 4.5**  \n",
      "  The model's response sufficiently answers the main question regarding the patient's condition and the doctor's actions. It provides a comprehensive summary of the situation up to the critical point. However, it does not mention the specifics of the lab test results or the next steps after the patient's passing, which were part of the true answer.\n",
      "\n",
      "- **Naturalness: 4.8**  \n",
      "  The model's response is fluent and human-like. It conveys information in a clear and professional manner similar to how a medical professional might summarize the case. There is a very slight room for improvement in making it sound less like a medical note and more like conversational speech.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response is coherent with the context given in the input. It accurately captures the details of the doctor's conversation regarding the patient's condition and the medical procedures undertaken.\n",
      "  \n",
      "- Completeness: 4.0  \n",
      "  - The model's response provides a summarized version of the situation but misses some specific information present in the true answer, such as the patient's age, history of diabetes and hypertension, and the specific dosages of teriparatide and elemental calcium. However, it still provides a sufficiently detailed overview of the key points.\n",
      "\n",
      "- Naturalness: 3.0  \n",
      "  - The model's response is more of a bulleted list rather than a naturally flowing conversation or narrative. While it conveys information clearly, it lacks the fluency and human-like quality of a conversational response, which impacts its naturalness.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context provided. It accurately reflects the symptoms, medical history, and suspected diagnosis according to the input context. \n",
      "- Completeness: 4.5\n",
      "  - The response sufficiently answers the question by summarizing the conversation and covering most of the relevant symptoms, medical history, and suggested diagnosis. However, it does not mention some minor contextual details such as the patient's occupation and family status.\n",
      "- Naturalness: 5.0\n",
      "  - The dialogue is fluent and sounds human-like, following a natural conversational flow typical of a doctor-patient interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  * The model’s response partly aligns with the context provided. It captures key points like the diagnosis and treatment but introduces an incorrect condition (\"subacute bacterial endocarditis\"), which was not mentioned in the conversation.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  * The model’s response summarizes some important aspects like diagnosis, laboratory findings, and treatment but omits other details, such as the patient's specific age, absence of respiratory symptoms, and certain test details mentioned in the conversation. Additionally, it adds unauthentic information about the suspected diagnosis.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  * The response is generally fluent and structured in a clear and professional manner, resembling a clinical note. It maintains a human-like tone appropriate for a medical summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response generally aligns with the context provided in the input. The details about the patient's symptoms, diagnostic results, and treatments were consistent with the information given in the dialogue. Some minor inconsistencies, like the patient's age, slightly reduce the coherence score.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response covers most of the essential information from the conversation. It mentions the main symptoms, diagnostic findings, and treatments. However, it lacks the patient's full obstetric history (gravida five, para five) and omits some context, such as the timeline of events and specifics about the pregnancy complications.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent and largely reads like a coherent summary one might expect from a medical professional. The language is clinical but clear, which fits the context of healthcare communication. Since it maintains a formal tone suitable for clinical documentation, it scores high in naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response accurately reflects much of the information provided in the input, such as the patient's medical conditions, test results, and treatment plan. However, there is a significant coherence issue: the gender and age are incorrectly identified. The input clearly presents the patient as a woman, but the model refers to a \"78-year-old man.\" This inconsistency impacts the logical alignment of the response with the provided context.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model's response captures most of the critical elements from the doctor-patient conversation, such as symptoms, diagnoses, and treatment plans. However, it lacks some specific details from the true answer, such as the patient's response to initial treatment, elevated erythrocyte sedimentation rate, and chronic HBV infection, affecting the completeness of the response.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response is largely fluent and human-like, with clear and coherent sentences. It reads like a summary a professional might give, aligning well with the conversational tone of the input. However, due to the incorrect gender and age identification, it slightly affects the perception of naturalness because it might seem dismissive of personal details to a human reader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the evaluation of the model's response, here's the assessment:\n",
      "\n",
      "- **Coherence:  4.5**\n",
      "  - The model's response logically follows the sequence of events described in the input. However, it slightly deviates in wording and structure, but the essence of the conversation remains intact. The conversation between the doctor and the patient is well-aligned with the scenario described.\n",
      "\n",
      "- **Completeness: 3.5**\n",
      "  - The model's response captures most of the important details, such as the symptoms, medical history, and the side effects of vancomycin. However, it misses the detail that the true answer includes about the timeline of when the infection started (three weeks post-surgery), which might be considered a significant gap in completeness.\n",
      "\n",
      "- **Naturalness: 4.8**\n",
      "  - The conversation in the model's response is very natural and human-like. The flow feels like an actual conversation one might experience in a medical setting, especially with the way the doctor and patient interact. Minor unnatural repetitions of some phrases could be improved for a perfect score.\n",
      "\n",
      "Overall, the model's response effectively conveys the logic and context of the interaction, though it slightly misses some detail in the completeness criterion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 3.5\n",
      "\n",
      "**Rationale:**\n",
      "\n",
      "- **Coherence**: The model's response logically aligns with the input context. It captures the sequence of medical events that occurred, including the patient's symptoms, medical history, initial treatment, and subsequent observations. The only gap is the incorrect age presented for the patient, which slightly affects the coherence.\n",
      "\n",
      "- **Completeness**: The model covers most of the critical information presented in the input, including the patient's condition, treatment steps, and medical evaluation results. However, it lacks some details, like the patient's age and some aspects of the patient's situation, such as the higher heart rate post-treatment, which were presented in the true answer.\n",
      "\n",
      "- **Naturalness**: The response is fairly fluent and detailed, resembling a summary that would be found in medical records. However, some parts sound more like a list of facts than a natural, human-like response. There is some rigidity in the language that makes it less conversational and more formal, which is slightly less natural compared to typical human dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  - The model's response logically aligns with the context provided in the input, capturing all relevant details related to the patient's third presentation.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  - While the model does accurately describe the patient's third presentation, it lacks details provided in the true answer regarding the timeline and prior medical episodes. However, for the specific question about the current presentation, the information is sufficient.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  - The response sounds fluent and human-like overall, although it reads somewhat like a structured medical report, which may slightly reduce the naturalness in a conversational context but is typical in a medical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 4.8\n",
      "\n",
      "**Coherence (4.5):** The model’s response is mostly coherent with the input conversation. It accurately captures the main points of the discussion between the doctor and the patient. However, there is a discrepancy in the patient's demographics (age and gender), which slightly affects coherence.\n",
      "\n",
      "**Completeness (4.0):** The model provides a detailed summary of the patient's medical history and presenting symptoms, as well as the treatment and outcome. However, the mention of the patient's gender and age in the model's response does not match the information provided in the true answer, which affects the completeness.\n",
      "\n",
      "**Naturalness (4.8):** The response is very natural and fluent. It reads like a well-structured clinical note, effectively summarizing the consultation in a professional and clear manner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The response effectively summarizes the relevant details of the patient's medical condition and the events surrounding the incident. It maintains logical consistency with the context provided in the input. However, there is a discrepancy in the patient's age; the input mentions age at 67, while the model's response indicates 64 years old.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - The response captures most of the relevant details, such as the patient's medical history, procedural details, and the critical incident. However, it omits some specific background information that the true answer includes, like the medications for hypertension and diabetes.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  - The language used in the response is fluent and human-like. It effectively conveys the sequence of medical events in a clear and professional manner which is suitable for the medical context described.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response is coherent with the context provided. It correctly identifies the main points of the conversation involving the patient's condition, the care plan agreed upon, and the pregnancy targets. It acknowledges the patient's known diagnosis of MODY 3 diabetes and her pregnancy. However, it mistakenly mentions the patient's age as 19 years old instead of providing accurate gestation details related to the prenatal calculations.\n",
      "\n",
      "- **Completeness: 3.5**  \n",
      "  The response covers some key points of the conversation, such as the patient's diagnosis and the plan for biweekly growth scans and consultations. It also mentions the pregnancy targets. However, it lacks several important details, including the patient's medical history, the specifics about her diabetes management (initial treatment with gliclazide, switching to insulin), the family history of diabetes, details about the father's MODY 2 diagnosis, and the inheritance possibilities for the fetus.\n",
      "\n",
      "- **Naturalness: 4.8**  \n",
      "  The response is fluently written and closely resembles how a human might summarize a clinical note. The language is clear and formal, fitting for a medical context. There are no grammatical errors or awkward phrasing.\n",
      "\n",
      "Overall, while the response is generally well-structured and clear, it lacks some depth of detail that would offer a more comprehensive understanding of the situation based on the provided conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns well with the context provided in the input. All major facts from the dialogue have been accurately represented. However, there is a minor lack of explicit mention that the patient did not experience symptoms of local infiltration, which was noted in the dialogue.\n",
      "\n",
      "- Completeness: 4.7  \n",
      "  The model's response is comprehensive and covers almost all aspects of the patient's medical condition and the subsequent medical actions described in the conversation. The only minor detail missing is the specific indication that the patient is Sri Lankan Tamil.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent and presents medical information in a human-like manner. It reads very naturally, with clear and consistent terminology used throughout the summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response aligns well with the context provided in the conversation. It accurately captures the sequence of events and details shared between the doctor and the patient. The main elements of the conversation, such as medical history, treatments, and examination results, are appropriately included. However, it lacks specific contextual information like the patient's demographic details, such as age or residency, which were present in the 'true answer.'\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response is mostly complete in terms of capturing the medical history and details provided in the conversation. Still, it misses some specific information such as the patient's age, residency specifics, and the reference ranges for some lab results. Additionally, the response does not explicitly mention the patient's nationality or the absence of recent travel, which could be relevant depending on the context of medical reporting.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The model's response is fluent and human-like, demonstrating a clear and concise summary of the doctor-patient exchange. The language used is professional and similar to what might be found in a clinical note, making it quite natural for the intended setting. Some directly quoted segments and technical terminology might make it slightly less natural for a layperson, but it is appropriate for the clinical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "  - The model's response lacks coherence as it incorrectly identifies the patient's gender and age. Additionally, it misidentifies crucial elements of the medical history that do not logically align with the provided context.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - While the response includes some details from the dialogue, such as the renal mass, nephrectomy, and follow-up recommendations, it fails to provide the complete and accurate patient profile, notably the gender, age, and the specifics of the patient's medical situation (e.g., history of gastric bypass surgery issues).\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The response reads fluently and has a natural tone, typical of medical case notes. However, the incorrect specific details somewhat undermine the perception of a realistic narrative from a human-like perspective.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5 \n",
      "  - The model's response generally aligns with the context, detailing the medical history and diagnosis. However, it incorrectly identifies the patient as a 7-year-old boy instead of the correct age of 27 months, which affects the coherence given that age can be significant in medical cases.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The model's response includes most of the relevant details such as symptoms, medical evaluations, and treatment outcomes, answering the implicit question about the patient's condition and treatment follow-up. Nevertheless, it misses specific details from the true answer like the mild prominence of the renal pelvis, and the fact that no intercurrent illnesses were reported.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent and sounds human-like, effectively summarizing the patient's information in a natural conversational tone. However, it does simplify the initial interaction between the doctor and the patient, making it slightly more robotic and less conversational in style.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is coherent with the context and aligns well with the overall narrative of the patient's medical journey from presentation to treatment. It accurately captures the sequence of events and the medical procedures described in the input conversation.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "While the model's response includes most of the key details, such as the patient's symptoms, treatment, and diagnosis, it omits specific details like the patient's age, the RT-PCR confirmation for COVID-19, and information about the specialist visit and orbital involvement that are present in the True Answer.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "\n",
      "The model's response is fluent and human-like, with a clear and logical structure. The language used is appropriately formal, given the medical context, and it reads smoothly. However, the absence of slight details hinders the complete natural flow of a comprehensive summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.0\n",
      "\n",
      "Explanation:\n",
      "- **Coherence (4.0)**: The model's response aligns well with the conversation provided. It summarizes the key points clearly, such as the patient's symptoms, medical history, and diagnosis as discussed in the dialogue. While it lacks specific details, it maintains a logical flow consistent with the input.\n",
      "\n",
      "- **Completeness (3.5)**: The response captures general aspects of the case, like the symptoms, medical history, and need for monitoring. However, it leaves out specific medical details and findings that are essential for a more precise clinical note, which are included in the true answer. Therefore, it partially answers the input's requirements.\n",
      "\n",
      "- **Naturalness (4.0)**: The model's response is fluent and well-structured, reflecting a human-like summary style typical of clinical documentation. It adequately presents information in a professional tone, suitable for a medical context. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "The model's response is coherent as it accurately aligns with the context provided in the conversation, capturing key aspects such as the patient's birth history, diagnosis of chromosome 1q21.1 deletion syndrome, SIADH, and the doctor's recommendations for monitoring the patient's condition. However, it could have more explicitly addressed the specific elements asked by the patient, such as explaining the significance of some details or the relevance of bringing in family members for support.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "The model's response sufficiently summarizes the key points discussed in the conversation, including the diagnoses and medical recommendations. However, it misses some specific details from the true answer that were present in the conversation, such as the full details of the infant's birth condition (e.g., head circumference, etc.) and maternal complications like gestational diabetes and hypertension.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "The response is written fluently and is easy to read, maintaining a human-like tone. It explains medical concepts clearly and summarizes the situation in a manner typical of a doctor's summary, demonstrating a very natural flow. There is, however, a slight inclination towards a more formal summary style than a conversational one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns well with the context provided in the input. It accurately recounts the detailed exchange between the doctor and patient, summarizing key points of the conversation and the patient's medical history.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model's response covers most of the essential information mentioned in the input, correctly listing the patient's symptoms, medical history, previous examinations, and the recommended follow-up. However, it lacks certain specific details like the exact nature of other normal test results (e.g., WBCs, kidney, and liver functions) and the outcomes of discussions with GI that are present in the true answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is written fluently and in a manner that sounds human-like. The language is clear and appropriately professional, suitable for a medical setting. It effectively conveys the information in a way that would be typical of a doctor's summary in a real clinical discussion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response generally aligns well with the context provided in the input. However, the model incorrectly states the patient's age as 60 instead of 45, which is a critical detail. This reduces coherence slightly.\n",
      "\n",
      "- Completeness: 4.8  \n",
      "  The model's response includes almost all the necessary details provided in the input, such as medical history, symptoms, and treatment plan. The only missing elements are the age discrepancy and that the chest X-ray revealed right basal pneumonia. \n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is articulated fluently and reads naturally. It resembles a structured and concise medical report, which fits the context, although the very structured style may give it a slightly mechanical feel compared to a conversational recap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's summary is largely coherent and aligns well with the provided conversation. It accurately captures the main points discussed between the doctor and the patient. However, it lacks some specific details about the initial treatments with antiallergic therapy and the patient's initial symptoms due to allopurinol, which are present in the true answer.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model's response covers most of the critical elements of the conversation but omits some specific background details mentioned in the true answer, such as the patient's medital treatment with allopurinol, lab findings at the initial hospital, and the progression of glucocorticoid therapy. Including these specifics would provide a more comprehensive understanding.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent and reads like a natural, human-like summary of the conversation. The language is clear and concise, making it easy to understand. There are no awkward or unnatural phrasings present in the summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 4.5\n",
      "- Naturalness: 4.5\n",
      "\n",
      "**Coherence**: The model's response accurately represents the dialogue provided in the input, capturing the key details and conclusions present in the discussion between the doctor and the patient.\n",
      "\n",
      "**Completeness**: The response covers most of the essential details from the dialogue, but it lacks mention of the patient's moderate to severe pain around the neck and shoulders, which is included in the true answer. This impacts the completeness slightly.\n",
      "\n",
      "**Naturalness**: The model's response is generally fluent and human-like, though it reads more like a clinical summary rather than a conversation. This slightly affects the naturalness score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response is generally coherent and aligns well with the given context. However, it inaccurately reports the patient's age as 68 instead of 54, which can lead to misunderstandings.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The model captures most of the critical details from the dialogue, such as symptoms, medical history, and examination results. However, it omits some specifics like the patient's occupation and details about emerging shortness of breath, and does not mention the absence of certain symptoms such as headache or abdominal issues. \n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is well-structured, fluent, and reads human-like. It lacks some natural variability one might expect in a summary from a different perspective but maintains high naturalness overall.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "  - The model’s response is not closely aligned with the context. It provides a generic summary rather than the specific details presented in the conversation.\n",
      "\n",
      "- Completeness: 1.5\n",
      "  - The response does not address specific details from the conversation such as the PCI details, complications, and treatments. It fails to mention crucial elements like the pericardial drain and fat embolization.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "  - The response is somewhat fluent and human-like, but is too abstract and lacks the specificity required to sound like a detailed and human-understandable summary of a medical procedure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "  The model's response is a structured summary of the conversation, which logically aligns with the provided context. However, it reads more like a checklist than a cohesive narrative, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "  The model's response captures most details of the doctor-patient interaction accurately but does not provide an analysis or conclusion about the case, such as the significance of the findings or plans for treatment, which are present in the true answer.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "  The response is structured and formal, resembling a clinical note more than natural dialogue. While this style is appropriate for medical documentation, it could be more human-like by integrating transitions or summaries that connect different parts of the conversation into a more flowing narrative.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input, summarizing the key findings and doctor-patient interactions effectively. However, it lacks a few specific details, such as the exact treatment dosages given in the true answer, which is a minor issue.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model sufficiently captures the main aspects of the conversation, diagnosis, and treatment plan. It mentions the key symptoms, examinations, and subsequent treatments. However, some details like the patient's age, specific dosage of nimodipine, and the NIHSS score are omitted, resulting in a slightly less complete response compared to the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent and human-like, resembling a clinical note. It uses appropriate medical terminology and presents the information clearly and concisely, making it sound professional and natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the input context and accurately reflects the patient and doctor's conversation. However, it omits some specific details from the dialogue, such as the patient's age, marital status, and history of hypoglycemic comas.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response adequately covers most of the key aspects discussed in the conversation, such as the patient's diabetes history, treatment regimen, complications, and the decision for pancreatic islet cell transplantation. However, it lacks detailed completeness compared to the \"True Answer,\" missing some specifics, like the exact age of diabetes onset and the details of the insulin regimen over the years.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The model's response is generally fluent and human-like, using language that would be expected in a professional medical context. However, some portions might benefit from slight rephrasing to enhance readability and engagement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response reflects an accurate understanding of the nature of the original conversation as a clinical summary. However, it lacks specific details that were present in the input, thus somewhat misrepresenting the granular level of detail maintained in the doctor-patient dialogue.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The model's response is quite generic and does not provide a detailed summary of the patient’s symptoms, medical history, or treatment plan as detailed in the conversation. It doesn’t capture specific medical details, conditions, or treatments discussed, like the bilateral weakness, respiratory failure, or medications prescribed.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is articulated in a natural and professional manner, resembling how a clinical note might begin. It is fluent and human-like, maintaining a structured and clear presentation, suitable for a medical context. However, the excessive generalization detracts slightly from its appropriateness in expressing the full context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response closely mirrors the dialogue with the doctor but incorrectly refers to the patient as \"he\" instead of \"she\". This misalignment in gender lowers the coherence as it doesn't logically match the context of the patient being a woman.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response captures the majority of the relevant details from the input, including medical history, treatment and medications, diet, and biometric measurements. However, it fails to mention the patient's age, which is present in the true answer. This somewhat affects the completeness of the summary.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response is overall fluent and human-like, using formal medical language appropriate for a clinical context. Aside from the gender error, the structurally coherent sentences contribute to a natural-sounding response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context and captures the key points of the conversation. However, there is a slight lack of focus as it does not specifically answer the patient’s question, \"What does that mean for me?\"\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response covers most of the key details from the conversation but does not provide a sufficient answer to the question about the implications of the findings for the patient's health. Instead, it only reports on the diagnostic process and findings without addressing the next steps or potential outcomes.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, maintaining a professional tone that is expected in a medical context. However, it reads more like a clinical summary rather than directly addressing the patient's inquiry in a conversational manner. The omission of empathetic or supportive language also slightly reduces naturalness in patient interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response aligns closely with the context provided, capturing the key elements such as the patient's medical history and the issue with their foot. However, it introduces the age 65 instead of 58, which slightly detracts from coherence.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model's response adequately answers the question by summarizing the patient's condition, the doctor's advice, and mentioning the patient's death due to an unrelated cause. It captures most of the details except for specifying the exact metatarsals involved.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is written in a fluent and professional manner. It resembles a medical summary and is coherent with how such cases are typically documented, which makes it sound human-like. However, the mention of the patient's death at the end could have been worded more empathetically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns with the context provided in the input. It accurately reflects the sequence of medical events and information shared during the conversation between the doctor and the patient.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model's response sufficiently answers the question posed by the conversation, summarizing the key medical details and progression leading to the patient's death. However, it lacks minor specific details present in the true answer, such as the patient's age and nationality, which would add to the completeness.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model’s response is fluent and sounds human-like, effectively summarizing the medical case in a coherent and professional manner. There is slight room for improvement to make the language more nuanced, but overall, it maintains clarity and professionalism.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is highly coherent with the dialogue provided in the input. It accurately reflects the conversation between the doctor and the patient, ensuring the logical sequence is preserved. However, some elements of the original dialogue, like specific questions about recent drug use and the results of the neurological examination, are omitted, which slightly affects coherence, but not significantly enough for more than a half-point deduction. \n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model's response is somewhat complete, focusing largely on essential parts of the patient's symptoms, examination findings, and laboratory results. It effectively mentions key points such as the patient's weakness, medical history, observed symptoms (pallor and icterus), and abnormal lab results. However, it omits some of the details from the true answer, such as a comprehensive neurological assessment and additional specific findings on the extremities or INR values, which are part of the complete picture needed for thorough medical documentation.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The model's response is very natural and reads like an authentic doctor-patient interaction. The language is fluent and human-like, with appropriate medical terminology used throughout. Any slight deduction may be attributed to the repetition or formulaic phrasing typical in such dialogues, though it closely mirrors real clinical exchanges realistically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is mostly coherent with the context provided, capturing the key details about the symptoms, examinations, and results. However, there is one significant mismatch: the patient's gender and age are incorrect. This affects coherence since it contradicts the specific details.\n",
      "  \n",
      "- Completeness: 4.8\n",
      "  - The model includes almost all the relevant information, outlining the symptoms, diagnostic tests, and the outcome, which is a referral to a specialist. The only information missing is the mention of consulting the Department of General Medicine specifically.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response is fluent, well-structured, and reads like a succinct summary one might expect from a medical record, maintaining a professional tone consistent with human-like communication.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context provided. It accurately summarizes the interaction, depicting the patient's symptoms, medical history, the procedures undertaken by the doctor, and the unfortunate outcome.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The response sufficiently answers the question and encapsulates key details, such as the patient's symptoms, medical history, examination results, and outcome. However, it omits specific details such as the patient's age and some exact phrases (e.g., \"Glasgow coma scale of 3 points\") which are mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response is fluent and human-like. It reads smoothly, much like a well-crafted clinical note, and the expression of sympathy to the patient's family is conveyed naturally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is mostly coherent with the input text, capturing the main elements of the conversation, such as the diagnosis of osteomyelitis, the identification of methicillin-resistant Staphylococcus aureus, and the subsequent treatment plans such as intravenous vancomycin and NPWT. However, it slightly lacks detail in relation to the progression of the treatment plan and subsequent observation results, which affects full coherence.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The model provides a good summary of the patient's diagnosis and immediate treatment steps. Still, it misses out on specifics like the initial three-day history of erythema and edema, the patient's complete neuropathy condition, and detailed postoperative observations. These omissions make the response less complete compared to the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The model's response is fluent and sounds human-like, following a logical structure that is easy to understand. The language used is appropriate and professional, typical of a summary you would expect in a medical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is largely coherent with the provided dialogue context. However, it missed some details like the true age of the patient, craniopharyngioma presentation as diplopia, and osteoporosis as a pre-existing condition. Additionally, the wording in the dialogue context suggests it’s a real-time conversation, whereas the model presents it as a retrospective narrative.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model covers most of the significant events and details from both the dialogue and the true answer. Nevertheless, it fails to mention some preoperative details and the specific cause of the craniopharyngioma presentation, which could affect medical interpretation.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is generally natural and human-like in tone. It preserves the first-person narrative consistent with the style used by the patient in the dialogue. However, the transition from real-time dialogue to retrospective recounting might reduce some natural conversational flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response accurately summarizes the information provided in the doctor-patient conversation. It logically aligns with the context of the medical history, treatments, and results shared during the conversation, maintaining consistency and relevance to the input provided.\n",
      "\n",
      "- **Completeness: 4.0**  \n",
      "  The model's response captures the essential points from the conversation, including the medical history, the nature of the surgery, and the treatments administered. However, it misses some specific details, such as the exact measurements of the lesion, and full extent of the side effects and specifics about the first-line modulated treatment schedule, which are present in the true answer.\n",
      "\n",
      "- **Naturalness: 5.0**  \n",
      "  The response is fluent and reads like a well-composed summary from a human. It conveys the medical details in a clear and structured manner, making it easy to follow while maintaining a professional tone appropriate for the context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response is generally coherent and aligns logically with the context of the discussion between the doctor and patient. However, there is an incorrect gender and age assignment, which affects coherence.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model's response captures most of the essential aspects of the patient's medical history and treatment outcomes. However, it misses some details such as the age and gender of the patient, mentions of the differential diagnosis (MRONJ), and details about the microbiologic cultures which were not sent.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent and reads naturally, resembling how a human might summarize the case. It contains no awkward phrasing or technical inaccuracies in the description of clinical findings and treatment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0 - The model's response maintains a consistent and logical flow with the provided context. It accurately reflects the conversation between the doctor, patient, and patient's family.\n",
      "\n",
      "- Completeness: 3.0 - While the model's response includes much of the conversation accurately, it does not highlight all specific details, such as the patient's occupation or smoking index, and does not mention a decrease in level of consciousness, which are present in the True Answer.\n",
      "\n",
      "- Naturalness: 5.0 - The dialogue sounds fluent and human-like, preserving an authentic conversational tone between the doctor, patient, and family members.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response is generally coherent with the information provided in the input conversation. However, the model incorrectly states the patient's age as 61 instead of 58, which is a minor discrepancy affecting coherence. Moreover, the \"True Answer\" includes additional specific medical details not articulated in the context, though largely these do not hinder the logical sequence of events presented.\n",
      "  \n",
      "- Completeness: 4.5  \n",
      "  - The model's response sufficiently answers the question about the patient's medical history and treatment outcomes, covering most of the major points in the input context. A few specific details, such as blood pressure readings and OCT findings, are missing when compared to the \"True Answer\", but these do not significantly detract from the overall response in terms of direction and elements covered.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  - The model's response is fluent and reads like a coherent medical summary that a human might produce. However, since it lacks conversational elements it operates more like a clinical report rather than a natural conversation between doctor and patient, yet for the nature of a clinical summary, it maintains a high degree of naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is coherent as it accurately highlights and reflects the flow of conversation between the doctor and the patient. It maintains logical alignment with the context, mostly capturing the medical history and discussions.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The model's response is quite complete, summarizing most of the key interactions between the doctor and patient. However, it lacks some specific details found in the true answer, such as the patient's age, the historical specifics of the cancer staging according to UICC, and some numerical details of tumor sizes.  \n",
      "  \n",
      "- Naturalness: 4.8\n",
      "  - The model's response is fluent and human-like, presenting the information in a clear and organized manner. It resembles how a human would summarize a medical consultation efficiently without unnecessary jargon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns well with the context provided in the input. It accurately summarizes the doctor's conversation with the patient, capturing the main points about the symptoms, treatment, and diagnosis of Cushing's syndrome. However, it misses some specifics, such as the precise dosage of dexamethasone and the measured hypokalemia level.\n",
      "\n",
      "- Completeness: 4.2\n",
      "\n",
      "The model's response substantially covers the key elements discussed in the input regarding the patient's symptoms, treatments, and diagnosis. However, it omits certain details found in the true answer, such as the specific dose of insulin aspart and the exact figures for hypokalemia, which would provide a more comprehensive answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The model's response is fluent, well-structured, and sounds natural and human-like. It presents the summarized information in a clear, readable format that effectively conveys the clinical insights derived from the conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response lacks coherence with the input, as it provides a high-level generic overview of what a clinical note might contain rather than specific details from the conversation, such as the patient's age, symptoms, specific diagnoses, and test results.\n",
      "\n",
      "- Completeness: 1.5  \n",
      "  The response fails to sufficiently answer or capture the question in the input or the key details of the conversation. The specific symptoms, treatments, and test results discussed are not detailed, reducing its utility as a summary of the conversation.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response is fluent and human-like, with structured sentences that are easy to follow. However, it still reads more like a generic description of a clinical note than a response specifically tailored to the provided interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response generally aligns with the context of the detailed medical conversation. However, it lacks specificity and doesn't capture some intricate details discussed in the original conversation, which could slightly affect coherence.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The model's response gives an overview of the conversation but lacks specific details about the patient's medical history, symptoms, and diagnostic findings. It does not provide specific information mentioned in the true answer, such as the poorly differentiated adenosquamous carcinoma and the histological findings.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent and human-like. It reads like a summary and maintains a professional tone that aligns well with medical documentation. However, it could be slightly more detailed to match typical medical note standards.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response is largely coherent and follows the logical progression of the conversation between the doctor and patient. It accurately captures the exchange of information about the patient's symptoms, history, and treatment options. However, it could be improved by explicitly addressing the patient's age and the specific details given in the conversation, such as the discovery of symptoms or how glycosuria was detected.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - The model's response successfully covers most key points from the original conversation, including the patient's medical history, symptoms, allergy, and treatment plan. Nevertheless, it misses specific detail about the patient's age, as well as future outcomes such as the anticipated reduction in UTIs and infections and any subsequent episodes of infection, limiting a full picture of the situation.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  - The model's response is articulated in a natural and fluent manner. It uses appropriate medical terminology and maintains a tone befitting a professional summary of a medical consultation, contributing to its human-like quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  * The model's response accurately captures key elements from the initial conversation, such as the patient's medical history, symptoms, and the results of the histopathologic examination. However, it incorrectly states the patient's age as 67 instead of 70 and omits some specific details mentioned in the initial interaction. \n",
      "- Completeness: 3.5  \n",
      "  * The response includes important information about the patient's condition and the outcomes of the biopsy but lacks some details that were in the true answer, such as the patient's use of zinc oxide cream without improvement, the attempted treatment with triamcinolone acetonide, the description of the lesion decrease, and the histopathologic details like interconnecting bands and lymphocytic infiltrate.\n",
      "- Naturalness: 4.5  \n",
      "  * The response sounds fluent and captures the medical summary well, although it appears more clinical and less conversational compared to a human doctor explaining the situation or results in layman's terms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided, capturing key events such as the severe headache, loss of consciousness, intubation, cardiac arrest, resuscitation, and medical results, including the COVID-19 positive test. However, it fails to mention nausea and vomiting and gives an incorrect age.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response sufficiently answers the question by providing a detailed account of the events and medical findings, including the conditions the patient was treated for. However, it misses the additional symptoms of nausea and vomiting mentioned in the true answer, and incorrectly states the patient's age.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent and human-like. The narrative is clear and well-structured, making it easy to understand, although it is formatted more like a case report than a conversational response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response is coherent with the context. It correctly identifies the patient's symptoms, diagnosis, and treatment plan as mentioned in the conversation. However, it lacks specific details about the patient's background and the presence of delusions, which are included in the true answer.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - The model's response is mostly complete but misses some important elements such as the patient's age, background, specific hallucinations, and the IQ level mentioned in the true answer. These details are crucial to fully encapsulate the patient's condition and history.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  - The model's response is fluently structured and reads like a clinical note written by a professional, which fits the context. However, a slight drop in score accounts for the lack of nuanced personal details that might be found in a more comprehensive note.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response is somewhat coherent with the input, as it captures the general flow of the doctor-patient conversation, focusing on symptoms, family history, test results, and treatment plan. However, it converts the dialogue into a clinical note format, which doesn't directly align with the conversational nature of the input. The note mentions patient details like age and gender, which are not present in the input, reducing coherence.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The model's response attempts to encapsulate the overall situation presented in the input but lacks specific details such as the exact symptoms, the nature of the diagnosis, and the next steps. While it does mention the treatment plan and hospitalization, it does not provide a detailed account of the conversation's progression or the doctor's explanation of the situation.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "The model's response is written in a structured, clinical note format, which affects its naturalness. While it is fluently composed and clear, it does not reflect the conversational, empathetic tone of the original input dialogue. It reads more like a summary or an after-the-fact documentation, rather than a human-like, real-time interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  The model's response is entirely consistent with the flow and details presented in the input dialogue. It logically aligns with the context and presents a realistic conversation between the doctor and the patient.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  The model's response captures most of the essential details from the true answer, including the symptoms, the treatment, and the follow-up outcomes. However, it lacks some specific details such as the patient's age and the mention of parietal-occipital diffusion, which, while not crucial to the immediate dialogue, are present in the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  The model's response reads fluently and mimics a natural human conversation. The interactions between the doctor and the patient are realistic and use language that one would expect in a medical exchange.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided evaluation metrics, here is the assessment of the model's response:\n",
      "\n",
      "- **Coherence: 4.5**\n",
      "  - The model's response aligns well with the context of the conversation, summarizing the patient’s medical history and current situation effectively. However, it does not mention the patient's age or ethnicity, which was later provided in the true answer. This slightly diminishes coherence with respect to full context.\n",
      "\n",
      "- **Completeness: 4.5**\n",
      "  - The response covers most of the key points discussed in the conversation, such as symptoms, blood test results, and treatment plan. It succinctly summarizes the patient's condition and the doctor's advice. However, it lacks details about the initial presentation and specific test result days mentioned in the true answer.\n",
      "\n",
      "- **Naturalness: 4.0**\n",
      "  - The response is clear and uses formal, medical terminology suitable for a clinical context. It sounds structured and professional, akin to a medical report summary. However, the language is more analytical than conversational, slightly affecting the naturalness from a human-like conversational standpoint. \n",
      "\n",
      "Overall, the model provides a detailed and accurate summary, with minor gaps in background and conversational flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response aligns well with the context provided in the input. However, it incorrectly states the patient's age as 39 instead of 37, which slightly affects the coherence regarding the patient's profile. Other information aligns well with the input dialogue.\n",
      "\n",
      "- **Completeness: 4.8**  \n",
      "  The model's response is nearly complete, covering all the essential points mentioned in the input conversation. The only minor discrepancy is the omission of the \"gravid 1, para 0 (G1P0)\" detail from the true answer, which is a specific medical detail that might be considered relevant.\n",
      "\n",
      "- **Naturalness: 5.0**  \n",
      "  The model's response is fluent and sounds human-like. It uses natural language and maintains clarity and structure consistent with how such a medical summary might be verbally or written down by a healthcare professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.2\n",
      "\n",
      "**Coherence**: The model's response is quite coherent with the input. It accurately summarizes the sequence of events and reflects the medical details of the patient interactions, including test results and discussions about the patient's treatment. However, it misses some specific details such as the dimensions of the aneurysmal dilatation in the RCA and the ulcerated non-calcified plaque in the LAD.\n",
      "\n",
      "**Completeness**: The model covers many of the key points from the input but lacks some important details such as the specific details of chest pain, the patient's condition after the myocardial infarction, and the detailed specifics of the lesions. It also does not address the final prognosis discussion with the patient's family.\n",
      "\n",
      "**Naturalness**: The model responds in a fluent and structured manner, maintaining a professional clinical tone that is consistent with the context. However, it reads more like a clinical summary rather than a dialogue, which slightly detracts from its naturalness as per the conversational nature of the input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is generally coherent with the context provided. It accurately captures the sequence of events, treatments, and outcomes as described in the conversation.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response sufficiently answers the question by summarizing the key events such as the initial symptoms, surgeries, complications, and final outcome. However, it lacks details such as the patient's age, the specific areas of the brain affected (fronto-temporo-parietal), and the midline shift, which were present in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response sounds fluent and human-like, maintaining a natural tone and providing a clear and concise summary of the medical case. The language used is appropriate for the context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It includes almost all relevant details regarding the patient's symptoms, medical history, and diagnostic steps taken. However, it misses certain context specifics such as the patient's age and nationality.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response sufficiently answers the main points but misses some detailed information, including the age and nationality of the patient, and specifics about the leukocytosis. It captures the overall situation well but could be more thorough.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, effectively summarizing a complex medical situation in clear and concise language. The structure and terminology are appropriate for a medical context, and the information flows logically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response captures the general sequence of events and key elements from the doctor-patient conversation, but it lacks specificity and detail about the diagnosis and findings that were clearly outlined in the conversation.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The model does mention the major themes but does not address all the specific details described in the conversation, such as the specific medical evaluations, levels of different hormones, and the thorough discussion of the post-operative condition.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The model's response is well-structured, clear, and sounds fluent. It reads like a summary, which is appropriate for a clinical note, but it lacks the detail expected from a human doctor summarizing such detailed medical information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.0\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence (4.5)**: The model's response is generally coherent with the context of the input. It accurately summarizes the dialogue between the doctor and the patient, including details about symptoms, tests, and results. However, there is a discrepancy in the patient's age, which affects the coherence slightly.\n",
      "\n",
      "- **Completeness (3.5)**: While the model's response covers most of the critical information from the conversation, it omits some details that appear in the true answer, such as the patient's age being 24 instead of 41, and some specific details about the diagnostic workup (e.g., anti-nuclear antibodies and anti-phospholipid antibodies) and exclusion of abnormalities via angiographic findings. Therefore, it doesn't fully match the completeness of the true answer.\n",
      "\n",
      "- **Naturalness (4.0)**: The response is fluent and reads like a well-structured summary. It sounds human-like and usefully conveys the information in a natural manner. However, it slightly lacks the engagement or conversational cues that might enhance naturalness further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0 \n",
      "  - The model's response logically aligns with the input. It follows the sequence of events and interactions that occurred in the dialogue between the doctor and the patient. The flow is maintained accurately with respect to the input context.\n",
      "  \n",
      "- Completeness: 4.5 \n",
      "  - While the model's response covers most of the conversation, it doesn't address that the lesion healed within 2 weeks, as stated in the true answer. Instead, it only mentions that after 4 months of follow-up, no contracture developed. Thus, it misses out on a few details about the healing timeline that are present in the true answer.\n",
      "\n",
      "- Naturalness: 5.0 \n",
      "  - The model's response is fluent and human-like. The dialogue between the doctor and the patient is natural and conversational, closely mirroring how a real-life medical consultation might proceed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response logically follows the input context but somewhat incorrectly presents the content. It suggests the patient is recounting their story posthumously, which does not align with normal conversational logic.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response covers most aspects of the situation described in the input, capturing key details about the patient's history, diagnosis, progression, and outcome. However, the order of presentation can be confusing as it combines patient and third-person perspectives.\n",
      "\n",
      "- Naturalness: 2.0\n",
      "  - The response does not exhibit natural language use due to the incongruity of the patient discussing their own death in first-person. Human-like fluency is compromised by this fundamental inconsistency in narration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is mostly coherent with the context provided in the input. It accurately captures the patient's medical history, diagnosis, preoperative details, intraoperative procedure, postoperative complications, and the conclusion about the sudden bilateral visual loss. However, there are minor discrepancies in the age of the patient and the lack of mention of BMI found in the true answer.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The model's response is fairly complete but not exhaustive. It addresses the main points discussed in the input, such as the patient's medical history, surgical details, and postoperative complications. However, it omits specific details like the patient's age (as mentioned in the true answer) and BMI, which are important in a clinical note but were not present in the initial input.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The model's response is well-structured, fluent, and human-like. The organization of the response is clear, and the language is appropriate for a clinical setting. It effectively summarizes the conversation in a way that is typical of clinical notes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.8\n",
      "  - The model's response logically aligns with the input, accurately summarizing the patient's medical situation and history as provided in the conversation. A slight deduction is given for the lack of specificity regarding patient age, which is present in the true answer but not in the model's response.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response covers most of the relevant medical details and observations shared in the provided context. However, it omits the information about the blood pressure measurement from four limbs and the improvement with hydration noted in the true answer. Therefore, the score is slightly reduced for leaving out these details.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "  - The model's response is fluent and uses appropriate medical terminology, making it sound human-like and professional. However, the text is a bit more structured like a report than a conversation, which slightly impacts the naturalness rating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0 \n",
      "  - The model's response logically aligns with the context of the doctor-patient conversation. It accurately captures the key details mentioned during the interaction.\n",
      "  \n",
      "- Completeness: 4.5\n",
      "  - The model provides a comprehensive overview of the patient's medical history and current condition, including essential details such as age at marriage, menstrual cycle history, ultrasound results, immunologic profile abnormalities, and pregnancy status. However, it lacks specific numerical values and minor details presented in the true answer.\n",
      "  \n",
      "- Naturalness: 4.0\n",
      "  - The language used in the model's response is fluent and professional, appropriate for a clinical note. However, it slightly lacks the warm, conversational tone found in natural human communication, as it reads somewhat like a structured summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context and information provided in the input. It accurately summarises the patient's medical history and the results of various tests and examinations. \n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response captures most of the significant information from the dialogue provided in the input. However, it omits specific mentions about the patient's age and the fact that the patient was a referral from a clinic, which appear in the true answer. \n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The model's response is fluent and human-like, suitable for a clinical note. There are no grammatical errors or awkward phrasing, though it slightly feels like a recitation of facts rather than a conversational recount.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "- Completeness: 2.5\n",
      "- Naturalness: 3.5\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence (3.0)**: The model's response provides a structured summary of the conversation by outlining the types of information discussed (such as chief complaint, presenting symptoms, etc.). However, it lacks alignment with specific details from the conversation, making it less coherent regarding actual content.\n",
      "  \n",
      "- **Completeness (2.5)**: The model's response gives a general description of what categories of information were covered but does not include the specifics needed to fully answer the question of summarizing the detailed conversation. Important patient details and medical terms are mentioned as included, but not actually presented.\n",
      "\n",
      "- **Naturalness (3.5)**: The language used is fluent and professional, consistent with a clinical note, but it lacks human-like detail and personalization specific to this patient interaction, which would enhance its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is mostly coherent with the input context. It correctly identifies the major symptoms and lab results that point to a severe infection. However, there's a minor inaccuracy regarding the mention of \"elevated potassium levels,\" which is not supported by the input data.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The response sufficiently answers the question about the doctor's diagnosis and decision regarding the patient's treatment. It includes key symptoms, medical history, and laboratory findings that contribute to the diagnosis. However, it slightly lacks details such as specific laboratory values and thorough medical history details that could enhance completeness.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and generally sounds human-like. It uses appropriate medical terminology and has a natural flow, conveying the diagnosis and recommended action smoothly. However, there is a small room for improvement in varying sentence structure and style to sound more conversational.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response logically summarizes the doctor-patient conversation to a large extent. However, it misses some details like the patient's age and the cerebrospinal fluid cultures, which are mentioned in the true answer.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - While the model captures the main points of diagnosis, treatment, and patient history, it omits specific details like the patient's age and the timing and frequency of follow-up MRIs, which are present in the true answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent and human-like, with clear and structured language that resembles how a clinician might write a clinical note. However, it lacks some specific medical jargon or details that might be included in a real clinical summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "  - The model's response aligns with some elements of the context, such as symptoms and actions to be taken by the doctor (tests and hospitalization). However, it introduces an acute kidney injury diagnosis that is not explicitly mentioned in the provided context, making it somewhat disconnected from the dialogue.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - The model's response partially describes the situation, including the patient's symptoms and the medical actions being taken. However, it lacks the depth and specific context provided in the true answer and fails to capture all the crucial medical history details.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The model's response is largely fluent and human-like, with coherent phrasing and a structured summary of the patient's situation and medical plan. However, the mention of an unfounded diagnosis slightly detracts from its naturalness and realism within the context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 5.0\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The model's response is entirely coherent, as it aligns perfectly with the context provided in the input conversation between the doctor and the patient. It also provides a detailed and complete response to the information exchange between the doctor and the patient, thoroughly capturing each detail mentioned, thus fully aligning with the true answer provided. Finally, the model's response maintains a fluent and human-like conversation flow, suggesting high naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "   - The model's response includes accurate elements from the conversation such as the patient's baseline creatinine and symptoms. However, it inaccurately describes the patient's demographic details, mentioning a 68-year-old male, while the true answer describes a 60-year-old Hispanic female. This discrepancy affects the logical alignment with the input context.\n",
      "\n",
      "- Completeness: 3.5\n",
      "   - The model sufficiently describes the patient's condition, symptoms experienced, and the medical interventions provided, which aligns with the conversation. However, it lacks details present in the true answer such as the patient's HIV status, specific HAART medications, and certain medical recommendations from specialties, lowering its completeness score.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "   - The model's response reads fluently and is structured in a coherent manner that resembles human-like communication. There are no grammatical or language issues, making it sound natural, but small contextual errors impact its perception slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0  \n",
      "  The model's response does not accurately reflect the content or details of the conversation. Instead, it provides a generic description that doesn't align with the specific details of the dialogue provided.\n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The response fails to address any specific aspects of the patient's medical history, symptoms, test results, or treatment plan mentioned in the input. It lacks the necessary detail to answer questions about the patient's condition.\n",
      "\n",
      "- Naturalness: 2.0  \n",
      "  While the response uses fluent and grammatically correct language, it reads more like a description of what a clinical note might contain, rather than a summary in a natural or engaging conversational tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the provided context. It accurately lists the patient's condition, medical history, vital signs, and treatment. The only minor discrepancy is the patient's age, which was mentioned as 62 in the model's response instead of 27.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model's response substantially covers all critical aspects of the situation described in the input. However, it misses the detail about the patient's age and the context about his behavior when angry, which is provided by his family.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent, structured clearly, and uses professional language typical of a medical summary. It reads naturally as a coherent medical report.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided. It accurately reflects the sequence of events and the patient's prior medical conditions as discussed in the given conversation, although it simplifies some details.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The response covers the essential points of the doctor's findings and the patient's subsequent prognosis. However, it omits certain specifics about the patient's long-term medical history and the implications of those conditions, which are mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The language used by the model is fluent and human-like, closely resembling a concise summary one might expect from a medical professional summarizing a case. It articulates the situation clearly and empathetically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is fairly coherent as it follows the sequence of events discussed in the input. It captures the key medical history and examination findings from the conversation. However, it lacks some details present in the true answer, such as the patient's demographic details (age, ethnicity, and parous status) and comprehensive description of the mass and history of referrals.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response includes many key points from the conversation, it omits certain information that is present in the true answer, such as the detailed description of the abnormal mammogram findings, the full details of the biopsy procedure, and other aspects like the patient's past mammogram timing or the context of physical examination findings.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fairly fluent and human-like, accurately reflecting how a patient might summarize their medical discussion with a doctor in a coherent way. However, it may slightly lack naturalness compared to a human who might include more personal reflections or ask clarifying questions. Nonetheless, the language used is clear and appropriate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "\n",
      "The model's response contains several logical misalignments with the context. It incorrectly identifies the patient as a 54-year-old female, while the input and true answer describe a 61-year-old male. Additionally, the model's response lacks chronological and factual accuracy regarding the series of medical events and treatments, which affects the logical sequence.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "While the model's response covers some of the key points, such as headache episodes, eyelid ptosis, a history of partial thyroidectomy, and certain treatments, it lacks significant details found in the true answer, including specific test results, the timeline of symptom development, and changes in medication. These omissions result in an incomplete overall clinical summary.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "The model's response generally maintains fluency and readability. However, certain disjointed phrasing and lack of clarity in presenting the patient's medical history and treatments slightly detract from its human-like quality. There's also a lack of nuanced expression expected in conveying such detailed medical information. Overall, it sounds fairly natural but not exceptionally polished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response generally aligns with the provided context, capturing the key events and medical conditions discussed between the doctor and the patient. However, there are some discrepancies, such as the incorrect age of the patient and the inaccurate COVID-19 test result.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model's response includes many of the important aspects but misses some critical details, such as the positive COVID-19 result, the patient being admitted to an isolation ward, and the infection control measures taken during the patient's care. These omissions make the response less comprehensive.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The language used in the model's response sounds fluent and human-like, with clear and coherent narration. However, occasional inconsistencies in the patient's details slightly affect the readability and natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "The model's response is coherent with the information provided in the dialogue. It accurately reflects the patient's condition, symptoms, and the medical interventions described. The only minor coherence issue is the age discrepancy, as the model states \"73-year-old\" instead of the correct age \"70-year-old.\"\n",
      "\n",
      "- Completeness: 4.8  \n",
      "The response is quite complete, capturing nearly all the essential details from the scenario, including the patient's symptoms, history, test results, treatments, and medical plan. The only omission is the respiratory rate (RR) in the vital signs section, which is a minor detail.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "The response is clear and logically structured, sounding professional and human-like. It resembles a concise medical summary, which fits the context, although it is slightly more formal and detailed than an average conversational tone. A touch more conversational phrasing could enhance naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is mostly coherent with the context provided. It accurately captures the patient's medical history as discussed in the dialogue. However, it identifies the patient as a 60-year-old male, which is incorrect based on the true answer indicating the patient is 67. \n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model's response covers many key aspects of the patient's medical history, including the COVID-19 diagnosis and treatment history. However, it lacks certain details present in the true answer, such as the specific timing of hospitalization, additional medical procedures, and some medications like metyrapone.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluently constructed and resembles a concise medical summary, which aligns with professional medical documentation standards. It maintains a consistent tone and structure, making it sound natural for a clinical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It accurately lists the patient's complications and medical history, maintaining the sequence of events that were described in the input.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response sufficiently answers the question by summarizing the condition, the test results, and the eventual outcome. However, it omits certain minor details such as specific medications and certain procedural post-discharge activities, like the follow-up appointments.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response is largely fluent and human-like, maintaining a formal and informative tone consistent with medical reporting. However, it could be viewed as a bit too clinical and detached when compared to a more conversational tone that might be used in a doctor-patient dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response is highly coherent with the context provided, as it accurately presents the details of the patient's case in a structured and logical manner.\n",
      "  \n",
      "- Completeness: 4.5\n",
      "  - The model's response is mostly complete but omits the patient's age, the specific volume of star fruit juice ingested, and the mention of reduced urine output. Otherwise, it covers all major points from the input.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent and human-like, maintaining a professional tone suitable for a medical context. However, slight improvements could be made for a more conversational tone, though this may not be necessary given the medical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns with the context provided, summarizing the patient's medical history consistently and accurately.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The response covers most of the essential details from the input text, including the diagnoses, treatments, and medical conditions. However, it omits some specific details such as the genetic mutations identified and some additional medical conditions like hypertension and asthma.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and human-like, using appropriate medical terminology and a clear, logical flow of information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response maintains some coherence with the context, as it correctly identifies the patient's ongoing treatments for diabetes and schizophrenia, and their smoking and drinking habits. However, it lacks alignment with the detailed medical and historical information provided in the input, such as the specifics of the emergency situation and laboratory findings.\n",
      "  \n",
      "- Completeness: 2.5\n",
      "  - The response is incomplete in terms of addressing the depth and details of the patient's case. While it touches on the patient's medication and suicide attempt, it fails to provide significant details such as the dosages of medication, the extent of the emergency intervention, or specific laboratory findings that were mentioned in the input.\n",
      "  \n",
      "- Naturalness: 4.0\n",
      "  - The model's response is generally fluent and human-like, capturing the natural flow of a medical consultation. However, the lack of detail and depth detracts slightly from its naturalness in the context of a thorough medical discussion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  - The model's response logically aligns with the context provided in the input. It accurately summarizes the patient's medical history, the findings from the pacemaker interrogation, echocardiography results, the recommendation of the treatment plan, and procedural details discussed between the doctor and patient.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  - The model's response sufficiently answers the question by covering the key aspects of the conversation; however, it lacks some minor details, such as the specific make and model of the pacemaker, the exact history of procedures like the benign tumor excision, atrial flutter ablation, and the exact details of symptom description like exertional dyspnoea.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  - The language used in the model’s response is fluent and human-like. It reads smoothly and conveys the information clearly, much like a well-written medical summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The response logically aligns well with the context provided in the input. The sequence of information regarding the patient's symptoms, examinations, findings, and diagnosis is consistent with the dialogue. The minor age discrepancy (72 vs. 73 years old) slightly affects coherence but is not a major issue.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The response provides an adequate summary of the patient's condition, including key details about the diagnosis, tests performed, and the necessary next steps (discussion of treatment options and monitoring). However, it omits some specifics such as drinking habits, pharyngolaryngoscopy findings, detailed CT findings, and SUVmax values mentioned in the true answer, which could potentially be important for a full understanding.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "  - The language used in the response is fluent and reads naturally, making it sound human-like. It appropriately mirrors the tone and structure expected in a medical summary. Any slight deviations do not significantly impact its natural presentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context provided in the input. It accurately reproduces the dialogue between the doctor and the patient, maintaining consistency throughout.\n",
      "\n",
      "- Completeness: 5.0\n",
      "  - The model's response sufficiently answers the question in the input by capturing all critical details from the doctor's conversation with the patient, covering their medical history, symptoms, diagnostic tests, surgery, and postoperative considerations.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response sounds fluent and human-like. The dialogue maintains natural conversation flow and clarity, resembling how a patient-doctor interaction would typically occur.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The model's response is generally coherent as it aligns logically with the given context and maintains a narrative structure that reflects the progression of medical evaluation and treatment. However, while it covers the key points, it omits some specific details such as the exact breakdown of lab results or the MRI findings. This slightly lowers the completeness as it doesn't fully capture all aspects of the true answer. In terms of naturalness, the response sounds fluent and human-like, appropriately summarizing the medical situation in a clinical tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response mostly aligns with the context and captures the key elements of the doctor-patient interaction, such as the syncopal episode, symptom inquiry, medical history, and findings from the examination and tests. However, there is a minor deviation where the model mentions \"normal blood pressure\" reported by the patient, which contradicts the context provided by the doctor and patient dialogue.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model's response covers many of the relevant points from the input, including detailed inquiries made by the doctor and some responses from the patient. However, it misses key elements like specific treatments given, the improvement of blood pressure and oxygenation with treatment, the detailed differential diagnosis, and the context of the pandemic in New York City, which were mentioned in the input.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response is generally fluent and coherent, using appropriate medical terminology and structuring the information in a logical order. While the text reads smoothly, the lack of some natural conversational transitions between major topics slightly affects its human-like quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "\n",
      "The model's response is generally coherent with the input context provided by the doctor-patient dialogue. However, it contains some inaccuracies in coherence, such as identifying the patient as a 68-year-old man, whereas the true answer indicates an 85-year-old woman. This detail impacts the coherence, as it conflicts with fundamental patient demographics that should have been consistent with the context.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response does a good job of outlining the major details and steps of the medical case presented, including the symptoms, medical history, diagnostic tests, pathology results, and treatment. However, it omits some details, such as the specific age-related detail, which could contribute to a comprehensive understanding of the case.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is articulated in a clear, concise, and human-like manner, mirroring the style of a medical case summary. The language used is fluent, professional, and mirrors how a clinician might summarize and document a case, aligning well with expectations for naturalness in a medical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically follows the context of the input, though it misses specific quantitative details such as the exact insulin doses used, which diminish the full coherence with the true answer.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model's response covers most of the conversation from the input but misses critical details like the exact insulin dosages and specifics about the psoriasis cream application, impacting the completeness of the answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The dialogue in the model's response sounds fluent and human-like, maintaining a natural conversational flow throughout the exchange.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the context provided in the input. It captures the sequence of the medical conversation and provides a coherent summary of the events discussed by the doctor and the patient. However, it could improve by offering more specific details from the input.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The response sufficiently answers the general flow of the conversation but misses specific details such as the patient's age, some precise medical conditions, and specific procedural steps mentioned in the input. This lack of depth results in a summary that feels slightly incomplete.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The language is fluent and mostly human-like, with clear and concise delivery. The tone is formal and matches the medical context, though it might benefit from a more conversational tone to better mimic the natural doctor-patient interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is mostly coherent with the context provided, but it misrepresents the patient as a 48-year-old man, while the true context describes a 60-year-old lady who is hypertensive. Despite this discrepancy in demographic details, the medical aspects of the response are aligned with the context.\n",
      "\n",
      "- Completeness: 4.5\n",
      "\n",
      "The model’s response captures almost all of the key medical information shared in the context, such as the symptoms, the CT scan findings, the initial and forthcoming medical interventions, and potential postoperative complications. However, it misses the specific details about the size and specifics of the aneurysm and the patient's history of being hypertensive under irregular medication.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The response is fluent and resembles a human-like explanation of the medical situation. It uses appropriate medical terminology and language that a healthcare professional might use while communicating this scenario, making it sound natural and professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "  - The model's response does not fully align with the context provided in the input. It incorrectly mentions \"non-convulsive status epilepticus,\" which was not part of the discussion. Moreover, it fails to accurately summarize the key points discussed, which impacts its coherence with the input.\n",
      "  \n",
      "- Completeness: 2.5\n",
      "  - The model's response mentions some aspects of the patient's medical history and symptoms, such as rhabdomyolysis, respiratory failure, and non-ST-elevation myocardial infarction. However, it omits critical elements like NMS, details of the treatment plan, and the patient's multi-organ insult, rendering it incomplete.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "  - The response is generally fluent and readable. It largely maintains a human-like tone, although it lacks specific details that would make the summary feel comprehensive or personalized, which affects its perceived naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response is highly coherent as it aligns perfectly with the context provided. The conversation follows a logical flow similar to the input context, preserving the sequence of questions and responses.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model provided a response that sufficiently covers the key details from the input context regarding the patient's symptoms and medical background. However, it slightly lacks explicit mention of some minor details from the true answer, such as the patient's previous job and spirometry test, although these aren't crucial for the flow of the conversation in the given context.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response is fluent and sounds very human-like. The conversation maintains a natural flow, mimicking the back-and-forth exchange typical of a doctor-patient interaction. Words and phrases are used appropriately, contributing to the naturalness of the dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the provided context but contains a critical error regarding the patient's age.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model's response sufficiently answers the question by summarizing the patient's medical condition and history, though it omits specific details like vital signs upon arrival.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, maintaining a professional medical tone consistent with the dialogue context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The model's response is a verbatim repetition of the conversation from the input, which makes it perfectly coherent with the context. There is no deviation in the logical flow of conversation between the doctor and the patient. However, the model misses some elements found in the \"True Answer,\" such as specific numeric details and some medical tests like the CT angiogram, affecting the completeness of the answer. Despite this, the repetition leads to a highly natural response as it retains the same human-like conversational flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is coherent as it aligns well with the context of the conversation, capturing the main points such as the diagnosis of contrast-induced kidney injury and atheroembolic disease, the dialysis treatment, and the unfortunate outcome of the patient's passing. However, the response misses some details like specific results from diagnostic tests and symptoms not directly discussed in the dialogue.\n",
      "  \n",
      "- Completeness: 3.5\n",
      "  - While the model's response captures the core elements of the patient’s medical condition and the treatment journey, it lacks depth in certain areas compared to the true answer. Important clinical information such as exact test results, specific symptoms like orthopnea, and underlying conditions like hemoglobin and serum creatinine levels are not included, making the summary less comprehensive.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The model's response is very fluent and reads like a natural, human-generated summary. It provides a structured narrative that would be understandable to both medical professionals and laypersons, though it does resemble more of a summary rather than a conversational tone. \n",
      "\n",
      "Overall, the response effectively conveys the gist of the situation but lacks some detailed clinical insights present in the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 점수:\n",
      "Coherence       4.123000\n",
      "Completeness    3.846000\n",
      "Naturalness     4.500000\n",
      "BLEURT          0.524231\n",
      "BERTScore_F1    0.485108\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# summarization\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT 모델 로드\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 평가 함수\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 점수 추출\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT 점수 계산\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT 및 BERTScore 계산\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# 점수 정규화 함수\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "summarization = df[df['task'] == 'summarization']\n",
    "results = []\n",
    "\n",
    "for _, row in summarization.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # 기본값 설정\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' 컬럼이 존재하는지 확인 후 정규화 수행\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"평균 점수:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided. It acknowledges the user's need to manage diabetes and gives general advice on medication and lifestyle changes. However, it does not directly address the specific blood sugar levels mentioned or suggest any modification in medication, which is why it's not perfectly coherent.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - While the response does provide general advice, it lacks specific dietary recommendations, precise modifications in medication, and follow-up instructions, which are present in the true answer. This makes it incomplete in terms of providing a comprehensive management plan for the patient's blood sugar concerns.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response is fluent and human-like. It is polite and reads smoothly, giving clear and friendly advice, reflecting a natural conversational tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response aligns well with the provided context, acknowledging the user's concern about pancreatic cancer and mentioning factors that could influence insulin levels, such as diet and stress. However, it slightly misses addressing the user's query about the insulin drop directly and could include a bit more specific information to close the loop.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The response provides a general reassurance regarding pancreatic cancer and suggests consulting a healthcare professional, which is helpful. However, it does not delve into potential explanations for the drop in insulin levels or why an MRI might not be necessary, missing details that were included in the true answer.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The language is fluent and human-like, maintaining a polite and empathetic tone throughout the response. The slight deduction is due to the repeated suggestion about consulting a healthcare professional without adding any unique insights that could improve the conversational flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided in the input. It accurately interprets the medical conditions mentioned and provides relevant explanations based on the reports implied in the question.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The response provides a thorough explanation of the potential treatments and conditions, addressing the main concerns about the mother’s eye problems. However, it doesn't directly express a clear recommendation between the treatment options since it's leaning towards recommending another consultation.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The response is fluent and human-like, maintaining a professional tone that is typical of medical advice. The detailed explanations and use of medical terminology are appropriate for this context, adding to the naturalness of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context provided. It correctly identifies that erectile dysfunction can be caused by various factors and acknowledges the use of Confido tablets, which were mentioned in the input. However, it does not directly address the query about the ineffectiveness of Confido.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response advises consulting a specialist and suggests general lifestyle changes, which are relevant. However, it lacks specific alternative treatments or medications suggested in the true answer, such as Tentex Forte, Tadalafil, or Sildenafil. This omission makes the response somewhat incomplete in providing actionable advice.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds human-like, maintaining a professional and empathetic tone. It uses clear and appropriate language for the context, addressing the problem delicately.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response logically aligns with the context provided, as it explains the potential relationship between diabetes and gum disease. However, it doesn't state the need for visual examination before concluding on the relationship, which is a key component in the true answer. \n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - The response offers a plausible explanation for the white spots, discusses the importance of dental consultation, and emphasizes diabetes management. However, it does not mention the need for examining images before making a clinical judgment, which could be important for thoroughness. \n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  - The answer is fluent and human-like, with courteous language and comprehensive sentences, providing a professional yet approachable tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided in the input. It references the frozen shoulder diagnosis and suggests consulting an orthopedic specialist, which correlates with the user's previous consultation. It also addresses the user's concern about shoulder pain and mentions potential alternative causes that should be considered.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model provides a generally complete answer, talking about frozen shoulder and mentioning other possible conditions like rotator cuff injuries or arthritis. It offers temporary pain management techniques, such as ice application and over-the-counter medications, and suggests consulting with a specialist. However, it doesn't recommend specific medications like the true answer does, nor does it discuss the possibility of diabetes, which could be relevant.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The response sounds fluent and human-like. It provides a clear and empathetic approach to the user's concerns, offering reassurance and practical advice. The language used is professional but approachable, which is appropriate for this context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context provided in the input. It acknowledges the patient's diabetic condition, discusses current medication use, and emphasizes the importance of consulting with a doctor for possible medication adjustments. Such coherence in aligning with the context of managing diabetes is evident.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model addresses the components of diabetes management, including diet, exercise, and medication adjustment. However, it lacks specific recommendations such as the addition of a new medication, which the True Answer suggests. The model offers more general guidance rather than a precise treatment adjustment.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and human-like. It uses polite and supportive language to engage with the user. The model presents its advice in a manner consistent with what one might expect from a healthcare professional, showcasing readability and conversational tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the evaluation metrics provided, here are the ratings for the model's response:\n",
      "\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response logically aligns with the context provided. It adequately interprets the given test results, making logical connections between the high blood sugar level, fatty changes in the liver, and the presence of fibroids in the uterus. However, it slightly ventures into areas that might presume prior knowledge not distinctly mentioned in the input, such as suggesting diabetes management without a confirmed diagnosis of diabetes in the input.\n",
      "\n",
      "- **Completeness: 4.0**  \n",
      "  The response sufficiently answers the question by interpreting the results of the report. However, it does not explicitly identify the diagnosis of \"Type II Diabetes Mellitus\" or \"Fibroid Uterus,\" which are present in the true answer. It does address the symptoms accordingly and provides a general management plan, but a clearer diagnosis would enhance completeness.\n",
      "\n",
      "- **Naturalness: 5.0**  \n",
      "  The model's response is fluent and human-like. It uses natural language to express concern and provides advice in a professional and empathetic manner. The response is structured well and sounds like it could come from a caring healthcare provider.\n",
      "\n",
      "Overall, the model's response is coherent, almost complete, and very natural, though it slightly misses on direct diagnosis identification as provided in the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context provided, as it discusses possible causes for burning sensations and suggests consulting a healthcare professional, which is relevant to the symptoms described.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response sufficiently answers the question by addressing possible causes and offering general advice on next steps. However, it lacks specific suggestions for diagnostic investigations such as blood sugar estimation or an X-ray of the cervical spine that are mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response sounds fluent, polite, and human-like. It provides a friendly and supportive tone, characteristic of human interactions, particularly in a healthcare setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context provided. It evaluates the patient's blood glucose levels and uses that data in conjunction with the HbA1c result to conclude that the patient is diabetic. The guidance provided about medication and lifestyle adjustments is consistent with standard advice for diabetes management.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model sufficiently answers the question by addressing the need for medication and suggesting metformin, alongside other lifestyle recommendations. However, it could be considered slightly lacking as it doesn't emphasize the importance of follow-up consultations with a healthcare professional, which the true answer highlights by directing the patient to seek advice from a diabetologist.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response sounds fluent and human-like. The language is clear and direct, similar to how a healthcare professional might communicate. The model provides detailed explanations and actionable advice in a natural manner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response partially aligns with the provided context by acknowledging the user's concerns about potential effects of the Keto diet and the importance of seeing an ophthalmologist. However, it does not fully address the specific issue of double vision or the effect of head position and eye pulling on alleviating symptoms, which were significant details in the user's description.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model suggests some actions and potential causes but does not fully address the user's specific observation about improving vision by changing head position or manipulating the eyelid, which is crucial for understanding the issue. It also does not address why reading glasses help but do not solve the problem completely.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is quite fluent and sounds natural, maintaining a conversational tone typical of human communication. It acknowledges the user's issues and offers a friendly closing remark, inviting further questions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context and provides a plausible explanation of the symptoms (phimosis and irritation). It suggests appropriate actions, like consulting a doctor for a further diagnosis and suggesting possible treatments. \n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response sufficiently answers the patient's query by acknowledging the issue and advising on next steps, like consulting a doctor. It provides a possible condition that matches the symptoms described, though a direct link to an online consultation as in the true answer could make it more complete.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The model's response is fluent and human-like. It is written in a polite, professional manner that one would expect from a medical professional offering preliminary advice via text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The response aligns well with the context, addressing the user's history and concerns about PAD and potential preventive measures, though it slightly misrepresents the stance on statins.\n",
      "\n",
      "- Completeness: 3.8  \n",
      "  The response covers the need to consult a vascular surgeon and provides some preventive recommendations. However, it lacks details on medical treatments like Cilostazol and Pentoxifylline and emphasizes lifestyle changes over medical treatment, which might not fully address the user's question.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and human-like, maintaining a professional yet empathetic tone, suitable for a medical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns with the context provided in the input. It identifies the main issue of weight loss in a diabetic patient and addresses it directly by suggesting consultation with a healthcare provider.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The response thoroughly addresses the question by discussing potential concerns and solutions, such as consulting a healthcare provider and maintaining a healthy lifestyle. However, it could be slightly improved by providing more concrete lifestyle recommendations or specific warning signs to watch for that may require immediate attention.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The language in the response is fluent and human-like. It conveys empathy and professionalism, similar to an interaction one might have with a healthcare provider.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "    - The model's response is generally coherent with the input context, addressing the medical scenario described and acknowledging the absence of significant blockages in the CT-angio report. However, it lacks specific details mentioned in the true answer, like minor diseases and potential myocardial bridging, which affects coherence.\n",
      "\n",
      "- Completeness: 3.5\n",
      "    - The response provides a reasonable approach about chest pain evaluation and general measures for managing diabetes. However, it misses specifics about potential treatments for heart attack prevention, such as recommending Antiplatelet Statin combination or discussing the potential cause of exertional pain like myocardial bridging. This limits the completeness of the answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "    - The language used is fluent and sounds human-like, maintaining a conversational and reassuring tone. It uses appropriate medical terminology while staying understandable to a layperson, contributing well to the naturalness of the dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "  - The response lacks logical alignment with the patient's symptoms and concerns. While it mentions PCOS-related factors, it oddly repeats the same normal ultrasound results numerous times, which detracts from a coherent analysis of the patient's issues based on the input provided.\n",
      "\n",
      "- Completeness: 1.0\n",
      "  - The model's response does not adequately address the patient's numerous concerns and conditions such as hyperandrogenism symptoms or suggestions for treatment, leaving many important questions unanswered.\n",
      "\n",
      "- Naturalness: 2.5\n",
      "  - The language used in the response is mostly formal and correct in terms of grammar, suggesting a partially natural flow. However, the repetitive nature of the response significantly reduces its readability and makes it seem unnatural or machine-generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns with the context provided in the input. It explains what Accentrix is, its purpose, and addresses the specific concern related to diabetic macular edema (DME), which is consistent with the context.\n",
      "\n",
      "- Completeness: 5.0  \n",
      "  The response sufficiently answers the question by providing detailed information about Accentrix, including its purpose, the method of administration, potential side effects, and the importance of consulting an ophthalmologist.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response sounds fluent and human-like. It uses professional and approachable language, suitable for a medical inquiry, and maintains an informative and empathetic tone throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response aligns broadly with the context regarding the boil and potential complications, but it misses specific points about diabetes, which could be relevant as per the true answer. It focuses on general information about potential treatments without addressing all specific concerns mentioned in the input.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While it provides a general explanation and suggests consulting a healthcare professional, it does not fully address the query or provide a second opinion. The response lacks a direct answer to the specific concerns about the necessity of surgery and specific diagnosis as requested by the user. It does not offer any possible scenarios that might lead to surgery as per the input request.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent, clear, and human-like. It is well-structured and uses appropriate language that is comfortable for general understanding. However, its formal tone might feel slightly impersonal for someone seeking a second opinion and reassurance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "    - The model's response logically aligns with the input context, addressing the user's experience with anxiety and providing general advice for managing it. However, it does not fully acknowledge the user's concern that their condition might be more than just anxiety, which the True Answer addresses by discussing potential biochemical reasons for severe anxiety.\n",
      "\n",
      "- Completeness: 4.0\n",
      "    - Although the model's response does provide a variety of potential treatments for anxiety and underscores the importance of seeking professional help, it does not address the user's suspicion that their condition might be atypical anxiety or something different. The True Answer goes a step further by explaining causes and advising a neurological consultation, explaining what might be happening biochemically.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "    - The response is fluent and human-like, maintaining a conversational tone that is suitable for addressing an individual's health concerns. The only drawback could be the somewhat generic nature of the advice, which lacks personalization considering the user's prolonged struggle with anxiety.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is mostly coherent with the input context. It addresses the symptoms and suggests potential reasons for the observed black dots and dry eyes. However, it suggests potential conditions (retinal detachment or tear) that might not align directly with the existing medical history related to dry eyes and vitrectomy, taking a slightly more serious tangent than the initial context.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response covers several aspects of the question, including dry eyes and potential associations with serious conditions like retinal detachment. However, it does not mention some pertinent details from the true answer, such as possible conditions like exposure keratopathy due to incomplete eyelid closure or the role of obesity and floppy eyelid syndrome, which would provide a more thorough response.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is generally fluent and human-like, using a professional tone suitable for a doctor-patient interaction. It explains potential causes and provides suggestions in a natural manner, although it could improve slightly by offering a more empathetic or personalized tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response aligns well with the context provided. It addresses the question about mild LVH, explaining its potential causes and offering reassurance, which is consistent with the input context.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model's response sufficiently answers the question regarding the potential concerns of mild LVH. It does a good job explaining what LVH could mean and advises on monitoring and lifestyle adjustments. However, it doesn't discuss differential diagnoses or acknowledge the specific scenario described (like palpitations subsiding by the time of the ECG), which are part of the nuanced details of the true answer.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The response sounds fluent and human-like, successfully mimicking the tone one would expect from a healthcare professional providing reassurance and advice. The conversational tone is well-managed, enhancing the perceived naturalness of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the context. It acknowledges the user's concerns about weight gain associated with specific diabetes medications and discusses alternatives like Metformin and SGLT2 inhibitors, which are mentioned in the user's query. The response incorporates the risks associated with the suggested medications and provides advice on monitoring health conditions, which matches well with the user's situation.\n",
      "\n",
      "- Completeness: 4.5\n",
      "\n",
      "The model's response is quite comprehensive. It covers multiple facets of the user's concerns: weight gain, kidney issues, and the effectiveness of the medications mentioned. It advises on alternative treatments and suggests lifestyle changes. However, it could have been slightly improved by providing more specific actions or strategies considering the user's particular medical history, but overall it provides a thorough answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The response is fluent, well-structured, and exhibits a polite tone, akin to how a human might naturally respond. It uses clear language and maintains an empathetic and supportive tone throughout the guidance. It reads smoothly and feels conversational while being informative, which makes it sound human-like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided by the user. It accurately identifies the association between flat feet, plantar fasciitis, and heel pain, which are relevant to the user's symptoms.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response adequately addresses the user's query by suggesting practical management strategies, such as wearing supportive shoes, applying ice, taking pain relievers, and consulting a healthcare professional if symptoms persist. However, it lacks some of the detailed considerations found in the true answer, such as the importance of controlling weight and other comorbid conditions, or specific guidance on exercises and diagnostic measures.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent, clear, and human-like. It employs polite language and provides explanations that are easy for a user to understand. The organization of information and recommendations is also well-structured.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is generally coherent with the context provided. It logically addresses the symptoms and issues mentioned, particularly focusing on the liver lesion which is consistent with the input information.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model provides a comprehensive evaluation of the situation, suggesting further consultations with specialists like a gastroenterologist or hepatologist. However, it misses some specific guidance given in the True Answer, such as the recommendation for Paracetamol for pain management and the advice on repeating ultrasounds for monitoring the lesion size.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, demonstrating empathy and professionalism, which aligns well with how a real doctor might communicate. There are no awkward phrasings or grammatical errors, contributing to a natural-sounding reply.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent as it logically aligns with the context of the input, addressing the connection between untreated OSA and cerebral changes. It appropriately recommends further evaluation by a sleep specialist, which makes sense given the presented medical history.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model suggests evaluations and potential treatments such as CPAP and lifestyle changes, it misses mentioning other significant risk factors for cerebral changes outlined in the true answer, such as hypertension, dyslipidemia, and other cardiovascular risks. It also doesn't address the irreversibility of the brain changes, as highlighted in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent, polite, and sounds human-like. It employs a professional tone appropriate for a doctor-patient interaction, making it natural to read.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is mostly coherent with the input context. It addresses the user's concern about metformin and provides general advice on diabetes management. However, it doesn't clarify the recall situation regarding metformin, which could have been explained better given the user's direct question.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model offers some valuable guidance, such as consulting a healthcare provider for alternative options and lifestyle management, it fails to address the user's very high blood sugar levels and the need for urgent action, as mentioned in the true answer. Additionally, it doesn't provide specific alternative medications or recommend any immediate investigations, which leaves the user's need for an alternative unanswered.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like. It uses appropriate language for delivering healthcare advice and feels conversational yet informative. The tone is friendly and supportive, which enhances the naturalness of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response provides a logical and relevant answer to the question. It considers the recent cold symptoms as a potential factor and mentions other serious conditions like a migraine or brain tumor, which are relevant possibilities. However, it could have mentioned more common causes.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The model's response touches on a few possible causes of the burning sensation, such as lingering infection, migraines, or brain tumors. It misses out on more commonplace causes like vitamin deficiencies or side effects of medications, which were mentioned in the true answer. It does suggest seeing a healthcare professional, which adds some value.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent and sounds human-like. The language used is polite and conversational, with a helpful and considerate tone. However, some phrasing could be slightly more nuanced to make it sound even more natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5   \n",
      "  The model's response logically aligns with the context provided in the input. It recognizes the ongoing use of over-the-counter medications and suggests consulting a dermatologist for further diagnosis and treatment plans. It also addresses the issue of itching associated with the infection, which was mentioned in the input.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model advises consulting a dermatologist, which is sensible, it doesn't suggest specific alternative medications or treatments that could be considered, which is a part of the true answer. It mentions oral antifungal medications and other treatment options but does not specify any, which could be helpful for the user.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is fluent and human-like. The language used is professional yet approachable, mimicking the kind of response one might expect from a healthcare professional. The tone is empathetic and considerate of the user's concerns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is mostly coherent and logically aligns with the context provided. It addresses the patient's concerns about surgery risks in relation to his age and medical conditions. However, it misses addressing specific concerns about achalasia surgery, prednisone use, and sleep apnea, which were mentioned in the input.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model provides a detailed discussion on gastric bypass surgery risks and considerations, it does not completely answer the input's implicit query about the achalasia surgery. It also fails to mention consultation with an anesthesiologist or directly address any personalized risk factors like the ongoing use of prednisone or sleep apnea.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response sounds very fluent and human-like. It is well-structured and reads like a response from a knowledgeable medical professional, using appropriate language for a doctor's communication with a patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context of the given input. It addresses the issues of anxiety, bloating, and constipation and relates them to the patient's current medications and health conditions. However, it does not mention any potential issues with the low dosage of the medications as noted in the true answer.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response covers advice about anxiety, digestive issues, and lifestyle changes, providing practical suggestions such as discussing medication adjustments and trying alternative treatments. However, it misses specific details mentioned in the true answer, like adjusting the dosage of current medications and avoiding Mirtazapine due to its side effects. Additionally, there is no mention of discussing potential interactions with medications for coronary artery disease or diabetes.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response sounds fluent and human-like, maintaining a compassionate and professional tone throughout. The language used is clear and conversational, making it easy for a patient to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The response logically aligns with the context provided in the input. The model understands that the jerks could be seizures and explores possible causes, including infections, metabolic disorders, and Alzheimer's. It relates the sudden jerks to potential underlying medical issues and suggests consultation with a neurologist, which is a logical next step.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The model provides a comprehensive response covering possible causes, necessary evaluations, and recommendations for immediate actions like consulting a neurologist and keeping the patient well-hydrated. However, it does not directly answer whether the jerks will come back, which was a specific part of the question. It implies that further evaluation is necessary to determine this, but an explicit statement acknowledging the uncertainty would enhance completeness.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The response is fluent and human-like, displaying empathy (\"I understand your concern\") and providing thoughtful advice. The language is clear and easy to understand, with a polite and professional tone suitable for a medical query. The suggestion to avoid stress and triggers is delivered naturally, akin to advice a real doctor might give.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response aligns with the context by addressing both hemoglobin and diabetes issues. However, it generalizes the advice and does not reference specific details from the provided reports or previous records, indicating a moderate level of coherence with the context.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  While the model mentions iron supplements and a healthy lifestyle for diabetes management, it lacks specific recommendations for medications, which were part of the user's request. This makes the response incomplete in relation to the specific medical guidance sought.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is overall fluent and human-like, using a polite and friendly tone suitable for a medical professional. However, it leans towards being overly generic, which slightly affects its naturalness in the context of a medical consultation that expects personalized advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided in the input. It correctly identifies the elevated TSH level and normal T3 and T4 levels and relates them to potential hypothyroidism, which is relevant given the input context. However, it could have addressed the absence of symptoms more explicitly as the true answer did.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model sufficiently addresses the question by identifying a possible thyroid issue (hypothyroidism) and suggesting monitoring and potential treatment. However, it lacks the depth provided by the true answer about subclinical hypothyroidism, the absence of treatment in many cases, and the recommendation for further testing if symptoms arise.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response is fluent, friendly, and human-like. It maintains a professional tone suitable for a medical context, provides reassurance, and encourages further engagement, which enhances its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and logically aligns with the context provided. It understands the issue at hand and addresses the main concerns, such as the leg swelling, possible underlying conditions, and the suggestion for a vascular examination. The connection with conditions like deep vein thrombosis is logically made, given the symptoms described.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model provides a fairly complete response, recommending follow-ups and diagnostic procedures like the Doppler test as suggested in the input. However, it lacks a more specific recommendation to see a podiatric surgeon or focus more on the existing risks of limb care in elderly diabetic patients. Additionally, it doesn't cover the potential need to re-evaluate continuing antibiotics or the involvement of other specialists as suggested in the true answer.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The model’s response sounds fluent and human-like, using a professional and empathetic tone typical of healthcare advice. It projects understanding and provides actionable steps in a reassuring manner, which is suitable for the context of addressing health concerns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "  The model's response is generally coherent and logically aligned with the context provided. It correctly links the symptoms of thickened and darker skin on the toe to the possible conditions of diabetic dermopathy and neuropathy, which are relevant to the patient's diabetes. However, it does not consider the specificity of the condition being localized to one toe, which the true answer mentions.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "  The model's response provides a plausible diagnosis and advice for consulting a doctor, which is important. However, it does not mention other potential conditions like frictional hyperkeratosis or acanthosis nigricans that the true answer considers, nor does it offer specific treatment advice beyond moisturizing, which the true answer provides in detail.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "  The model's response is quite natural, sounding fluent and human-like. It uses clear and polite language typical of a medical professional addressing a patient. The suggestion to consult a doctor and apply moisturizer are conveyed in a straightforward manner. However, the inclusion of neuropathy without clear connection to localized skin thickening slightly reduces its naturalness in context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context provided in the input. It addresses the user's concerns about nightfall and weakness during sex, noting that nightfall is normal but suggesting that more frequent occurrences or accompanying symptoms might indicate an issue. The advice provided aligns with general health advice.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides general information and advice on lifestyle changes and suggests consulting a healthcare provider, which is appropriate. However, it lacks specificity compared to the true answer, which mentions checking for diabetes mellitus and other potential causes like endocrine issues. This makes the response less thorough in exploring potential underlying medical reasons.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and sounds human-like. It uses friendly and professional language typical of a healthcare provider, although there is a slight repetition with phrases like \"thank you for reaching out\" and \"please do not hesitate to ask,\" which could be streamlined for improved naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "  The model's response logically aligns with the context provided in the input. It accurately identifies the symptoms affecting the right leg and hand and relates them to the MRI findings of a vascular issue. The response correctly emphasizes the need for medical attention and acknowledges the complexity of restoring function without a specific diagnosis.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "  The model provides a general answer about the need for medical evaluation and the factors influencing recovery. However, it does not explicitly address the potential outcomes or prognosis in as much detail as the true answer, such as the need for a detailed scan report review. It does mention that the recovery depends on the specific diagnosis and treatment plan, which partially answers the question about restoring function.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "  The language of the response is fluent and reads like it was written by a human. It maintains a professional and empathetic tone appropriate for a medical context, offering practical advice and a gentle reminder to consult healthcare professionals.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is largely coherent with the context provided. It addresses the severity of the symptoms mentioned and the conditions like diabetes and high blood pressure. However, it doesn't address the specific medication \"Angised\" or the hospital treatment in detail, which could slightly impact coherence.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response suggests consulting a cardiologist and mentions lifestyle changes, it doesn't address some critical aspects. Specifically, it fails to distinguish angina as a potential cause, lacks direct advice about specific home remedies or immediate medication changes, and doesn't inquire about specific medical history or treatments in depth, unlike the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds natural, adopting a friendly and professional tone. It smoothly provides general advice, making it appear human-like in interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The response logically aligns with the context of the question, directly addressing the blood sugar levels and the associated concern about whether they are within normal limits.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The response sufficiently answers the question by stating the blood sugar levels are within normal ranges and advises monitoring. It also recommends consulting a pediatrician for further testing or treatment, which is a comprehensive approach. However, it could improve slightly by providing more detail about the specific ranges considered normal for children.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, providing clear and sensible advice. The tone is reassuring and professional, but the response could be improved by using proper punctuation, such as capitalizing the beginning of sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "\n",
      "  The model's response logically aligns with the context provided in the input. It discusses typical procedures a doctor might follow when examining someone with erection problems, covering medical history, lifestyle habits, and possible physical examinations.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "  The model's response sufficiently answers the question with a general overview but lacks specific details about the examination of local anatomical issues, such as examining the testis and penis, which were mentioned in the true answer. It could also briefly mention more specialized tests like the stamp test or penile Doppler.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "  The response sounds fluent and human-like. It uses appropriate professional language and provides a clear and comforting tone, which is suitable for someone seeking medical advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the input context and effectively addresses the individual's expression of depression and suicidal thoughts. It emphasizes the importance of seeking professional help and provides general advice on managing symptoms, maintaining coherence with the input scenario.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response sufficiently answers the input by acknowledging the severity of the symptoms and offering immediate advice. While it mentions steps to manage symptoms and seeking professional assistance, it doesn't delve into specific treatment options or medical evaluations as the true answer does, such as the advice on psychological or medical consultations. However, it does cover the key aspect of ensuring immediate safety and seeking help, which is crucial given the context.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response is fluent and human-like, maintaining a compassionate and empathetic tone suitable for the sensitivity of the issue discussed. The language used is clear and relatable, contributing to a natural-sounding response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and logically aligns with the context given. It correctly identifies sciatica as a potential condition linked to the symptoms described, which is a possible real-world interpretation of the user's situation.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a thorough explanation of what sciatica is and suggests some common causes. It also offers advice on initial self-care as well as the importance of seeing a doctor. However, it does not address other potential conditions or diagnostic steps, as mentioned in the True Answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like. It conveys empathy and provides information clearly, similar to how a doctor might communicate with a patient. There are no awkward or unnatural parts in the text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided by discussing potential causes of frequent urination and suggesting consulting a healthcare professional, which is coherent with the user's concerns.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  While the model provides a comprehensive overview of potential causes and suggests actions such as consulting a doctor and lifestyle changes, it doesn't address the user's specific mention of becoming aroused when the bladder is full, which is covered in the true answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is fluent, with a professional and empathetic tone that is very similar to how a human healthcare professional would respond.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response is logically aligned with the input. It acknowledges the symptoms described and suggests consulting a healthcare professional, which aligns with the severity and nature of the symptoms presented.\n",
      "\n",
      "- **Completeness: 3.5**  \n",
      "  The response provides a general approach to addressing the issue by suggesting a visit to a healthcare professional and offering lifestyle advice. However, it does not address potential specific causes like stress or prostate issues mentioned in the true answer, and it overlooks advising on specific medications or relaxation techniques.\n",
      "\n",
      "- **Naturalness: 4.8**  \n",
      "  The response is very fluent and human-like, sounding like genuine advice from a concerned individual. It uses polite language and offers a clear, compassionate explanation and guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and logically aligns with the context provided. It acknowledges the improvements mentioned in the input and discusses the potential causes of the bitter taste, linking it to the medications the mother is on.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model answers the query about the side effects of the steroids and mentions the involvement of diabetes medication as a potential factor. It also suggests consulting a doctor, which makes the response reasonably complete. However, it does not provide specific medicine recommendations to reduce side effects, as requested.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and sounds human-like. It uses polite language and conveys empathy effectively, maintaining a professional and conversational tone throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response suggests a diagnosis of mallet finger, which generally involves physical injury or trauma to the finger, whereas the input specifically mentions no injury, swelling, bruising, or discoloration. This suggests a misunderstanding or misalignment with the context provided.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The model provides a detailed explanation of mallet finger, including potential treatments and a recommendation to consult a medical professional. However, it does not consider other potential diagnoses that align with the symptoms and history provided in the input, thus offering an incomplete range of possibilities.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent and well-structured, with a professional and considerate tone. It reads naturally, similar to how a human doctor might communicate, aside from the content accuracy issues regarding diagnosis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided metrics, here is the evaluation for the model's response:\n",
      "\n",
      "- **Coherence: 4.0**  \n",
      "  The model's response is generally coherent with the input context. It acknowledges the age and health condition of the patient, the issue with the bone marrow biopsy, and the concern about myelodysplastic syndrome (MDS). However, the response goes slightly off-topic by providing advice on supportive care, which wasn't specifically requested in the original question.\n",
      "\n",
      "- **Completeness: 4.0**  \n",
      "  The model addresses the inquiry about whether the fibrino-leukocytic nature of the material is indicative of the suspected condition, suggesting that it is consistent with MDS but also noting the insufficient quality of the biopsy material. However, the explanation about the fibrino-leukocytic consistency could be more precise, as the true answer emphasizes this doesn't directly prove the suspected condition. Moreover, the suggestion to repeat testing aligns with the true answer's recommendation.\n",
      "\n",
      "- **Naturalness: 4.5**  \n",
      "  The response sounds fluent and human-like. It uses appropriate medical terminology and maintains a professional tone. The response flows logically, offering a general explanation and advice, albeit slightly more general than needed for the specific question.\n",
      "\n",
      "Overall, the model provides a coherent, fairly complete, and natural-sounding response with minor deviations in detail accuracy.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context provided, as it addresses the foot injury and the potential seriousness due to the change in color. However, it suggests possibilities like deep tissue injury which might not be directly supported by the given context and doesn't take into account managing her diabetes, which is vital in the situation.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model provides a comprehensive discussion of possible complications related to the foot injury and suggests medical examinations and treatment options. However, it does not mention diabetes management, which is a critical aspect of healing in diabetic patients. This omission makes the response less complete.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is very natural and human-like. It uses empathetic language and a professional tone that is typical of a healthcare provider discussing a medical concern. The language is fluent and easy to understand, making it sound as if a human could have written it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is generally coherent with the input, addressing the issue of recurrent fungal infection and linking it to the use of Oxra. However, it slightly misses the explicit link between diabetes management and poor control that can lead to such infections, as highlighted in the true answer.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The response provides some useful information, such as continuing with the Lulifin cream and lifestyle changes for diabetes management. However, it lacks a complete explanation regarding the need for a more comprehensive treatment plan, including possible sexual abstinence and addressing potential partner treatment, as suggested in the true answer.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "\n",
      "The language used in the response is fluent and human-like, offering advice in a conversational manner. It empathizes with the user's concerns and provides advice in a friendly tone. There are no major unnatural or awkward phrases present.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It addresses the concern about risk from a used needle that didn't pierce the skin and discusses the low likelihood of virus transmission.\n",
      "  \n",
      "- Completeness: 4.0  \n",
      "  The model provides a comprehensive overview of the risk associated with needlestick injuries, emphasizes monitoring for symptoms, and suggests seeking medical attention if necessary. However, it could have been more complete by directly suggesting specific tests or encouraging dialogue with the person whose needle it was, like the true answer does.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response sounds fluent and human-like. It uses empathetic language and suggests practical steps in a reassuring manner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "The model's response logically aligns with the context provided. It correctly identifies the fasting glucose and HbA1c levels as potential indicators of diabetes and makes reasonable inferences based on the height and weight information.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "The response provides a comprehensive answer, offering practical suggestions for lifestyle changes and the potential need for medication. However, it does not fully match the \"True Answer,\" which suggests consulting a diabetologist online.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "The response is fluent and human-like, with polite and informative communication. The language used feels appropriate and professional for a medical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The response logically aligns with the context, offering a thoughtful and relevant answer to the question about supplements to manage HbA1c levels. It provides a recommendation for chromium picolinate and some general advice on lifestyle changes, which makes sense in the context of wanting to reduce HbA1c.\n",
      "\n",
      "- Completeness: 3.8  \n",
      "  While the model's response touches on several important aspects like chromium picolinate, lifestyle changes, and a warning to consult a doctor, it lacks the thoroughness seen in the true answer regarding specific dietary recommendations and a broader range of supplements. Some of the detailed suggestions found in the true answer, like omega 3, magnesium, and vitamin supplements, are missing.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The language used is fluent and human-like, providing a clear and empathetic response. The tone is professional yet approachable, making it easy to read and understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent in the sense that it logically addresses the symptoms mentioned in the input and offers treatment suggestions relevant to the user's condition. However, it might benefit from acknowledging the history of antibiotic use mentioned in the input.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model provides a fairly comprehensive response by suggesting several symptomatic treatments and addressing potential next steps. It could, however, more directly consider the specific medications already tried by the user and explicitly suggest seeing a doctor if the symptoms persist, especially considering the prolonged nature of the symptoms.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response is mostly fluent and human-like. It uses polite language and provides a range of suggestions. There are some minor grammatical issues (“i would suggest you to”) and redundancies in suggesting treatments (\"take some antibiotics if your symptoms do not improve within a week\" is a bit too general and could be more cautious given the user's situation), but overall, it maintains a natural tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "    The model's response logically aligns with the context provided but is somewhat general. It acknowledges the patient's high-risk status due to age and medical conditions, and it suggests consulting a cardiologist for a comprehensive evaluation. However, it lacks specific details about the medical options being considered, such as the differences between angioplasty and bypass surgery, especially in older patients with diabetes.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "    The model's response is partially complete. It suggests that angioplasty or bypass might be necessary and advises consulting a cardiologist, which is a reasonable recommendation. However, it does not provide specific guidance or insight into the decision-making factors between angioplasty and bypass, especially the details mentioned in the true answer about the limitations of angioplasty in this context and the advantages of minimally invasive options.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "    The response is fluent and sounds human-like, with appropriate empathy and understanding of the concern. It uses polite language and constructs sentences clearly and naturally. However, it could slightly improve its medical explanation to enhance persuasiveness and authority. Still, overall, it uses very natural language.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "    - The model's response is generally coherent, as it acknowledges the improvement in glucose control and the issues with dehydration and diuretics. However, it does not directly address the specific question about suggesting non-diuretic medications which were asked for in the context.\n",
      "\n",
      "- Completeness: 2.5\n",
      "    - The response lacks completeness as it fails to provide specific non-diuretic medication suggestions to lower blood pressure, which was the main question. It provides some general advice but does not directly answer the query.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "    - The response is natural and fluent, resembling human language. It conveys empathy and understanding, and it maintains a polite tone throughout. However, it is slightly generic in its advice, lacking a personalized touch that might come from a more engaged human response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "  - The model's response mentions low blood sugar, dehydration, anemia, and heart problems as potential causes, even though these were specifically ruled out in the input. This shows a lack of alignment with the detailed medical history provided.\n",
      "  \n",
      "- Completeness: 1.5\n",
      "  - The response fails to suggest any specific next steps or further tests that align with the input, such as the head-up tilt test or considering panic attacks. Instead, it offers general advice that doesn't comprehensively address the question or consider the exhaustive tests already performed.\n",
      "  \n",
      "- Naturalness: 3.5\n",
      "  - The response is generally fluent and mimics a human-like structure with polite language and standard advice. However, there are parts where the advice is not tailored to the specific context, potentially impacting its perceived authenticity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the context provided. It acknowledges the mother's health condition as outlined in the input and makes connections between diabetes, typhoid, and the potential impact on the blood clot, which reflects a logical interpretation of the symptoms described.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model provides a generally adequate answer but lacks a critical element mentioned in the true answer: the urgency to consult a neurosurgeon due to the potential for serious intracranial causes of the headache. The response focuses more on the antibiotic treatment for typhoid and monitoring the blood clot, which, while relevant, does not address the urgency of the headache's potential causes comprehensively.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The model's response is fluent and human-like. It demonstrates empathy with a polite tone and uses appropriate medical advice language, making it sound natural as if coming from a concerned health professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.5\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence (4.5)**: The model's response logically aligns with the context provided and offers general advice on treating fungal infections and preventing recurrence. However, it doesn't delve into potential underlying causes like diabetes, which could impact coherence given the true answer's focus on this aspect.\n",
      "  \n",
      "- **Completeness (3.5)**: The response provides a good overview of what might be causing the recurring problem but lacks the specific actionable advice offered in the true answer, such as the use of a specific cream or addressing potential underlying issues like diabetes. Without these, the answer might feel less sufficient to the user.\n",
      "\n",
      "- **Naturalness (4.5)**: The response is fluent, polite, and human-like, using language that is typical of a healthcare professional. It clearly and professionally communicates the information, thus scoring high on naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.0\n",
      "\n",
      "**Evaluation:**\n",
      "\n",
      "1. **Coherence (4.5)**: The model's response logically aligns with the context provided. It recognizes the primary issue of nasal obstruction and provides guidance on when a biopsy might be necessary. However, it doesn't mention age-specific risks, which slightly reduces coherence with the true answer.\n",
      "\n",
      "2. **Completeness (3.5)**: The model does cover important points like considering a biopsy if severe symptoms are present and suggests consulting a specialist. However, it misses discussing the specifics of surgery, age-related risks, and pre-existing conditions like BP or diabetes which the true answer highlights as critical for assessing severity.\n",
      "\n",
      "3. **Naturalness (4.0)**: The response is generally fluent and human-like. It communicates in a professional yet relatable manner, though it could benefit from a more structured paragraph format to enhance readability and flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response logically aligns with the context provided. It addresses the elevated serum creatinine and triglyceride levels and the patient's diabetes management. However, it lacks some direct follow-up questions about the patient's history, such as the duration of diabetes or any existing kidney issues, which the true answer includes.\n",
      "\n",
      "- **Completeness: 4.0**  \n",
      "  The response gives a detailed overview of potential complications and advice on managing triglycerides, but it doesn't address the need to review the decision to stop diabetes medication as the true answer suggests. It also doesn't offer a direct call to action, such as consulting a diabetologist for further personalized advice, although it does suggest working with a healthcare provider.\n",
      "\n",
      "- **Naturalness: 5.0**  \n",
      "  The response sounds fluent and human-like, using professional medical terminology appropriately while remaining accessible to the patient. The tone is empathetic and informative, effectively resembling communication one might have with a healthcare professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is logically aligned with the provided context. It addresses the key points of the medical query, explaining the rationale behind the medication regimen and the potential effects of changing medications. However, it could have explicitly noted the differences between Olmezest and Tazloc-H regarding their uses to improve coherence further.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - While the response touches on the important aspects of managing hypertension and diabetes with the given medications, it lacks detailed advice on self-monitoring techniques for blood pressure and pulse as provided in the true answer. It also misses out on the explanation about the urine infection management and more detailed advice on the timing and dosage of Metformin ER.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The response is fluent and generally human-like, with a comforting tone commonly expected from a physician. It conveys the information in a clear and thoughtful manner, though perhaps a little more personalization would enhance the naturalness.\n",
      "\n",
      "Overall, the model's response is quite reliable, but there's room for improvement in providing more comprehensive advice and detailing specific self-monitoring measures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is generally coherent and logically aligns with the context provided. It acknowledges the symptoms and prior medical evaluations mentioned, as well as the need for further medical consultation. However, it slightly lacks depth in addressing specific symptoms like stiffness and numbness.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model's response provides some helpful suggestions like over-the-counter pain relief and exercise, but it does not fully address all the symptoms mentioned (e.g., weakness, low energy, and numbness) and does not suggest necessary diagnostic steps such as a biopsy, as mentioned in the true answer. A more thorough exploration of potential underlying causes would improve completeness.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent, polite, and conversational, resembling how a healthcare professional might respond to a patient's inquiry. It uses appropriate language for general medical advice, maintaining a reassuring and helpful tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It addresses the blood sugar reading and explains the need for further tests to diagnose diabetes.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response is fairly complete in explaining the diagnostic process for diabetes but could improve by offering more immediate advice or guidance, in line with the true answer, like dietary suggestions.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, with polite and informative language suitable for a healthcare context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the context provided in the input. It recognizes the recurring issue with the ingrown nail and offers a detailed explanation of what an ingrown nail is, possible causes, and treatment options. However, it could include more personalized advice relevant to the user's situation, such as confirming the previous surgical intervention and how it relates to future treatment steps.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response provides a comprehensive overview of general treatments for ingrown nails and suggestions for when to seek medical attention. It addresses the problem well but lacks specific advice related to the user's medical history and the specifics provided in the true answer, such as medication options and the suggestion to check sugar levels. Including these details would make the response more complete.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The response is fluent and human-like, using conversational language that is easy to understand. It offers empathy and encouragement, making it sound professional yet approachable, akin to advice you'd receive in a real-life consultation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response logically aligns with the context of the symptoms described, as it suggests consulting a healthcare professional and keeping a record of the symptoms. However, it lacks specific connections to the symptoms mentioned (e.g., the possible neurological or cardiac issues indicated by the true answer).\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  - The response is quite general and lacks specific medical insights or possible explanations for the symptoms, such as potential neurological or cardiac issues that are mentioned in the true answer. It advises a general consultation without addressing specific medical considerations.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  - The response is fluent and human-like, utilizing polite and empathetic language. It follows a natural progression, acknowledging the concern, suggesting practical steps, and offering further help if needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically addresses the context provided in the input, discussing both the elevated C-reactive protein levels and joint pain. It relates these symptoms to possible diabetes complications and suggests arthritis as a potential cause for the joint pain, which is coherent with the information given.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response adequately answers the main question by explaining the possibility of elevated C-reactive protein levels in a diabetes context and addresses the joint pain. However, it could have provided a bit more detail about potential connections and treatments specifically related to high C-reactive protein levels, possibly mentioning other related conditions or further tests that might be necessary.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and human-like, employing a polite and empathetic tone. It correctly uses medical terms in an accessible way and gives practical advice on immediate actions to take. The language feels natural for a doctor-to-patient communication scenario.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response logically aligns with the context provided. It accurately identifies the symptoms related to menopause and acknowledges the reported blood test results as normal. However, it lacks the depth of analysis provided in the true answer regarding possible causes and necessary further investigations.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The model's response acknowledges the symptom descriptions and normal test results but falls short in offering a comprehensive answer. It does not explore potential causes for the symptoms, such as hormone imbalances or other conditions suggested in the true answer. The response misses specific recommendations for further tests or monitoring of conditions like hypertension or thyroid issues.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is fluent and sounds human-like. It uses appropriate language and structure to convey the information clearly. However, it could be slightly improved by incorporating more empathetic or reassuring language that might be typical in a healthcare professional's communication.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context, acknowledging the patient's medical history and discussing the possibility of placing an AV fistula in the chest area due to the patient's amputation. However, it lacks detail about different types of AV fistulas and other potential placement areas like the leg, which are mentioned in the true answer.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides an answer to the main query about the possibility of placing an AV fistula near the chest. However, it doesn't fully explore all the alternatives mentioned in the true answer, such as detailed types of AV fistulas or the option of placing a fistula in the leg or using a central line.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and human-like, maintaining a polite and professional tone as expected in a medical consultation. It reads smoothly and provides reassurance, encouraging further discussion with a doctor for personalized advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided by acknowledging the conditions and lifestyle factors mentioned (hypertension, obesity, cessation of smoking and alcohol). It also discusses the relevance of medications and lifestyle changes in managing the patient's condition.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model provides a thorough answer regarding the management of mild concentric left ventricular hypertrophy through lifestyle changes and medication. However, it does not specifically answer the question of whether LVH will regress purely with diet and exercise, which slightly reduces completeness.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response is fluent, human-like, and professionally respectful. It uses appropriate medical terminology and provides advice in a manner consistent with how a doctor might communicate with a patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It correctly identifies the complexity of managing multiple health conditions and stresses the importance of consulting a healthcare provider for personalized care. The response is coherent with the information given about the patient's condition.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response addresses several key aspects, such as monitoring medication interactions and the importance of tailored treatment plans. However, it lacks specific details on any drug interactions or unnecessary medications, which the user was particularly concerned about. The true answer mentions Rifampicin's interaction, which the model's response does not.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and human-like, using empathetic language and structured paragraphs. The tone is supportive and professional, akin to how a healthcare provider might communicate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "The model's response logically aligns with the context. It mentions the significance of the ANA test in relation to autoimmune conditions, which is relevant given the input information. However, it does not tackle the more immediate context of the complications related specifically to hepatitis E and diabetes, which are significant parts of the user's context.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "While the model addresses the ANA result and potential autoimmune conditions, it does not sufficiently answer the question concerning hepatitis E's life-threatening potential and complications. The true answer provides dietary advice and reassurance about hepatitis E, which the model's response lacks.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "The response sounds fluent and human-like, adopting a professional yet empathetic tone expected in medical communication. It provides logical advice and encourages consultation with a medical professional, which seems natural for a situation involving health concerns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "\n",
      "- Coherence: 4.5\n",
      "\n",
      "  The model's response logically aligns with the context provided. It acknowledges the ongoing knee pain and suggests practical next steps, such as continuing consultations and considering a second opinion. The advice on over-the-counter pain management and exercises also aligns well with the symptoms described.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "  The model provides a comprehensive response by suggesting follow-ups, second opinions, pain management, and exercises. However, it does not address the unique situation of the patient being diabetic, which could be relevant in some medical contexts. It also doesn't make use of the attached MRI reports, which could have been analyzed for additional insights.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "  The response is fluent, polite, and empathetic, resembling human-like communication effectively. The explanation and advice are straightforward, and the tone is conversational, which enhances its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the input context, mentioning the 9mm gallstone and noting that normal lipid levels suggest the gallstone is not related to high cholesterol. The advice to monitor health and consult a doctor for further tests is sensible. However, it doesn't delve into specifics about gallstones as is done in the true answer.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides general advice but lacks specific guidance and information that the true answer provides. Specifically, it doesn't address the nature of pain associated with gallstones, potential other causes of abdominal pain, or suggest possible medications or tests to undertake, as given in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response sounds natural and human-like, with a polite and considerate tone. It is well-structured and uses suitable language for a healthcare consultation context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response is coherent with the context provided. It addresses the user's main concerns about early bronchiectatic changes, the distinction from bronchiectasis, treatment options, and life expectancy considerations. However, it does not mention atelectasis, which was highlighted in the true answer.\n",
      "\n",
      "- **Completeness: 4.0**  \n",
      "  The model provides a substantial amount of information regarding early bronchiectatic changes, bronchiectasis, and treatment, including lifestyle and medication advice. However, it does not cover certain treatments like Aerodil or Acebrophylline mentioned in the true answer. It also lacks guidance on diagnostic tests like sputum Gram staining, AFB, and fungal staining, which are present in the true answer.\n",
      "\n",
      "- **Naturalness: 4.8**  \n",
      "  The model's language is very fluent and human-like, demonstrating empathy and understanding of the user's concerns. It maintains a professional yet approachable tone consistent with how a healthcare provider might communicate with a patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the provided input by acknowledging the mother's medical history and suggesting that her symptoms might be related to her medications and overall condition. However, it lacks a specific diagnosis that is suggested in the true answer (i.e., acid reflux and stress as potential causes).\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model's response provides general guidance, such as consulting with a doctor and possible lifestyle adjustments, but it does not offer specific treatment suggestions like the true answer does. The true answer also mentions particular medications (Colospa Retard) and the importance of following up with the doctor, which are not included in the model's response.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, expressing empathy and providing reasonable advice in a polite and professional tone. It suggests a natural flow for addressing a concerned patient's inquiry, though it slightly lacks the specificity and authority one might expect from an expert, preventing a perfect score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is mostly coherent, aligning logically with the context. It accurately acknowledges the main concerns: meningioma, frontal atrophy, and the lightened MRI area, and suggests consulting a healthcare provider. However, it doesn't specifically mention all the potential causes discussed in the input.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model provides a general overview and advises consulting a healthcare provider, which is appropriate. However, it misses addressing some specific points like the potential causes of brain atrophy (e.g., stress, Choline deficiency, low blood pressure), and it doesn't touch upon the specific potential interpretations of the MRI lightened area (e.g., infection vs. tumor) as asked in the input.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and sounds human-like. It uses language typical of medical advice, and the tone is empathetic, fitting the context of a medical inquiry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and aligns logically with the context provided in the input. It addresses the concern of irregular bleeding following intercourse and suggests possible reasons such as hormonal imbalance or an infection. The response recognizes the situation of recent sexual activity, which is a relevant factor mentioned in the input.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response does not fully capture the aspects covered in the true answer. While it mentions possible causes like hormonal imbalance and infection, it does not address the possibility of pregnancy or mechanical causes like vaginal tears during sexual activity, both of which are significant considerations. Suggestions for specific tests like hCG or TSH are missed, limiting the completeness of the answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds very human-like. It uses polite language, is empathetic, and encourages the user to consult a doctor, which is typical of human health professionals' recommendations. The suggestion to take over-the-counter pain relievers also contributes to a natural and caring tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is generally coherent and logically addresses the input context. It acknowledges the use of medications and discusses potential effects of using hot water, which aligns well with the information provided in the input.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the model mentions that the redness and pain could be due to irritation from hot water and advises consulting a doctor, it lacks specific medical insights regarding the condition, such as the possibility of candidal balanitis or advice against using Surfaz SN due to its steroid content. It also does not provide follow-up questions that would help in diagnosing the condition more precisely.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is quite natural and fluent, with a conversational tone that sounds human-like. The language used is clear and easy to understand, with no awkward phrasing or grammatical errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is coherent with the input context. It acknowledges the user's concerns about diabetes management, particularly the effects of certain medications on weight and kidney health. While the model does mention that sodium glucose transporter medications don't carry a risk of kidney damage, which might require more nuance, overall, the response logically aligns with the given medical situation.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response addresses the main concerns presented in the input, including weight gain and kidney health related to the medications discussed. However, it could have explored more specific alternatives or detailed guidance on how to transition or test the new options with precise personal health conditions mentioned. The recommendation to consult with a healthcare provider is sound but mirrors the offered true answer without the added layer of directing to a specific professional or platform.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The model's response is fluent, well-structured, and sounds human-like. The language is clear, and the tone is appropriately considerate for a medical advisory setting. It maintains a respectful and empathetic approach throughout, reinforcing a natural and human-like interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the context provided in the input. It recognizes that the patient is concerned about their diet plan and the allowance for non-vegetarian foods. It appropriately advises on the general guidelines of protein consumption and the need for monitoring intake due to other dietary restrictions.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "While the response addresses the question about the consumption of non-vegetarian foods, it lacks specific information regarding how often fish and chicken can be consumed, which the patient explicitly asked about. It also does not provide detailed guidance on managing the specific dietary restrictions beyond protein intake, such as low potassium, low urate, and low phosphorus aspects.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "\n",
      "The language used in the model's response is fluent and human-like. It maintains a professional and empathetic tone typical of medical advice. The response could improve slightly by being more personalized or directive, rather than deferring too quickly to a generic suggestion to \"consult with your doctor or a nutritionist.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  - The model's response is logically aligned with the context provided in the input. It addresses the individual's concerns regarding their blood sugar levels and HbA1c test results appropriately.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  - The response sufficiently answers the user's questions by explaining the significance of the test results, offering reassurance, and suggesting lifestyle modifications. It could be more complete by explicitly mentioning the reliability of HbA1c vs. FBS in detail.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  - The response is fluent and human-like, with a comforting and professional tone that matches how a doctor might naturally respond to such a query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and logically aligns with the context provided. It acknowledges the heart attack and the artery blockage, discusses stenting, and also suggests consulting with a cardiologist for personalized treatment.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model's response covers some treatment options and emphasizes lifestyle changes, it doesn't specifically address the severity of the blockages as pointed out in the true answer. It also lacks emphasis on the urgency of the situation and the necessity of immediate medical intervention as recommended (stenting), which is suggested by the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent, human-like, and empathetic. It uses polite language, provides advice, and encourages further consultation with a healthcare professional. The tone is reassuring and professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is generally coherent with the input. It identifies a possible condition (Peyronie's disease) that aligns with some of the symptoms described, though it doesn't fully explore all possibilities mentioned in the true answer.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response addresses a possible cause of the symptoms but lacks completeness because it doesn't mention other potential causes, such as tight frenulum or partial phimosis, which are important considerations according to the true answer. It also does not address pain management options related to these conditions.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is mostly fluent and human-like. It opens and closes politely, offers a potential diagnosis in a compassionate manner, and provides general advice that sounds natural. However, the advice provided (applying ice packs) is somewhat generic and not necessarily aligned with standard medical advice for the condition mentioned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response maintains logical alignment with the input context. It addresses the concern about the fever and acknowledges the need for medical evaluation, which is consistent with the context. However, it lacks specific consideration of the patient's existing medical conditions (diabetes and uncontrolled blood sugar), which are significant in this context.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response offers general advice on managing fever and blood sugar, but it does not specifically answer the questions about which antibiotic to prescribe for fever or specific recommendations for anti-diabetic medication adjustments. It falls short of providing a complete answer with the necessary clinical specificity expected in this scenario.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, using natural language to convey its advice. It provides a well-structured and clear message, though it could be slightly more specific in addressing the particular medical nuances presented in the input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It reasonably interprets the symptoms described as potentially linked to hypoglycemia and suggests seeking medical advice.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model provides a plausible explanation for the symptoms and advises future actions, such as monitoring blood sugar levels and consulting a healthcare provider. However, it lacks mention of other potential causes such as low hemoglobin, vitamin deficiencies, or thyroid issues, as stated in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent, polite, and sounds human-like. It simulates a professional yet approachable tone, appropriate for a healthcare context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is generally coherent and aligns well with the context provided in the input. It acknowledges the elevated cholesterol and triglyceride levels and suggests consulting a primary care physician, which is a logical step. The response explains the risk factors and suggests lifestyle changes to manage cholesterol levels, which are appropriate given the context of the input.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model's response does cover the main concerns raised in the input, such as the risks associated with elevated cholesterol, potential need for medication, and lifestyle changes. However, it does not address the possibility of hereditary factors as part of the cause for high cholesterol or emphasize the user's specific risk due to family history. Additionally, the model does not specifically answer whether the cholesterol levels are too high for lifestyle changes alone to be effective.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "\n",
      "The model's response is quite natural and fluent, mirroring how a human might respond. The tone is polite and informative, and the use of language is clear and easy to understand. There's a slight deviation from a natural human response in terms of addressing all specific personal factors, but overall, it reads smoothly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context by addressing the main concern of the slow urine stream and suggesting a urological examination. However, there is a slight misunderstanding regarding urinary incontinence, which was not mentioned in the input.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides a reasonable suggestion by advising the patient to consult a urologist, but it lacks specific advice related to managing symptoms or addressing the patient's frustration and embarrassment. Additionally, it does not fully explore other possible explanations or solutions for urination difficulties despite the normal prostate scan.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and human-like, effectively mimicking a conversational tone that one would expect from a doctor. It is polite and empathetic, though it could benefit from a more personalized touch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is generally coherent with the input. It correctly addresses the concern about potential variations due to the menstrual cycle and offers general advice on managing diabetes. However, there is a slight factual inaccuracy regarding the type of glucose test, as the patient's context specifies a fasting test.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model provides an answer that acknowledges the potential for slight variation in results due to menstruation and suggests a follow-up with a doctor. However, it could be more complete by directly addressing the difference between fasting and non-fasting glucose tests, as well as providing professional advice from an obstetrician or gynecologist, which the true answer implies.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is fluent, conversational, and human-like, demonstrating a friendly and empathetic tone. The suggestion to consult a doctor and the advice on lifestyle changes are appropriately phrased, contributing to the naturalness of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the context of the input, discussing potential reasons why the WBC count might be elevated. However, it could have been slightly more tailored to the specific case details provided, such as the recent stent implementation.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The model provides a plausible and informative answer regarding possible causes for the elevated WBC count but does not offer a concrete action plan or next steps aside from advising to consult a healthcare provider. The response is informative but lacks specificity in terms of actions or further investigation recommendations.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The response is fluent and human-like, with a polite and professional tone expected from a healthcare provider. The language is clear, empathetic, and appropriate for someone seeking medical advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response acknowledges the age and HbA1c level provided in the input but does not recognize that the HbA1c is relatively well controlled. It correctly identifies the connection between diabetes and the issue discussed but fails to provide specific information about the cause of the frenulum tearing.\n",
      "  \n",
      "- Completeness: 3.0  \n",
      "  While the response provides general advice about the management of diabetes and the need for medical evaluation, it does not decisively address the choice between circumcision and frenuloplasty. The response does not explain which option might be better suited for the specific situation described.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and reads naturally, with a comforting and supportive tone typically used in healthcare communications. It is well-structured and easy to understand, making it sound human-like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "    - The model's response is coherent as it addresses the fluctuating blood sugar levels and acknowledges the concern about family history, aligning well with the context. However, it could have been slightly more specific regarding the variability of glucometer readings.\n",
      "\n",
      "- Completeness: 4.0\n",
      "    - The response suggests getting a proper test at a recognized laboratory, which is a crucial recommendation. However, it lacks a comprehensive mention of specific tests like HbA1c, FBS, PPBS, and urine complete, which are included in the true answer.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "    - The response is written fluently and sounds human-like, providing a caring and professional tone expected from a doctor. It gives advice in a clear and polite manner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "The model's response is logically aligned with the context provided. It acknowledges the question about increasing chances of getting pregnant and gives a detailed list of lifestyle factors that can influence fertility. However, it doesn't address specific medical checks or age-related advice mentioned in the true answer.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "The response covers a broad range of lifestyle recommendations that are relevant to the question. However, it lacks some specific medical considerations and tests mentioned in the true answer, such as checking certain health indicators and age-specific advice, which are crucial for a comprehensive answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "The response is fluent and sounds human-like. It starts with a polite greeting and congratulatory note, providing a comforting and professional tone typical of a healthcare provider, making it sound very natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is logically aligned with the context provided. It acknowledges the user's concern, suggests potential causes such as infection or inflammation, and emphasizes seeking professional help, which is coherent with the context of a health inquiry. However, it could have been more specific about potential age-related issues, considering the user is turning 20.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The response provides general advice and urges consultation with a healthcare professional, which is crucial. However, it lacks specific inquiries that could guide the user toward identifying their condition more precisely, such as asking about additional symptoms or medical history. This omission limits the response's completeness compared to the True Answer, which delves deeper into possible symptoms and underlying conditions.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The response is fluent and sounds human-like. It uses empathetic language, acknowledges the user's difficulty in discussing the issue, and offers practical interim advice. The formulation of the advice and the language used make the response sound natural and considerate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns logically with the context and acknowledges the user's concern about recurrent miscarriages. It provides a general explanation of possible causes and steps forward, showing understanding.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response suggests seeing a healthcare provider, it lacks specific medical advice or a detailed diagnostic plan, which is provided in the true answer. The model's response is more general and doesn't explain specific tests or conditions to investigate.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent, empathetic, and human-like. The language is professional and comforting, fitting the tone one would expect from a healthcare professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.0**  \n",
      "  The model's response is generally coherent with the context provided, discussing blood sugar levels in relation to the user's active lifestyle and diet. However, it misses the specific concern of Vitamin D deficiency mentioned in the context.\n",
      "\n",
      "- **Completeness: 3.0**  \n",
      "  The model's response addresses general health monitoring but fails to mention the specific issue of vitamin D levels being borderline, which is crucial for a comprehensive answer based on the given report.\n",
      "\n",
      "- **Naturalness: 4.5**  \n",
      "  The model's response is fluent and human-like, with clear and natural language. However, it lacks a personalized touch or specific recommendations compared to the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and logically aligns with the context provided. It acknowledges the user's hypertension and high blood sugar levels, and offers general advice on managing these conditions, which is relevant to the user's situation.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model gives some advice on lifestyle changes and stresses consulting a doctor, it doesn't mention more specific actions such as fasting recommendations, dietary specifics, or the importance of conducting additional tests like HBA1c, as highlighted in the true answer. It lacks specific guidance that could help the user immediately.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent and sounds human-like. It uses polite and empathetic language, which seems appropriate for a conversation with a healthcare professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It recognizes that the user likely has type 2 diabetes following pregnancy diabetes and recommends consulting a doctor, which is a coherent suggestion. It appropriately addresses the concern of high fasting blood sugar levels. However, the model does make an assumption about the condition (type 2 diabetes) without the confirmatory context found in the true answer.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response sufficiently answers the question by advising the user to consult a doctor and suggesting possible lifestyle changes and medication. However, it could be more complete by providing specific target blood sugar levels and by addressing the potential for reversing diabetes in early stages, as mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent and human-like, with a polite and understanding tone that is typical of a human expert providing professional advice. The language used is clear and appropriate for the context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context by acknowledging the symptoms and suggesting a consultation with a specialist. However, it could have provided more detailed diagnostic possibilities like plantar fasciitis as mentioned in the true answer.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model suggests consulting a podiatrist and outlines possible steps for diagnosis and treatment broadly, it lacks the specific guidance and potential treatments that are suggested in the true answer. This results in a response that is less informative and actionable.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, with polite and empathetic language. It effectively communicates a sense of care and understanding, although it lacks the detailed expert tone found in the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context provided. It acknowledges the concern of experiencing sharp pain and suggests possible causes like muscle strain or digestive issues. However, it would be more aligned if it directly addressed whether it could be something serious, specifically acknowledging the concern about severity. \n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model provides a general answer that covers various potential causes and offers initial steps for managing pain, aligning with a doctor's initial advice before a detailed diagnosis. However, it lacks in-depth follow-up questions or a direct indication of whether the situation might be serious, as illustrated in the True Answer. \n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response sounds fluent and human-like, making use of polite language and providing a thoughtful, empathetic tone suitable for addressing medical concerns in text form.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5 \n",
      "  - The model's response is generally coherent and logically aligns with the context. It explains possible reasons for elevated CRP levels, though it does not mention allergic rhinitis, which could be a probable cause related to the given health conditions.\n",
      "\n",
      "- Completeness: 4.0 \n",
      "  - The response provides a good explanation for elevated CRP levels, emphasizing the absence of infections. However, it misses a direct link to possible causes such as allergic rhinitis and does not discuss anxiety management or the specific details about fluctuations in CRP that could align more directly with the input.\n",
      "\n",
      "- Naturalness: 4.7 \n",
      "  - The response is fluently written and sounds professional and human-like in tone. It uses clear and concise language that is typical of communication from a healthcare provider.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 점수:\n",
      "Coherence       4.345000\n",
      "Completeness    3.601000\n",
      "Naturalness     4.713000\n",
      "BLEURT          0.555760\n",
      "BERTScore_F1    0.625785\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# generation\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT 모델 로드\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 평가 함수\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 점수 추출\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT 점수 계산\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT 및 BERTScore 계산\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# 점수 정규화 함수\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "generation = df[df['task'] == 'generation']\n",
    "results = []\n",
    "\n",
    "for _, row in generation.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # 기본값 설정\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' 컬럼이 존재하는지 확인 후 정규화 수행\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"평균 점수:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column BLEURT not found in DataFrame. Skipping normalization.\n",
      "Warning: Column BERTScore_F1 not found in DataFrame. Skipping normalization.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Coherence', 'Completeness', 'Naturalness', 'BLEURT', 'BERTScore_F1'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 147\u001b[0m\n\u001b[1;32m    144\u001b[0m evaluation_df \u001b[38;5;241m=\u001b[39m normalize_scores(evaluation_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEURT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m evaluation_df \u001b[38;5;241m=\u001b[39m normalize_scores(evaluation_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore_F1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m average_scores \u001b[38;5;241m=\u001b[39m evaluation_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoherence\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleteness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaturalness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEURT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore_F1\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m평균 점수:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(average_scores)\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Coherence', 'Completeness', 'Naturalness', 'BLEURT', 'BERTScore_F1'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# daily_diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT 모델 로드\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 평가 함수\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 점수 추출\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT 점수 계산\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT 및 BERTScore 계산\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# 점수 정규화 함수\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "daily = df[df['task'] == 'daily_diets']\n",
    "results = []\n",
    "\n",
    "for i, row in daily.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_outpu_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Evaluation {i+1} result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # 기본값 설정\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' 컬럼이 존재하는지 확인 후 정규화 수행\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"평균 점수:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 점수:\n",
      "Coherence       3.223577\n",
      "Completeness    2.880081\n",
      "Naturalness     3.008130\n",
      "BLEURT          0.488236\n",
      "BERTScore_F1    0.627131\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# alternative_diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT 모델 로드\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 평가 함수\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 점수 추출\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT 점수 계산\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT 및 BERTScore 계산\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# 점수 정규화 함수\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "alternative = df[df['task'] == 'alternative_diet']\n",
    "results = []\n",
    "\n",
    "for _, row in alternative.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Evaluation {i+1} result:\\n{evaluation}\")\n",
    "            \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # 기본값 설정\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' 컬럼이 존재하는지 확인 후 정규화 수행\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"평균 점수:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>servings</th>\n",
       "      <th>steps</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition_facts</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark</td>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark: Dive into ...</td>\n",
       "      <td>10 min</td>\n",
       "      <td>4 hr</td>\n",
       "      <td>6 Servings</td>\n",
       "      <td>['Cover a freezer-safe tray with parchment pap...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...</td>\n",
       "      <td>{'Servings': '6 Servings', 'Serving Size': '1 ...</td>\n",
       "      <td>[{'label': 'Plain Nonfat Greek yogurt', 'us_me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maple-Pumpkin Spice Oatmeal Cookies</td>\n",
       "      <td>Description not found</td>\n",
       "      <td>10 min</td>\n",
       "      <td>25 min</td>\n",
       "      <td>14 Servings</td>\n",
       "      <td>['Preheat the oven to 350 degrees F. Line two ...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...</td>\n",
       "      <td>{'Servings': '14 Servings', 'Serving Size': '1...</td>\n",
       "      <td>[{'label': 'old-fashioned rolled oats', 'us_me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0   Raspberry Swirl Frozen Yogurt Bark   \n",
       "1  Maple-Pumpkin Spice Oatmeal Cookies   \n",
       "\n",
       "                                         description prep_time cook_time  \\\n",
       "0  Raspberry Swirl Frozen Yogurt Bark: Dive into ...    10 min      4 hr   \n",
       "1                              Description not found    10 min    25 min   \n",
       "\n",
       "      servings                                              steps  \\\n",
       "0   6 Servings  ['Cover a freezer-safe tray with parchment pap...   \n",
       "1  14 Servings  ['Preheat the oven to 350 degrees F. Line two ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...   \n",
       "1  ['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...   \n",
       "\n",
       "                                     nutrition_facts  \\\n",
       "0  {'Servings': '6 Servings', 'Serving Size': '1 ...   \n",
       "1  {'Servings': '14 Servings', 'Serving Size': '1...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  [{'label': 'Plain Nonfat Greek yogurt', 'us_me...  \n",
       "1  [{'label': 'old-fashioned rolled oats', 'us_me...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfh = pd.read_csv(\"/data/jaesung/llm_for_diabetes/src/data/data2_daily_diets/diabetes_food_hub_new_nutri_facts.csv\")\n",
    "dfh.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [00:00<00:00, 22063.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results for Each Row ===\n",
      "Row Index: 661\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 662\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 663\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 664\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 665\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 666\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 667\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 668\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 669\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 670\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 671\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 672\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 673\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 674\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 675\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 676\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 677\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 678\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 679\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 680\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 681\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 682\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 683\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 684\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 685\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 686\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 687\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 688\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 689\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 690\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 691\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 692\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 693\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 694\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 695\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 696\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 697\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 698\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 699\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 700\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 701\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 702\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 703\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 704\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 705\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 706\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 707\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 708\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 709\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 710\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 711\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 712\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 713\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 714\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 715\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 716\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 717\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 718\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 719\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 720\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 721\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 722\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 723\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 724\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 725\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 726\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 727\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 728\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 729\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 730\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 731\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 732\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 733\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 734\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 735\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 736\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 737\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 738\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 739\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 740\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 741\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 742\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 743\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 744\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 745\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 746\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 747\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 748\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 749\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 750\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 751\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 752\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 753\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 754\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 755\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 756\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 757\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 758\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 759\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 760\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 761\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 762\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 763\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 764\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 765\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 766\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 767\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 768\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 769\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 770\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 771\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 772\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 773\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 774\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 775\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 776\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 777\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 778\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 779\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 780\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 781\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 782\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 783\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 784\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 785\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 786\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 787\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 788\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 789\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 790\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 791\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 792\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 793\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 794\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 795\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 796\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 797\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 798\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 799\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 800\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 801\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 802\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 803\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 804\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 805\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 806\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 807\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 808\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 809\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 810\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 811\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 812\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 813\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 814\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 815\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 816\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 817\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 818\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 819\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 820\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 821\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 822\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 823\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 824\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 825\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 826\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 827\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 828\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 829\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 830\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 831\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 832\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 833\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 834\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 835\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 836\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 837\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 838\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 839\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 840\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 841\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 842\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 843\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 844\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 845\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 846\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 847\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 848\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 849\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 850\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 851\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 852\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 853\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 854\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 855\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 856\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 857\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 858\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 859\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 860\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 861\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 862\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 863\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 864\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 865\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 866\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 867\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 868\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 869\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 870\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 871\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 872\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 873\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 874\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 875\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 876\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 877\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 878\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 879\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 880\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 881\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 882\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 883\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 884\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 885\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 886\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 887\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 888\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 889\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 890\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 891\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 892\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 893\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 894\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 895\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 896\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 897\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 898\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 899\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 900\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 901\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 902\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 903\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 904\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 905\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 906\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 907\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 908\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 909\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 910\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 911\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 912\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 913\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 914\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 915\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 916\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 917\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 918\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 919\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 920\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 921\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 922\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 923\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 924\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 925\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 926\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 927\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 928\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 929\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 930\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 931\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 932\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 933\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 934\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "=== Overall Averages ===\n",
      "Output Average Nutri-Score: None\n",
      "Model Output Average Nutri-Score: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# daily diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return all(key in data for key in ['Breakfast', 'Lunch', 'Dinner'])\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # 과일/채소 비율을 100g 기준으로 변환\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data) if isinstance(data, (int, float, str)) else default\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # 전체 무게 계산\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g 기준으로 성분 정규화\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_meal_nutri_score(meal_data, dfh):\n",
    "    meal_scores = {}\n",
    "\n",
    "    for meal, title in meal_data.items():\n",
    "        matched_row = find_most_similar_row(title, dfh)\n",
    "        if matched_row is None:\n",
    "            continue\n",
    "\n",
    "        nutrition_facts = matched_row['nutrition_facts']\n",
    "        ingredients = matched_row['ingredients']\n",
    "        score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "\n",
    "        if score is None:\n",
    "            print(f\"Warning: Nutri-Score calculation failed for meal '{meal}' with title '{title}'.\")\n",
    "            grade = \"N/A\"\n",
    "        else:\n",
    "            grade = get_nutri_score_grade(score)\n",
    "\n",
    "        meal_scores[meal] = {'score': score, 'grade': grade}\n",
    "\n",
    "    return meal_scores\n",
    "\n",
    "def calculate_scores_with_comparison(df, dfh):\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        output_scores = {}\n",
    "        model_scores = {}\n",
    "        if is_valid_meal_structure(row.get('output', '')):\n",
    "            output_data = json.loads(row['output'])\n",
    "            output_scores = calculate_meal_nutri_score(output_data, dfh)\n",
    "        if is_valid_meal_structure(row.get('model_output_512', '')):\n",
    "            model_data = json.loads(row['model_output_512'])\n",
    "            model_scores = calculate_meal_nutri_score(model_data, dfh)\n",
    "        results.append({'row_index': idx, 'output_scores': output_scores, 'model_scores': model_scores})\n",
    "    return results\n",
    "\n",
    "def calculate_average_scores(results):\n",
    "    \"\"\"\n",
    "    Calculate the average Nutri-Scores for outputs and model outputs.\n",
    "    \"\"\"\n",
    "    output_total_score = 0\n",
    "    model_total_score = 0\n",
    "    output_count = 0\n",
    "    model_count = 0\n",
    "\n",
    "    for result in results:\n",
    "        # Extract output scores\n",
    "        for meal, score_data in result['output_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                output_total_score += score_data['score']\n",
    "                output_count += 1\n",
    "\n",
    "        # Extract model scores\n",
    "        for meal, score_data in result['model_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                model_total_score += score_data['score']\n",
    "                model_count += 1\n",
    "\n",
    "    # Calculate averages\n",
    "    output_avg = output_total_score / output_count if output_count > 0 else None\n",
    "    model_avg = model_total_score / model_count if model_count > 0 else None\n",
    "\n",
    "    return output_avg, model_avg\n",
    "\n",
    "\n",
    "# 'daily_diets' task Nutri-Score calculation\n",
    "filtered_df = df[df['task'] == 'daily_diets']\n",
    "results = calculate_scores_with_comparison(filtered_df, dfh)\n",
    "\n",
    "# Calculate overall averages\n",
    "output_avg, model_avg = calculate_average_scores(results)\n",
    "\n",
    "# Print results\n",
    "print(\"=== Results for Each Row ===\")\n",
    "for result in results:\n",
    "    print(f\"Row Index: {result['row_index']}\")\n",
    "    print(f\"Output Scores: {result['output_scores']}\")\n",
    "    print(f\"Model Output Scores: {result['model_scores']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== Overall Averages ===\")\n",
    "print(f\"Output Average Nutri-Score: {output_avg}\")\n",
    "print(f\"Model Output Average Nutri-Score: {model_avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/246 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 158/246 [03:34<01:46,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error identifying fruits and vegetables: unterminated string literal (detected at line 1) (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 207/246 [04:37<00:40,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Total weight is zero. Skipping calculation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [05:27<00:00,  1.33s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 216\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# Execution\u001b[39;00m\n\u001b[1;32m    215\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malternative_diet\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 216\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_scores_with_comparison_no_meals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Cell \u001b[0;32mIn[32], line 207\u001b[0m, in \u001b[0;36mcalculate_scores_with_comparison_no_meals\u001b[0;34m(df, dfh)\u001b[0m\n\u001b[1;32m    200\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    201\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_index\u001b[39m\u001b[38;5;124m'\u001b[39m: idx,\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         })\n\u001b[1;32m    206\u001b[0m final_output_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(output_scores_list) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(output_scores_list) \u001b[38;5;28;01mif\u001b[39;00m output_scores_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m final_model_output_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_output_scores_list\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(model_output_scores_list) \u001b[38;5;28;01mif\u001b[39;00m model_output_scores_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Average Nutri-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_output_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Output Average Nutri-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_model_output_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# alternative diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return isinstance(data, dict)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # 과일/채소 비율을 100g 기준으로 변환\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # 전체 무게 계산\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g 기준으로 성분 정규화\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_scores_with_comparison_no_meals(df, dfh):\n",
    "    results = []\n",
    "    output_scores_list = []\n",
    "    model_output_scores_list = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            output_text = row.get('output', '')\n",
    "            if output_text:\n",
    "                matched_row = find_most_similar_row(output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    output_scores_list.append(output_score)\n",
    "                else:\n",
    "                    output_score = None\n",
    "\n",
    "            model_output_text = row.get('model_output_512', '')\n",
    "            if model_output_text:\n",
    "                matched_row = find_most_similar_row(model_output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    model_output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    model_output_scores_list.append(model_output_score)\n",
    "                else:\n",
    "                    model_output_score = None\n",
    "\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': output_score,\n",
    "                'model_output_score': model_output_score\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': None,\n",
    "                'model_output_score': None\n",
    "            })\n",
    "\n",
    "    final_output_avg = sum(output_scores_list) / len(output_scores_list) if output_scores_list else None\n",
    "    final_model_output_avg = sum(model_output_scores_list) / len(model_output_scores_list) if model_output_scores_list else None\n",
    "\n",
    "    print(f\"Output Average Nutri-Score: {final_output_avg}\")\n",
    "    print(f\"Model Output Average Nutri-Score: {final_model_output_avg}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Execution\n",
    "filtered_df = df[df['task'] == 'alternative_diet']\n",
    "results = calculate_scores_with_comparison_no_meals(filtered_df, dfh)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env_kernel",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
