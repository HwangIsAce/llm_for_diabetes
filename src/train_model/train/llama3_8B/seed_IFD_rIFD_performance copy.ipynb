{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# \n",
    "file_paths = [\n",
    "    \"/data/jaesung/llm_for_diabetes/src/trial8/train/llama3_3B/response/real_seed_IFD_rIFD14.jsonl\",\n",
    "    # \"/data/jaesung/llm_for_diabetes/src/trial/CoT_collection/model_response/test_1.jsonl\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.2900\n"
     ]
    }
   ],
   "source": [
    "# medqa\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "qa1 = df[df['task'] == 'qa1']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(qa1)\n",
    "\n",
    "for _, row in qa1.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.3100\n"
     ]
    }
   ],
   "source": [
    "# medmcqa\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "qa2 = df[df['task'] == 'qa2']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(qa2)\n",
    "\n",
    "for _, row in qa2.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "# pubmedqa\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "qa3 = df[df['task'] == 'qa3']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(qa3)\n",
    "\n",
    "for _, row in qa3.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "# bionli\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "nli = df[df['task'] == 'nli']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(nli)\n",
    "\n",
    "for _, row in nli.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating drug/effect pairs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 22698.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Drug/Effect Pair Evaluation (Strict Match, cleaned)\n",
      "‚úÖ Precision: 0.3434\n",
      "‚úÖ Recall   : 0.3400\n",
      "‚úÖ F1 Score : 0.3417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_drug_effect_clean(text):\n",
    "    \"\"\"\n",
    "    output ÎòêÎäî model_output_32ÏóêÏÑú drugÏôÄ effect Í∞íÏùÑ Ï∂îÏ∂úÌïòÍ≥†,\n",
    "    \\nÏù¥ÎÇò ÌäπÏàò ÌÜ†ÌÅ∞ Ïù¥ÌõÑÏùò ÏÑ§Î™ÖÏùÄ Ï†úÍ±∞ÌïúÎã§.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return {\"drug\": None, \"effect\": None}\n",
    "    \n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # drug Ï∂îÏ∂ú\n",
    "    drug_match = re.search(r'drug:\\s*([^,\\n|<]+)', text)\n",
    "    drug = drug_match.group(1).strip() if drug_match else None\n",
    "\n",
    "    # effect Ï∂îÏ∂ú\n",
    "    effect_match = re.search(r'effect:\\s*([^\\n|<]+)', text)\n",
    "    effect = effect_match.group(1).strip() if effect_match else None\n",
    "\n",
    "    return {\"drug\": drug, \"effect\": effect}\n",
    "\n",
    "# ‚úÖ 're2' taskÎßå ÌïÑÌÑ∞ÎßÅ\n",
    "re_df = df[df['task'] == 're2'].reset_index(drop=True)\n",
    "\n",
    "# ‚úÖ ÌÜµÍ≥Ñ Î≥ÄÏàò Ï¥àÍ∏∞Ìôî\n",
    "true_positive, false_positive, false_negative = 0, 0, 0\n",
    "\n",
    "# ‚úÖ ÌèâÍ∞Ä Î£®ÌîÑ\n",
    "for _, row in tqdm(re_df.iterrows(), total=len(re_df), desc=\"Evaluating drug/effect pairs\"):\n",
    "    true_vals = extract_drug_effect_clean(row['output'])\n",
    "    pred_vals = extract_drug_effect_clean(row['model_output_32'])\n",
    "\n",
    "    if true_vals[\"drug\"] and true_vals[\"effect\"]:\n",
    "        if true_vals == pred_vals:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "            if pred_vals[\"drug\"] or pred_vals[\"effect\"]:\n",
    "                false_positive += 1\n",
    "    elif pred_vals[\"drug\"] or pred_vals[\"effect\"]:\n",
    "        false_positive += 1\n",
    "\n",
    "# ‚úÖ ÏßÄÌëú Í≥ÑÏÇ∞\n",
    "precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# ‚úÖ Ï∂úÎ†•\n",
    "print(\"\\nüìä Drug/Effect Pair Evaluation (Strict Match, cleaned)\")\n",
    "print(f\"‚úÖ Precision: {precision:.4f}\")\n",
    "print(f\"‚úÖ Recall   : {recall:.4f}\")\n",
    "print(f\"‚úÖ F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model_output_32'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_output_32'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# outputÍ≥º model_output Î™®Îëê Î¶¨Ïä§Ìä∏ ÌòïÌÉúÎ°ú ÌååÏã±\u001b[39;00m\n\u001b[1;32m     24\u001b[0m ie[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ie[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(safe_eval)\n\u001b[0;32m---> 25\u001b[0m ie[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_output_32\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ie[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_output_32\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(safe_eval)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Precision, Recall, F1-score Í≥ÑÏÇ∞ Ìï®Ïàò\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_scores\u001b[39m(y_true, y_pred):\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_output_32'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 'ie' ÌÉúÏä§ÌÅ¨ ÌïÑÌÑ∞ÎßÅ\n",
    "ie = df[df['task'] == 'ie'].copy()\n",
    "\n",
    "# Î¨∏ÏûêÏó¥ ÌòïÌÉúÎ•º ÏïàÏ†ÑÌïòÍ≤å Î¶¨Ïä§Ìä∏Î°ú ÌååÏã±ÌïòÎäî Ìï®Ïàò\n",
    "def safe_eval(val):\n",
    "    if isinstance(val, list):  \n",
    "        return [str(i).strip().lower() for i in val]\n",
    "    elif isinstance(val, str) and val.strip():  \n",
    "        try:\n",
    "            parsed = ast.literal_eval(val)\n",
    "            if isinstance(parsed, list):\n",
    "                return [str(i).strip().lower() for i in parsed]\n",
    "            else:\n",
    "                return [str(parsed).strip().lower()]\n",
    "        except:\n",
    "            return [val.strip().lower()]\n",
    "    return []\n",
    "\n",
    "# outputÍ≥º model_output Î™®Îëê Î¶¨Ïä§Ìä∏ ÌòïÌÉúÎ°ú ÌååÏã±\n",
    "ie[\"output\"] = ie[\"output\"].apply(safe_eval)\n",
    "ie[\"model_output_32\"] = ie[\"model_output_32\"].apply(safe_eval)\n",
    "\n",
    "# Precision, Recall, F1-score Í≥ÑÏÇ∞ Ìï®Ïàò\n",
    "def calculate_scores(y_true, y_pred):\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for true_vals, pred_vals in zip(y_true, y_pred):\n",
    "        if not true_vals and not pred_vals:\n",
    "            all_precisions.append(1.0)\n",
    "            all_recalls.append(1.0)\n",
    "            all_f1s.append(1.0)\n",
    "            continue\n",
    "\n",
    "        true_count = Counter(true_vals)\n",
    "        pred_count = Counter(pred_vals)\n",
    "\n",
    "        TP = sum(min(true_count[k], pred_count[k]) for k in true_count.keys() & pred_count.keys())\n",
    "        FP = sum(pred_count[k] - true_count.get(k, 0) for k in pred_count.keys())\n",
    "        FN = sum(true_count[k] - pred_count.get(k, 0) for k in true_count.keys())\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    return sum(all_precisions) / len(all_precisions), sum(all_recalls) / len(all_recalls), sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "def calculate_scores_ignore_duplicates(y_true, y_pred):\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for true_vals, pred_vals in zip(y_true, y_pred):\n",
    "        true_set = set(true_vals)\n",
    "        pred_set = set(pred_vals)\n",
    "\n",
    "        TP = len(true_set & pred_set)\n",
    "        FP = len(pred_set - true_set)\n",
    "        FN = len(true_set - pred_set)\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    return sum(all_precisions) / len(all_precisions), sum(all_recalls) / len(all_recalls), sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "\n",
    "# Ï†êÏàò Í≥ÑÏÇ∞\n",
    "precision, recall, f1 = calculate_scores_ignore_duplicates(ie[\"output\"], ie[\"model_output_32\"])\n",
    "\n",
    "# Ï∂úÎ†•\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 5.0\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The model's response maintains coherence by logically aligning with the context provided in the input, accurately incorporating the sequence and content of the conversation. It replicates each piece of information offered by both the doctor and the patient, ensuring completeness by thoroughly addressing the input without omitting relevant details. Furthermore, the response sounds fluent and human-like, capturing the natural flow of dialogue between the doctor and the patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0 - The model's response is coherent and logically aligns with the context provided in the input. It maintains the flow of conversation and reflects the patient's situation accurately.\n",
      "- Completeness: 4.0 - While the model's response captures most of the essential details, it lacks some specific details provided in the true answer, such as the exact hospital location, the female's age, and additional management details (e.g., MgSO treatment), which could be critical depending on the context.\n",
      "- Naturalness: 5.0 - The response is fluent, human-like, and fits naturally in the form of a medical dialogue exchange.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response is coherent with the given context. It closely follows the conversational structure of the input text, accurately depicting the dialogue between the doctor and the patient. The information about symptoms, medical history, laboratory results, and diagnosis aligns with the context provided.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model's response provides a comprehensive answer to the patient's questions and covers most of the critical details from the true input context. However, it doesn't clarify what \"PTCL, NOS\" stands for (Peripheral T-cell Lymphoma, Not Otherwise Specified), nor does it elaborate on the implications of a stage IVB diagnosis, which could be beneficial for understanding.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is natural and fluent, closely mimicking a typical doctor-patient conversation. The language used is appropriate and human-like, maintaining a respectful and informative tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the dialogue provided in the input and provides a coherent overview of the events leading up to the end of the patient's treatment.\n",
      "  \n",
      "- Completeness: 4.5\n",
      "  - The model's response sufficiently covers most of the key points discussed in the dialogue, such as the symptoms, medical history, examinations, and the unfortunate outcome. However, it lacks certain specific details provided in the true answer, like the patient's medications, their ill-appearance, and specific physical exam findings like lung auscultation details.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The model's response is fluent and human-like, maintaining a formal and clinical tone appropriate for a medical summary. However, the abrupt transition to the unfortunate outcome could be presented more empathetically or with a smoother narrative flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response aligns logically with the context provided in the input. It consistently follows the dialogue pattern and includes the details of diagnosis, treatment, and follow-up, which are coherent with the doctor's discussion with the patient and the patient's family.\n",
      "  \n",
      "- Completeness: 4.5\n",
      "  - The model's response sufficiently answers the implicit questions within the conversation by covering the diagnosis, treatment procedures, and outcomes. However, it does not include additional context or conditions such as the patient's history with diabetes mellitus and hypertension, which are part of the true answer but were not prompted in the conversational input.\n",
      "  \n",
      "- Naturalness: 5.0\n",
      "  - The model's response is fluent, consistent, and human-like. It maintains a conversational tone similar to a real doctor-patient dialogue, and the language used is clear and appropriate for the context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns with the provided conversation and context. It follows the sequence of questions and answers between the doctor and patient consistently and accurately.\n",
      "\n",
      "- Completeness: 5.0  \n",
      "  The response sufficiently covers all the major points in the interaction, matching the information provided in the true answer. It addresses the patient's symptoms, medical history, and prior treatments. The response also concludes with a diagnosis and indication of further tests needed, which is consistent with the provided information.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is fluent and mimics a natural and professional conversation between a doctor and a patient. The dialogue appears smooth and human-like, with appropriate language use for a clinical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "  - The model's response introduces information that is inconsistent with the provided context, such as the mention of severe pneumonia, which is not explicitly discussed in the context. Additionally, it introduces new elements like a total knee replacement and a skin infection that weren't mentioned in the dialogue. This misalignment affects the overall coherence of the model's response.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The model fails to answer pertinent details mentioned in the true answer, such as the findings from diagnostic tests and the exact diagnosis of septic pulmonary embolism (SPE), which were significant in the doctor's discussions with the patient. Instead, it introduces details not relevant to the question asked or the context provided.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "  - The conversation flows relatively smoothly, with interactions resembling a natural exchange, albeit with some awkward transitions or extraneous additions. The language used is generally fluent, but the inclusion of unrelated or false information reduces the sense of realism.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context provided. It precisely follows the flow of the conversation between the doctor and the patient, addressing each point without any logical inconsistencies.\n",
      "\n",
      "- Completeness: 4.8\n",
      "  - The model's response sufficiently answers the question in the input, covering all aspects of the conversation that were presented. The minor deviation is in the detail level, where the patient's detailed medical history (e.g., gravida and para numbers) is not mentioned, though it does not affect the overall comprehensiveness significantly.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response sounds fluent and human-like. The conversation progression feels natural and adheres to the typical dialogue structure you would expect in a medical setting, maintaining a coherent back-and-forth dynamic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 5.0\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "- **Coherence (4.5):** The model's response logically aligns with the context provided, maintaining consistency with the doctor's dialogue and the patient's responses. It correctly follows the sequence of conversation events, but it misses some specific medical information from the true answer, which slightly affects coherence with the full medical context. \n",
      "\n",
      "- **Completeness (4.0):** The model's response captures most of the critical points from the dialogue and provides a logical flow of conversation regarding symptoms, test results, and necessary treatments. However, it lacks some details from the true answer, such as the specific medical history elements and additional treatments undertaken, which are important for a comprehensive view of the patient's situation.\n",
      "\n",
      "- **Naturalness (5.0):** The model's response is fluent and sounds human-like, fitting well into the context of a natural patient-doctor conversation. The dialogue is smooth and appropriately responsive to the patient's questions and needs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent with the context provided in the input. It successfully outlines the sequence of events from the medical history to the treatment plan and the unfortunate outcome, maintaining logical alignment with the conversation.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model covers most aspects of the conversation including medical history, symptoms, diagnosis, and treatment. While it doesn't include specific details such as the exact timeline of the infection development, it captures the gist necessary for a clinical note. The response mentions patient's details like name and age that aren't in the provided context, potentially suggesting a general format rather than specific information.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The model's response reads fluently and very much like something a healthcare professional might write in a clinical note. It is structured and uses appropriate medical terminology, making it sound natural within the context of a medical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context. It maintains a consistent dialogue structure with the patient and provides relevant medical explanations and updates, mirroring the input sequence. Minor details such as figures mentioned in the true answer are missing, but these are not critical to coherence.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model provides a thorough and sufficient answer to the sequence of patient-doctor interactions. Key information about diagnosis, treatment, and patient condition is well-covered. However, some contextual details, such as the hospital location, are not explicitly stated.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is fluent and sounds natural. The language and exchange are consistent with typical doctor-patient conversations, with responses that are clear, polite, and reassuring, as expected in a medical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model‚Äôs response logically aligns with the context provided in the input, accurately reflecting the sequence of events and details shared in the dialogue between the doctor and patient.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model's response is quite comprehensive in summarizing the key information from the conversation, but it misses some specific timing details such as the time interval between the first and second presentation and after the discharge. The patient's age is also slightly incorrect.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The language used in the model's response is fluent and human-like, maintaining a clear and professional tone that matches the medical context presented in the input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response closely aligns with the context provided in the input conversation. It follows the logical progression of the dialogue and replicates the interactions between the doctor and patient accurately.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response captures almost all details from the conversation. However, it misses some nuanced details present in the true answer, such as the patient's age and certain specific descriptors (e.g., the exact location of the plaques). Despite this, it sufficiently covers the vast majority of the important points.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response maintains a natural conversational flow typical of a doctor-patient interaction. The exchanges are fluent, and the language used is appropriate for the setting, making the dialogue sound human-like and plausible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is generally coherent but lacks some alignment with the input details. It captures the critical event of a sudden drop in heart rate and blood pressure leading to the patient's death, aligning with the cause of death described in the input. However, it omits some background details like the patient's diabetes and hypertension history and age.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "While the model correctly identifies the key events leading to the patient's death, it lacks completeness in terms of detailing the patient's full medical history and specific events leading up to the cardiac arrest. Important details such as the patient's response to anesthesia and specific medical conditions are missing.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response reads fluently and sounds human-like. It delivers the information in a clear and structured manner, making it easy to understand. However, the brevity and omission of detailed medical history diminish its naturalness slightly in a thorough medical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 3.0**  \n",
      "  The model's response is somewhat coherent but includes some inaccuracies and assumptions not directly supported by the context. For example, it talks about a treatment plan involving insulin injections and emphasizes the potential need to discuss delivery timing, none of which was explicitly mentioned in the original conversation.\n",
      "\n",
      "- **Completeness: 3.5**  \n",
      "  The response covers several elements relevant to the situation, such as the need for close monitoring, the switch from gliclazide to insulin, and the importance of managing blood glucose levels. However, it omits specific details about biweekly growth scans, individualised pregnancy targets, and inheritance possibilities, which are crucial to the original context.\n",
      "\n",
      "- **Naturalness: 4.0**  \n",
      "  The language used in the model's response sounds quite fluent and human-like, with a professional tone appropriate for a medical consultation. It successfully engages in a dialog that could occur naturally in a clinical setting, although it might slightly overuse medical jargon for an antenatal visit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response is coherent in the sense that it aligns well with the details provided in the conversation and the true answer about the patient's condition and treatment. However, it slightly misrepresents by saying \"I am glad to hear that your symptoms have improved,\" which contradicts the given context as there is no indication of symptom improvement.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  - The model covers a significant portion of the essential points, such as the findings from the ultrasound, the decision to undergo a total thyroidectomy, and the procedural details. However, it omits mention of certain symptoms like difficulty breathing and swallowing, and the fact that the patient was clinically euthyroid, which are present in the true answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  - The response is fluent and formatted in a manner that is typical of medical communication, sounding professional and human-like without any noticeable grammatical errors or awkward constructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0  \n",
      "  The model's response is not coherent. It simply repeats the input dialogue without any logical processing or reformulation into a structured answer related to the patient's profile.\n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The response lacks completeness as it does not synthesize the information in the input to answer any question. It does not even address the question implied by the true answer, which seeks a medical summary or patient history.\n",
      "\n",
      "- Naturalness: 1.0  \n",
      "  The response is not natural as it repeats the input verbatim instead of providing a human-like summary or synthesis. The absence of reformulation or interpretation makes it seem algorithmic rather than human-like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 4.5\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The model's response is a highly coherent and logical sequence that aligns well with the provided context. It maintains the flow of the dialogue, reflecting the information consistently and accurately as given. The response is complete in covering most parts of the narrative but lacks some specific details (such as the patient's demographics and recommended actions) that were present in the true answer. The naturalness of the model's response is excellent, as it maintains a fluent, conversational, and human-like dialogue throughout the interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.8\n",
      "  - The model's response effectively retells the dialogue from the input text. It maintains logical consistency and alignment with the context provided. However, there is a minor discrepancy as the model did not mention the renal ultrasound findings or that the mother had to give water to the patient to stimulate diuresis.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response is largely complete, capturing key points regarding the patient's condition, medical history, evaluations, and treatment. However, it omits certain details such as the renal ultrasound findings and the specific mention of the mother's need to stimulate diuresis with water, which could provide more insight into the patient's case.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response sounds very fluent and human-like. It captures the natural flow and tone of a conversation between a doctor and patient, maintaining clarity and smoothness throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.5  \n",
      "  The model's response is not coherent as it incorrectly attributes dialogue lines to the wrong speaker and jumbled the sequence, creating confusion. The roles of Doctor and Patient are swapped and not preserved properly.\n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The response is incomplete as it fails to provide any coherent summary or reflection of the medical event described. It misses key details about the patient's diagnosis and treatment explained in the context.\n",
      "\n",
      "- Naturalness: 1.0  \n",
      "  The response lacks naturalness because it repeats the input dialogue without making logical sense or maintaining proper speaker roles, resulting in a robotic and nonsensical output.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response accurately replicates the input dialogue verbatim, which ensures complete alignment with the context.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - While the model's output accurately replicates the context and provides detailed information from the original conversation, it does not effectively summarize or condense the provided details as succinctly as the True Answer does.\n",
      "  \n",
      "- Naturalness: 5.0\n",
      "  - The conversation naturally flows, capturing a human-like interaction due to the verbatim repetition of the input dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context provided in the input. It consistently follows the progression of the conversation, addressing the key medical findings and patient interactions as described in the input.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response sufficiently answers the question posed in the input, providing a comprehensive overview of the patient's condition and test results. However, it does not mention some details present in the true answer, such as gestational diabetes and hypertension during pregnancy or specifics about the patient's head circumference and capillary refill time, which may be considered as minor omissions.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The model's response sounds fluent and human-like, effectively mimicking a conversation between a doctor and a patient. The dialogue is coherent, maintains a natural flow, and uses appropriate medical terminology as would be expected in a real-world clinical setting. There are no major issues affecting the naturalness of the conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response maintains a logical alignment with the context provided. It follows the conversation systematically and confirms key details back to the patient, which is consistent with the dialogue presented.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model sufficiently captures the main details outlined in the input and matches closely with the important elements from the true answer. However, it could have been slightly more informative by including details such as the results of other normal blood test results and the fact that images from the CT angiogram were unavailable.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response is fluent and appears quite human-like, maintaining a conversational flow typical of a medical consultation. However, the repetition of structured agreements (\"is that correct?\") might cause it to feel somewhat mechanical over an extended dialogue, slightly reducing the natural conversational feel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context provided in the input. It follows the dialogue format accurately and presents the sequence of medical events and actions taken by the doctor in a coherent manner.\n",
      "\n",
      "- Completeness: 5.0\n",
      "  - The model's response sufficiently answers the question by covering details about the patient's medical history, the medical findings, the diagnosis, and the treatment plan, matching the level of detail in the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response sounds fluent and human-like, maintaining a conversational tone appropriate for a doctor-patient interaction. The dialogues are structured well, and the language used is consistent with typical human communication in a medical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response is coherent with the dialogue context as it maintains the same sequence of conversation between the doctor and patient. However, the roles between doctor and patient are reversed at the start, which slightly affects the coherence.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The model's response captures some details from the true answer, such as the timeline of the skin condition and the treatment administered. However, it lacks contextual specifics like the mention of allopurinol tablets, specific laboratory data, and the treatment regimen details, which are present in the true answer.\n",
      "  \n",
      "- Naturalness: 4.5\n",
      "  - The dialogue flows naturally, and the language used is human-like and fluid. The reversal of roles affects the initial naturalness but the rest of the conversation maintains a natural and realistic exchange.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response repeats large portions of the input verbatim. While it aligns with the context by restating the dialogue, it fails to interpret or summarize the content in a meaningful way, and the abrupt switch to an incomplete conversation without the initial query appears illogical.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The model does not sufficiently answer the question. It mainly copies the dialogue without addressing the specific medical findings or summarizing the case contextually.\n",
      "\n",
      "- Naturalness: 2.5\n",
      "\n",
      "The copied dialogue sections are naturally phrased since they mirror human conversation, but reusing this text verbatim without synthesis leads to a lack of fluency and engagement typical of a natural conversational response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns with the context provided in the input. It mirrors the structure and content of the initial conversation between the doctor and the patient, following the same flow and ensuring each part connects well with the previous and next parts.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model's response adequately repeats the doctor-patient dialogue but lacks the broader summarization and conclusions drawn in the true answer. While it covers all procedural steps and questions asked, it does not condense or provide the synthesis of information like the true answer does.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response sounds fluent and human-like. The exchanges between doctor and patient are well-structured and mirror natural conversational patterns without awkward phrasing or unnatural language.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context provided. It accurately follows the progression of the medical procedure described in the input and maintains consistent details throughout the dialogue.\n",
      "  \n",
      "- Completeness: 4.5\n",
      "  - The model's response provides a comprehensive answer by reiterating the medical details and procedures without omitting any critical points. While it mirrors the input conversation almost verbatim, it doesn't fully capture the succinct report-like details present in the \"True Answer,\" such as the patient's age.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The dialogue sounds fluent and conversational, maintaining a natural, human-like interaction between the doctor and the patient. The language used is appropriate for the context of a medical conversation, and the exchange feels realistic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is coherent as it follows the structure of the interaction between the doctor and the patient logically. The dialogue matches the context, but notably, it replicates the input rather than generating a unique response or summary.\n",
      "  \n",
      "- Completeness: 2.0\n",
      "  - While the model's response accurately reproduces the interaction between the doctor and the patient, it does not provide a clear and concise summary or an answer to any specific question. It misses key elements mentioned in the True Answer, such as additional findings from the family medicine specialist and the specific symptoms related to anxiety disorder.\n",
      "  \n",
      "- Naturalness: 5.0\n",
      "  - The dialogue sounds fluent and human-like as it mimics a natural conversation between a doctor and a patient, maintaining the expected format and tone of a medical consultation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context. It correctly mentions the patient's symptoms, the examination findings, the treatments administered, and the follow-up required. However, it misses a few nuanced details like acral paresthesias and specific descriptions of the symptoms, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response effectively covers the main points: the symptoms, diagnostic observations, treatment, and recovery timeline. However, it omits certain details such as the acral paresthesias, the exact treatment specifics involving nimodipine, and some specific test results (like index-nose test findings), which were mentioned in the context.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, presenting the information in a coherent sequence that would be typical of a clinical summary. There are no grammatical issues or awkward phrasings that would detract from its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is mostly coherent with the provided dialogue and reflects the essential details discussed. It accurately summarizes the patient's medical history, insulin regimen, complications, and recent mental health changes. However, it lacks the specific detail that the patient is a married female, mother of two children, which might be considered relevant depending on the context of the information needed.\n",
      "\n",
      "- Completeness: 4.2  \n",
      "  The response sufficiently answers the question and covers the crucial aspects of the patient's situation, including the details of the insulin treatment and complications associated with their condition. However, it omits some specific details mentioned in the true answer, such as the patient's age, family details, and specific incidents of hypoglycemic comas, which if included, could provide a fuller understanding of the patient's situation.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The language used in the model's response is fluent and human-like. It uses professional medical terminology appropriately, creating a response that sounds like it could come from a healthcare professional summarizing a patient's case. The sentence structure flows naturally, enhancing readability and understanding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response generally aligns with the context provided in the input. However, it mistakenly switches the roles of the patient and doctor at the beginning, which might confuse the coherence slightly.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model's response covers most of the details provided in the \"True Answer\". However, it omits the part related to cerebrospinal fluid (CSF) analysis being performed, which was mentioned towards the end of the \"True Answer\".\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The model's response is mostly fluent and sounds human-like. The dialogue is mostly clear and maintains a medical professional tone. The initial role switch disrupts this naturalness slightly, but the flow is otherwise maintained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "\n",
      "The model's response is incoherent. It reversed the roles of doctor and patient, presenting patient statements as responses from the doctor and vice versa. Additionally, the sequence of information is jumbled, leading to illogical exchanges that do not align with the context provided in the input.\n",
      "\n",
      "- Completeness: 1.0\n",
      "\n",
      "The model fails to provide a coherent and complete answer to the input context and questions. The response does not summarize or extract relevant data from the input as expected, nor does it address the medical context or any follow-up appropriately.\n",
      "\n",
      "- Naturalness: 2.0\n",
      "\n",
      "Although the language used in individual sentences may appear to be grammatically correct, the overall structure and dialogue flow are unnatural due to the incorrect role designation, which negatively impacts the naturalness of the conversation. Overall, it lacks the fluency and human-like quality expected in a coherent dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0 \n",
      "   - The model's response aligns logically with the context provided, maintaining a consistent narrative throughout the interaction.\n",
      "\n",
      "- Completeness: 4.5\n",
      "   - The model's response is generally complete, providing sufficient information to answer the patient's question. However, it does not explicitly address some clinical details like the absence of febrile illness or constitutional symptoms, which are present in the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "   - The model's response sounds fluent and human-like, closely resembling the tone and structure of a typical doctor-patient conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the evaluation metrics provided, here is the assessment of the model's response:\n",
      "\n",
      "- **Coherence: 2.0**\n",
      "  - The model's response lacks coherence as it simply reverses the roles of the doctor and patient, with each asking and responding to questions in the wrong context. This switch breaks the logical alignment with the scenario where the doctor should be providing medical insights and the patient should be providing personal and medical information.\n",
      "\n",
      "- **Completeness: 1.0**\n",
      "  - The response doesn't sufficiently answer any explicit question or provide a meaningful summary of the situation. Instead, it is a mere role reversal dialogue that leaves out critical aspects of the medical condition or care advice from the initial scenario.\n",
      "\n",
      "- **Naturalness: 3.0**\n",
      "  - Although the dialogue reads fluently, it doesn't make sense due to the reversed roles. The language used is natural and human-like, which slightly compensates for the lack of context-appropriate content. However, this artificiality reduces its effectiveness as a conversation within the given context.\n",
      "\n",
      "Overall, the model's response lacks relevancy and correctness due to the incorrect exchange between roles, significantly affecting coherence and completeness, while it maintains a moderate level of syntactical naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response maintains logical alignment with the context. However, an incorrect age is reported for the patient (65-year-old male instead of a 52-year-old Sudanese man). This discrepancy slightly reduces coherence.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model's response provides a thorough summary of the conversation, capturing all key details and conclusions. The omission of the patient's nationality and minor details, like ‚Äúimpending conization‚Äù seen in the true answer, accounts for a slight deduction.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, effectively summarizing the patient's situation in well-constructed sentences. Minor issues in wording and slight verbosity prevent a perfect score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It reproduces the dialogue accurately with the progression of the conversation. However, it slightly lacks some specific details mentioned in the \"True Answer,\" such as the neurological examination and details regarding bilateral lower extremity findings.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model provides a comprehensive transcript of the patient-doctor interaction, capturing relevant symptoms, and laboratory findings. However, the response does not include all the clinical examination details present in the \"True Answer,\" such as the abdominal, respiratory, and cardiovascular findings, which might be crucial for a thorough understanding of the patient's condition.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is fluent and sounds human-like. It follows a natural conversational flow that is typical of a doctor-patient interaction, using language that medical professionals would likely use when discussing symptoms and lab results with a patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.5\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence**: The model's response is highly coherent, mirroring the conversation from the input with consistent details. The interaction between the doctor and the patient logically follows the sequence of symptoms and examinations.\n",
      "  \n",
      "- **Completeness**: The model captures a significant part of the conversation, but it stops too soon, omitting some final details present in the true answer, such as some patient-related specifics and the overall clinical overview. Therefore, it slightly lacks the full depth and breadth of the true response provided in the true answer.\n",
      "\n",
      "- **Naturalness**: The dialogue in the model's output flows naturally and reads like a conversation one might expect between a doctor and a patient. However, it's slightly repetitive due to how closely it mirrors the input, which may detract from the perception of a more varied natural dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response is entirely coherent with the provided input. The dialogue follows a logical progression, matching the context given in the input scenario.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response captures almost all critical points like the patient's conditions, symptoms, examinations, and the outcome. However, it omits minor details such as the patient's vomit absence mentioned in the True Answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response sounds fluent and human-like. The conversation flows naturally, maintaining an appropriate tone and structure expected within a doctor-patient interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 4.5\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "- **Coherence (4.5)**: The model's response logically aligns with the context provided in the input. It captures most of the key interactions and events described in the conversation between the doctor and the patient. The sequence of events is accurately reflected, from the diagnosis to the management plan. However, the response misses minor details, such as the specific timeline after the surgery, which might marginally affect the coherence score.\n",
      "\n",
      "- **Completeness (4.0)**: The model's response sufficiently answers the question by summarizing the progression from diagnosis to treatment and follow-up care. However, it lacks some specific details present in the true answer, such as the initial condition of neuropathy and advanced cellulitis. It also doesn't mention the patient's age and medical history details, which slightly affects its completeness.\n",
      "\n",
      "- **Naturalness (4.5)**: The response is fluent and sounds human-like, effectively articulating the sequence of care. The language used is clear and mirrors the type of summary one might expect from a medical professional's report. There are no grammatical or syntactical errors that disrupt the natural flow of the summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 3.5\n",
      "\n",
      "**Coherence**: The model's response has several inaccuracies. For instance, it incorrectly implies that the surgical procedure directly led to the development of diabetes insipidus and delirium, whereas these occurred during the postoperative course. Additionally, the model incorrectly reports that the patient passed away, which is not mentioned in the provided context. These issues detract from the coherence of the response.\n",
      "\n",
      "**Completeness**: The model captures some of the key events, such as the development of diabetes insipidus and the cardiac arrests, but it omits significant details like the patient's medical history, pre-surgery evaluations, and does not mention some crucial events like the emergency head CT scan and cardiac ultrasound findings. Therefore, the response is not entirely complete in summarizing the situation.\n",
      "\n",
      "**Naturalness**: The response is fairly fluent and human-like but could be improved. The language used is mostly appropriate for a medical context, but the statement regarding the patient's death is abrupt and could be phrased more empathetically. There's also a lack of some necessary transitional language to guide the reader smoothly through the events.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response is coherent in terms of how it replicates the context of the original interaction between the doctor and the patient. However, it does not provide the necessary synthesized information in a format typical for a QA task or a summary. It seems more like a repeated reiteration without processing or reformulating based on the input.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  The model's response effectively fails to provide a cohesive and complete answer or summation of the input data. It repeats the interactions verbatim rather than integrating and summarizing information into a distinct, comprehensive response such as the \"True Answer,\" which distills and summarizes the scenario.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The model's response is natural and human-like, maintaining the flow of conversation in a typical dialogue fashion. It resembles a natural conversation between a doctor and a patient but lacks transformation or summarization as expected in a QA task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the input context, maintaining the sequence and flow of the conversation between the doctor and the patient. All details are consistent with the provided dialogue.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The model's response sufficiently captures the interaction between the doctor and patient, repeating most of the provided context. However, it lacks some detail present in the true answer, such as the patient's age and the specific discussion of microbiologic cultures, which were not sent.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response sounds fluent and human-like, accurately replicating the conversational exchange between the doctor and patient without any awkward phrasing or grammatical issues.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response aligns perfectly with the context provided in the input. It maintains the dialogue's flow naturally without deviating from the original content.\n",
      "  \n",
      "- Completeness: 4.5\n",
      "  - The model reproduces the dialogue comprehensively. However, it does not include some specific details like the patient's age, smoking index, occupation, or previous spirometry results, which were present in the true answer. These details might not be necessary for a summary of present conversation but are useful for a complete medical report.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response sounds fluent and human-like. The dialogue maintains a conversational tone that is appropriate for the interaction between a doctor and a patient in a clinical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "\n",
      "The model's response shows role reversal, as the patient and doctor roles are swapped in the conversation context. This leads to a major logical misalignment, as doctors should be diagnosing and patients expressing symptoms, not the other way around. The dialogue does not make logical sense within the context of a patient-doctor consultation.\n",
      "\n",
      "- Completeness: 1.0\n",
      "\n",
      "The model's response does not address the true answer appropriately. It does not correctly identify or summarize the clinical information such as the patient's medical history, diagnosis, or treatment. As such, it fails to provide an adequate or relevant answer to the prompts in the input.\n",
      "\n",
      "- Naturalness: 2.0\n",
      "\n",
      "The dialogue structure of the response appears fluent and grammatically correct, similar to natural human conversation. However, the reversal of roles and illogical progression of the conversation reduces the perceived naturalness, as it deviates significantly from realistic human interactions in a medical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is mostly coherent with the context provided, accurately reflecting the key points of the doctor-patient conversation, such as the patient's cancer diagnosis, diabetes, and treatment history. However, it lacks some specific details present in the conversation, such as the precise medical procedures and timeline, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The model's response captures some essential aspects of the input, like the patient's diagnosis and ongoing treatment discussion. However, it omits significant details about the specific medical history, procedures performed, and the timeline of events, reducing its overall completeness. \n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response is fluent and human-like, paraphrasing the conversation naturally without any awkward phrasing. It is written in a clear and concise manner that sounds professional and appropriate for a medical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 5.0\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The model's response is highly coherent, as it logically aligns with the context provided and maintains consistency with the information shared between the doctor and patient. It is thorough and complete in addressing the patient's condition, explaining the connection to Cushing's syndrome and outlining potential long-term effects. The dialogue sounds fluent and natural, mimicking a genuine and empathetic conversation between a doctor and patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  \n",
      "  The model's response logically aligns with the context provided in the input. It accurately follows the flow of the conversation between the doctor and the patient, capturing the essential details about symptoms, tests, and proposed next steps. Minor deductions come from a lack of detailed explanation of why continuous monitoring was recommended.\n",
      "\n",
      "- Completeness: 4.0 \n",
      "\n",
      "  The model's response sufficiently answers the question by summarizing the interaction, including key points about the symptoms, previous diagnoses, and treatments. However, it omits certain details present in the true answer, such as specific temperature values and test outcomes, which would offer more depth.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "  The response is fluent and human-like, maintaining a consistent and professional tone that mirrors how a doctor might summarize a patient consultation. It clearly organizes the information, making it easy to follow. Minor deductions are due to the slightly mechanical listing of events without much variation in sentence structure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response reproduces the dialogue exactly as given in the input, showing strong coherence in terms of aligning with the context. However, the response does not show synthesis or summarization of information which might indicate a deeper understanding of the input context beyond mere repetition.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - While the model's response replicates all parts of the dialogue, it does not provide a summary or distillation of the patient's medical history or current condition as a coherent narrative that would sufficiently answer a question about the patient's case. The \"True Answer\" is a summarized and informative version, which the model fails to offer.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "  - The response successfully replicates the human dialogue provided in the input, maintaining fluency. However, being an exact repetition without transformation or summarization suggests a lack of sophistication in conversational dynamics or nuanced understanding present in more advanced human-like communications.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is highly coherent as it logically aligns with the provided input. It accurately summarizes the patient's situation and the doctor's advice. However, there's subtle redundancy as it repeats much of the information already established in the conversation, which some might find slightly misaligned with the purpose of a condensed summary.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The model's response covers most of the critical information discussed between the doctor and the patient, such as the UTIs, type 2 diabetes, Candida infection, glycosuria, and treatment plans. However, it omits mentioning the age of the patient and explicitly saying there were no leukocytes or bacteria in the urinalysis, which are present in the true answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is mostly natural and human-like, especially in its direct reproduction of the patient's dialogue and its fluid recapitulation of the doctor's advice. However, the inclusion of both the doctor‚Äôs and patient‚Äôs perspectives in one speech block may slightly affect the natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response is coherent and logically aligns with the context provided in the input. It accurately continues the dialogue without introducing inconsistencies or irrelevant information.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response is mostly complete in terms of capturing the essential interactions and medical information discussed. However, it lacks detailed information from the True Answer, such as specific findings from the biopsy and further medical examination results.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response maintains a fluent and human-like quality throughout the dialogue. The language used is appropriate for a medical setting, and the interaction feels natural for a doctor-patient conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns well with the context provided in the dialogue. It accurately captures the sequence of events and the clinical details provided by the doctor. However, it incorrectly states the patient's age as 70 years old instead of 73, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model‚Äôs response covers most of the key points mentioned in the true answer, such as the history of hypertension and type II diabetes mellitus, the major medical events (e.g., headache, loss of consciousness, cardiac arrest), vital signs, and test results. However, it omits some nuanced details like the role of caretakers or return of spontaneous circulation and does not mention the nausea and vomiting, which provides a fuller picture in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model‚Äôs response is fluent and reads like a well-crafted clinical summary. It uses appropriate medical terminology and sentence structure, making it sound professional and human-like. However, in the context of an interactive dialogue, maintaining the narrative could make it sound more direct and conversational.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the context of the conversation. It accurately captures key elements mentioned in the dialogue, such as the symptoms, diagnosis, and treatment. However, it could slightly improve by including some additional details from the conversation, like the patient's auditory hallucinations.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response addresses the main components of the medical discussion: symptoms, diagnosis, treatment, and management advice for Type 2 diabetes. However, it omits specific details found in the true answer, such as the patient's IQ level, the exact dosage of medications, and further background information provided in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent and sounds human-like. It presents the information clearly and logically without awkward phrasing, reflecting a natural manner of communication typically found in clinical summaries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "To evaluate the model's response based on the provided metrics, here's the analysis:\n",
      "\n",
      "1. **Coherence**: The model's response is coherent with the input in terms of the sequence of conversational exchanges between the doctor and the patient. It effectively mirrors the back-and-forth communication as presented and maintains logical consistency throughout. However, it misses the inclusion of additional background details mentioned in the true answer, such as the patient's age and specific demographic and personal health information (e.g., smoking status, the regularity of menses, and childbirth history), making it feel like an incomplete record when compared to a comprehensive case description. \n",
      "   \n",
      "   - Coherence: 4.0\n",
      "\n",
      "2. **Completeness**: The model's response captures the primary elements of the conversation, including the symptoms, family history, and a preliminary diagnosis regarding cancer cells affecting the right eye. However, it lacks additional context provided in the true answer, which includes detailed demographic information and a more thorough medical background. This exclusion affects the response's completeness in representing the entire case. As such, while the model effectively answers the immediate questions posed in the dialogue, it falls short of encompassing the full scope of the true answer.\n",
      "\n",
      "   - Completeness: 3.5\n",
      "\n",
      "3. **Naturalness**: The dialogue in the model's response flows smoothly and resembles a realistic doctor-patient interaction. The responses are not only logically structured but also use language that would be typical in a clinical setting. The model effectively mimics human-like conversation, maintaining a natural and empathetic tone, especially in the sensitive context of discussing a cancer diagnosis.\n",
      "\n",
      "   - Naturalness: 4.5\n",
      "\n",
      "Overall, the model's strengths lie in maintaining a logical and natural conversational structure, but it could benefit from integrating more detailed information to enhance completeness and fully encompass the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is coherent and follows the logical progression of the conversation between the doctor and the patient. It captures the dialogue accurately, although there is a minor deviation with the initial greeting being incorrectly attributed in the response.\n",
      "  \n",
      "- Completeness: 3.5\n",
      "  - The model provides a detailed replay of the interaction between the doctor and patient, which covers all relevant points discussed in the input, except it doesn't explicitly state the patient's age, which is present in the true answer. The level of detail about the symptoms and treatment progression is sufficient.\n",
      "  \n",
      "- Naturalness: 4.8\n",
      "  - The model's response is very natural and human-like. It appropriately switches speakers and uses language fluently in a conversational manner closely mimicking real-world dialogue scenarios. The only unnatural aspect is the initial greeting confusion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.5\n",
      "- Naturalness: 5.0\n",
      "\n",
      "**Evaluation Explanation**:\n",
      "- **Coherence**: The model's response generally maintains a coherent flow by accurately capturing the sequence of events and medical conditions described in the input dialogue. However, there is a minor lack of specific detail compared to the true answer, resulting in a slight deduction.\n",
      "- **Completeness**: The model provides a comprehensive account of the medical history and condition, but lacks specific details such as the patient's age and ethnicity. It misses a slight level of detail found in the true answer (e.g., nadir of thrombocytopenia and physical examination results).\n",
      "- **Naturalness**: The dialogue generated by the model is very natural and human-like, mirroring the professional tone and structure one would expect in a doctor-patient conversation, earning it the full score in this category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided conversation between the doctor and the patient, and comparing it to the true answer, here are the evaluations for each metric:\n",
      "\n",
      "- **Coherence: 4.5**\n",
      "  - The model's response maintains good coherence by closely following the sequence of events and exchanges that happened in the initial conversation between the doctor and patient. Most details, such as medical history, test results, and treatments, align well. However, small contextual nuances, like the initial trimester of the twin pregnancy with G1P0 detail, are missing.\n",
      "  \n",
      "- **Completeness: 4.0**\n",
      "  - The model's response is quite complete in terms of replicating the conversation accurately. It captures most of the essential information, but some details like the patient's specific age and the medical terms \"G1P0\" are omitted. These minor omissions affect the level of detail that supplements the context.\n",
      "  \n",
      "- **Naturalness: 4.5**\n",
      "  - The dialogue within the model's response sounds fluent and human-like, maintaining a conversational tone consistent with the original conversation. The flow between questions and answers appears natural, though it doesn't include additional human-like nuances or emotional elements beyond what was originally given.\n",
      "\n",
      "Overall, the model replicated the original conversation accurately with good coherence and naturalness but was slightly less complete with minor missing details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0 \n",
      "  - The model's response maintains a strong logical alignment with the context provided in the input. It accurately replicates the sequence of events and medical findings as described in the patient-doctor interaction. The chronological order and the details of medical procedures and outcomes are consistent with the input scenario.\n",
      "  \n",
      "- Completeness: 4.5 \n",
      "  - The model's response adequately answers the question posed by the input. It covers the main events and outcomes, including the medical history, test results, and subsequent treatments, leading to the patient's adverse event. However, there is a slight lack of detail in terms of specific measurements and findings that are present in the \"True Answer\" but not in the model's response, such as specific measurements of the RCA aneurysm and the exact nature of the LAD plaque.\n",
      "\n",
      "- Naturalness: 5.0 \n",
      "  - The response is very fluent and sounds human-like. The language used is appropriate for a medical conversation between a doctor and a patient/family, and it handles the sensitive situation of the patient's death with professionalism and compassion. The dialogue flows naturally and mimics real doctor-patient interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the context, accurately recounting the series of medical events and treatments described in the input. Some minor discrepancies in specific details, such as the omission of \"tiger hide\" appearance and the age of the patient, prevent it from achieving a perfect score.\n",
      "\n",
      "- Completeness: 4.3  \n",
      "  The response covers most key elements of the case, including the symptoms, diagnostic procedures, surgeries, and treatments. However, it lacks specific details, such as the exact description of the brain herniation appearance (\"tiger hide\") and the age of the patient, which could provide a more comprehensive answer.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluently written and maintains a coherent narrative structure that is typical of a medical case summary, closely resembling human communication. Minor improvements in fluency and conciseness could be made for a perfect naturalness score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response is almost an exact repetition of the input, indicating perfect alignment with the context. All elements match the conversation context provided.\n",
      "  \n",
      "- Completeness: 2.0\n",
      "  - The model's response replicates the dialogue without summarization or conclusion insights. This approach doesn‚Äôt succinctly capture the essence of the patient‚Äôs information as the ‚ÄúTrue Answer‚Äù does. It lacks the coherent narrative and additional details seen in the \"True Answer\".\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response is coherent and natural since it follows the provided conversation verbatim, making it sound fluent and very human-like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response aligns well with the context provided. It accurately reflects the sequence and details shared in the dialog about the patient's condition and medical treatment, including the pituitary mass, the surgical approach, and the outcomes.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  - While the model addresses the primary elements of the patient's medical situation‚Äîsuch as the discovery and removal of the pituitary mass, postoperative conditions, and treatments‚Äîit omits several specific details, including the initial cause for the MRI, specifics of the endocrine evaluations, and the details of the neuro-ophthalmology testing. The final pathology result mentioned in the model's response aligns with the incomplete information given, although more detail was expected.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  - The language used by the model is generally fluent and clear, though somewhat structured and technical, akin to a medical report rather than casual conversation. It could benefit from slightly more human-like language but maintains a professional tone appropriate to the context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0 - The model's response closely follows the dialogue and logically aligns with the context provided in the input. It maintains the sequence of the interaction accurately.\n",
      "- Completeness: 3.5 - While the model captures the entirety of the conversation, it simply replicates the input dialogue without synthesizing or distilling information as the true answer does. It doesn't focus on key aspects like the patient's age and summary of findings.\n",
      "- Naturalness: 5.0 - The model's response is a verbatim repetition of the input dialogue, ensuring fluency and human-like conversation.\n",
      "\n",
      "Overall, while the model replicates the input accurately in terms of coherence and naturalness, it lacks completeness by not summarizing or condensing the interaction effectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "\n",
      "The model's response introduces significant discrepancies with the original context. For instance, the patient in the context is a 59-year-old female, whereas the model refers to a 45-year-old male. Additionally, the model claims that the wound is 4 months old, while in the original context, the lesion healed within 2 weeks and the follow-up period was 4 months. These inconsistencies impact the coherence of the response.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The response captures some key elements, such as the use of cefazolin sodium and silver sulfadiazine cream, and the eventual healing of the wound. However, it misses specific details like the identification of the plant as Ranunculus arvensis and the fact that the wounds were circumferential around both knees, not just the left knee. This incomplete depiction affects the overall completeness.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response uses fluent, well-structured language and accurately mimics a human-like narrative. There are no awkward or unnatural phrasings, and it reads smoothly as a clinical recounting. Therefore, it scores high in naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response maintains logical consistency with the context provided. The dialogue mirrors the input context but flips the roles of Doctor and Patient, which can be seen as a lack of awareness of the expected format of the response. However, it reproduces the conversation detail accurately.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The model repeats the input conversation verbatim instead of synthesizing or summarizing the information given. It does not directly address the content expected in the \"True Answer,\" which includes providing a condensed summary of the situation from a third-person perspective rather than a repetition of the dialogue.\n",
      "\n",
      "- Naturalness: 2.0\n",
      "  - While the repeated dialogue itself is human-like in terms of language, the role reversal and failure to produce a narrative summary diminish its naturalness. The response seems like a mechanical reproduction of input rather than generating a fluent and human-like summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model‚Äôs response logically aligns with the context provided, as it consistently references the patient's medical history, surgical details, and postoperative observations in a manner that accurately reflects the input.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model‚Äôs response addresses the main aspects of the patient's history and surgery. However, it omits specific details mentioned in the true answer, such as the patient's age, BMI, and certain nuances in the surgical process or examination results that are not explicitly queried by the doctor during the conversation.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response sounds fluent and human-like, resembling a natural conversation between a doctor and patient. It uses appropriate language and maintains a coherent dialogue flow similar to the input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 4.8\n",
      "- Naturalness: 5.0\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "- **Coherence:** The model's response is fully coherent with the context provided. It accurately reflects the dialogue and incorporates the details from the input scenario. The sequence of events and conversations flow logically.\n",
      "\n",
      "- **Completeness:** The model's response is very complete, capturing the majority of the important details from the input, such as the vital signs, medical history, examination findings, and treatment steps. It only slightly lacks specificity around improvement after hydration which was mentioned in the true answer but not in the model's dialogue.\n",
      "\n",
      "- **Naturalness:** The conversation sounds natural and human-like, maintaining a consistent tone and style typical of a doctor-patient interaction. The language used is clear and fluently conveys medical information in an understandable manner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response is a direct reflection of the input context. It follows the conversational exchange logically and maintains consistency with the information presented in the input.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - While the model's response accurately presents the conversation from the input, it does not transform this dialogue into a concise summary similar to the \"True Answer.\" The key details are all mentioned, but the information isn't extracted or reformulated into a cohesive singular description.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The dialogue presented in the model's response is fluent and human-like. The conversation appears natural without any language errors or awkward phrasing, maintaining the tone of a real doctor-patient interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 3.5\n",
      "\n",
      "**Coherence**: The model's response contains a general summary of the conversation but lacks specifics. While it aligns with the context of providing a summary, it doesn't address the detailed information exchanged between the doctor and patient, such as exact test results and symptoms.\n",
      "\n",
      "**Completeness**: The response is vague and lacks detail. It doesn't provide specific information about the patient's condition or the tests conducted as seen in the true answer. Key aspects, like the patient's medical history or the test results, are not captured.\n",
      "\n",
      "**Naturalness**: The response generally maintains a professional tone and sounds structured, which aligns with a clinical summary. However, it reads more like a description of a process rather than a natural conversation or detailed note.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  *Explanation*: The model's response provides a general overview but lacks specific details mentioned in the input conversation. It doesn't fully reflect the sequence and specificities of the patient-doctor dialogue. It is somewhat coherent but misses contextual alignment due to its vagueness.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  *Explanation*: The response is lacking in detail, as it does not include key specifics such as the patient's demographic details, symptoms, family and medical history, or the exact details of the mental state examination that were discussed in the conversation. It refers to a structured note but fails to summarize the crucial points adequately.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  *Explanation*: The response is written in a natural and fluent manner, structured as a clinical note summary one might expect. However, it still maintains a somewhat generic tone that lacks personalization which was evident in the original conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response is coherent, as it logically aligns with the context provided in the input. All relevant information from the dialogue is presented accurately, following the sequence of the patient's symptoms and past medical history.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model's response thoroughly addresses the exchange between the doctor and patient, matching the input context. However, the recommendation for hospital admission based on the diagnosis of a severe infection could include more explanation about the potential infection types or initial treatment plans, which slightly affects the completeness.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response sounds fluent and natural, resembling a human-like conversation between a doctor and a patient. The language is professional and appropriately detailed, fitting the clinical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 5.0**  \n",
      "  - The model's response logically aligns with the context provided in the input. It accurately follows the interaction between the doctor and the patient, addressing the sequence of events and discussions in a logical order.\n",
      "\n",
      "- **Completeness: 4.5**  \n",
      "  - The model's response sufficiently answers the implied question of explaining the patient's situation and treatment plan. However, it lacks some specific details found in the true answer, such as the mention of cerebrospinal fluid (CSF) cultures and their negative result, and additional details on follow-up MRIs.\n",
      "\n",
      "- **Naturalness: 5.0**  \n",
      "  - The model's response is fluent and human-like, maintaining the conversational tone and structure of a typical doctor-patient dialogue. It reads naturally and is easy to understand from a human perspective.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response maintains a logical alignment with the context provided in the input. It accurately follows the dialogue between the doctor and the patient, reflecting the patient's medical history and current symptoms.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model's response effectively captures most of the details about the patient's condition, history, and current symptoms. However, it misses some details from the true answer such as the specifics of the patient's medication dosages and a few nuances of the medical history, like the specific response to treatment with viral load details.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response reads fluently and sounds human-like. The dialogue between the doctor and the patient is natural and consistent with real-life medical consultations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the context of the dialogue, providing a logically consistent summary of the conversation between the doctor and the patient. It follows the sequence of events and captures the main points discussed. However, it misses the mention of the patient's demographic details, which is a minor discrepancy.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response captures most of the essential elements such as the duration of symptoms, previous treatments, physical examination findings, and CT scan results. However, it omits the mention of the patient's demographic (age and ethnicity), specific symptoms like fever, diaphoresis, and weight loss, as well as the malodorous breath that was part of the true answer, which are crucial details necessary for a complete understanding of the context.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like. The wording is clear and resembles a natural patient-doctor summary discussion. It maintains a respectful and concise tone suitable for a healthcare setting. However, it slightly lacks variation in expression that might be seen in a real conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the context provided in the input. However, it repeats verbatim parts of the doctor-patient conversation from the dialog instead of rephrasing or summarizing it, which can suggest a lack of depth in understanding the context fully. \n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The model's response does not fully cover important aspects mentioned in the true answer. It misses specific details from the true answer such as the patient's age, ethnicity, HIV status, management of HAART therapy, and detailed lab findings (e.g., phosphorus levels, fractional urinary phosphorus excretion). It also leaves out the progression and outcomes after medication adjustments.\n",
      "\n",
      "- Naturalness: 3.0  \n",
      "  The response is generally fluent and reads somewhat naturally since it mimics a conversation format, but it heavily relies on copying the dialogue from the input. This verbatim repetition may detract from the natural flow and adds no new human-like explanation or summary, limiting its perceived naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 5.0\n",
      "\n",
      "Explanation:\n",
      "\n",
      "- **Coherence**: The model's response follows the dialogue and logically aligns with the context provided in the input. There is no apparent deviation or non-sequitur in the conversation. Thus, coherence is rated highly at 4.5.\n",
      "\n",
      "- **Completeness**: The model's response does well in mirroring the input dialogue, but it lacks the depth and additional context found in the true answer, such as the patient's background and the noted medical history related to his travels and past medical incidents. The response does not mention the patient's background, travel, or history of sporotrichosis, which are relevant details in the true answer's context. Therefore, the completeness score is lower at 2.0.\n",
      "\n",
      "- **Naturalness**: The model's response is very fluent and reads like a natural continuation of a typical patient-doctor dialogue. The language used is appropriate for the medical setting, and the sentences flow smoothly. Hence, the naturalness score is high at 5.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response exhibits high coherence with the input context. It accurately follows the format and flow of the conversation between the doctor and the patient, maintaining logical consistency throughout. However, it does not include the detail about the patient's uncontrollable anger when mentioned by the family, which might have provided a slightly more rounded understanding.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model's response essentially mirrors the input, repeating much of the dialogue without synthesizing or summarizing it into a more comprehensive answer. It misses providing some background context such as the fact that the patient requested the transfer, was initially seen at another hospital, and the additional input from his family regarding his behavior, resulting in a less complete response compared to the true answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The conversation sounds fluent and human-like. The dialogue reads naturally and maintains a conversational tone appropriate to a medical setting, suggesting high naturalness in the model's output.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response aligns well with the context provided in the input. The doctor-patient interaction follows a logical progression based on the medical history and examination details supplied. The model maintains consistency with the information exchanged during the interaction.\n",
      "  \n",
      "- Completeness: 4.5\n",
      "  - The model's response provides a comprehensive recount of the patient's medical history and the current situation. However, the true answer offers additional specifics regarding the dosages and dates that are not fully captured by the model. It conveys the necessary steps taken medically but lacks some detailed background provided in the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The conversation portrayed by the model is fluent and natural, mimicking a real-life interaction between a doctor, patient, and the family. The language used is human-like and appropriate given the gravity and sensitivity of the situation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response is coherent in terms of structure and sequence but lacks significant details compared to the true answer. The response correctly captures the dialog format but mimics the provided input rather than summarizing the key information.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "While the model's response accurately repeats the original input conversation word-for-word, it is incomplete concerning summarizing the patient's medical condition. The true answer provides a detailed summary of the patient's medical status and examination findings, while the model's output merely reproduces the conversation without extracting or summarizing relevant data.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The model's response is perfectly natural and fluent, as it matches the input dialogue verbatim. The conversation sounds human-like and retains the natural flow present in the input exchange.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response accurately mirrors the conversation structure and content of the input scenario. It maintains logical consistency with the progression of the patient's medical history and treatment details.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response thoroughly covers the details provided in the input. However, it stops without addressing the final section concerning the referral to the clinic and additional tests in October, which was included in the true answer. This slight omission impacts the completeness rating but only minimally since the primary details are thoroughly addressed.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The dialogue between the doctor and patient in the model's response is fluent and mirrors a realistic conversation in a clinical setting. The language used is clear and human-like, maintaining an appropriate tone for a medical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response follows the dialogue logically, maintaining consistency with the patient's medical history and the sequence of events described by the doctor.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model's response covers the key aspects of the input, but it is quite verbatim to the input context rather than paraphrasing or summarizing. It repeats the dialogue rather than providing a concise answer like the true answer does. For completeness as a response on its own, it would benefit from being more succinct.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "  - The model's output is not a naturally flowing and coherent response for a question-answering setting; it's a direct rehash of the dialogue in the input. While it retains the original structure and phrasing, this doesn't sound human-like for a summarization or standalone answer as it lacks brevity and synthesis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 4.5\n",
      "- Naturalness: 4.8\n",
      "\n",
      "**Coherence**: The model's response accurately replicates the dialogue from the input, maintaining logical consistency and adherence to the details provided in the context. Therefore, it scores a perfect 5.0 for coherence.\n",
      "\n",
      "**Completeness**: The model's response effectively conveys the interactions between the doctor and the patient. However, the response could include more explicit details available in the true answer, such as the explicit mention of the patient's age and some additional lab results, which slightly reduces the completeness score.\n",
      "\n",
      "**Naturalness**: The dialogue generated by the model flows well and resembles a human-like conversation between a doctor and a patient. Thus, it is rated at 4.8 for naturalness. The repetition of the input text, while perfectly natural, prevents a higher score in a situation where a model-generated summary is compared against a descriptive true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response logically reflects the context of the conversation. It provides a coherent summary of the doctor-patient interaction and includes key points such as the patient's symptoms, past medical history, and the doctor's plan for testing and monitoring. However, it slightly simplifies and omits some detailed specifics that are present in the input.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The response captures several important aspects of the conversation, including the patient's symptoms, diagnosis, and medical history, as well as some of the medications. However, it lacks detail on the full scope of the medical history and specific treatments, such as chemotherapy cycles and the past surgical history, that are detailed in the input. Consequently, the essence of the discussion is shortened, leading to a somewhat incomplete picture.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response is fluently written and human-like, maintaining a natural summary style. It delivers information in a manner that is easy to understand and reflects a typical summary one might expect from a human summarizer, although some specifics are condensed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically consistent with the input context, as it accurately reproduces the conversation between the doctor and patient. However, slight discrepancies in the medical narrative, such as not mentioning immunosuppression, slightly affect coherence.\n",
      "\n",
      "- Completeness: 4.7  \n",
      "  The model's response captures the entire dialogue, covering all critical points of the patient's medical history and clinical course. It misses some detailed medical information present in the true answer, such as the specific age and medication names, but it doesn't affect the overall understanding substantially.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is fluent and reads very naturally, similar to a real-life doctor-patient conversation. The responses are appropriately structured and maintain a human-like quality throughout the exchange.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response is logically aligned with the context provided in the input. It follows the sequence of the interaction between the doctor and the patient and maintains consistency in the medical information given.\n",
      "\n",
      "- Completeness: 5.0  \n",
      "  The model's response thoroughly covers the dialogue presented in the input. It captures all the relevant details from the patient's medical history, symptoms, investigation results, and subsequent treatment steps, thereby sufficiently answering the associated questions.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response sounds fluent and human-like. The interactions between the doctor, patient, and patient's family are natural and mimic a real-life clinical setting, maintaining an appropriate level of professionalism and empathy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is generally coherent and aligns well with the patient's comments in the input, particularly focusing on the most recent concerns of polyuria, polydipsia, and the diabetes insipidus diagnosis. However, it does not reflect the full scope of the medical history discussed in the dialogue.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model's response addresses some key aspects of the patient's concerns, such as the current symptoms and recent diagnosis. However, it lacks details about the patient's cancer treatment history and other medical conditions, which are crucial elements of the complete medical narrative.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The response sounds reasonably fluent and human-like but could be improved with a bit more nuance in language or phrasing to resemble natural conversational patterns. The structure is straightforward, maintaining clarity and directness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is coherent and aligns well with the context provided in the input. It repeats the conversation between the doctor and the patient accurately. However, it does not provide all the details from the true answer, which might affect the overall coherence slightly if additional context is crucial.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The model's response sufficiently answers the patient's question about laboratory findings but lacks some detailed information from the true answer, such as measurements for various parameters and additional historical data like insulin use, family medical history, and specifics of the suicide attempt. These details could be important to fully address the implied question about the patient's health status comprehensively.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The dialogue provided by the model sounds fluent and human-like. The language and manner of speaking closely resemble natural conversation between a doctor and a patient, which enhances the naturalness metric.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response is mostly a repetition of the input conversation, rather than a new coherent response. It does not logically follow from the context as it mostly echoes the input. \n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The model's response does not sufficiently answer any posed question in the input. It repeats the dialogue instead of summarizing or offering insights on the procedure or diagnosis.\n",
      "\n",
      "- Naturalness: 1.0  \n",
      "  While the text itself is taken from the original dialogue and retains some natural phrasing, as a response, it sounds unnatural because repeating the entire conversation does not align with the expected output in a Q&A format. There is no transformation or adaptation, which makes it sound robotic rather than human-like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided in the input, repeating information about the diagnosis and examination that matches the details presented. However, it does not mention the patient's age or the lack of smoking, which are stated in the true answer context.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The response sufficiently answers the main points about the diagnosis of squamous cell carcinoma and the possible treatment options. Still, it lacks some specifics present in the true answer, such as the SUVmax values from FDG PET/CT, the lack of neck lymph node accumulation, and specifics regarding the histopathological findings for the tongue-base lesion.\n",
      "  \n",
      "- Naturalness: 5.0\n",
      "  - The dialogue flows naturally and sounds human-like, maintaining a conversational tone appropriate for a medical consultation. It effectively simulates a realistic doctor-patient interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context provided in the input, maintaining a consistent dialogue between the doctor and patient throughout the conversation.\n",
      "  \n",
      "- Completeness: 5.0\n",
      "  - The model's response sufficiently covers all the essential details present in the input dialogue and provides a comprehensive account of the medical case from admission to surgery, consistent with the true answer.\n",
      "  \n",
      "- Naturalness: 5.0\n",
      "  - The model's response sounds fluent and human-like, accurately mimicking the natural flow of a conversation between a doctor and patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "  - The model's response does not introduce a coherent summary and instead appears to repeat the patient-doctor conversation verbatim, without aligning the information logically with the context required for a summary. This limits its coherence with the task of summarizing the situation.\n",
      "\n",
      "- Completeness: 1.5\n",
      "  - The response does not effectively provide a standalone answer or summary that covers all the necessary details, observations, tests, and treatments that were described. It heavily relies on repeating the conversation without condensing or emphasizing the critical points from the interaction.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "  - The response does sound human-like since it mimics the format and responses of the dialogue accurately. However, because it is a repetition of direct speech rather than a synthesized answer, it lacks the compositional skill normally expected in a cohesive summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response aligns well with the context of the conversation. It accurately captures many key elements such as the patient's symptoms, history, and treatment approach mentioned in the input. However, there are a couple of inaccuracies, like the statement that the temperature of 36.6¬∞C is \"slightly elevated,\" which could have been clearer.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The model's response thoroughly covers most of the critical information from the input. It includes details on the patient's past medical history, the differential diagnosis considered, and the treatment provided. However, it does not mention some specific elements like the patient's age and ethnic background, which were part of the \"True Answer\".\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent and human-like, using appropriate medical terminology within a clinical context. It presents the information in a coherent and logical manner akin to what might be expected from a professional medical summary, although there might be minor room for improvement in phrasing for a natural narrative flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided input, model response, and true answer, here's the evaluation:\n",
      "\n",
      "- **Coherence: 4.5**  \n",
      "  The model's response is largely coherent with the context provided. It captures the essential details and sequence of events accurately. The logical flow from symptoms to diagnosis, treatment, and discharge aligns well with the input conversation. However, minor details such as the patient's gender and age are missing.\n",
      "\n",
      "- **Completeness: 4.0**  \n",
      "  The model provides a comprehensive summary of the events and medical findings. It includes most of the critical details, such as laboratory results, diagnosis, and treatment, but it misses some specifics like the patient's age, gender, and the prior history of nonspecific abdominal discomfort and weight loss. While these details don't directly impact the medical conclusion, they are pertinent to a complete patient profile.\n",
      "\n",
      "- **Naturalness: 4.7**  \n",
      "  The model's response is fluent and maintains a professional tone typical of a medical summary. It reads naturally and uses appropriate medical terminology, similar to how a healthcare professional would summarize a case. However, slight improvements could be made to enhance readability and engagement by including personal pronouns and a continuous narrative flow.\n",
      "\n",
      "Overall, the model performs well in capturing and summarizing the medical dialogue, with room for improvement in adding comprehensive personal details and enhancing linguistic engagement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 5.0\n",
      "\n",
      "**Coherence**: The model's response logically aligns with the context of the dialogue provided. It maintains the structure and flow of a coherent medical conversation between a doctor and a patient. The responses are consistent with the preceding dialogue.\n",
      "\n",
      "**Completeness**: The model's response repeats the conversation from the input almost verbatim. It does not address some specific details provided in the \"True Answer,\" such as the exact amount of insulin used or the specific regimen changes during hospitalization. Therefore, while the model captures the surface details of the patient's condition, it lacks some of the deeper details that were present in the true answer, leading to a lower score for completeness.\n",
      "\n",
      "**Naturalness**: The language used in the model's response is fluent and mimics a natural conversation between a doctor and a patient. The sentences are well-constructed and human-like, warranting a high score in naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "\n",
      "  The model's response logically aligns with the context provided in the input. It accurately reflects the conversations between the doctor and the patient, capturing the sequence of events and medical procedures described.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  \n",
      "  The model's response provides most of the essential information conveyed in the true answer. While it captures the details of the patient's medical history, symptoms, the echocardiography results, and the procedural challenges faced, it doesn't mention some specific details like the patient's age, the Fr size of the access points, or references to supplementary materials.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  \n",
      "  The model's response sounds fluent and human-like. The conversation is clear, with appropriate medical terminology, and it maintains a conversational tone that matches a real interaction between a doctor and a patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response does not correctly reflect the roles of the patient and doctor, as it has swapped the roles in parts of the dialogue. This disrupts the logical flow, making it inconsistent with the context provided.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - While the model's response includes much of the information from the scenario, it doesn't incorporate specific details provided in the true answer, such as the patient's age and history of hypertension. However, it still adequately covers the main events and medical actions described in the input.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The conversation in the model's response is generally fluent and human-like, with only minor unnatural aspects due to the role-swapping error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "\n",
      "The model's response is coherent and logically aligns with the context provided. The interaction between the doctor and the patient is consistent and follows the expected sequence of a medical consultation, discussing symptoms, treatments, and monitoring.\n",
      "\n",
      "- Completeness: 4.5\n",
      "\n",
      "The model's response mostly captures the essential information found in the true answer, such as the patient's symptoms, medical history, changes in medication, and treatments administered. However, it misses specific details like creatine kinase levels, ECG results, and dosing specifics, which slightly detracts from its completeness.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The dialogue between the doctor and the patient is fluent and human-like. The response captures the natural flow of a medical consultation, including the patient's reactions and the doctor's explanations, making it sound convincing and realistic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response is coherent as it logically follows the progression of the conversation between the doctor and the patient. It aligns well with the context given in the input, mirroring the interaction accurately.\n",
      "\n",
      "- Completeness: 4.5\n",
      "  - The response captures most of the essential details from the conversation, maintaining the flow and exchange of information. However, it does not explicitly mention some small details given in the true answer, like the patient's profession and the specific details from spirometry, which slightly impacts the completeness concerning the richer context provided in the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The dialogue in the model's response reads naturally, displaying fluency and a human-like quality. The conversation between the doctor, patient, and patient's family is smooth and reflective of how such interactions typically occur in a medical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns with the context provided. It accurately reflects the conversation between the doctor and the patient, maintaining the sequence and content of the dialogue.\n",
      "\n",
      "- Completeness: 5.0  \n",
      "  The model's response sufficiently answers the input question by covering the key information exchanged during the conversation between the doctor and the patient. It includes all necessary details regarding the patient's condition and the doctor's advice.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response sounds fluent and human-like, effectively mirroring the conversational tone and structure expected in a medical consultation. The dialogue feels authentic and natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response closely follows the nuanced conversation and maintains logical alignment with the context provided in the input. It captures the sequence and detail of the exchanges accurately.\n",
      "\n",
      "- Completeness: 5.0\n",
      "  - The model's response provides a comprehensive answer reflecting all the key elements present in the input. It conveys the full scope of the dialogue and outcomes, including the critical elements such as the patient's history, symptoms, diagnostics, treatment, and eventual outcome.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The language used in the model's response is fluent and mimics a natural conversation. It maintains a style and tone that is consistent with human dialogue, making it sound realistic and human-like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 2.0**  \n",
      "  The model's response is a verbatim repetition of the input dialogue rather than a logical, concise clinical note that captures the essential details of the conversation. It lacks interpretation and synthesis of the information, which undermines coherence, as it does not reflect the required clinical summary.\n",
      "\n",
      "- **Completeness: 1.5**  \n",
      "  The model's response technically covers the dialogue, but because it repeats the text rather than summarizing it, it misses opportunities to provide a synthesized view of the patient's condition, diagnosis, and treatment as seen in the true answer. Essential details such as the patient's initial complaints, medical history, specific investigation results, and the trajectory of the treatment and outcome are not clearly highlighted or structured in a clinical note format.\n",
      "\n",
      "- **Naturalness: 3.0**  \n",
      "  The model's response is fluent in terms of grammar and sentence construction, since it directly copies the dialogue. However, this does not fully match the natural style expected for a clinical note, which typically would not be verbatim repetition but instead a summarized and structured presentation of key medical information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌèâÍ∑† Ï†êÏàò:\n",
      "Coherence       4.273000\n",
      "Completeness    3.668000\n",
      "Naturalness     4.446000\n",
      "BLEURT          0.609452\n",
      "BERTScore_F1    0.543397\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# summarization\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "summarization = df[df['task'] == 'summarization']\n",
    "results = []\n",
    "\n",
    "for _, row in summarization.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns with the context provided. It addresses the high blood sugar levels and HbA1c values, emphasizing the importance of maintaining blood sugar control and offering general advice for managing diabetes.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the model's response provides general advice on diet, exercise, and the importance of following the doctor's prescription, it lacks specific medication recommendations or adjustments. The true answer suggests adding another medication (voglibose) and specifies a follow-up plan, which the model's response does not.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and human-like. It uses polite and empathetic language, addressing the patient directly and offering supportive advice, which contributes to its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context of the input, acknowledging the patient's concerns about insulin levels and advising consultation with a doctor. However, it introduces conditions like obesity or metabolic syndrome without direct evidence from the provided data, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response covers several potential factors that could affect insulin levels, such as stress and underlying health conditions, but it does not specifically address why pancreatic cancer is unlikely, which is a primary concern of the patient. It could provide more detailed reassurance or reasons why a pancreas MRI is not immediately necessary.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The language is fluent and human-like, showing empathy and providing a comprehensive response that feels conversational and genuinely concerned about the patient's well-being. It lacks minor personalization or specificity regarding the case details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "   The model's response is logically aligned with the context provided. It reviews the test results, discusses the conditions (macular hole, leakage in the retina), and links them to the patient's medical history of diabetes and high blood pressure. However, it deviates by making a specific treatment recommendation without additional context to justify the decision over the options mentioned in the query.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "   The model offers potential insights into the test results and provides a treatment recommendation. However, it doesn't address the specific treatments (Lucentis and Accentrix) that the two doctors suggested. It offers a separate recommendation (laser treatment for macular hole sealing) which might not align with the options provided by the medical professionals consulted. A complete answer would consider these treatments directly.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "   The response is fluent and human-like, with a polite and helpful tone. It demonstrates a good level of natural language use and maintains an empathetic tone typical of doctor-patient communications. However, the specific treatment recommendation without a broader discussion might slightly reduce the perception of its naturalness from a professional standpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response displays a logical alignment with the context provided. It addresses the issue of erectile dysfunction, mentions potential causes, and suggests consulting a doctor for further evaluation. However, it could have been more specifically aligned with the details about the history of the issue and previous medication usage noted in the input.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a broad overview of potential treatments and lifestyle changes for erectile dysfunction, which partially answers the question. However, it doesn't inquire about other health conditions like diabetes or hypertension, nor does it suggest specific medications like Tentex Forte as seen in the true answer.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and reads naturally. It uses a conversational and empathetic tone appropriate for a medical discussion, making it sound human-like. There is a minor use of repetitive phrasing (\"consult a doctor\"), but overall it maintains a clear and professional tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is coherent in addressing the concern about the white spots on the gums and suggests that they might not necessarily be related to diabetes. However, it doesn't mention the need to visually assess the gums, which is important for coherence based on the true answer's guidance.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The response provides useful general advice on maintaining oral and overall health, but it misses a specific recommendation to share images of the gums for a more accurate assessment, which is a key part of the true answer.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The response is fluent, polite, and human-like, maintaining a friendly and supportive tone throughout. It uses clear and natural language that closely resembles how a human might respond in a conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.0**  \n",
      "  The model's response is generally coherent and aligns logically with the context provided in the input. It acknowledges the user's symptoms and suggests further consultation with an orthopedic specialist, which is in line with the steps taken by the user previously. However, the model doesn't address some specifics mentioned in the input, such as the ineffectiveness of previously tried remedies or the specifics about elbow pain, which slightly detracts from its coherence.\n",
      "\n",
      "- **Completeness: 3.0**  \n",
      "  While the model provides a general recommendation to consult a specialist and to take over-the-counter pain relievers, it lacks specific advice on the treatment of frozen shoulder, which would include physiotherapy as expressed in the True Answer. It doesn't mention the possibility of diabetes or the need for further imaging like an ultrasound. These omissions make the response somewhat incomplete.\n",
      "\n",
      "- **Naturalness: 4.5**  \n",
      "  The response sounds fluent and natural, with a compassionate tone that is appropriate for medical interaction. It communicates suggestions in a clear and professional manner. There are no awkward phrasing or grammatical issues, so it sounds human-like and approachable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context of managing diabetes and suggest reasonable approaches to manage blood sugar. However, it doesn't directly mention or acknowledge the current medication (Tablet Glynase MF) the user is taking.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response provides general recommendations about monitoring, diet, exercise, medication, and lifestyle changes, it lacks the specificity in adjustments to medications which was present in the true answer. It doesn't recommend specific drugs like voglibose nor provide a follow-up plan.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, with polite language and structured guidance. It sounds professional and considerate, fitting for a healthcare context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "   The model's response is coherent and logically aligns with the information given in the input. It correctly identifies fatty changes in the liver and uterine fibroids, which are mentioned in the report. It also notes the importance of consulting a doctor for further evaluation, which is appropriate.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "   The response sufficiently addresses the main points of the input, such as the fatty liver, bulky uterus with fibroid, and elevated blood sugar levels, suggesting potential conditions and the need for medical consultation. However, it could improve by providing a more explicit mention of diabetes (Type II Diabetes Mellitus) and discussing the significance of the specific blood sugar level, as seen in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "   The response is fluent, clear, and maintains a reassuring and professional tone throughout, making it sound human-like and suitable for the context of a medical query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response logically aligns with the provided context, recognizing the symptoms of burning sensations in the body and advising a consultation with a doctor. However, it could have addressed potential medical causes more explicitly, as mentioned in the true answer.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The response lacks depth in addressing the underlying medical conditions that could cause burning sensations, such as neuropathy or diabetes. While it mentions stress, anxiety, or physical activity, it doesn't acknowledge more serious conditions, thus providing a less comprehensive answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response is fluent, polite, and human-like. It resembles the manner in which a professional might respond in a conversational setting but slightly lacks specificity that a trained medical professional might offer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "   The model's response logically aligns with the context provided. It accurately interprets the glucose test results as indicative of diabetes and provides relevant advice on starting treatment and making lifestyle changes. However, it doesn't reference the HbA1c report attached, which would make the response more aligned with the given inputs.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "   The response sufficiently answers the question of whether the individual should take any tablets, offering a comprehensive view on starting treatment for diabetes. While it does not explicitly say \"yes, take a tablet,\" it implies the need for medication. Nonetheless, it would benefit from a more direct recommendation based on the attached HbA1c report.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "\n",
      "   The response is fluent and human-like, with a professional, empathetic tone appropriate for a medical inquiry. It could improve slightly by acknowledging the patient's concerns more directly or empathizing with the lack of medication taken in the past year.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 3.5**  \n",
      "  The model's response is generally coherent with the input, as it acknowledges the symptom of double vision (diplopia) described by the user. However, it doesn't address specific features mentioned in the input, such as improvement with head position changes or pulling on the eyelid, which are key to understanding the underlying issue.\n",
      "\n",
      "- **Completeness: 3.0**  \n",
      "  While the model identifies the symptom (diplopia) and appropriately suggests seeing an ophthalmologist, it lacks depth in its explanation. It does not provide insights into why the user's vision changes with head position or eyelid manipulation, nor does it connect the user‚Äôs age-related vision issues to the problem.\n",
      "\n",
      "- **Naturalness: 4.5**  \n",
      "  The model's response is generally fluent and human-like, with clear and polite language. It offers practical advice and sounds like a genuine attempt to help the user, although slightly generic in nature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It acknowledges the issue with the foreskin and suggests seeing a urology specialist, which is reasonable given the symptoms described.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response is fairly complete in terms of providing immediate advice and suggesting seeing a doctor for further diagnosis and treatment. However, it doesn't specifically address the lack of improvement despite using Aspoline, which could have been explored further.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The language used in the response is fluent and human-like, maintaining a conversational and empathetic tone. The advice is provided in a friendly and approachable manner, which enhances its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the context, addressing the individual's cardiovascular health issues and the need for prevention and possible surgical procedures. However, it slightly misses emphasizing the urgency or specific specialists needed.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides a general overview of preventive measures, lifestyle changes, and the possibility of surgery, but it lacks specific details on medications and doesn't mention consulting a vascular surgeon, which is an important step given the seriousness of the conditions described.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent, human-like, and uses empathetic language, contributing to a natural and supportive tone, although there is a slight redundancy in repeating some points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It connects the concern of weight loss to the medication being taken and suggests potential next steps. It could be slightly improved by directly addressing the specific context like referring to the user's blood sugar control as mentioned in the input.\n",
      "\n",
      "- Completeness: 4.8  \n",
      "  The response adequately addresses the concern about weight loss in relation to the medication, suggesting consultation with a doctor and proposing lifestyle management options. It provides a comprehensive plan of action for managing the issue.\n",
      "\n",
      "- Naturalness: 4.9  \n",
      "  The response is very fluent and sounds natural. It reads like advice from a healthcare professional and uses appropriate medical guidance without any awkward or unnatural phrasing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "The model's response partially aligns with the given context but contains some logical inconsistencies. Specifically, the statement \"This means that your heart is not receiving enough blood flow due to blockages\" contradicts the earlier mention that the angiogram showed no blockages. This confusion affects the logical coherence of the response.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "The response fails to provide a comprehensive answer to the user's query about medication for preventing a heart attack. While it advises consulting a cardiologist and continues with general lifestyle advice, it lacks specific medication recommendations such as those mentioned in the true answer, like Antiplatelet Statin. This omission impacts completeness significantly.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "The response is mostly fluent and sounds human-like with appropriate concern and suggestions. However, slightly awkward phrasing in parts, like the logical inconsistency, reduces the overall naturalness score, even though the tone and language are otherwise conversational.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "  - The model's response generally aligns logically with the context, acknowledging the main symptoms and conditions presented by the input. It appropriately connects the presented symptoms to potential causes, such as linking hormonal imbalances to PCOS. However, it makes some generalizations and assumptions without referencing specific lab results that are provided in the true answer.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - While the model addresses various symptoms and provides a general overview of conditions like PCOS and their typical management, it misses specific details found in the true answer, such as the mention of hyperthyroidism, the suggestion of antithyroid drugs, and specific diabetes management strategies. The model's response is somewhat informative but lacks specific treatment recommendations tailored to the hormonal issues detailed in the true answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is generally fluent and resembles human-like communication. It acknowledges the user's concerns empathetically and provides advice in a friendly and supportive manner. The structure and language used sound natural, making the response easy to read and understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response discusses Accentrix as a medication for type 2 diabetes, which is not relevant to the context provided. The question is about diabetic macular edema treatment rather than diabetes management.\n",
      "\n",
      "- Completeness: 1.5  \n",
      "  The model fails to address the specific query about the Accentrix injection in the context of the attached OCT report, which indicates diabetic macular edema. Instead, it provides general information about diabetes management, missing the specific focus on the eye condition.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and sounds human-like. It is clearly written and easy to understand, but the unnatural part lies in the lack of relevance to the specific medical situation presented.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response is generally coherent, logically aligning with the context provided. It addresses the medical context, explaining potential reasons for the doctor's recommendation of surgery. However, it does not fully explore specific details or complex aspects such as diabetes, which may affect the condition's severity.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - The response lacks specific details and alternative medical considerations present in the \"True Answer.\" It does not address some critical aspects, like the possibility of diabetes affecting the condition, the specifics of the infection, or a detailed treatment plan. It provides a plausible reasoning but doesn't supply enough depth or specificity that could offer a comprehensive second opinion.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The language used in the response is fluent and human-like, utilizing natural conversational phrasing. The explanation is articulate and easy to understand, maintaining a respectful and professional tone throughout. However, it could improve by expressing more empathy towards the patient's concern.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent with the input, addressing the user's concern about severe anxiety and offering potential treatment options like cognitive-behavioral therapy (CBT) and medications. It aligns well with the context, providing logical next steps for someone experiencing significant anxiety.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response offers a comprehensive range of treatment options, including both therapy and medication. However, it lacks a direct exploration of the possibility that the user's anxiety might be part of a broader issue, as the user suspects. The model does highlight the importance of professional help, which covers part of the concern, but a more in-depth discussion about potential underlying conditions could enhance completeness.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and human-like, maintaining a professional yet empathetic tone suitable for a medical context. It is polite, encouraging, and supportive, resembling a response one might expect from a healthcare provider.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is mostly coherent with the context. However, it doesn't specifically address some key details provided in the input, such as the issue with the eyelid not closing or the past eye surgeries, which could affect the interpretation of the visual symptoms.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the response touches on the possibility of dry eyes causing cloudy vision, it does not thoroughly address all the points mentioned in the user's description (e.g., the eyelid not closing completely, past vitrectomy, need for cataract surgery). The suggestion for artificial tears is useful but lacks the depth provided in the true answer, which includes additional considerations and questions for a comprehensive evaluation.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is quite natural and human-like, with appropriate language and tone for communicating health-related advice. It provides a logical suggestion in a polite and professional manner typical of medical advice. However, a slightly more in-depth explanation or follow-up questions could enhance its conversational quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided. It addresses the user's concern about mild LVH and the connection to anxiety, consistent with the given medical context.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - While the model responds to the question about mild LVH and suggests monitoring, it lacks detailed explanations or alternative assessments about mild LVH. The true answer provides more depth in explaining possible conditions and reassuring the user further.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent, human-like, and empathetic. It offers practical advice in a conversational tone, suitable for someone seeking medical reassurance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  *Explanation*: The model's response is coherent as it acknowledges the patient's concerns about weight gain and the impact of medications on diabetes management. It provides logical advice relevant to the context, such as discussing with a doctor and considering lifestyle changes.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  *Explanation*: The response addresses the general concerns about medication effects on weight and diabetes but does not provide specific guidance about the medications mentioned (sodium glucose transporter, slow-release insulin). While advising consultation with a doctor is practical, this does not fully answer the patient's request for guidance on specific medications.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  *Explanation*: The model's response is written in a fluent and human-like manner. It uses polite, professional language suitable for a healthcare context, making the communication feel authentic and natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5 \n",
      "    - The model's response is coherent with the input, providing a logical explanation related to the symptoms of flat feet and heel pain, suggesting possible plantar fasciitis as a cause. The response aligns well with the context.\n",
      "\n",
      "- Completeness: 4.0 \n",
      "    - The response is fairly complete, covering potential treatments and considerations like physical therapy, exercises, and medication for plantar fasciitis, a condition that can be related to flat feet. However, it could be more comprehensive by suggesting an evaluation for other possible conditions, similar to the true answer's suggestion to check for bone abnormalities or comorbid conditions.\n",
      "\n",
      "- Naturalness: 4.8 \n",
      "    - The response is fluent and sounds human-like, with a polite and professional tone typical of a healthcare provider. It gives clear explanations and recommendations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.5**  \n",
      "    The model's response logically aligns with the context provided. It correctly identifies the symptoms and the significance of the findings related to the liver lesion, hemangioma. The mention of liver disease and the need for further evaluation is consistent with the given information. However, it could slightly overemphasize the potential for malignancy based on the context.\n",
      "\n",
      "- **Completeness: 4.0**  \n",
      "    The response covers the major aspects of the father's condition, such as the significance of the hemangioma, the need for further imaging, and consulting a specialist. However, it lacks specific advice about monitoring or managing the lesion conservatively or when to consider surgical intervention, which were mentioned in the true answer.\n",
      "\n",
      "- **Naturalness: 4.8**  \n",
      "    The response sounds fluent and human-like. It uses professional language that is typical of a healthcare provider while remaining empathetic to the user's concerns. The response is well-structured and offers clear guidance, closely resembling human medical advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.0**  \n",
      "  The model's response logically aligns with the context provided in the input. It acknowledges the connection between obstructive sleep apnea and the observed brain changes, which is consistent with the input information. However, it does not explain the changes as indicative of small vessel disease, which is a significant part of the true answer. \n",
      "\n",
      "- **Completeness: 3.0**  \n",
      "  The response somewhat addresses the question but lacks critical details provided in the true answer, such as other risk factors like uncontrolled hypertension, dyslipidemia, and the irreversibility of the brain changes. These omissions make the response less complete compared to the true answer.\n",
      "\n",
      "- **Naturalness: 4.5**  \n",
      "  The response is generally fluent and sounds human-like. It presents the information in a professional and conversational manner, although it misses some specificity and acknowledgment of the complexity of the condition that would further enhance its naturalistic and authoritative tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "  The model's response is coherent in the sense that it addresses the concern about the metformin recall and suggests consulting a doctor for alternative medications. However, it does not mention the specific context of the user‚Äôs high sugar levels nor does it directly address the urgency due to the user's last sugar level reading. Including these details could make the response more aligned with the input context.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "  The response provides general advice about consulting a doctor and mentions alternative medications, but it lacks specificity regarding managing high sugar levels which were highlighted in the input. There is no mention of any plan for immediate intervention to address the user's critical sugar level or a suggested course of action until a new medication is prescribed.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "  The response is generally fluent and sounds professional and human-like. It reassures the user and provides advice in a manner that feels natural for a healthcare provider, but it slightly lacks an empathetic tone which can make it feel more personalized and engaging.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is generally coherent with the context provided, addressing the symptom of a burning sensation on the head and suggesting possible causes. However, it introduced a topic‚Äîburning mouth syndrome‚Äîthat seems irrelevant to the user's head-related concern.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response covers several possible causes for the symptom and suggests a course of action, such as consulting a healthcare provider and taking pain relievers. It misses out on some potential causes (e.g., vitamin deficiency, sinusitis) mentioned in the true answer, highlighting a minor gap in completeness.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent and reads quite naturally. It uses clear language and offers practical advice, closely resembling a human-like interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model‚Äôs response logically aligns with the context in the input, addressing the issue of ringworm and providing suggestions related to the symptoms described. However, it lacks specific guidance on the resistant strain of fungus and the caution against steroid creams mentioned in the true answer.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model offers a range of suggestions, such as ensuring correct usage of medications, considering additional antifungal creams, and keeping the skin dry, it misses specific treatment recommendations given in the true answer, such as the exact medication (Trfy 250 mg) and application guidelines (DK gel) for a potential resistant strain.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, with empathetic language and a clear structure. It sounds professional and appropriately courteous for a doctor-patient interaction, although it can be slightly more precise in recommending specific actions, as shown in the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response partially aligns with the context provided in the input. It acknowledges the patient's concerns about surgical risks but incorrectly suggests that the risks are not very high for someone in their age group. This oversight affects the coherence since the patient has several health issues that might increase surgical risks. Moreover, the suggestion to stop smoking is misplaced as the patient already quit smoking at 40. \n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The response doesn't fully address the specific concerns about anesthesia and surgical risks, particularly given the patient's multiple health conditions (age, obesity, diabetes, emphysema, sleep apnea, high blood pressure, and current medications). While it mentions general surgical risks, it lacks detailed, personalized insights or advice on managing those risks given the patient's particular health profile. \n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The response is written in a friendly and human-like manner, with fluent language use throughout. However, the recommendation to stop smoking, which the patient has already done, slightly detracts from the naturalness as it indicates a lack of attentiveness to the details provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context by acknowledging the user's concerns about anxiety, heart disease, and potential implications on their health. It provides a coherent suggestion to work with healthcare providers for a comprehensive treatment plan. However, it briefly touches on medication without specific detail about the medications mentioned, which leaves a slight gap in logical coherence.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides a general overview of managing anxiety related to the user's health conditions and suggests lifestyle recommendations. However, it lacks detailed advice specific to the user's medication and how it might relate to their symptoms, which the true answer provides thoroughly.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent, human-like, and conveys empathy, which makes it pleasant to read. It sounds professional yet approachable, fitting for a healthcare scenario.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response logically aligns with the context provided. It addresses the concern about the jerks in relation to Alzheimer's disease and medication side effects. The mention of monitoring for other serious conditions like a stroke further demonstrates coherence with the context. However, the initial statement \"it is great to hear that your mother is recovering well\" might slightly misinterpret the situation as the query primarily focuses on concerns rather than recovery status.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - The response is fairly complete, addressing the potential causes of the jerks and the importance of monitoring the mother's condition. It provides advice to consult with a doctor, which is useful. However, it could improve by providing a bit more detail on what specific adjustments might be needed concerning the medication or further steps in case the jerks return.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  - The response is highly fluent and human-like. It uses courteous language and engages with the concerns empathetically. The structure of the response is clear and natural, making it easy to read and understand. There are no awkward phrases or unnatural transitions, hence scoring high in naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "    - The model's response provides some general advice for improving blood sugar and hemoglobin levels, which logically aligns with the context provided. However, it lacks specific details related to the patient's case, as seen in the true answer.\n",
      "\n",
      "- Completeness: 2.5\n",
      "    - The response is somewhat incomplete as it does not address specific medications or changes needed in the patient's current regimen, which the true answer partially provides (e.g., the mention of Glycomet G2 and the use of ROXCEF and BIO D 3). It mainly gives generic dietary and exercise advice without specific medical recommendations.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "    - The response is fluent and sounds human-like, using polite and conversational language. It effectively communicates advice in a manner that is easy to understand, though it could be enhanced with a more personalized approach.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "\n",
      "    The model's response is coherent to an extent as it addresses the elevated TSH levels, connects them to hypothyroidism, and mentions the typical symptoms associated with the condition. However, it could have better aligned with the context by highlighting that elevated TSH in the context of normal T3 and T4 might suggest subclinical hypothyroidism, rather than definitively suggesting hypothyroidism.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "    The response provides a general overview of hypothyroidism and its treatment but misses nuances present in the true answer. It does not address the possibility of subclinical hypothyroidism or mention potential tests like the anti-TPO antibodies test. It also lacks guidance on evaluating for symptoms or the need for follow-up tests specific to the user's situation.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "    The response sounds quite fluent and human-like. It uses appropriate medical terminology and offers advice in a manner consistent with how a doctor might communicate. However, minor improvements could be made to make it sound more tailored and empathetic to the individual's specific circumstances, such as addressing the absence of symptoms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the context provided and discusses potential causes for the leg swelling, such as diabetic neuropathy and DVT, both relevant to the patient's condition. However, it does not mention a Doppler test, which the original query highlighted as a necessity according to another doctor.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model answers the question regarding the cause of the leg swelling and potential treatment options, it lacks specific advice on conducting a color Doppler test, which might be crucial. It also doesn't address why continued antibiotic use doesn't necessarily imply an internal problem and how such a problem might be diagnosed.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and sounds human-like, maintaining a professional tone appropriate for a medical response. It uses medical terminology effectively while remaining understandable to a non-expert audience.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "  - The model's response partially aligns with the context, focusing on diabetes-related complications. However, it introduces the possibility of peripheral neuropathy, which is not directly suggested by the symptoms described (e.g., there is no mention of numbness, tingling, or pain).\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - The response suggests managing diabetes and general foot care, which is somewhat relevant but misses more specific potential diagnoses such as frictional hyperkeratosis or acanthosis nigricans. It also lacks detailed treatment options provided in the true answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent, polite, and human-like, offering general advice and expressing willingness to help further, which contributes to its natural tone. However, the introduction of peripheral neuropathy could be slightly misleading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.8\n",
      "  - The model's response logically aligns with the context provided in the input. It acknowledges the user's concerns and offers a broad overview of potential causes and the steps to take for further evaluation. It also makes a connection between the symptoms of weakness during sex and the possibility of underlying medical conditions, which is coherent with the user's concerns.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - While the model provides a detailed response, focusing on the importance of getting a medical evaluation and considering lifestyle modifications, it doesn't mention specific tests like checking blood sugar levels or assessing for diabetes mellitus, which are mentioned in the true answer. These details could provide more completeness in terms of specific medical evaluations.\n",
      "\n",
      "- Naturalness: 4.9\n",
      "  - The model's response is very fluent and human-like. It uses a conversational tone, is polite, and sounds like it could have been written by a medical professional, with a focus on reassuring the user and suggesting practical next steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response generally aligns with the context, discussing diabetes and possible complications such as aneurysms and diabetic neuropathy. However, it confuses the symptoms described (sudden dysfunction of a limb) with diabetic neuropathy, which tends to manifest differently. The mention of aneurysms doesn't directly align with the provided context of MRI findings of a vein burst, likely indicating a stroke rather than an aneurysm.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  While the response covers general advice on diabetes management and physical therapy, it doesn't directly address the primary concern: the likelihood of regaining function in the right leg and hand. The model fails to acknowledge the specific implications of a burst blood vessel in the brain and how it might affect recovery potential, unlike the true answer which mentions the importance of assessing the extent of brain damage.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and has a human-like tone, with a compassionate and engaging style that is typical in professional advice settings. It acknowledges the person's concerns and provides detailed suggestions, although the conversational tone may slightly offset the technical medical context needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5 - The model's response logically aligns with the context provided and identifies angina as a possible condition. It acknowledges the symptoms and provides general advice relevant to someone with the father's medical conditions.\n",
      "  \n",
      "- Completeness: 4.0 - While the response offers a reasonable explanation for the father's symptoms and suggests a generalized course of action, it lacks specificity regarding required medical evaluations and medications. It could improve by addressing the particular medical history mentioned by offering clearer next steps or specifying potential medication adjustments.\n",
      "\n",
      "- Naturalness: 4.8 - The response is fluent and sounds human-like, maintaining a conversational and empathetic tone. It effectively addresses the concerns while encouraging further consultation with a healthcare professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context by discussing blood sugar levels and their implications. It correctly identifies the son's symptoms (thirst and elevated blood sugar) as potential concerns and suggests diabetes as a possibility, which reflects coherence with the provided information.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The response addresses the main concern by explaining the normal and slightly elevated blood sugar levels and provides guidance on monitoring and further steps, like consulting a pediatrician or considering diabetes testing. However, it might have been slightly improved by explicitly reassuring the parent about the general levels and clarifying the normal range boundaries.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, with a polite and somewhat empathetic tone appropriate for addressing health concerns. The language used is clear and professional, typical of a medical consultation. The model also offers further assistance, enhancing its naturalness and conversational quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the context, explaining the general process of an examination for erection problems. It captures the essence of what a doctor might do, although some specific details such as a stamp test or penile Doppler are missing compared to the true answer.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response sufficiently answers the question by outlining the steps a doctor might take during an examination. However, it omits some specific tests and procedures mentioned in the true answer, such as checking for a local problem, the size, and consistency of the testis, and more detailed diagnostics involved.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and sounds very natural, closely resembling how a doctor would discuss potential steps during a consultation for erection problems. It maintains an appropriate tone and structure throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the context provided. It acknowledges the presence of depression and addresses common symptoms associated with it. The advice to seek professional help and maintain a healthy lifestyle is appropriate, though slightly more emphasis on immediate danger due to suicidal thoughts could improve coherence.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a substantial amount of relevant information about depression and offers general advice on managing it. However, it lacks specific recommendations regarding the severity of the situation due to suicidal thoughts and does not mention potential medical interventions like inpatient care or testing as the true answer suggests.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent, comforting, and human-like. It uses appropriate language and tone for offering support to someone experiencing depression, which reads naturally and empathetically. Acknowledging the immediate risks of suicidal thoughts could enhance the perceived urgency and care in the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context of nerve pain but lacks specificity regarding the symptoms described (e.g., location and intensity of pain). It provides general advice for nerve pain management rather than addressing specifics mentioned in the input like the inability to walk, sit, or lay down, which could suggest an acute or severe issue.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides several potential treatment options and lifestyle changes but does not delve into possible diagnoses or recommend diagnostic tests, which are included in the true answer. It misses addressing conditions that could contribute to the described symptoms or suggesting immediate pain relief strategies, such as specific medications.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and reads in a human-like manner, with a courteous and supportive tone. It uses understandable language and offers a friendly touch by encouraging the patient to reach out for more assistance. However, there is repetition in suggesting \"lifestyle changes\" twice, which slightly impacts the naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is coherent and logically aligns with the context. It addresses the major concern about frequent urination and suggests consulting a doctor for a proper evaluation. However, it doesn't directly address the erotic sensation part mentioned in the input.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The response suggests consulting a doctor and mentions a urine test, but it lacks specific details like ruling out urinary tract infections or checking blood sugar levels as mentioned in the true answer. Additionally, it fails to address the concern about the erotic sensation when the bladder is full, which could help reassure the patient.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The response is mostly fluent and human-like. It uses polite and professional language that is appropriate for a doctor's communication with a patient. However, some parts could be simplified or made more engaging to sound more natural and conversational.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is coherent with the user's input. It logically aligns with symptoms such as increased frequency of urination and burning sensation, identifying them as possible indicators of a urinary tract infection (UTI). The model also suggests the importance of ruling out underlying medical conditions, which is consistent with assessing the situation described by the user.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model provides a fairly complete response by offering a possible explanation (UTI) and suggesting appropriate next steps, including urinalysis, culture, and potential treatment options such as antibiotics. However, it misses other potential causes mentioned in the true answer, such as stress or prostate gland swelling, and does not address the user's existing medical tests like uroflowmetry.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The response is natural and fluent, resembling how a human might explain these concepts in a professional and empathetic manner. It uses clear language and a friendly tone, which feels human-like and is easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent as it logically aligns with the information provided. It acknowledges the treatment and improvement in the mother's condition and relates the bitter taste to the potential side effects of steroids.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response addresses the main concern about the side effects of steroids and offers advice on consulting a healthcare provider for further management. However, it could have provided more specific recommendations or suggestions to reduce the side effect.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response sounds fluent and human-like, maintaining a professional tone appropriate for a medical context. It is polite and empathetic, which contributes to its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "The model's response provides a coherent explanation of the pain as potentially being due to a nerve issue, which aligns with the symptoms described in the input. However, it lacks a more comprehensive exploration of other potential causes that the true answer considers, such as diabetes-related issues or cervical spondylosis.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "The response is somewhat complete as it addresses the potential of a nerve injury and suggests consulting a healthcare professional. Still, it does not thoroughly explore the range of possible causes and associated diagnostic steps outlined in the true answer, which indicates a more precise approach to pinpointing the underlying cause.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "The model's response is mostly natural and human-like, using polite and empathetic language typical of professional medical communication. However, it could be perceived as a bit generic due to the lack of specific diagnostic decision-making or personalized considerations, which slightly detracts from the naturalness of an expert consulting tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response is largely coherent with the input, recognizing the details about the elderly person's myelodysplastic syndrome and the nature of the biopsy material. However, it does not fully address the subtlety about the inadequacy of the sample and misinterprets the fibrino-leukocytic consistency.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The model partially answers the question by linking fibrino-leukocytic material to myelodysplastic syndrome but lacks critical aspects. It misses the nuance around the insufficiency of the sample for a definitive diagnosis and does not suggest the need to repeat the biopsy.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The response is very fluent and human-like, providing a warm, empathetic tone, which is appropriate for addressing concerns about a loved one's health. The language used is professional and accessible.   \n",
      "\n",
      "The response could be improved by directly addressing the issue of sample quality and whether another biopsy is necessary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response is partially coherent. It correctly identifies the concern about deep tissue injury given the described symptoms. However, it wrongly suggests taking immediate action to the hospital again, despite the patient already being taken to the ER.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model provides some useful information by highlighting the potential for serious complications from a deep tissue injury in diabetics. However, it lacks some context-specific elements, such as discussing the potential for impaired blood sugar levels or clarifying the discoloration and natural healing process as seen in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is written fluently and in a friendly, human-like manner. The language is comfortable and clear, resembling how a healthcare professional might speak to a patient.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It discusses the possibility of a recurring fungal infection due to diabetes and recommends consulting a doctor, which is coherent with the symptoms and history provided. However, it unnecessarily repeats information about using mild soap and antifungal cream.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model addresses some aspects of the problem, such as recommending consulting a doctor for diabetes control and maintaining hygiene, it doesn't fully address the recurrence issue or the partner‚Äôs potential need for treatment, as mentioned in the true answer. It also doesn't discuss the possibility of incomplete treatment, which is relevant to the recurrence.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response sounds generally fluent and human-like, providing helpful suggestions with a polite tone. However, the redundancy of certain recommendations slightly detracts from the natural flow of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It correctly addresses the concerns about the risk of contracting viruses such as HIV or hepatitis B from a used needle and acknowledges the user's worry after the incident.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response reassures the user about the low risk of infection and provides general advice on hygiene, it lacks specific details found in the true answer, such as the importance of understanding the needle user's HIV status and the option of a diagnostic test for additional reassurance.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The model's response is fluent and human-like, using empathetic and reassuring language. The message is clear and effectively communicates care and advice to the user.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The response logically aligns with the context provided. It addresses the blood sugar levels mentioned, gives advice on monitoring and possible lifestyle changes, and emphasizes the importance of consulting a doctor. However, it mistakenly notes that the blood sugar levels are within a normal range, which is not accurate for fasting glucose.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides general advice and guidance on managing blood sugar levels, which is useful, but it doesn't address the specific medical situation. It fails to adequately analyze the provided glucose levels, particularly the high fasting glucose, and the implications of an HbA1c of 6.2%.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds very human-like. It is conversational, empathetic, and provides comprehensive advice, making it easy to understand and relatable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is coherent and aligns logically with the provided context. It correctly identifies the user's concern about a rising HbA1c level and suggests relevant supplements. However, it does not fully address the user's history of HbA1c changes, as mentioned in the statement about a previous level of 5.2%.\n",
      "\n",
      "- Completeness: 3.8\n",
      "  - The response provides a reasonable set of suggestions to manage HbA1c, such as supplements (chromium, alpha-lipoic acid, omega-3), lifestyle changes, and diet advice. However, it lacks mention of some specific dietary and lifestyle details found in the true answer, such as the importance of consuming low GI foods, specific quantities of supplements, and detailed dietary changes like consuming cinnamon or avoiding tea and coffee.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response is fluent and human-like, using an empathetic and informative tone that is typical in a professional healthcare setting. The language is clear and well-structured, making it easy for a user to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response incorrectly states that the user has been diagnosed with diabetes, which is contradictory to the input stating \"no diabetes.\" This discrepancy indicates a lack of coherence with the input context.\n",
      "  \n",
      "- Completeness: 3.0  \n",
      "  The response provides some generic advice on managing symptoms and suggests consulting a healthcare professional, which addresses the user's request for guidance. However, the incorrect mention of diabetes affects the accuracy and trustworthiness of the response, detracting from its completeness.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and demonstrates a natural, human-like tone. It provides clear advice and polite suggestions, making it easy to read and comprehend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.0**  \n",
      "  The model's response logically aligns with the context provided. It explains the conditions related to coronary artery disease and presents both angioplasty and bypass surgery as treatment options, which are relevant to the input. However, it lacks specific consideration of the grandfather's age and the complexity of his medical condition as detailed in the true answer.\n",
      "\n",
      "- **Completeness: 3.0**  \n",
      "  While the response covers general treatment options for coronary artery disease, it does not sufficiently address the specific aspects of the grandfather's condition, such as the impact of his age on treatment suitability, the low ejection fraction, or the complexity of the lesion. The true answer suggests a stronger recommendation against angioplasty and discusses the benefits of minimally invasive bypass, which the model's response does not mention.\n",
      "\n",
      "- **Naturalness: 4.5**  \n",
      "  The model's response is fluent and sounds human-like, using clear and appropriate language for the context. It maintains a professional tone typical of medical advice, though some sentences could be more concise to reflect natural human conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent with the context provided. It acknowledges the patient's issues with diuretics and dehydration, aligns with the request for non-diuretic options, and makes relevant suggestions that are consistent with current medical practices. However, it doesn't fully account for the fact that the patient is already taking valsartan, which is an ARB.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response is partially complete. It successfully provides a class of drugs (ARBs) as an alternative, but it lacks a wider range of options available for managing hypertension, such as beta-blockers, alpha-blockers, or lifestyle changes mentioned in the true answer. It also doesn't suggest any new medications outside the ARB class or acknowledge the added complexities of concurrent conditions like retinopathy or dry eye disease.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is highly natural and fluent. It uses clear language and is easy to understand. The explanation of how ARBs work is well articulated and follows a logical sequence, which contributes to the overall human-like quality of the response. The only minor issue could be the repetition regarding ARBs, as it does not completely account for the fact that valsartan, an ARB, is already being used by the patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The response logically aligns with the context of the question, acknowledging the tests that have already been conducted. However, it suggests additional tests that have already been done, such as the MRI and EEG, making the recommendations somewhat redundant.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response offers a variety of further avenues to explore, but it does not mention orthostatic intolerance or panic attacks as potential causes, which are key suggestions in the true answer. These omissions prevent the response from being fully comprehensive.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The language used is fluent and sounds quite human-like, with a reassuring and polite tone. It effectively addresses the concern and offers next steps in a professional manner. It could be slightly improved by being more succinct and avoiding repetition.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The response aligns logically with the context provided. It acknowledges the conditions mentioned (diabetes, typhoid, blood clot, and headache) and offers a logical course of action. However, it could better address the immediate concern regarding the blood clot and potential seriousness explicitly rather than general advice.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response sufficiently answers part of the question by suggesting immediate medical attention and monitoring. However, it lacks a detailed explanation of potential serious causes like intracranial pressures or the specific focus on seeing a neurosurgeon, as mentioned in the true answer. It also doesn't explicitly advise against taking pain relief medicine without specialist advice.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, with courteous language and a reassuring tone. It provides clear instructions and empathy, characteristic of a human conversational style, though the ending feels somewhat abrupt with the formal sign-off.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response logically aligns with the context, explaining the common nature of jock itch and how to manage it. However, it doesn't consider some contextual details such as the possible underlying diabetes mentioned in the true answer.\n",
      "  \n",
      "- Completeness: 4.0  \n",
      "  - The response gives a comprehensive approach to managing jock itch, including continued use of creams, potential prescription medications, and lifestyle suggestions. However, it lacks potential underlying health issues that could contribute to recurrence, such as diabetes.\n",
      "  \n",
      "- Naturalness: 4.8  \n",
      "  - The language used in the model's response is fluent and human-like. It is polite, informative, and easily understandable, making it sound very natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is fairly coherent as it aligns with the context provided, discussing the role of a biopsy in confirming the nature of the polyp and mentioning the importance of following the doctor's recommendations. However, it does not address some specific details that are vital according to the true answer, such as the risk profiling related to age and unilateral presence of the nasal polyp.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The response partially answers the question by explaining the purpose of a biopsy, but it lacks completeness regarding specific reasoning for the biopsy in this context, particularly the importance of ruling out malignancy due to age and unilateral polyp presence. It also doesn't provide a clear opinion on the severity level, unlike the true answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is fluent and reads like a human-written piece, using polite language and a clear structure. There is little to no awkward phrasing, making it sound natural and conversational.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is generally coherent with the context, acknowledging the elevated triglyceride levels and providing lifestyle advice which is logical given the health details provided. However, it misses addressing the significance of the increased creatinine levels and the history of diabetes provided in the input.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "While the model addresses concerns about triglyceride levels, it fails to tackle the elevated serum creatinine and its implications, which are crucial given the context of diabetes. The response misses the opportunity to discuss the potential kidney health concerns and does not suggest any reassessment of stopping diabetes medication, which is pertinent given the provided health metrics.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is mostly fluent and sounds human-like, effectively using language that would be typical in a response from a healthcare professional. It communicates well without noticeable syntax or grammatical errors but might appear slightly generic or templated in its advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5\n",
      "  - The model's response contains inaccuracies about the medications. It incorrectly describes Tazloc-H as a combination of metformin and hydrochlorothiazide, which is false. It also confuses the categories of the medications (Gemer is not a thiazolidinedione). This affects the logical alignment with the input.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The model provides some useful information about managing diabetes and the purpose of some medications, but it fails to address specific concerns raised in the query, such as evaluations on the switch from Prolomet XL to Tazloc-H and potential supplementation with additional medications based on heart rate.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The response is mostly fluent and human-like with clear explanations, though it contains errors that would not typically be made by a knowledgeable expert, affecting the perceived reliability of the content.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "The model's response provides a general overview of lymphadenopathy and some lifestyle suggestions, which logically align with the context of the user's symptoms. However, it doesn't directly address specific symptoms mentioned, such as stiffness, numbness, or low energy, which affects coherence.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "The response is quite general and lacks specific suggestions or explanations related to the user's detailed symptoms and medical history. Key aspects such as the presence of knots, the stiffness and weakness, low energy, and low sedimentation rate are not sufficiently addressed, reducing the overall completeness.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "The response is fluently written and sounds natural and human-like. It offers a friendly and encouraging tone, which is beneficial in a medical context. However, the repetition of \"important\" makes it slightly less varied in language.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It correctly identifies the user‚Äôs concern about blood sugar and gives a sensible, context-appropriate response about monitoring levels and consulting a doctor. \n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response addresses the question of whether the user might be diabetic by advising regular monitoring and speaking to a doctor, but it lacks direct informational guidance about diabetes diagnosis criteria, like fasting blood sugar levels indicating diabetes. The true answer gives more actionable advice regarding diet, which is missing in the model‚Äôs response.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is very natural and fluent. It contains a polite introduction and a clear explanation, consistent with human-like conversation. However, it could involve more specific medical insights for a slightly higher degree of naturalness in the context of a medical consultation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent as it logically follows the complaint about an ingrown nail, offering a comprehensive explanation of possible causes and treatment options.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response is somewhat complete as it does provide a general overview of treatment for an ingrown nail. However, it lacks specific medical advice, such as the use of medication or checking sugar levels, which were suggested in the true answer. It doesn't address prevention or specific steps tailored to the user's long-term issue.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response sounds fluent and human-like. It is polite and reads like advice from a health professional, maintaining a conversational tone and offering empathy toward the user's situation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context of the father's symptoms and attempts to provide a reasonable explanation linking them to potential cardiac issues. However, it lacks consideration of neurological causes, which were important in the true answer. \n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response is somewhat complete as it addresses a potential cardiac issue and suggests further testing and a cardiologist consultation. However, it misses a crucial neurological perspective and overlooks the recommendation for an MRI, thus not covering all bases thoroughly.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent, professional, and sounds human-like. It maintains a reassuring tone and provides specific suggestions and tests, resembling a conversation one might have with a doctor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and aligns with the context provided regarding the grandfather's shoulder and wrist pain, diabetes, and elevated CRP levels. The explanation offered logically connects diabetes with inflammation and high CRP levels.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  The model provides a comprehensive response about the possible link between diabetes and inflammation and suggests further consultation with specialists. It doesn't directly answer whether such a high CRP value is possible but implies it through context, which is reasonably complete in addressing the user's concerns.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and sounds human-like, with appropriate language and tone expected in a medical inquiry context. The explanation and recommendations flow naturally and politely.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is logically aligned with the context provided. It acknowledges the tests done and the normal ranges mentioned, and it suggests seeking further medical evaluation. It addresses the symptoms described by the user and provides appropriate advice considering the information given.\n",
      "  \n",
      "- Completeness: 3.5\n",
      "  - The model provides a general suggestion to seek further medical evaluation and maintains a focus on maintaining a healthy lifestyle. However, it lacks the specificity seen in the true answer, where specific tests and potential conditions (like postmenopausal hormone imbalances and hypothyroidism) are suggested for investigation. \n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The response is very fluent, polite, and sounds natural in tone. It communicates empathy and gives advice in a friendly and professional manner, making the interaction feel quite human-like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is coherent as it discusses the placement of an AV fistula and the implications regarding an individual's condition with high creatinine levels. However, it doesn't address the specific queries about alternative locations, such as the chest area, which slightly impacts its alignment with the input context.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the model provides general information about AV fistulas and advises consulting with the healthcare team, it does not fully answer the specific questions regarding alternative placement locations, such as near the chest, thereby missing a critical aspect of the query.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and human-like, with a professional tone appropriate for a medical query. It demonstrates a natural flow and courteous closing, although it slightly overuses formalities which impact its conciseness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The response logically addresses the context provided in the input, particularly focusing on lifestyle changes that can help address the conditions mentioned. However, it does not directly discuss whether mild concentric LVH will regress with diet and exercise.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the response provides general advice on lifestyle modifications and medication for managing blood pressure and cholesterol, it does not specifically answer the main question about whether mild concentric LVH will regress with diet and exercise. The model should have addressed this aspect directly to be considered complete.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and generally sounds human-like. It provides constructive advice in a polite and conversational tone, although it could be slightly more personalized to the specific query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the input context. It acknowledges the severity of the mother's health situation and emphasizes support and communication with healthcare professionals, which is a coherent approach given the described situation.\n",
      "  \n",
      "- Completeness: 3.0  \n",
      "  The response provides general advice on handling the emotional and logistic aspects of the mother's treatment but falls short on specific medical guidance. It does not address potential drug interactions or details of the TB treatment as explicitly as the true answer. \n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The language is fluent and human-like, providing empathetic and supportive guidance. It reads naturally, as if from a concerned healthcare professional or counselor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response is mostly coherent with the input, addressing the user's concerns about diabetes, hepatitis E, and the ANA test. However, it could provide more specific information related to the individual's circumstances, such as the implications of 10 points on the hepatitis E test.\n",
      "\n",
      "- Completeness: 3.0\n",
      "  - While the model addresses the concern about the ANA test and provides general health advice, it doesn't directly answer whether the conditions are life-threatening or discuss potential complications in detail. The true answer offers reassurance about hepatitis E's normally non-life-threatening nature and guidance on diet and further ANA testing, which the model's response lacks.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response sounds fluent and human-like, using a supportive tone and clear language. It could, however, be improved by integrating a little more specific medical guidance, which would enhance its usefulness to the user.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided. It acknowledges the information given in the input, such as the knee pain, being a runner, having an MRI, and being diabetic. The response also appropriately relates these factors to potential causes and suggests further action, which is coherent with the scenario.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The response addresses the main issue of knee pain and offers general advice regarding diabetes management and maintaining health. It suggests consulting an orthopedic surgeon for further evaluation, which is relevant advice. However, it could have been more specific or offered additional possible explanations or interim steps for managing pain while waiting for further consultations.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The response is fluent and phrased in a human-like manner. It offers empathy, discusses the situation logically, and uses language that is natural for a conversation between a doctor and a patient. There are no awkward phrasing issues, making it sound very natural overall.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "    - The model's response generally aligns with the context of the input. It correctly notes that gallstones are common at the user's age and suggests consulting a doctor, which is logical advice. However, the need for immediate surgery is not the only option, especially given the typical nature of such gallstone sizes and the lack of specific symptoms listed in the input. Hence, the response could be better aligned with gallstone treatment understanding.\n",
      "  \n",
      "- Completeness: 3.5  \n",
      "    - The response partially answers the request for further action by suggesting a consultation with a doctor and possible lifestyle changes. However, it does not fully recognize that gallstones of the indicated size often do not cause symptoms and might not require surgical intervention without symptom analysis. It also does not address the need for more information about the pain to diagnose its cause properly, which is suggested in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "    - The response is generally smooth and human-like. It is friendly and provides advice in an accessible way. The language is natural and maintains a conversational tone throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context given. It addresses the patient's inquiries about early bronchiectatic changes, life expectancy, and treatment options, although it lacks some details and specific clarifications present in the true answer.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model sufficiently answers several of the patient's questions but falls short on specific details such as the distinction between early bronchiectatic changes and bronchiectasis and the mention of atelectasis. It also lacks some specific treatment recommendations and further investigative steps present in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and human-like, with a polite and reassuring tone typical of a healthcare professional. It provides advice on lifestyle changes and emphasizes consulting a doctor, which contributes to its naturalness. However, it could be slightly enhanced with more specific information or further empathy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context provided in the input. It acknowledges the existing health issues and medications and suggests consulting a doctor for further examination, which is coherent with the medical history and symptoms described.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model's response is somewhat complete but lacks specificity. It correctly identifies the need for medical consultation, but it does not provide a potential explanation or a specific course of action like the true answer, which suggests acid reflux and stress as probable causes and recommends a specific medication.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model‚Äôs response is fluent and sounds human-like. It uses polite and empathetic language, making it seem as though the advice is coming from a healthcare professional. However, the lack of a concrete recommendation detracts slightly from the perceived expertise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "\n",
      "The model's response is generally coherent with the context provided. It addresses the questions about the lightened area potentially being an infection or a tumor, the issue of atrophy, and the role of acetyl carnitine. However, it lacks specific details that could enhance coherence, such as mentioning specific conditions like migraines that could also cause hyperintense lesions.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The model's response covers the basic points of the questions asked, such as the possibility of the lightened area being either an infection or tumor, and discusses potential causes for atrophy. However, it doesn't delve into other potential causes and broader perspectives like those provided in the true answer (e.g., hypertension, diabetes, a healthy lifestyle) or offer comforting assurance about cognitive function and management of atrophy symptoms.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The response is fairly natural, as it is structured in a clear and concise manner. The language is fluent, though a bit more engagement or empathy might make it sound more human-like and relatable. The use of phrases like \"It is important to consult with a doctor\" adds a touch of professional advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is generally coherent with the context provided. It acknowledges the user's menstrual cycle, recent sexual activity, and concerns about irregular bleeding. However, it makes assumptions about ovulation timing without addressing potential issues noted in the true answer like vaginal tear or external factors like thyroid problems.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model provides a range of possibilities, such as ovulation or pregnancy, and suggests taking a pregnancy test for confirmation. However, it falls short in providing a comprehensive evaluation like considering vaginal tears after initial intercourse and recommending tests like serum TSH or a pelvic examination, which are suggested in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like. It adopts a reassuring and friendly tone, which makes it sound natural and engaging. The conversational style is appropriate for the context, although slightly more detail might enhance its naturalness further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "    The model's response logically aligns with the context provided in the input. It appropriately addresses the concern of recurrent red rashes and advises against using certain ointments without medical consultation. The suggestion to see a specialist is also reasonable. However, it could have been more specific regarding the patient's symptoms and history based on the input provided.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "    The response partially addresses the question but lacks specific guidance on next steps and alternative treatments. It does not explore potential diagnoses like candidal balanitis, which might be relevant given the symptoms described. While it advises seeking specialist evaluation, it misses opportunities to inquire about further symptoms or history that could help logically deduce the condition.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "\n",
      "    The response is fluent and human-like, using language that is polite and empathetic. It is professional in tone, which fits the context of a medical inquiry. There are no grammatical errors, and the sentence structure is clear and cohesive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is coherent as it addresses the connection between diabetes, cardiovascular disease, and the user's expressed concerns about medications and their potential risks, providing a logical flow based on the context.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model discusses the importance of managing blood sugar and encourages consulting a doctor for tailored advice, it lacks specific guidance on the medications mentioned, like addressing the concerns with sodium glucose transporters or the slow-release insulin.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent and well-structured, reading naturally like a human wrote it. It uses clear, respectful language appropriate for a medical consultation, though it slightly lacks the depth a real doctor might provide in such scenarios.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided and addresses the health concerns mentioned, such as diabetes, high blood pressure, and potential kidney problems which relate to the elevated levels of creatinine, uric acid, and protein. \n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the response provides some general dietary advice focusing on a low-protein diet and the avoidance of fish and chicken, it lacks specific guidance on how often non-vegetarian foods can be consumed. It also doesn't address the detailed dietary plan that accommodates the low potassium, low urate, and low phosphorus requirements as mentioned in the input. \n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, with clear explanations and a polite, informative tone typically used by a healthcare provider.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response contains incorrect information. It incorrectly states that an HbA1c level of 4.8 indicates prediabetes, whereas an HbA1c of 4.8 is actually considered normal. This misalignment with the context undermines its coherence.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model addresses the need for lifestyle changes and regular monitoring, which is a relevant response to the user's concerns about prediabetes. However, because it contains inaccurate information about the HbA1c results, it falls short of completely reassuring the user based on their specific test results.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is generally fluent and uses a professional tone that one would expect from a healthcare interaction. The language is clear and understandable, without any noticeable grammatical errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and aligns logically with the context provided in the input. It acknowledges the previous heart attack, discusses the known issue of blocked arteries, and presents stenting as a treatment option, which aligns with the input information. However, it does not specifically address the severity of the blockages (90% and 75%) as mentioned in the input.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response covers several treatment options, including stenting and alternatives like medication and lifestyle changes, which provides a comprehensive view. However, it lacks explicit recommendations about the urgency of stenting given the degree of blockage. The true answer emphasizes the importance of stenting due to the high level of blockage and suggests that no medicine can open this level of blockage, which would have been valuable information to include.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and reads in a natural, human-like manner. The language used is clear and appropriate for addressing the concerns of a patient, making it sound like something a healthcare professional might write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is generally coherent, acknowledging the symptoms and suggesting seeing a doctor. However, it lacks specific alignment with certain details such as the diabetes mentioned by the user.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  While the response advises consulting a doctor, it lacks completeness as it does not explain potential causes or specifics about the symptoms, unlike the true answer which gives multiple possibilities and a recommendation.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is natural and fluent, maintaining a professional tone typical of a medical consultation. It sounds like something a doctor would typically say, although it could have been made slightly less generic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0. The model's response aligns logically with the context provided in the input. It acknowledges the need to identify the cause of the fever and suggests consulting a doctor. It also addresses concerns about blood sugar control and provides general advice. However, it lacks specific guidance and diagnostic insights that a medical professional might suggest.\n",
      "\n",
      "- Completeness: 3.0. The response partially addresses the question but lacks detailed recommendations that would add substantial value, such as suggesting specific tests or more precise antibiotic usage based on test results. While it recognizes the complexity of the situations, it remains somewhat generic regarding managing the fever and blood sugar levels.\n",
      "\n",
      "- Naturalness: 4.5. The language used by the model is fluent and human-like, maintaining a professional and empathetic tone. The response is clear and gracefully structured but slightly repetitive in emphasizing the need to consult a doctor without offering actionable insights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the context provided. It acknowledges the symptoms described and suggests potential explanations like hypoglycemia, which is a reasonable consideration given the symptoms of dizziness, weakness, and unusual tiredness. However, it lacks mention of other possibilities like thyroid problems or deficiencies, which could improve coherence with the broader spectrum of possible causes.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response is fairly comprehensive, addressing the user's symptoms and suggesting a potential cause, as well as recommending a doctor's evaluation. However, it could be more complete by also considering other possible causes, such as vitamin deficiencies or thyroid issues mentioned in the true answer. Including these possibilities would give a fuller picture of what could be causing the symptoms.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The response sounds very fluent and human-like, using a conversational tone and providing reassurance. It effectively balances professional advice with empathy, which is typical of human doctors addressing patient concerns. It is slightly verbose, which can affect the naturalness, but it remains largely natural in tone and delivery.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided and acknowledges the concern of high cholesterol levels and the associated risks, including potential lifestyle changes and medication as part of possible treatments. However, it does not directly address the familial risk factors mentioned.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response covers some important aspects such as lifestyle changes and the potential need for medication. However, it misses the nuanced details about hereditary risk mentioned in the true answer and does not address specific potential side effects or the necessity of consulting a physician for further personalized advice.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The language used in the response is fluent, clear, and human-like. The model effectively uses standard expressions and reassurances that are commonly found in professional health advice, providing a comforting and authoritative tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  - The model's response generally aligns with the context. It correctly addresses the symptom of a slow urine stream and mentions diabetes and potential prostate issues. However, there is a minor misalignment since the input specifies that prostate scans are normal, but the model still suggests it could be related to the prostate, which can seem redundant.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - The response provides useful advice about potential causes and suggests consulting a doctor, which is good. However, it could have been more complete by directly addressing the concern about not being able to stand while urinating and providing more detailed advice tailored to the user's unique situation mentioned in the context, such as muscle constriction.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  - The response is fluent and human-like, with polite phrasing and a helpful tone. It uses soft, reassuring language that lends human quality, although a slight improvement in addressing the user's specific details could enhance naturalness further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response somewhat aligns with the context by addressing blood sugar fluctuations during the menstrual cycle. However, there's an inconsistency: it misinterprets fasting guidelines by suggesting a scenario where the glucose test might have been affected by eating, despite mentioning a 12-hour fast. This reduces coherence.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The response partially answers the question by suggesting that menstrual cycles can affect blood sugar levels. However, it fails to definitively state whether a 12-hour fasting glucose test would be specifically affected by the menstrual cycle. The provided information is vague and incomplete, and it lacks a direct answer.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The model's response sounds fluent and human-like. It reads smoothly and uses a conversational tone, although it could be improved by avoiding contradictory statements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided, recognizing the high WBC count as a potential indicator of infection or inflammation and the importance of consulting a doctor, which is relevant to the user's medical background.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response sufficiently answers the question by highlighting the significance of a high WBC count and suggesting consultation with a doctor for further investigation. However, it doesn't mention the possibility of contacting a hematologist directly, as suggested in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds human-like, offering clear advice in a reassuring manner. It uses appropriate language and tone for addressing a medical concern.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is coherent in the sense that it outlines the possible reasons behind the tearing of the frenulum and describes the two surgical options available. However, it does not specifically address the individual's HbA1c levels or the frequent occurrence of smegma as mentioned in the context, which is necessary to align more closely with the input.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response provides comprehensive general information about the medical procedures but fails to directly advise on which procedure could be more beneficial considering the user's specific condition, particularly regarding the crossover effects of diabetes and infections. It does not clearly relate the individual's well-managed HbA1c levels to the decision-making process for surgery, hence falling short of being fully complete.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and professional, sounding appropriately human-like for a medical consultation. The language used is clear and understandable, maintaining a formal yet accessible tone suitable for a patient interaction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context provided. It acknowledges the concern, discusses potential factors that could affect blood sugar levels, and suggests discussing the results with a doctor for a proper diagnosis, which aligns with the scenario presented in the input.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model's response provides a general overview and suggests seeking medical advice and making lifestyle changes, but it lacks specific mention of the alternative tests recommended in the true answer, such as HbA1c, FBS, and PPBS. It gives a broad response without addressing specific diagnostic steps.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent, well-structured, and human-like. It uses natural language to convey advice and recommendations, sounding empathetic and professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the input query. It emphasizes creating a healthy environment for conception, which matches the query's intent. However, it could be slightly more specific about medical checks and factors affecting male fertility. \n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response addresses several important points, such as maintaining a healthy weight, diet, exercise, avoiding tobacco and alcohol, managing stress, and considering supplements. It also suggests regular check-ups. However, it misses mentioning some key medical checks and specific considerations for different ages, as noted in the true answer, such as visits to the gynecologist, fertility testing, and understanding of the fertile period.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "The response is fluent, conversational, and human-like. It starts with a friendly greeting and uses understandable language, making it sound natural and approachable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It correctly identifies the potential issue with the prostate and suggests a common condition (prostate inflammation) that could explain the symptoms described by the user. The advice given is appropriate and follows a logical progression from symptom recognition to potential next steps.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response sufficiently addresses the question by suggesting a potential cause (prostate inflammation) and offering immediate steps to manage symptoms (such as taking pain relievers and seeing a urologist). However, it lacks some depth in terms of diagnostics and doesn't explore other potential causes or inquire about additional symptoms that could aid in diagnosis, as seen in the true answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is fluent and human-like. It uses appropriate and empathetic language, which adds to the naturalness of the response. The tone is professional and compassionate, similar to what one might expect from a doctor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context by addressing the concern of miscarriages and suggests possible common causes. It advises consulting a doctor, which is consistent with the context of seeking medical advice.\n",
      "  \n",
      "- Completeness: 3.5\n",
      "  - While the model provides a general overview of potential causes for miscarriages, it lacks specific advice on what investigations should be done, as seen in the true answer. It could have included suggestions for specific tests like diabetes and thyroid screening or expanded on the need for further specific diagnostic exams.\n",
      "  \n",
      "- Naturalness: 4.8\n",
      "  - The model's response is fluent and human-like. It uses compassionate and reassuring language, which is typical in medical advice contexts. The tone is supportive and respectful, encouraging further questions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is mostly coherent with the input context. It correctly identifies the healthy lifestyle and analyzes the blood glucose and thyroid profile results well. However, the model incorrectly states that the TSH levels are a bit high, which contradicts the input data given. Additionally, it claims the vitamin D levels are normal, which they are not as per the reference in the true answer.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The model addresses most parts of the input, covering exercise, diet, and test results. However, it overlooks the slightly low vitamin D level that necessitates intervention. Missing this point results in an incomplete analysis of the test results.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is written fluently and in a human-like manner. It uses appropriate language for a medical consultation and provides general health advice. Although there's a slight misunderstanding in interpreting the results, the style remains natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The response logically aligns with the context by acknowledging the high blood sugar levels, recognizing the medication being used, and suggesting consulting a doctor, which demonstrates understanding of the gravity of the situation. However, it incorrectly lists the components of Co-Diovan, which contains valsartan and hydrochlorothiazide, not enalapril.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response addresses the immediate concern regarding high blood sugar levels and suggests lifestyle modifications like diet and exercise but does not provide specific actionable steps or alternative medication suggestions like the true answer does. It also does not directly address the question about continuing fasting.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response sounds fluent and human-like with polite and concise advice. The tone is professional and empathetic, consistent with what one might expect from a healthcare provider. However, the completeness issue could slightly affect its perceived naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response logically aligns with the context given and acknowledges the change in blood sugar levels over time. It provides sensible advice on consulting a doctor and highlights the importance of ongoing diabetes management.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - While the model suggests some appropriate next steps such as consulting a doctor and lifestyle changes, it doesn't provide specific details on target blood sugar levels or address potential implications of the user's age or future pregnancy plans, which are covered in the True Answer.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  - The response is fluent and human-like, maintaining a professional and empathetic tone that is appropriate for a medical consultation. It reads like a considerate response from a healthcare professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response logically aligns with the context in that it attempts to provide a diagnosis and treatment plan based on the symptoms described. However, the diagnosis of a bone spur is different from the true answer's diagnosis of plantar fasciitis, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response provides a plausible diagnosis and suggests some treatment options like RICE therapy and NSAIDs, which partially answers the query. But it misses specific medication recommendations and additional treatment options (like those involving physical therapy) that are present in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and human-like, using appropriate language and structure for a medical consultation. It maintains a professional tone and is easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It acknowledges the concern of the patient and references possible causes of the pain, which fits well within the given information in the input.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model addresses the question by mentioning potential causes of the pain and advises consulting a healthcare professional but does not delve into further inquiries or diagnostic questions, as the true answer does. It provides a reasonable response but lacks in-depth questioning or guidance that might lead to a more thorough assessment.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response sounds very fluent and human-like. It adopts a professional tone that is appropriate for a doctor-patient interaction, making it sound natural and considerate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns logically with the context provided. It explains the nature of CRP and ESR appropriately, though it could better address specific conditions mentioned, such as allergic rhinitis, which is highlighted in the input.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response covers the main points regarding CRP levels and potential causes for inflammation, but it lacks specific recommendations or connections to the listed conditions, like allergic rhinitis, and doesn't address the question about the normal ESR level in detail.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is fluent and human-like. It maintains a compassionate tone and is well-articulated, sounding like a patient-focused conversation one might have with a healthcare provider.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌèâÍ∑† Ï†êÏàò:\n",
      "Coherence       4.103000\n",
      "Completeness    3.411000\n",
      "Naturalness     4.630000\n",
      "BLEURT          0.692195\n",
      "BERTScore_F1    0.497527\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# generation\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "generation = df[df['task'] == 'generation']\n",
    "results = []\n",
    "\n",
    "for _, row in generation.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column BLEURT not found in DataFrame. Skipping normalization.\n",
      "Warning: Column BERTScore_F1 not found in DataFrame. Skipping normalization.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Coherence', 'Completeness', 'Naturalness', 'BLEURT', 'BERTScore_F1'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 147\u001b[0m\n\u001b[1;32m    144\u001b[0m evaluation_df \u001b[38;5;241m=\u001b[39m normalize_scores(evaluation_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEURT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m evaluation_df \u001b[38;5;241m=\u001b[39m normalize_scores(evaluation_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore_F1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m average_scores \u001b[38;5;241m=\u001b[39m evaluation_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoherence\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleteness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaturalness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEURT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore_F1\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÌèâÍ∑† Ï†êÏàò:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(average_scores)\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Coherence', 'Completeness', 'Naturalness', 'BLEURT', 'BERTScore_F1'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# daily_diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "daily = df[df['task'] == 'daily_diets']\n",
    "results = []\n",
    "\n",
    "for i, row in daily.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_outpu_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Evaluation {i+1} result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌèâÍ∑† Ï†êÏàò:\n",
      "Coherence       3.223577\n",
      "Completeness    2.880081\n",
      "Naturalness     3.008130\n",
      "BLEURT          0.488236\n",
      "BERTScore_F1    0.627131\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# alternative_diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "alternative = df[df['task'] == 'alternative_diet']\n",
    "results = []\n",
    "\n",
    "for _, row in alternative.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Evaluation {i+1} result:\\n{evaluation}\")\n",
    "            \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>servings</th>\n",
       "      <th>steps</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition_facts</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark</td>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark: Dive into ...</td>\n",
       "      <td>10 min</td>\n",
       "      <td>4 hr</td>\n",
       "      <td>6 Servings</td>\n",
       "      <td>['Cover a freezer-safe tray with parchment pap...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...</td>\n",
       "      <td>{'Servings': '6 Servings', 'Serving Size': '1 ...</td>\n",
       "      <td>[{'label': 'Plain Nonfat Greek yogurt', 'us_me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maple-Pumpkin Spice Oatmeal Cookies</td>\n",
       "      <td>Description not found</td>\n",
       "      <td>10 min</td>\n",
       "      <td>25 min</td>\n",
       "      <td>14 Servings</td>\n",
       "      <td>['Preheat the oven to 350 degrees F. Line two ...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...</td>\n",
       "      <td>{'Servings': '14 Servings', 'Serving Size': '1...</td>\n",
       "      <td>[{'label': 'old-fashioned rolled oats', 'us_me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0   Raspberry Swirl Frozen Yogurt Bark   \n",
       "1  Maple-Pumpkin Spice Oatmeal Cookies   \n",
       "\n",
       "                                         description prep_time cook_time  \\\n",
       "0  Raspberry Swirl Frozen Yogurt Bark: Dive into ...    10 min      4 hr   \n",
       "1                              Description not found    10 min    25 min   \n",
       "\n",
       "      servings                                              steps  \\\n",
       "0   6 Servings  ['Cover a freezer-safe tray with parchment pap...   \n",
       "1  14 Servings  ['Preheat the oven to 350 degrees F. Line two ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...   \n",
       "1  ['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...   \n",
       "\n",
       "                                     nutrition_facts  \\\n",
       "0  {'Servings': '6 Servings', 'Serving Size': '1 ...   \n",
       "1  {'Servings': '14 Servings', 'Serving Size': '1...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  [{'label': 'Plain Nonfat Greek yogurt', 'us_me...  \n",
       "1  [{'label': 'old-fashioned rolled oats', 'us_me...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfh = pd.read_csv(\"/data/jaesung/llm_for_diabetes/src/data/data2_daily_diets/diabetes_food_hub_new_nutri_facts.csv\")\n",
    "dfh.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [00:00<00:00, 22063.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results for Each Row ===\n",
      "Row Index: 661\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 662\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 663\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 664\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 665\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 666\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 667\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 668\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 669\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 670\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 671\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 672\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 673\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 674\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 675\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 676\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 677\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 678\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 679\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 680\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 681\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 682\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 683\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 684\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 685\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 686\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 687\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 688\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 689\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 690\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 691\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 692\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 693\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 694\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 695\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 696\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 697\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 698\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 699\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 700\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 701\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 702\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 703\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 704\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 705\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 706\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 707\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 708\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 709\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 710\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 711\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 712\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 713\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 714\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 715\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 716\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 717\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 718\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 719\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 720\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 721\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 722\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 723\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 724\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 725\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 726\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 727\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 728\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 729\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 730\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 731\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 732\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 733\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 734\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 735\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 736\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 737\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 738\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 739\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 740\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 741\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 742\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 743\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 744\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 745\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 746\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 747\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 748\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 749\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 750\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 751\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 752\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 753\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 754\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 755\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 756\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 757\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 758\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 759\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 760\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 761\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 762\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 763\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 764\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 765\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 766\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 767\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 768\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 769\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 770\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 771\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 772\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 773\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 774\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 775\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 776\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 777\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 778\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 779\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 780\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 781\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 782\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 783\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 784\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 785\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 786\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 787\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 788\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 789\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 790\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 791\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 792\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 793\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 794\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 795\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 796\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 797\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 798\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 799\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 800\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 801\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 802\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 803\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 804\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 805\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 806\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 807\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 808\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 809\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 810\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 811\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 812\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 813\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 814\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 815\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 816\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 817\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 818\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 819\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 820\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 821\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 822\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 823\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 824\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 825\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 826\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 827\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 828\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 829\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 830\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 831\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 832\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 833\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 834\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 835\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 836\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 837\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 838\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 839\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 840\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 841\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 842\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 843\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 844\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 845\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 846\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 847\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 848\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 849\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 850\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 851\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 852\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 853\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 854\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 855\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 856\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 857\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 858\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 859\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 860\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 861\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 862\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 863\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 864\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 865\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 866\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 867\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 868\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 869\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 870\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 871\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 872\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 873\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 874\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 875\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 876\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 877\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 878\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 879\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 880\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 881\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 882\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 883\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 884\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 885\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 886\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 887\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 888\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 889\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 890\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 891\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 892\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 893\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 894\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 895\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 896\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 897\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 898\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 899\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 900\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 901\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 902\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 903\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 904\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 905\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 906\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 907\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 908\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 909\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 910\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 911\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 912\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 913\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 914\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 915\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 916\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 917\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 918\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 919\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 920\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 921\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 922\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 923\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 924\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 925\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 926\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 927\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 928\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 929\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 930\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 931\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 932\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 933\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 934\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "=== Overall Averages ===\n",
      "Output Average Nutri-Score: None\n",
      "Model Output Average Nutri-Score: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# daily diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return all(key in data for key in ['Breakfast', 'Lunch', 'Dinner'])\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # Í≥ºÏùº/Ï±ÑÏÜå ÎπÑÏú®ÏùÑ 100g Í∏∞Ï§ÄÏúºÎ°ú Î≥ÄÌôò\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data) if isinstance(data, (int, float, str)) else default\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # Ï†ÑÏ≤¥ Î¨¥Í≤å Í≥ÑÏÇ∞\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g Í∏∞Ï§ÄÏúºÎ°ú ÏÑ±Î∂Ñ Ï†ïÍ∑úÌôî\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_meal_nutri_score(meal_data, dfh):\n",
    "    meal_scores = {}\n",
    "\n",
    "    for meal, title in meal_data.items():\n",
    "        matched_row = find_most_similar_row(title, dfh)\n",
    "        if matched_row is None:\n",
    "            continue\n",
    "\n",
    "        nutrition_facts = matched_row['nutrition_facts']\n",
    "        ingredients = matched_row['ingredients']\n",
    "        score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "\n",
    "        if score is None:\n",
    "            print(f\"Warning: Nutri-Score calculation failed for meal '{meal}' with title '{title}'.\")\n",
    "            grade = \"N/A\"\n",
    "        else:\n",
    "            grade = get_nutri_score_grade(score)\n",
    "\n",
    "        meal_scores[meal] = {'score': score, 'grade': grade}\n",
    "\n",
    "    return meal_scores\n",
    "\n",
    "def calculate_scores_with_comparison(df, dfh):\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        output_scores = {}\n",
    "        model_scores = {}\n",
    "        if is_valid_meal_structure(row.get('output', '')):\n",
    "            output_data = json.loads(row['output'])\n",
    "            output_scores = calculate_meal_nutri_score(output_data, dfh)\n",
    "        if is_valid_meal_structure(row.get('model_output_512', '')):\n",
    "            model_data = json.loads(row['model_output_512'])\n",
    "            model_scores = calculate_meal_nutri_score(model_data, dfh)\n",
    "        results.append({'row_index': idx, 'output_scores': output_scores, 'model_scores': model_scores})\n",
    "    return results\n",
    "\n",
    "def calculate_average_scores(results):\n",
    "    \"\"\"\n",
    "    Calculate the average Nutri-Scores for outputs and model outputs.\n",
    "    \"\"\"\n",
    "    output_total_score = 0\n",
    "    model_total_score = 0\n",
    "    output_count = 0\n",
    "    model_count = 0\n",
    "\n",
    "    for result in results:\n",
    "        # Extract output scores\n",
    "        for meal, score_data in result['output_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                output_total_score += score_data['score']\n",
    "                output_count += 1\n",
    "\n",
    "        # Extract model scores\n",
    "        for meal, score_data in result['model_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                model_total_score += score_data['score']\n",
    "                model_count += 1\n",
    "\n",
    "    # Calculate averages\n",
    "    output_avg = output_total_score / output_count if output_count > 0 else None\n",
    "    model_avg = model_total_score / model_count if model_count > 0 else None\n",
    "\n",
    "    return output_avg, model_avg\n",
    "\n",
    "\n",
    "# 'daily_diets' task Nutri-Score calculation\n",
    "filtered_df = df[df['task'] == 'daily_diets']\n",
    "results = calculate_scores_with_comparison(filtered_df, dfh)\n",
    "\n",
    "# Calculate overall averages\n",
    "output_avg, model_avg = calculate_average_scores(results)\n",
    "\n",
    "# Print results\n",
    "print(\"=== Results for Each Row ===\")\n",
    "for result in results:\n",
    "    print(f\"Row Index: {result['row_index']}\")\n",
    "    print(f\"Output Scores: {result['output_scores']}\")\n",
    "    print(f\"Model Output Scores: {result['model_scores']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== Overall Averages ===\")\n",
    "print(f\"Output Average Nutri-Score: {output_avg}\")\n",
    "print(f\"Model Output Average Nutri-Score: {model_avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/246 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 158/246 [03:34<01:46,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error identifying fruits and vegetables: unterminated string literal (detected at line 1) (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 207/246 [04:37<00:40,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Total weight is zero. Skipping calculation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 246/246 [05:27<00:00,  1.33s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 216\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# Execution\u001b[39;00m\n\u001b[1;32m    215\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malternative_diet\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 216\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_scores_with_comparison_no_meals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Cell \u001b[0;32mIn[32], line 207\u001b[0m, in \u001b[0;36mcalculate_scores_with_comparison_no_meals\u001b[0;34m(df, dfh)\u001b[0m\n\u001b[1;32m    200\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    201\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_index\u001b[39m\u001b[38;5;124m'\u001b[39m: idx,\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         })\n\u001b[1;32m    206\u001b[0m final_output_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(output_scores_list) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(output_scores_list) \u001b[38;5;28;01mif\u001b[39;00m output_scores_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m final_model_output_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_output_scores_list\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(model_output_scores_list) \u001b[38;5;28;01mif\u001b[39;00m model_output_scores_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Average Nutri-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_output_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Output Average Nutri-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_model_output_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# alternative diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return isinstance(data, dict)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # Í≥ºÏùº/Ï±ÑÏÜå ÎπÑÏú®ÏùÑ 100g Í∏∞Ï§ÄÏúºÎ°ú Î≥ÄÌôò\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # Ï†ÑÏ≤¥ Î¨¥Í≤å Í≥ÑÏÇ∞\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g Í∏∞Ï§ÄÏúºÎ°ú ÏÑ±Î∂Ñ Ï†ïÍ∑úÌôî\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_scores_with_comparison_no_meals(df, dfh):\n",
    "    results = []\n",
    "    output_scores_list = []\n",
    "    model_output_scores_list = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            output_text = row.get('output', '')\n",
    "            if output_text:\n",
    "                matched_row = find_most_similar_row(output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    output_scores_list.append(output_score)\n",
    "                else:\n",
    "                    output_score = None\n",
    "\n",
    "            model_output_text = row.get('model_output_512', '')\n",
    "            if model_output_text:\n",
    "                matched_row = find_most_similar_row(model_output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    model_output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    model_output_scores_list.append(model_output_score)\n",
    "                else:\n",
    "                    model_output_score = None\n",
    "\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': output_score,\n",
    "                'model_output_score': model_output_score\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': None,\n",
    "                'model_output_score': None\n",
    "            })\n",
    "\n",
    "    final_output_avg = sum(output_scores_list) / len(output_scores_list) if output_scores_list else None\n",
    "    final_model_output_avg = sum(model_output_scores_list) / len(model_output_scores_list) if model_output_scores_list else None\n",
    "\n",
    "    print(f\"Output Average Nutri-Score: {final_output_avg}\")\n",
    "    print(f\"Model Output Average Nutri-Score: {final_model_output_avg}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Execution\n",
    "filtered_df = df[df['task'] == 'alternative_diet']\n",
    "results = calculate_scores_with_comparison_no_meals(filtered_df, dfh)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env_kernel",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
