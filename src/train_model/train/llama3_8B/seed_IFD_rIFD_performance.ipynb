{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# \n",
    "file_paths = [\n",
    "    \"/data/jaesung/llm_for_diabetes/src/trial8/train/llama3_3B/response/real_seed_IFD_rIFD14.jsonl\",\n",
    "    # \"/data/jaesung/llm_for_diabetes/src/trial/CoT_collection/model_response/test_1.jsonl\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.2400\n"
     ]
    }
   ],
   "source": [
    "# medqa\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "qa1 = df[df['task'] == 'qa1']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(qa1)\n",
    "\n",
    "for _, row in qa1.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "# medmcqa\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "qa2 = df[df['task'] == 'qa2']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(qa2)\n",
    "\n",
    "for _, row in qa2.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.2000\n"
     ]
    }
   ],
   "source": [
    "# pubmedqa\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "qa3 = df[df['task'] == 'qa3']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(qa3)\n",
    "\n",
    "for _, row in qa3.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-based Accuracy: 0.0700\n"
     ]
    }
   ],
   "source": [
    "# bionli\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú (API ÌÇ§ ÏÑ§Ï†ï)\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def check_answer_correctness(true_answer, model_answer):\n",
    "    \"\"\"\n",
    "    GPT-3.5-turboÎ•º ÏÇ¨Ïö©ÌïòÏó¨ true_answerÏôÄ model_answerÍ∞Ä Í∞ôÏùÄ ÏùòÎØ∏Ïù∏ÏßÄ ÌåêÎ≥Ñ\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are evaluating the correctness of an AI-generated medical answer.\n",
    "    Compare the following two answers and determine if they mean the same thing.\n",
    "\n",
    "    **Correct Answer**: {true_answer}\n",
    "    **Model Output**: {model_answer}\n",
    "\n",
    "    If the model output correctly conveys the same answer as the correct answer, respond only with \"YES\".\n",
    "    If the model output is incorrect or has a different meaning, respond only with \"NO\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result == \"YES\"  # GPT ÏùëÎãµÏù¥ YESÎ©¥ Ï†ïÎãµ Ï≤òÎ¶¨\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT evaluation: {e}\")\n",
    "        return False  # Ïò§Î•ò Î∞úÏÉù Ïãú Ïò§Îãµ Ï≤òÎ¶¨\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌïÑÌÑ∞ÎßÅ\n",
    "nli = df[df['task'] == 'nli']\n",
    "\n",
    "# Ï†ïÎãµ ÌåêÎ≥Ñ ÏàòÌñâ\n",
    "correct_count = 0\n",
    "total_count = len(nli)\n",
    "\n",
    "for _, row in nli.iterrows():\n",
    "    true_answer = row['output'].strip()\n",
    "    model_answer = row['model_output_32'].strip()\n",
    "    is_correct = check_answer_correctness(true_answer, model_answer)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "\n",
    "# Accuracy Í≥ÑÏÇ∞\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "print(f\"GPT-based Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating drug/effect pairs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 20153.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Drug/Effect Pair Evaluation (Strict Match, cleaned)\n",
      "‚úÖ Precision: 0.2900\n",
      "‚úÖ Recall   : 0.2900\n",
      "‚úÖ F1 Score : 0.2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_drug_effect_clean(text):\n",
    "    \"\"\"\n",
    "    output ÎòêÎäî model_output_32ÏóêÏÑú drugÏôÄ effect Í∞íÏùÑ Ï∂îÏ∂úÌïòÍ≥†,\n",
    "    \\nÏù¥ÎÇò ÌäπÏàò ÌÜ†ÌÅ∞ Ïù¥ÌõÑÏùò ÏÑ§Î™ÖÏùÄ Ï†úÍ±∞ÌïúÎã§.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return {\"drug\": None, \"effect\": None}\n",
    "    \n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # drug Ï∂îÏ∂ú\n",
    "    drug_match = re.search(r'drug:\\s*([^,\\n|<]+)', text)\n",
    "    drug = drug_match.group(1).strip() if drug_match else None\n",
    "\n",
    "    # effect Ï∂îÏ∂ú\n",
    "    effect_match = re.search(r'effect:\\s*([^\\n|<]+)', text)\n",
    "    effect = effect_match.group(1).strip() if effect_match else None\n",
    "\n",
    "    return {\"drug\": drug, \"effect\": effect}\n",
    "\n",
    "# ‚úÖ 're2' taskÎßå ÌïÑÌÑ∞ÎßÅ\n",
    "re_df = df[df['task'] == 're2'].reset_index(drop=True)\n",
    "\n",
    "# ‚úÖ ÌÜµÍ≥Ñ Î≥ÄÏàò Ï¥àÍ∏∞Ìôî\n",
    "true_positive, false_positive, false_negative = 0, 0, 0\n",
    "\n",
    "# ‚úÖ ÌèâÍ∞Ä Î£®ÌîÑ\n",
    "for _, row in tqdm(re_df.iterrows(), total=len(re_df), desc=\"Evaluating drug/effect pairs\"):\n",
    "    true_vals = extract_drug_effect_clean(row['output'])\n",
    "    pred_vals = extract_drug_effect_clean(row['model_output_32'])\n",
    "\n",
    "    if true_vals[\"drug\"] and true_vals[\"effect\"]:\n",
    "        if true_vals == pred_vals:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "            if pred_vals[\"drug\"] or pred_vals[\"effect\"]:\n",
    "                false_positive += 1\n",
    "    elif pred_vals[\"drug\"] or pred_vals[\"effect\"]:\n",
    "        false_positive += 1\n",
    "\n",
    "# ‚úÖ ÏßÄÌëú Í≥ÑÏÇ∞\n",
    "precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# ‚úÖ Ï∂úÎ†•\n",
    "print(\"\\nüìä Drug/Effect Pair Evaluation (Strict Match, cleaned)\")\n",
    "print(f\"‚úÖ Precision: {precision:.4f}\")\n",
    "print(f\"‚úÖ Recall   : {recall:.4f}\")\n",
    "print(f\"‚úÖ F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model_output_32'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_output_32'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# outputÍ≥º model_output Î™®Îëê Î¶¨Ïä§Ìä∏ ÌòïÌÉúÎ°ú ÌååÏã±\u001b[39;00m\n\u001b[1;32m     24\u001b[0m ie[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ie[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(safe_eval)\n\u001b[0;32m---> 25\u001b[0m ie[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_output_32\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ie[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_output_32\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(safe_eval)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Precision, Recall, F1-score Í≥ÑÏÇ∞ Ìï®Ïàò\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_scores\u001b[39m(y_true, y_pred):\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_output_32'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 'ie' ÌÉúÏä§ÌÅ¨ ÌïÑÌÑ∞ÎßÅ\n",
    "ie = df[df['task'] == 'ie'].copy()\n",
    "\n",
    "# Î¨∏ÏûêÏó¥ ÌòïÌÉúÎ•º ÏïàÏ†ÑÌïòÍ≤å Î¶¨Ïä§Ìä∏Î°ú ÌååÏã±ÌïòÎäî Ìï®Ïàò\n",
    "def safe_eval(val):\n",
    "    if isinstance(val, list):  \n",
    "        return [str(i).strip().lower() for i in val]\n",
    "    elif isinstance(val, str) and val.strip():  \n",
    "        try:\n",
    "            parsed = ast.literal_eval(val)\n",
    "            if isinstance(parsed, list):\n",
    "                return [str(i).strip().lower() for i in parsed]\n",
    "            else:\n",
    "                return [str(parsed).strip().lower()]\n",
    "        except:\n",
    "            return [val.strip().lower()]\n",
    "    return []\n",
    "\n",
    "# outputÍ≥º model_output Î™®Îëê Î¶¨Ïä§Ìä∏ ÌòïÌÉúÎ°ú ÌååÏã±\n",
    "ie[\"output\"] = ie[\"output\"].apply(safe_eval)\n",
    "ie[\"model_output_32\"] = ie[\"model_output_32\"].apply(safe_eval)\n",
    "\n",
    "# Precision, Recall, F1-score Í≥ÑÏÇ∞ Ìï®Ïàò\n",
    "def calculate_scores(y_true, y_pred):\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for true_vals, pred_vals in zip(y_true, y_pred):\n",
    "        if not true_vals and not pred_vals:\n",
    "            all_precisions.append(1.0)\n",
    "            all_recalls.append(1.0)\n",
    "            all_f1s.append(1.0)\n",
    "            continue\n",
    "\n",
    "        true_count = Counter(true_vals)\n",
    "        pred_count = Counter(pred_vals)\n",
    "\n",
    "        TP = sum(min(true_count[k], pred_count[k]) for k in true_count.keys() & pred_count.keys())\n",
    "        FP = sum(pred_count[k] - true_count.get(k, 0) for k in pred_count.keys())\n",
    "        FN = sum(true_count[k] - pred_count.get(k, 0) for k in true_count.keys())\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    return sum(all_precisions) / len(all_precisions), sum(all_recalls) / len(all_recalls), sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "def calculate_scores_ignore_duplicates(y_true, y_pred):\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for true_vals, pred_vals in zip(y_true, y_pred):\n",
    "        true_set = set(true_vals)\n",
    "        pred_set = set(pred_vals)\n",
    "\n",
    "        TP = len(true_set & pred_set)\n",
    "        FP = len(pred_set - true_set)\n",
    "        FN = len(true_set - pred_set)\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    return sum(all_precisions) / len(all_precisions), sum(all_recalls) / len(all_recalls), sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "\n",
    "# Ï†êÏàò Í≥ÑÏÇ∞\n",
    "precision, recall, f1 = calculate_scores_ignore_duplicates(ie[\"output\"], ie[\"model_output_32\"])\n",
    "\n",
    "# Ï∂úÎ†•\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "The model's response is non-existent, which necessitates specific scores on the metrics provided:\n",
      "\n",
      "- **Coherence**: 1.0  \n",
      "  There is no response, hence no logical alignment with the context can be evaluated or assessed.\n",
      "  \n",
      "- **Completeness**: 1.0  \n",
      "  The model's response does not answer the question at all, lacking any information or details necessary to evaluate completeness.\n",
      "\n",
      "- **Naturalness**: 1.0  \n",
      "  With no response provided, the aspect of fluency or human-like quality of language cannot be determined.\n",
      "\n",
      "Overall, the model's performance is insufficient as no output was generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the given input and the model's response:\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "  The model's response is missing entirely (\"<|end_of_text|>\"). There is no logical alignment or structure since no response has been generated.\n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "  The model's response does not answer the question or provide any information regarding the complex medical and pregnancy situation described. It's completely absent.\n",
      "\n",
      "- **Naturalness: 1.0**  \n",
      "  Since the model's response is non-existent, it cannot be evaluated for fluency or human-likeness.\n",
      "\n",
      "Overall, the model failed to provide a response, hence the lowest possible scores for each metric.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided input and model's response, here's the evaluation:\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "  The model's response is completely absent, which means there is no logical alignment or flow based on the input context. \n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "  The model did not provide any response, leaving the patient's questions unanswered. As such, the model's response does not fulfill the requirement to sufficiently answer the patient's questions regarding their diagnosis and next steps.\n",
      "\n",
      "- **Naturalness: 1.0**  \n",
      "  There is no response from the model, so the evaluation for naturalness cannot be applied as there is no text to assess for fluency or human-like qualities.\n",
      "\n",
      "Overall, due to the lack of response, the model scores the lowest on all metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "\n",
      "The model's response is coherent in that it outlines general information about what a doctor's note should include, which aligns with the context of discussing the patient's medical condition and treatment. However, it does not directly address or integrate the specific dialogue or details from the interaction between the doctor and the patient, which affects its coherence with the given situation.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The model's response does not actually address the core details found in the interaction between the doctor and patient. Instead, it provides a template for a doctor's note that could apply to almost any patient, lacking specifics about the symptoms, medical history, examination findings, or any mention of the ultimate diagnosis and outcome discussed in the context.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The model's response is natural in its language use and reads fluently. It is structured and formatted in a clear, professional manner typical of medical documentation guidelines, which makes it seem human-like in terms of language and presentation. However, the generic nature of the response reduces its efficacy in communicating concretely about the situation at hand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Given that the model's response is `<|end_of_text|>`, indicating that it provided no response at all, the evaluations for each metric based on the absence of content are as follows:\n",
      "\n",
      "- **Coherence: 1.0**\n",
      "  - Since there is no response provided by the model, there is no content to evaluate for logical alignment with the context.\n",
      "\n",
      "- **Completeness: 1.0**\n",
      "  - The model fails to offer any response, thus it does not provide an answer to the question asked by the patient's family about the patient's current and future condition.\n",
      "\n",
      "- **Naturalness: 1.0**\n",
      "  - With no response, there is nothing to evaluate in terms of fluency or human-like quality.\n",
      "\n",
      "Overall, without any output from the model, the evaluation metrics inevitably score the lowest possible ratings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided evaluation metrics, here's the assessment of the model's response:\n",
      "\n",
      "- Coherence: 1.0\n",
      "  - The model's response is missing entirely. Therefore, it cannot be evaluated for coherence with the context provided in the input, as there is no logical alignment or disalignment present.\n",
      "\n",
      "- Completeness: 1.0\n",
      "  - The response does not provide any answer or information, thus failing to address or answer any part of the question or situation described in the input. \n",
      "\n",
      "- Naturalness: 1.0\n",
      "  - Given that there is no response from the model, it cannot be evaluated for fluency or human-like quality in its language.\n",
      "\n",
      "The model's response does not exist, resulting in the lowest possible score for each of the metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "It seems there is a lack of a direct response from the model (denoted as \"<|end_of_text|>\"). This will significantly affect the evaluation, especially in the second metric. Here's how I'd rate each metric:\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "  Without a response, there's no way to determine if the model's output logically aligns with the provided context. Consequently, coherence is rated at the lowest possible score.\n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "  Again, without a response, the model doesn't answer the question at all. Hence, completeness is also rated at the lowest possible score.\n",
      "\n",
      "- **Naturalness: 1.0**  \n",
      "  Naturalness refers to the fluency and human-likeness of the response. With no response from the model, it is impossible to evaluate these aspects. Therefore, the score for naturalness must be 1.0.\n",
      "\n",
      "Overall, the lack of a response leads to the lowest scores for all metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.0\n",
      "- Naturalness: 4.5\n",
      "\n",
      "**Evaluation:**\n",
      "\n",
      "- **Coherence (4.5):** The model's response maintains a logical structure and flow, adequately capturing the chronological sequence and details of the medical interaction. It starts with the patient's initial symptoms and follows through with the diagnostic process and outcomes, which aligns with the original conversation.\n",
      "\n",
      "- **Completeness (3.0):** While the response captures the broad strokes of the conversation, it does not adequately condense all the important aspects into a clear clinical note. It is more of a verbatim repetition rather than an extracted summary with critical information structured succinctly. Specific details, such as the timeline (e.g., \"Postpartum day 53\"), are missing, which are present in the true answer.\n",
      "\n",
      "- **Naturalness (4.5):** The model's response sounds fluent and human-like. The language used is clear and precise, and it closely resembles how clinical notes could be structured. However, the repetition of the dialogue rather than a summarized narrative detracts slightly from how an actual summary might be perceived.\n",
      "\n",
      "Improvements could be made on completeness by transforming the call-and-response structure into a more concise, integrated clinical note that covers all key details and insights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "\n",
      "The model's response inaccurately summarizes the conversation by describing a 65-year-old male, Mr. Y, instead of the 80-year-old Caucasian female patient as described in the true answer. Additionally, the model fails to mention important details such as the patient's hemoptysis and incorrect bacterial, mycobacterial and fungal infection results during the bronchoscopy. These discrepancies indicate a lack of coherence with the provided context and true answer.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The model captures some of the main symptoms such as fatigue, weakness, and coughing, and notes the multifocal pneumonia, acute kidney injury, and renal replacement therapy. However, it misses critical elements from the true answer, such as the intravenous treatments received, laboratory tests results, and a more detailed history guiding the reason for renal replacement therapy initiation. The incompleteness in terms of symptoms and treatment process reduces the overall effectiveness of the summary.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response is generally fluent and sounds human-like. It uses polite language, correctly structures sentences, and communicates information in a professional tone. However, a minor issue is the repetitive nature of some statements, which slightly detracts from the natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "  The model's response captures the main points of the conversation but lacks a logical alignment with the context. It should provide more structured information and a structured clinical note format, summarizing the patient's conditions and treatment more explicitly.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "  The model includes several key elements such as chronic conditions, surgical procedure, administration of vancomycin, and the development of blisters. However, it omits the critical and outcome-focused components about the severity of the infection and the patient's unfortunate passing, which are essential for a clinical note.\n",
      "\n",
      "- Naturalness: 2.5\n",
      "\n",
      "  The response sounds somewhat disjointed, lacking fluency and cohesion. The repetition of the dialogue transcripts verbatim doesn‚Äôt conform to the concise and structured language typically seen in clinical notes. A more fluent narrative summarization style would improve the naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0  \n",
      "  The model's response is entirely absent, so it does not logically align with the context provided in the input.\n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The model's response does not answer the question or address the scenario at all.\n",
      "\n",
      "- Naturalness: 1.0  \n",
      "  Since there is no response, there is nothing to evaluate for fluency or how human-like it sounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Given that the model's response is essentially blank (\"<|end_of_text|>\"), I will evaluate the response using the criteria provided:\n",
      "\n",
      "- **Coherence: 1.0**\n",
      "  - Without any response, coherence cannot be assessed. There is no content to determine whether it aligns logically with the input context.\n",
      "\n",
      "- **Completeness: 1.0**\n",
      "  - The model's response fails to answer the question or encapsulate any of the information given in the input. It provides no details about the patient's presentations or medical history.\n",
      "\n",
      "- **Naturalness: 1.0**\n",
      "  - The response is empty, hence it does not sound fluent or human-like. There is no attempt at generating a human-like response.\n",
      "\n",
      "Overall, the response is entirely lacking, earning the lowest score in each category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Given that the model's response is empty, we can rate the model's response as follows:\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "  The model's response does not exist, so it cannot logically align with the context provided in the input.\n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "  The model's response is completely missing, so it does not sufficiently answer the question in the input or provide any information.\n",
      "\n",
      "- **Naturalness: 1.0**  \n",
      "  Since there is no response, naturalness cannot be evaluated, and thus it scores the lowest possible rating.\n",
      "\n",
      "Overall, the absence of any response from the model results in the lowest possible score for each metric.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.0**  \n",
      "  The model's response is generally coherent with the input context, providing a well-structured summary. However, it misrepresents the format as a series of questions and responses, whereas the input was a dialogue narrative. While it correctly identifies the key elements from the input, it inaccurately frames them as question-answer pairs, which might slightly detract from its logical alignment with the input context.\n",
      "  \n",
      "- **Completeness: 3.5**  \n",
      "  The response captures much of the important information regarding the patient's medical history, treatment details, and events in the operating room. However, it falls short by not explicitly including the critical outcome of the situation (i.e., the patient's death) and the emotional dialogue at the end between the family and the doctor. Therefore, while informative, it lacks complete coverage of the input's conclusion.\n",
      "\n",
      "- **Naturalness: 3.0**  \n",
      "  The model's response is clear but somewhat mechanical due to its structured, enumeration-like format. While it conveys clinical details well, it lacks a natural conversational tone since it is presented as a list rather than flowing narrative prose. This structure can make it seem less human-like and more like a procedural document.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response aligns well with the context provided in the input. It follows a logical structure, presenting the information in a manner consistent with the conversational flow between the doctor and the patient. However, it can improve by matching more precisely the detailed nature of a clinical note.\n",
      "  \n",
      "- Completeness: 3.5\n",
      "  - The model's response captures many key elements, such as the patient's condition, history, and treatment plan, but it's not sufficient as it misses some specific details mentioned in the conversation. A more complete response would include all relevant data points discussed in the dialogue.\n",
      "  \n",
      "- Naturalness: 4.0\n",
      "  - The response is generally fluent and maintains a professional tone appropriate for a clinical note. However, it occasionally feels slightly less human compared to the true answer, which affects the overall naturalness. More fluid integration of details could enhance its human-like quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "  - The model's response is completely absent, so it doesn‚Äôt provide any logical alignment with the context provided.\n",
      "- Completeness: 1.0\n",
      "  - The model‚Äôs response is absent; therefore, it does not answer the question or provide any information related to the input.\n",
      "- Naturalness: 1.0\n",
      "  - Since there is no response from the model, it cannot be evaluated for fluency or human-like quality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Given the information that the model's response is `<|end_of_text|>`, it indicates that the model provided no response to the input. Here's the evaluation based on the metrics:\n",
      "\n",
      "- **Coherence: 1.0**\n",
      "  - Since there is no response, there's no logical alignment with the context provided in the input.\n",
      "\n",
      "- **Completeness: 1.0**\n",
      "  - The model fails to provide any answer, thus it does not answer the question or capture any details from the input.\n",
      "\n",
      "- **Naturalness: 1.0**\n",
      "  - With no text generated, there's no assessment of fluency or whether it sounds human-like.\n",
      "\n",
      "Overall, the model did not respond and therefore scores the lowest on all metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response logically aligns with the context given. It correctly reproduces the conversation between the doctor and the patient, maintaining consistency with the initial input dialogue.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - While the model's response accurately mimics the dialogue from the input, it does not provide an overarching summary or highlight the key medical details and outcomes, such as the diagnosis and treatments, which the true answer does cover.\n",
      "  \n",
      "- Naturalness: 4.5\n",
      "  - The response is highly fluent and mirrors a natural conversational flow between a doctor and a patient. It consistently uses appropriate language and maintains the format of a genuine doctor-patient interaction. However, it might be considered slightly repetitive without providing new information or insights beyond the original dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 3.5\n",
      "- Naturalness: 4.8\n",
      "\n",
      "**Coherence**: The model's response logically aligns with the conversation flow between the doctor and patient. It captures the sequential nature of the doctor-patient interaction, including symptoms, medical history, and treatment details.\n",
      "\n",
      "**Completeness**: While the model includes key details of the medical conversation, such as symptoms, tests conducted, and the treatment plan, it misses some specific details present in the true answer, like the social history of the mother returning to work, the age of the patient, and the renal ultrasound findings regarding the duplicated collecting system. These omissions affect the completeness of its summary.\n",
      "\n",
      "**Naturalness**: The model's language is fluent and human-like. It presents the information in a professional, doctor-note style, which sounds natural for the context of summarizing a clinical conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0  \n",
      "  The model's response is completely incoherent as it provides no content or logical alignment with the context of the input.\n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The model's response does not contain any information or attempt to answer the task; it is a null response.\n",
      "\n",
      "- Naturalness: 1.0  \n",
      "  The absence of a response from the model results in a lack of any natural, fluent, or human-like characteristics, thus earning the lowest possible score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "    - The model's response accurately follows the structure and sequence of the conversation. It logically aligns with the context provided, organizing the information in a manner consistent with a clinical note.\n",
      "- Completeness: 5.0\n",
      "    - The model's response includes the patient's age, symptoms, diagnostic findings, treatment, and medical history, as well as the results of the physical examination. This thoroughly covers all key points mentioned in the conversation.\n",
      "- Naturalness: 5.0\n",
      "    - The model's response is structured cleanly and reads fluently as a clinical summary. It sounds professional, clear, and human-like, maintaining the formal tone typically expected in clinical documentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0 (The model's response logically aligns with the context provided. It appropriately addresses the medical condition discussed, SIADH, and requests further information on it, demonstrating an understanding of the context.)\n",
      "- Completeness: 4.5 (The response sufficiently asks follow-up questions pertinent to understanding and managing SIADH, which adds depth. However, it does not directly summarize or reflect on key details shared during the doctor's explanation that might be pertinent to the decision-making regarding talking to the mother or arranging follow-ups.)\n",
      "- Naturalness: 5.0 (The language used in the model's response is fluent, polite, and human-like, resembling a genuine inquiry from a patient seeking more information about their medical condition.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response closely aligns with the context provided. It captures the details of the dialogue between the patient and the doctor, and maintains logical consistency with the events described.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response does a good job of summarizing the question context, but it omits some specific details found in the provided context and true answer, such as the exact age of the patient and some specifics of the findings. However, it still captures the essential aspects needed to answer the question.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent and structured in a human-like manner. It presents the information clearly and logically, similar to a concise medical summary one would expect in a clinical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is coherent as it captures all significant events and findings discussed in the conversation between the doctor and the patient. It logically aligns with the context provided, although it is framed as a written summary rather than a direct verbal exchange.\n",
      "  \n",
      "- Completeness: 4.8\n",
      "  - The model's response covers almost all key details from the conversation, including patient history, the condition diagnosed, treatment administered, and the outcome. The only minor aspect missing is a direct mention of the X-ray finding of right basal pneumonia. Otherwise, it sufficiently answers the implied question of summarizing the conversation.\n",
      "\n",
      "- Naturalness: 3.8\n",
      "  - While the response is structured well and clearly communicated, it reads more like a formal letter or medical summary rather than a conversational statement. This affects the naturalness as it shifts away from sounding entirely fluent and human-like in the context of a dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "The model's response is completely absent as indicated by \"<|end_of_text|>\", so it's challenging to provide ratings for coherence, completeness, and naturalness. However, given the parameters of the task, here's an evaluation based on the lack of a response:\n",
      "\n",
      "- Coherence: 1.0\n",
      "  - Since there is no response, there can be no logical alignment with the context provided in the input. \n",
      "\n",
      "- Completeness: 1.0\n",
      "  - The absence of a response means that the model's answer does not sufficiently address any part of the question.\n",
      "\n",
      "- Naturalness: 1.0\n",
      "  - There is no response to assess for fluency or human-like language.\n",
      "\n",
      "If the task permits feedback for improvement, it would be critical for the model to at least generate a basic summary or response to better engage with the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "It appears that the model did not generate a response, as indicated by the \"<|end_of_text|>\" placeholder. Given the lack of an actual response from the model, the evaluation of the response's quality based on the provided metrics would be as follows:\n",
      "\n",
      "- Coherence: 1.0 \n",
      "  - Rationale: There is no response to compare against the context, therefore coherence cannot be established.\n",
      "\n",
      "- Completeness: 1.0 \n",
      "  - Rationale: The absence of a response means that the question from the input is not addressed at all.\n",
      "\n",
      "- Naturalness: 1.0 \n",
      "  - Rationale: Without a response, there is nothing to assess for fluency or how human-like the response is.\n",
      "\n",
      "In summary, due to the model not providing a response, all metrics are scored at the lowest level.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Since the model's response is empty and doesn't provide any content, the evaluation would be as follows:\n",
      "\n",
      "- **Coherence**: 1.0\n",
      "  - The model's response does not logically align with the context because it provides no information or connection to the input context.\n",
      "  \n",
      "- **Completeness**: 1.0\n",
      "  - The model's response completely fails to answer the question or provide any insight, as there is no response provided at all.\n",
      "  \n",
      "- **Naturalness**: 1.0\n",
      "  - An empty response does not exhibit any traits of fluency or sound human-like, as there is nothing to evaluate regarding language or expression.\n",
      "\n",
      "Overall, the model did not generate any response, thus failing to meet any of the evaluation criteria.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "To evaluate the QA model's response based on the absence of the provided summary of the conversation, we will assess each metric independently:\n",
      "\n",
      "1. **Coherence**: 2.0\n",
      "   - The model's response indicates an intention to generate a structured clinical note but fails to provide any meaningful content or structure. There's no coherence between the input dialogue and what would be an expected summarization in the form of a clinical note. The absence of a response signifies a lack of logical alignment with the conversation.\n",
      "\n",
      "2. **Completeness**: 1.0\n",
      "   - The response does not contain any information from the input to form a clinical note. It completely lacks content related to the patient's condition, the medical procedures performed, or the outcome, thus failing to sufficiently answer the task.\n",
      "\n",
      "3. **Naturalness**: N/A\n",
      "   - Since there is no actual content provided in the response, it is impossible to evaluate the naturalness or fluency of the output as there is no text to assess for human-like fluency. In such cases, the score is not applicable.\n",
      "\n",
      "(Note: Given the task is a summarization and the response is effectively non-existent, the metrics are based on the recognition of an absence of output rather than evaluating any present text.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "    - The model's response starts to organize the provided information into a clinical note but abruptly ends and is not fully aligned with the input conversation.\n",
      "   \n",
      "- Completeness: 2.0\n",
      "    - The response is incomplete and does not adequately summarize the entire conversation. Important details such as the patient's complaints, test results, and anxiety disorder diagnosis are missing.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "    - The language used is somewhat professional and sounds plausible for a clinical context. However, the response is cut off mid-sentence, which detracts from its overall naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.5\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response is fairly coherent with the given context, aligning well with the patient's symptoms, examination findings, and treatment trajectory as described by the doctor. It captures most key elements of the conversation, such as the headache, speech disorder, anisocoria, treatment with salicylic acid, and the CT scan results.\n",
      "\n",
      "In terms of completeness, the response includes the majority of critical details mentioned in the interaction. However, it omits some specifics, such as the exact blood pressure values and the administration of intravenous nimodipine, which are present in the true answer. Nonetheless, the overall summary sufficiently answers the implicit question about the patient‚Äôs condition and treatment.\n",
      "\n",
      "Regarding naturalness, the response reads fluently and could convincingly be a human-generated summary. It uses appropriate medical terminology when summarizing the doctor's findings and recommendations, maintaining a professional tone typical in a medical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Given that the model's response is `<|end_of_text|>`, it suggests that the model failed to generate an answer. Let's evaluate the response based on the provided metrics:\n",
      "\n",
      "- **Coherence: 1.0**\n",
      "  - The model's response does not provide any information and therefore does not logically align with the context or engage with the input at all.\n",
      "\n",
      "- **Completeness: 1.0**\n",
      "  - The model did not generate a response to address or answer any part of the discourse. It lacks completeness entirely by failing to produce any content.\n",
      "\n",
      "- **Naturalness: 1.0**\n",
      "  - As there is no actual response given by the model, we cannot evaluate its fluency or human-like quality. Therefore, it scores the lowest in naturalness.\n",
      "\n",
      "Overall, the model's response is ineffective as it provides no evaluable content against the metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Given the input, the model's response was \"<|end_of_text|>\", which is effectively an empty response.\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "  The model's response is completely lacking; it does not logically align with the context since there is no response to evaluate.\n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "  The response is entirely incomplete as it provides no answer to the question or summary of the information, failing to convey any relevant details provided in the input.\n",
      "\n",
      "- **Naturalness: 1.0**  \n",
      "  Since there is no content to assess how fluently or human-like the model responded, a score of 1.0 is warranted for naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0 - The model's response is completely absent. As there is nothing to align with the input context, coherence cannot be rated beyond the minimum score.\n",
      "- Completeness: 1.0 - The model's response does not provide any information or answer to the input, resulting in the lowest score for completeness.\n",
      "- Naturalness: 1.0 - With no text provided, there's nothing to assess in terms of naturalness or fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Given that the model's response is empty, here is the evaluation based on the provided metrics:\n",
      "\n",
      "- **Coherence**: 1.0  \n",
      "The model has produced no response, so there is no content available to determine if it aligns logically with the context provided.\n",
      "\n",
      "- **Completeness**: 1.0  \n",
      "The absence of a response indicates that the model fails to answer the question. Thus, it does not sufficiently address the patient's inquiry or any part of the input dialogue.\n",
      "\n",
      "- **Naturalness**: 1.0  \n",
      "Since the model's response is empty, it cannot be assessed for fluency or human-like qualities in its language use.\n",
      "\n",
      "Overall, the model has not provided any output to evaluate, resulting in the lowest possible scores for all metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 3.5**  \n",
      "  The model's response is somewhat coherent in terms of creating a structured note from the information within the conversation. However, it doesn't directly pertain to the patient's condition or the context. It shifts focus to documentation rather than addressing the situation after the patient's death.\n",
      "\n",
      "- **Completeness: 2.0**  \n",
      "  The response does not address the key information about the patient's eventual death, which is a significant part of the input context. The proposed format for a note is comprehensive, but it fails to respond to the specific situation of the patient dying and the doctor's interaction with the family afterward.\n",
      "\n",
      "- **Naturalness: 4.0**  \n",
      "  The response is fluent and human-like in constructing a medical note, with clear and structured language. However, the expectation was for conversational dialogue, and the model generated a clinical document instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "The model's response is essentially empty, indicating it did not generate any output.\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "  Since the model provided no content, it cannot be evaluated for coherence in relation to the context.\n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "  The response does not provide any information; hence it fails completely to answer the question or summarize the situation.\n",
      "\n",
      "- **Naturalness: 1.0**  \n",
      "  With no response provided by the model, we cannot assess the fluency or human-like quality.  \n",
      "\n",
      "The model's output does not fulfill any metrics due to the lack of a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model did not provide any response, therefore scoring the lowest possible rating for each metric.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "The model's response appears to be empty, represented by \"<|end_of_text|>\", which implies that it has not provided any content. Consequently, the response rates poorly across all the metrics as follows:\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "  Since there is no response, there is nothing to align logically with the context provided in the input.\n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "  The model fails to provide any answer to the question, thus not fulfilling the requirement for sufficient information or completion.\n",
      "\n",
      "- **Naturalness: 1.0**  \n",
      "  An absence of response cannot be considered fluent or human-like, resulting in a score of 1.0 for naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response is entirely absent, which leads to the lowest possible scores across all evaluation metrics. Without a generated response, there is no content to assess for logical alignment with the context (Coherence), provision of an adequate answer (Completeness), or fluency and naturalness in communication (Naturalness).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "  - The model's response repeats the full conversation, providing no analysis or structured summary, as requested by the task. This repetition lacks logical alignment with the input task of producing a clinical note.\n",
      "  \n",
      "- Completeness: 1.0\n",
      "  - The response doesn't address the task of converting the conversation into a structured clinical note. It simply restates the conversation without summarizing, omitting crucial synthesis and summarization expected in a clinical note.\n",
      "  \n",
      "- Naturalness: 3.0\n",
      "  - While the language used in the response is fluent and human-like, it falls short of transforming the dialogue into a coherent, structured clinical note. The response retains a conversational tone instead of adopting a formal, concise clinical note format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5  \n",
      "  The model's response suggests writing a clinical note based on the given dialogue but it fails to provide a cohesive note. It mentions how the note should be structured without actually delivering the expected content directly. Therefore, it lacks logical alignment and completeness in terms of content.\n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The model does not provide an actual clinical note or any relevant information from the conversation. It only gives instructions on how to write a note. Thus, it completely misses out on answering the task as specified.\n",
      "\n",
      "- Naturalness: 2.0  \n",
      "  The model's response is somewhat fluent and appropriate in terms of style, as it talks about structuring a note but it's not natural within the context because it fails to fulfill the specified task of actually drafting the clinical note, which detracts from its perceived naturalness in execution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0 \n",
      "    - The model's response is entirely absent. It doesn't align with the context since there's no content to assess.\n",
      "\n",
      "- Completeness: 1.0\n",
      "    - The model provides no answers or information, therefore, it fails to address any of the questions or summarize the context.\n",
      "\n",
      "- Naturalness: 1.0\n",
      "    - The absence of a response results in no evaluation of naturalness or fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  - The model's response logically aligns with the context provided. It accurately follows the sequence of events and details presented in the conversation between the doctor and the patient.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "  - The model's response captures most of the critical information regarding the patient's diagnosis, medical history, and treatment. However, it omits some specific details present in the true answer, such as the patient's age, the differential diagnosis of medication-related osteonecrosis of the jaw (MRONJ), and the absence of microbiologic cultures.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  - The model's response is fluent and reads in a human-like manner. It effectively summarizes the medical scenario using professional and coherent language. However, it lacks the nuanced complexity found in a human's description, which includes age specifics and differential considerations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response closely aligns with the context provided. It accurately captures many details about the patient's condition, history, and the doctor's findings. However, there are minor inconsistencies, such as the patient's age and the omission of some details related to the decrease in level of consciousness.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response captures most of the key points in the scenario, such as symptoms, medical history, examination findings, and the outcome. However, it leaves out specific details like the exact age of the patient, the history of drowsiness, and occupational background, which were present in the true answer.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The language used in the model's response is fluent, clear, and similar to what one might expect from a healthcare professional summarizing a case. It maintains a formal and informative tone appropriate to the context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "    *Explanation: The model's response is coherent with the context provided in the input. It accurately reflects the conversation between the doctor and the patient, summarizing the main points without introducing inconsistencies.*\n",
      "- Completeness: 4.0\n",
      "    *Explanation: The model's response includes most of the critical information from the conversation, including the patient's conditions, symptoms, and treatment. However, some medical details like blood pressure and the exact phrasing about the absence of diabetic retinopathy could be more detailed.*\n",
      "- Naturalness: 4.5\n",
      "    *Explanation: The model's response is fluent and human-like, using polite language and a formal letter format that is suitable for the intention of the patient. However, slight improvements in phrasing could enhance its naturalness.*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response aligns well with the context provided in the input. It presents a clear and structured clinical note that accurately reflects the information shared in the doctor-patient conversation with appropriate medical terminology and details.\n",
      "  \n",
      "- Completeness: 4.0  \n",
      "  - While the model captures most of the critical details from the conversation, it slightly omits some specific quantitative details such as the maximum tumor diameter from the hepatectomy (55 mm instead of 37 mm in the follow-up CECT), which is a relevant piece of information. However, the major clinical facts are present and adequately addressed.\n",
      "  \n",
      "- Naturalness: 4.5  \n",
      "  - The model's response is natural and flows like a human-written clinical note. It employs professional and suitable medical language that would be expected in a clinical document, making it sound fluent and coherent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "The model's response does not contain any text. This makes it difficult to evaluate based on the specified criteria, as the lack of a response means there is nothing to assess for coherence, completeness, or naturalness. However, given that the model failed to produce any output, ratings should reflect the absent response.\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "  There is no response to evaluate for coherence. The model did not produce any text that could be matched to the logical flow or context of the input.\n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "  The model's response is missing entirely, which means it does not provide any answer or address any aspect of the question from the input. Therefore, it is not complete.\n",
      "\n",
      "- **Naturalness: 1.0**  \n",
      "  With no text response, there is no basis to assess whether the model's output is fluent or sounds human-like. \n",
      "\n",
      "Overall, the lack of a response results in low scores across all dimensions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 2.0\n",
      "\n",
      "**Explanation**:\n",
      "\n",
      "- **Coherence**: The model's response does not align logically with the context. The user's input consisted of detailed medical history and examination, while the model's response is vague and generic, showing a lack of understanding of the context provided.\n",
      "\n",
      "- **Completeness**: The response does not provide an answer or any specific information related to the patient's condition or the doctor's findings, making it completely insufficient in answering any implicit or explicit questions derived from the input.\n",
      "\n",
      "- **Naturalness**: While the model's response is fluent and grammatically correct, it lacks specificity and engagement that would be expected in a human-like conversation in this medical context. Thus, it scores slightly higher on naturalness than the other metrics but still is very low.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the given information, the evaluation of the model's response is as follows:\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "  The model's response is completely missing. It doesn't attempt to provide any answer or summary of the conversation between the doctor and the patient, thus there is nothing to assess for logical alignment with the input context. \n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "  The response is empty, providing no information or details, so it does not even begin to address the question or prompt. This results in an absolute lack of completeness.\n",
      "\n",
      "- **Naturalness: N/A**  \n",
      "  Since the response is completely absent, there is no text to evaluate for naturalness or fluency. Consequently, it's not applicable to assess naturalness.\n",
      "\n",
      "Overall, the model failed to produce any output, hence the evaluations reflect absence across all key metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response aligns perfectly with the context provided, maintaining the logical flow and sequence of the interaction between the doctor and the patient.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The model captures most of the case details and responses between the doctor and the patient. However, it misses details about the patient's age and the specific glycosuria measurement (>20 g/l), as well as information about future UTIs and infections as mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The dialogue is fluent and human-like, resembling a natural conversation one might expect in a clinical setting. The exchange between the doctor and patient flows smoothly, and the language used is appropriate and clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically follows the input dialogue and maintains consistency with the clinical details provided. The conversation is coherent and progresses logically from history-taking to diagnosis discussion, treatment options, and additional diagnostic steps.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The model's response captures the essence of the input dialogue and adequately covers the main points, including patient history, suspected conditions, and treatment plans. However, it lacks detailed descriptions present in the \"True Answer,\" such as the specific changes in the lesion over time and the more granular details of the biopsy findings.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "  - The dialogue reads fluently and authentically, closely mimicking a real conversation between a doctor and patient. The language used is natural and appropriately adjusted for medical discussions, demonstrating good conversational flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Without a model's response to evaluate, I must assume an absence of completion. Therefore:\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "Please provide the model's response for a complete evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response is empty, which means it fails to logically align with the context provided, does not answer the question at all, and lacks any human-like fluency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "\n",
      "The model's response does align generally with the context provided in the input but it does not delve into specifics such as the specific details of the patient's condition or the exact findings of the doctor's tests. \n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The response adequately summarizes the overall interaction between the doctor and the patient, highlighting the key points, such as the symptoms, family history, and proposed next steps. However, it lacks specific details about the patient's diagnosis and some key elements from the true answer, which would be critical in a thorough medical summary.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response is very fluent and human-like, effectively summarizing the essence of the conversation in a professional and structured manner. It appropriately uses medical terminology within the context of the dialogue, which is generally fitting for a healthcare setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response aligns well with the context provided in the input dialogue. It captures the essential details about the patient's condition, treatment, and outcomes. However, it omits the patient's specific medical history details such as her age and all reported conditions.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - The response answers most of the key aspects of the patient's visit and treatment. However, it lacks some specific details present in the true answer, such as the patient's age, the exact side locations and diffusion of the headache, and detailed descriptions of triggers during the first six months.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  - The response is fluent and structured in a natural, human-like manner. It reads like a coherent doctor's note, summarizing the visit effectively. The language is formal and appropriate for a medical document.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response is completely empty, offering no logical, comprehensive, or fluent follow-up to the input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "For the provided scenario, it appears that the model's response is missing entirely. Therefore, each metric is impacted negatively due to the lack of an actual response.\n",
      "\n",
      "- **Coherence**: 1.0  \n",
      "  Since there is no response, there is no content to assess logical alignment with the context.\n",
      "\n",
      "- **Completeness**: 1.0  \n",
      "  The model fails to provide any answer to the questions or context provided, resulting in a lack of completeness.\n",
      "\n",
      "- **Naturalness**: 1.0  \n",
      "  Without any generated text, there is no opportunity to evaluate the fluency or human-like quality of the model's output.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response is somewhat coherent with the conversation. It mentions the various components present in the dialogue like medical history, test results, and treatment plan. However, it lacks specific details and nuances shared in the dialogue, such as particular test findings and detailed patient outcomes.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The model's response provides a general overview but misses crucial specifics found in the conversation. Key findings from tests and their implications are omitted, and it doesn't address the critical outcome of the patient's death. The response fails to summarize the entire scope of the conversation accurately.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The language used in the model's response is fluent and maintains a professional tone suitable for a clinical note. It reads in a well-structured and human-like manner, although it lacks some depth and detail required for complete clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Since the model's response is empty, we have to evaluate it directly based on the given metrics:\n",
      "\n",
      "- **Coherence**: 1.0\n",
      "  - The model's response provides no information, therefore it does not align logically with the detailed conversation and context provided in the input.\n",
      "\n",
      "- **Completeness**: 1.0\n",
      "  - The model's response is entirely absent, so it fails to answer or address any part of the question or context from the input.\n",
      "\n",
      "- **Naturalness**: 1.0\n",
      "  - An empty response lacks any level of fluency or human-like qualities, resulting in a score of 1.\n",
      "\n",
      "In each category, the correct answer demonstrates a high degree of these qualities, whereas the model's response completely lacks them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It correctly follows the sequence of events described during the medical consultation. However, it incorrectly refers to the patient as \"he\" even though we know from the True Answer that the patient is female, which could slightly affect coherence.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model response captures most of the essential details from the interaction between the doctor and the patient. However, it omits some specific details such as the doctor's intention to keep the patient for further observation due to exacerbated symptoms at the ward, which affects the completeness of the response.\n",
      "\n",
      "- Naturalness: 3.5  \n",
      "  The model's response is structured more like a list of events rather than a fluent narrative. The sentences follow a repetitive pattern and lack the variation and fluidity typically present in a human-like dialogue summary. While accurate, this style reduces its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the evaluation of the model's response, which is empty, here are the ratings for each metric:\n",
      "\n",
      "- **Coherence: 1.0**\n",
      "  - The model's response is not logically aligned with the context as there is no content provided. An empty response shows no alignment or coherence with the given context of the dialogue, which had detailed medical information.\n",
      "\n",
      "- **Completeness: 1.0**\n",
      "  - The response does not answer the question at all, as it provides no information or content. Given the context, the model was expected to summarize or give a continuation that reflects the true answer scenario. An empty response does not meet these expectations.\n",
      "\n",
      "- **Naturalness: 1.0**\n",
      "  - The response does not sound fluent or human-like, as there is no response at all. The lack of any content results in a failure to meet any naturalness criteria.\n",
      "\n",
      "Overall, the lack of any generated content significantly detracts from the performance across all evaluated metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Given the lack of model output in the response area, the model has provided no information to evaluate. Thus, the model's performance against the metrics is minimal.\n",
      "\n",
      "- Coherence: 1.0\n",
      "  - Without a response, there's no indication of whether the model understands the context or maintains logical consistency with the conversation.\n",
      "\n",
      "- Completeness: 1.0\n",
      "  - A non-existent answer fails to fulfill the requirement of providing information or answering the question.\n",
      "\n",
      "- Naturalness: 1.0\n",
      "  - A lack of text means there's nothing to assess for fluency or human-like quality. \n",
      "\n",
      "Overall, the model did not perform the task, resulting in the lowest scores across all evaluation criteria.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the provided input and the absence of a Model's Response, the evaluation against the metrics would be as follows:\n",
      "\n",
      "- **Coherence: 1.0**\n",
      "  - The model did not generate a response. Therefore, there's no coherent connection between an answer and the given context.\n",
      "  \n",
      "- **Completeness: 1.0**\n",
      "  - Without a response from the model, the answer does not address any aspect of the question or input at all.\n",
      "\n",
      "- **Naturalness: 1.0**\n",
      "  - Since there's no response, it can't be evaluated for fluency or human-likeness.\n",
      "\n",
      "Overall, the model's lack of a response leads to the lowest possible scores across all evaluation criteria.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "**Evaluation Explanation**:\n",
      "- **Coherence**: The model's response follows the thread of the conversation and maintains consistency with the context. The dialogue is directly copied and pasted in the response, which inherently maintains coherence.\n",
      "  \n",
      "- **Completeness**: The model's response fails to summarize the conversation as requested. Instead, it repeats the entire dialogue verbatim. There is no synthesized clinical note provided that encapsulates the key details and medical events discussed between the doctor and patient.\n",
      "\n",
      "- **Naturalness**: The response lacks naturalness because it does not attempt to create a new or synthesized human-like response; instead, it simply outputs the input context as is, which feels mechanical and not like a genuine summary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0 - The model's response aligns with the conversational context, as it captures the key medical details and events shared between the doctor and the patient. However, it lacks the specific structured clinical note format that was referred to in the input.\n",
      "  \n",
      "- Completeness: 3.5 - The summary omits some details such as the BMI, the specific phrasing for the total hip arthroplasty, and the more structured nature of a clinical note. Additionally, the detail about the patient's ophthalmologic exam seven months prior is not included.\n",
      "  \n",
      "- Naturalness: 4.2 - The model's response maintains fluent and human-like language. However, the lack of specific structure typical of a clinical note reduces its perceived naturalness within the given context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the input context and provides a logical summary of the events described in the doctor-patient interaction. It accurately captures key details, such as the patient's symptoms, medical history, and results from various tests. However, there are minor inconsistencies, like omitting the details of blood pressure improvement after hydration.\n",
      "\n",
      "- Completeness: 4.7  \n",
      "  The model effectively captures the essential information needed to understand the patient's condition, including symptoms, medical history, test results, and the provisional diagnosis. It closely mirrors the key elements of the true answer. Some minor details, like the patient's age and the absence of significant blood pressure differences from four limbs, are omitted, but the overall answer is sufficient.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is very fluent and natural, reading like a human-written summary of a medical conversation. The language is clear and professional, appropriate for a medical context. The response maintains a formal tone suitable for the interaction's nature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response is non-existent, indicated by the special token `<|end_of_text|>`. Therefore, it scores the lowest possible rating for each metric as it provides no information or logical alignment, does not answer the question, and doesn't provide any fluent or human-like response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response presents the conversation as a flowing narrative, aligning logically with the sequence. However, it lacks explicit recognition of some medical specifics that would reinforce coherence regarding clinical notes.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response captures many essential points of the conversation but misses some critical information such as the patient's exact age, mention of never smoking, and the lack of lymph node palpation, as stated in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent and relatively human-like, serving as a coherent summary of the conversation's structure. It could be more succinct in its language to align closely with typical clinical note style.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "The model's response is completely empty, which greatly affects its scores across all metrics. Here is my evaluation based on the provided metrics:\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "  The model's response lacks any content, making it impossible to assess coherence or logical alignment with the context.\n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "  The response does not provide any information or answer the question at all, resulting in a score of 1 for completeness.\n",
      "\n",
      "- **Naturalness: 1.0**  \n",
      "  Since the response is entirely absent, there is no language to evaluate for fluency or human-likeness.\n",
      "\n",
      "Overall, the absence of a response leads to the lowest possible scores in all categories.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "The model's response is entirely missing; it provided no output text. Therefore, assessment across all metrics will be at the lowest score due to the lack of content to evaluate.\n",
      "\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context provided in the input. It covers the key points from the conversation, including the symptoms, medical history, examination, and treatment. However, some specific details mentioned in the conversation, such as the negative result of the cerebrospinal fluid cultures, were not explicitly noted, which slightly impacts coherence.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model's response covers most of the essential elements in the conversation, such as symptoms, medical history, and treatment plan. However, it lacks some details, such as the cerebrospinal fluid culture results. Also, it omits specific follow-up timelines and the removal of ethambutol from the regimen after 6 months, which are present in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response sounds fluent and human-like. It reads like a clinical note expected from a healthcare professional summarizing a complex medical conversation. The language is clear and appropriately formal for a clinical setting. However, it could be slightly more concise in parts for enhanced naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response includes some inaccuracies and omissions. It mentions respiratory and urinary symptoms, as well as seizures, which the patient explicitly denied. This misalignment affects the coherence of the model's response with the provided input context.\n",
      "  \n",
      "- Completeness: 2.5  \n",
      "  The model's response partially addresses the situation by suggesting general steps like reviewing medical history and performing tests. However, it does not sufficiently incorporate all relevant aspects of the patient's specific condition, such as the medication regimen and her transplantation and liver disease history.\n",
      "  \n",
      "- Naturalness: 4.0  \n",
      "  The model's response reads fluently and is structured in a logical and human-like manner. However, the use of a generic approach and lack of personalization somewhat detracts from its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response aligns well with the input conversation and logically summarizes the key points discussed between the doctor and the patient. However, it could have mentioned more nuanced details like the patient's malodorous breath or the doctor's specific conclusion about the specialist.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The response captures most of the conversation's content but misses some medical details such as the malodorous breath and some information on the physical exam like poor dentition and mild tenderness, which are present in the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response is fluent, concise, and resembles a coherent summary that a human might produce, maintaining a clear and organized structure throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response aligns well with the context provided in the input. It captures the sequence and content of the doctor-patient conversation, presenting details related to symptoms, diagnosis, and treatment. However, it misses some specific details like the mention of HIV or the role of tenofovir in the context, which appears in the true answer. \n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The model provides an adequate summary that covers most of the conversation, including the main points like the patient's symptoms, treatment changes, and follow-up plan. However, it lacks some critical details provided in the true answer, such as the specific medical background (e.g., HIV, fractional urinary phosphorus excretion, and the involvement of infectious diseases specialists). These omissions affect the completeness of the model's summary.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The model's response is fluent and reads naturally. It uses clear and coherent language to summarize the interactions between the doctor and patient. The sequence of events is logical, contributing to the overall naturalness, even though there are some minor repetitions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "\n",
      "The model's response fails to logically align with the context provided in the input. It inaccurately states that the patient's condition has improved, whereas the conversation indicates the patient needs further treatment for Listeria and an abscess, and his diabetes is not well controlled. Therefore, there is a significant misalignment between the input and the model's response.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The model's response does not sufficiently answer the question or summarize the expected follow-up actions based on the doctor's recommendations. It incorrectly states improvements in symptoms and blood work, which were not mentioned in the dialogue. Thus, it does not adequately cover the necessary medical information or follow-up steps outlined by the doctor.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "While the model's response is somewhat structured and polite, it lacks fluency due to inaccuracies and unrealistic progression of the medical situation. The language style is formal and polite, but the content does not make sense given the medical context, which reduces the overall naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Since the model provided no response and only ended the text abruptly with \"<|end_of_text|>\", its performance can be evaluated as follows:\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "The model did not provide any information, so there is no logical alignment or coherence with the input context.\n",
      "\n",
      "- **Completeness: 1.0**  \n",
      "The model's response is entirely empty, so it fails to answer any part of the question or provide any information.\n",
      "\n",
      "- **Naturalness: 1.0**  \n",
      "Given the absence of a response, the model cannot be evaluated on naturalness or fluency. There is no text to assess for human-like or fluent qualities.\n",
      "\n",
      "Overall, the model did not deliver any output, which results in the lowest possible scores across all evaluation criteria.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "- Completeness: 2.0\n",
      "- Naturalness: 4.0\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1. **Coherence (3.0):** The model's response is moderately coherent. It provides a step-by-step narrative that roughly follows the order of the conversation. However, it does not distill the interactions into a structured clinical note, and lacks the cause-effect relationship between medical history and current symptoms. The summary presented seems more of a verbatim account rather than a properly constructed clinical narrative expected in medical documentation.\n",
      "\n",
      "2. **Completeness (2.0):** The response lacks completeness as it skims over essential details. Important points such as the patient's final outcome, specific test results, and treatments discussed near the story's end are missing. The model does not include important diagnostic considerations or the plan discussed in the consultation. The end-of-life events and their context are wholly absent, impacting the note's utility and comprehensiveness.\n",
      "\n",
      "3. **Naturalness (4.0):** The model's response maintains a decent level of fluency and correctness in language usage. The grammar is proper, and the sentence structure is appropriate, making the read quite natural. Though passive voice is used occasionally, which is common in medical documentation, the missing conclusion hampers full storytelling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response is entirely absent, offering no alignment with the provided context, no answer to the question, and therefore no demonstration of fluency or naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "  - The model's response essentially copies the original conversation without any summarization or restructuring. It doesn't logically condense the information into a coherent note, failing to align with the task requirement of creating a clinical summary.\n",
      "\n",
      "- Completeness: 1.0\n",
      "  - The model fails to provide any synthesis of the conversation into a clinical note. It doesn't address the main points highlighted in the explanation or provide structured information on diagnosis, treatment, and follow-up, as expected for a complete response.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "  - While the model's output is fluent and grammatically correct, it doesn't exhibit the natural and structured flow expected in a clinical note. It doesn't sound human in the context of summarization because it lists dialogue verbatim rather than synthesizing information naturally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response does not provide any content and therefore cannot be evaluated on coherence, completeness, or naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the information provided, it seems that the model's response is not present. Consequently, I will evaluate the model's response as follows:\n",
      "\n",
      "- **Coherence**: 1.0  \n",
      "  Without any model response text to assess, it is impossible to evaluate if it logically aligns with the input context. Thus, it scores the minimum.\n",
      "\n",
      "- **Completeness**: 1.0  \n",
      "  Similarly, without a response, the model fails to answer the question at all. Therefore, the answer is entirely incomplete and scores the minimum.\n",
      "\n",
      "- **Naturalness**: 1.0  \n",
      "  Again, with no text provided by the model, there is nothing to evaluate in terms of fluency or human-like quality. Hence, it receives the minimum score.\n",
      "\n",
      "Overall, the model did not provide any output, leading to minimum scores across all evaluation metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response is empty (\"<|end_of_text|>\") and does not provide any answer or information, which means it lacks coherence, completeness, and naturalness. Thus, the response does not logically align with the context, fails to answer the question, and does not demonstrate any fluent, human-like language.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "  - The model provided no response, which means it cannot be evaluated for logical alignment with the context.\n",
      "  \n",
      "- Completeness: 1.0\n",
      "  - The model gave an empty response, providing no information to answer the question or to summarize the situation.\n",
      "\n",
      "- Naturalness: 1.0\n",
      "  - With no text generated by the model, it is impossible to evaluate the fluency or human-likeness of the response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0\n",
      "  - The model's response does not logically align with the context. Instead of responding to the patient's family or summarizing the case details, the model continuously repeats inquiries that are irrelevant to the given dialogue.\n",
      "\n",
      "- Completeness: 1.0\n",
      "  - The response fails to answer any part of the exchange or summarize the patient's condition, treatment, or any relevant information from the detailed interaction between the doctor and the patient.\n",
      "\n",
      "- Naturalness: 1.0\n",
      "  - The model's response is highly unnatural due to the excessive repetition of phrases and questions. It does not flow as a coherent or human-like discussion, detracting from its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "For evaluating the Model's Response based on the given metrics:\n",
      "\n",
      "1. **Coherence**: The coherence of the model‚Äôs response is quite high as the conversation maintains logical progression and follows the dialog pattern of the input. There is alignment in the dialogue's structure and flow, matching with the input context. However, there are minor deviations noted that affect complete clarity, such as the incomplete ending in the second response, which hints at some predicted path but cuts off prematurely.\n",
      "   - **Rating**: 4.5\n",
      "\n",
      "2. **Completeness**: The first response is essentially a verbatim repetition of the input dialogue and is complete in itself. However, the second response is incomplete, cutting off in the middle of detailing the third line of treatment, which results in partial information compared to both the input or the true answer. This lack of completeness in the second response results in the model not providing the full picture.\n",
      "   - **Rating**: 3.0\n",
      "\n",
      "3. **Naturalness**: The dialogue maintains a natural flow and the linguistics appear human-like. It coherently follows through logical questioning and answering typical in a doctor-patient interaction, without displaying syntactic interruptions or awkward phrasing, until the incomplete end of the second response.\n",
      "   - **Rating**: 4.0\n",
      "\n",
      "Overall, the performance indicates high coherence and naturalness but suffers significantly in completeness due to the incomplete response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response aligns well with the context provided. It replicates the dialogue in a way that makes sense logically and maintains the integrity of the original conversation flow. It accurately reflects the medical history and interactions between the doctor and the patient.\n",
      "  \n",
      "- Completeness: 3.5  \n",
      "  - The model's response accurately captures the details from the dialogue, but it misses some specific details in the \"True Answer\" such as dosage details of medications, the patient's family medical history, exact amount of alcohol consumed, and some vital statistics during the emergency department visit. While it reflects the general situation, it lacks the depth and specificity of the true response.\n",
      "  \n",
      "- Naturalness: 5.0  \n",
      "  - The response reads fluently and naturally, preserving the conversational tone typical of a doctor-patient interaction. It demonstrates human-like coherence in dialogue structuring and content delivery.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "- Completeness: 1.0\n",
      "- Naturalness: 1.0\n",
      "\n",
      "The model's response is an empty output, which does not align with the context, fails to answer any question, and does not provide any text that can be assessed for naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response logically aligns with the context provided. It follows the sequence of events and findings discussed in the doctor-patient conversation, ensuring that the essential clinical details are maintained. However, some details are indirectly mentioned or less concise compared to the true answer. \n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The model captures most of the essential details regarding the patient's condition, including the diagnosis of squamous cell carcinoma, the medical history, and test results. Some specifics, like maximum standardized uptake values (SUVmax) and certain procedural details, are missing or less comprehensive compared to the true answer.\n",
      "\n",
      "- Naturalness: 3.5\n",
      "\n",
      "The model's response sounds fluent and human-like but is somewhat dry and clinical, as is expected for a clinical note. It may lack slight nuances of language that would enhance readability for a broader audience or a less clinical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response closely aligns with the context provided in the input. It accurately reflects the dialogue between the doctor and patient, maintaining a logical sequence of events and interactions as presented in the input.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The model's response is nearly an exact replica of the input conversation, offering a detailed recount. However, it does not summarize or distill the critical medical details into a concise clinical note or summary, unlike the True Answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response maintains a natural flow consistent with human dialogue. Both the doctor's and the patient's lines sound fluent and human-like, matching the tone and style of the input conversation.\n",
      "\n",
      "Overall, the model performs well in mimicking the interaction, but it doesn't effectively meet the task of summarizing the conversation into a structured clinical note.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "The model's response is empty (\"<|end_of_text|>\"), providing no information.\n",
      "\n",
      "- **Coherence: 1.0**\n",
      "  - The response is entirely absent, thus there is no alignment with the context provided. The response fails to connect logically to any preceding dialogue.\n",
      "\n",
      "- **Completeness: 1.0**\n",
      "  - The model does not provide any answer, therefore it does not address any part of the questions or the context. It is entirely insufficient in providing an answer.\n",
      "\n",
      "- **Naturalness: 1.0**\n",
      "  - With no response presented, the model cannot be assessed for fluency or human-likeness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "It seems there was no model response provided here; the response placeholder is empty. Since there is no text to evaluate from the model, I'll provide a set of scores reflecting this scenario:\n",
      "\n",
      "- Coherence: 1.0 (Without any response from the model, there's no basis to determine coherence with the context.)\n",
      "- Completeness: 1.0 (The model provided no answer, so it cannot be considered complete per the information requested in the input.)\n",
      "- Naturalness: 1.0 (Without a response, it is impossible to assess the naturalness or fluency of the language.)\n",
      "\n",
      "If there had been a response, each metric would have been evaluated based on the alignment, sufficiency, and fluency of that text considering the provided context and true answer. Please let me know if a model response should be included for evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0  \n",
      "  The model's response is completely empty. It does not provide any information, making it impossible for it to align with the context provided in the input.\n",
      "\n",
      "- Completeness: 1.0  \n",
      "  The model's response is entirely missing, hence it does not answer the question at all, resulting in an incomplete response.\n",
      "\n",
      "- Naturalness: 1.0  \n",
      "  Since there is no response given, it cannot be evaluated for fluency or human-like qualities.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "  - The model's response generally aligns with the input context, repeating much of the dialogue. However, it does not provide any additional insights or information that a coherent summary might include.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The model's response rephrases parts of the input dialogue but misses important details such as the specific amount of insulin used, testing results, and treatment methods. It also fails to mention the patient's transition and discontinuation advice relevant to the Psoriasis flare, thus not fully addressing the depth of information in the true answer.\n",
      "\n",
      "- Naturalness: 3.0\n",
      "  - While the response flows fluently and replicates a conversational tone, it is more of a verbatim repetition rather than a human-like summary or a nuanced answer that understands the question context deeply. The transition between conversational and summary content is lacking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Since the model's response is not provided (denoted by \"<|end_of_text|>\"), it is impossible to evaluate it on the given metrics. Therefore, I will assess each metric based on the absence of a response:\n",
      "\n",
      "- **Coherence: 1.0**  \n",
      "  Without any content, there is no logical alignment with the context provided in the input.\n",
      "  \n",
      "- **Completeness: 1.0**  \n",
      "  The model did not provide a response, so it does not answer the question or summarize the conversation adequately.\n",
      "  \n",
      "- **Naturalness: 1.0**  \n",
      "  Without text, there is no opportunity to evaluate the fluency or the human-like quality of a response.\n",
      "\n",
      "Overall, the model fails on all metrics due to the absence of a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response accurately follows the sequence of the conversation and maintains logical alignment with the provided context. However, it reads more as a transcript than a summarized clinical note.\n",
      "  \n",
      "- Completeness: 2.5\n",
      "  - The response is essentially a direct repetition of the conversation without summarization or synthesizing the information into a structured clinical note. It misses critical elements such as patient demographics and details like family history or the lack of addiction, which are included in the true answer's clinical summary.\n",
      "  \n",
      "- Naturalness: 4.5\n",
      "  - The language of the model's response is fluent and human-like. However, it doesn't convert the conversation into a concise, medically structured summary, which affects the overall naturalness expected of a clinical note format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "    - The model's response is generally coherent, aligning well with the context provided in the dialogue. It follows the logical sequence from the conversation, capturing the crucial elements like the patient's symptoms and medical history, the NMS diagnosis, and treatments initiated in the hospital. However, minor details in the dialogue, such as the patient's response to hearing about the heart attack, are not highlighted, impacting coherence slightly.\n",
      "\n",
      "- Completeness: 4.7\n",
      "    - The response adequately summarizes most of the significant aspects of the scenario, including the patient's past medical history, the symptoms presented, and the extensive medical interventions performed. It covers the core outcomes like NMS, rhabdomyolysis, and myocardial infarction. A few additional details from the conversation, such as specific medication doses and the patient's personal reactions, could enhance completeness.\n",
      "\n",
      "- Naturalness: 3.8\n",
      "    - The response sounds somewhat clinical and structured, more fitting for a medical report rather than a conversational answer or summary. It efficiently conveys pertinent information but lacks a natural, conversational flow that might be expected in a direct interaction narrative. Including more personal touches or variations in sentence structure could improve its naturalness slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response simply repeated the dialogue without synthesizing the information into a clinical note, which is what the prompt requested. While it did provide all the information present in the dialogue, it didn't organize or interpret this information in a structured clinical note, which was the task given. Therefore, the response does not logically align with the context in terms of completing the task of summarization into a clinical note.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "While the model captures all the components of the conversation, it completely lacks the structure, synthesis, and focus required for a clinical note. The model essentially mirrored the dialogue verbatim, which means it did not fulfill the requirements of creating a clear and structured clinical note as was experienced in the \"True Answer,\" which organized the information clearly and succinctly.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The language of the model‚Äôs response is natural and fluent. However, it loses naturalness in the context of medical documentation as it didn't transition the conversation into a professional and structured note format required for clinical summaries. In the context of reflecting direct speech, it is quite natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence**: 5.0  \n",
      "  The model's response closely aligns with the original conversation. The responses are consistent with the context of the dialogue, maintaining logical flow throughout the interaction.\n",
      "\n",
      "- **Completeness**: 4.5  \n",
      "  The model successfully captures all critical details from the conversation, effectively reflecting the patient's symptoms, diagnostic findings, and diagnosis. However, it lacks the age of the patient which is present in the True Answer's context.\n",
      "\n",
      "- **Naturalness**: 5.0  \n",
      "  The dialogue maintains a natural and human-like interaction between the doctor and patient. The language is clear, fluent, and resembles an actual medical consultation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It effectively captures the sequence of events from the initial presentation to the patient's eventual passing. The major elements of the diagnosis, treatment, and follow-up are consistent with the provided dialogue.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response sufficiently answers the question by summarizing the key medical details and outcomes. However, it omits specific details from the true answer, such as the patient's age, being an African American male, the exact nature of previous heart blocks, and some examination findings like the chest radiograph results, which could add to the thoroughness of the summary.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, using appropriate medical terminology and organized presentation of the facts. The structure is clear and logically sequenced, making it easy to follow. However, it lacks a few nuanced details that could enhance its naturalness in a comprehensive medical discussion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 1.0 (The model's response is missing entirely, thus there is no logical alignment with the context provided in the input.)\n",
      "- Completeness: 1.0 (The model does not provide any answer, hence it does not at all address the question concerning what happened to the patient.)\n",
      "- Naturalness: 1.0 (Without any generated response, it cannot be evaluated for fluency or human-likeness.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌèâÍ∑† Ï†êÏàò:\n",
      "Coherence       2.275000\n",
      "Completeness    1.937000\n",
      "Naturalness     2.341000\n",
      "BLEURT          0.408753\n",
      "BERTScore_F1    0.344517\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# summarization\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "summarization = df[df['task'] == 'summarization']\n",
    "results = []\n",
    "\n",
    "for _, row in summarization.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response is logically aligned with the context of managing diabetes and provides a comprehensive approach involving medication, diet, and lifestyle changes. It appropriately acknowledges the limitations of the current medication and suggests potential alternatives, which is a coherent response considering the given blood sugar levels.\n",
      "  \n",
      "- Completeness: 4.0\n",
      "  - The response addresses the key aspects of managing diabetes by mentioning medication, diet, and lifestyle changes. However, it does not provide a specific drug recommendation or follow-up plan, as seen in the True Answer (e.g., suggestion of Tablet Volibo and a follow-up timeline). The model presents a general guide but lacks the specific actionable steps provided in the True Answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The language used in the model's response is fluent, clear, and sounds human-like. It effectively communicates the information in a polite and empathetic manner, which is typical of a professional healthcare consultation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 3.5**  \n",
      "  The model's response is mostly coherent with the context provided. It explains the role of insulin and mentions possible conditions such as hyperinsulinemia and tumors that could relate to the user's question. However, it somewhat diverges by discussing high insulin levels when the user mentions that their insulin levels have decreased. This could cause some confusion.\n",
      "\n",
      "- **Completeness: 3.0**  \n",
      "  The response provides a detailed explanation of insulin‚Äôs role and possible next steps such as an MRI or CT scan, but it doesn‚Äôt directly address the drop in insulin levels specifically asked by the user. The core concern about pancreatic cancer is addressed, but it suggests a range of tests without explaining whether they are necessary given the user's particular context.\n",
      "\n",
      "- **Naturalness: 4.5**  \n",
      "  The language used in the response is fluent and sounds quite human-like. The response is structured politely and appears to try and reassure the user while providing information, aligning well with how a healthcare provider might communicate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns logically with the context, giving a detailed explanation of diabetic retinopathy, which is consistent with the symptoms described. However, it could have more directly addressed the specific treatments mentioned (Lucentis and Accentrix) in the input.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a thorough explanation of diabetic retinopathy, its stages, and general treatment options. However, it lacks specific guidance about the recommended treatments (Lucentis and Accentrix doses), which would have made the answer more complete.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent and reads as human-like. It presents information in a structured and professional manner, suitable for a medical context. A minor deduction is due to the repetitive elements toward the end, which slightly affects the flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "The model's response logically aligns with the context of the input. It acknowledges the specific problem mentioned (erectile dysfunction), the duration, and the prior use of Confido tablets. It provides a rational progression from potential causes to treatment options.\n",
      "\n",
      "- Completeness: 4.5  \n",
      "The response is comprehensive and covers a range of potential causes and treatments for erectile dysfunction. However, it doesn‚Äôt specifically inquire about the user‚Äôs history with diabetes or hypertension or suggest Tentex Forte, which was mentioned in the true answer. Nonetheless, it still offers detailed solutions and recommendations.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "The response is fluent and human-like, mimicking a professional tone expected from a doctor. It logically lays out the potential issues and solutions, using clear language that is easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response logically aligns with the context provided. It acknowledges the concern about the white spots on the gums and relates it to a possible medical evaluation, while also addressing general advice for managing prediabetes.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - The model's response sufficiently answers the user's question by suggesting that the white spots may not necessarily be related to prediabetes and recommends consulting a doctor for further evaluation. However, it doesn't specifically state that images or a more detailed examination might be necessary, which the true answer suggests.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  - The model's response sounds fluent and human-like, providing a considerate and informative answer, which includes practical advice and a polite closing statement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response is generally coherent with the input. It acknowledges the shoulder pain and suggests seeking a healthcare professional's evaluation, advising rest, and recommending over-the-counter pain relief. However, it does not directly address the specific concerns about the elbow and wrist, nor does it mention the previous diagnosis of frozen shoulder.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The response provides general advice on managing shoulder pain, such as resting, applying ice/heat, and maintaining good posture, which are relevant actions. However, it falls short in addressing the specific details shared, such as the pain in the elbow and wrist, and the lack of relief from previous treatments. Additionally, it doesn't offer targeted advice like the true answer does (e.g., specific medication suggestions, checking for diabetes).\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The language and style of the model's response are fluent and human-like, making it accessible and easy to understand. It follows a logical structure and uses clear, professional language.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0  \n",
      "  The model's response logically aligns with the context provided in the input. It identifies the patient's condition accurately and offers advice consistent with managing type 2 diabetes mellitus, addressing both medication and lifestyle adjustments relevant to the initial query.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides a broad overview of diabetes management, focusing on diet and exercise, which are crucial components. However, it lacks specificity in terms of recommending specific additional medications as in the true answer (i.e., Tablet Volibo). While it advises consulting a doctor for potential new medications, it isn't as direct or prescriptive as the true answer suggests.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and human-like, maintaining a professional yet approachable tone appropriate for a healthcare provider. It exhibits characteristics of natural language usage and coherent sentence structure throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5 \n",
      "  - The model's response logically aligns with the context provided in the input. It interprets the findings from the lab report, explaining the implications of each finding accurately.\n",
      "  \n",
      "- Completeness: 4.0 \n",
      "  - The response sufficiently answers the question by interpreting the report's findings. However, it does not diagnose Type II Diabetes Mellitus directly or offer direct links or steps for further consultation, which could have added to its completeness.\n",
      "  \n",
      "- Naturalness: 5.0 \n",
      "  - The response is fluent and human-like, using polite and clear language to communicate with the patient, similar to what one might expect from a health professional in a written consultation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "\n",
      "The model's response somewhat logically aligns with the symptoms described in the input. The mention of nerve damage and infections as possible causes connects to the symptom of burning sensation. However, it inaccurately describes burning as a sign of \"numbness,\" which doesn't logically link to the context given burning does not equate to or directly indicate numbness.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The response addresses the symptom and offers a potential cause in a generic way but does not specify typical causes like peripheral neuropathy or diabetes as noted in the true answer. It lacks specific recommendations for initial tests, such as blood sugar tests or X-rays, which reduces completeness.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is generally fluent and human-like, employing a conversational tone and providing detailed advice, which contributes to its natural flow. However, there is slight awkwardness in equating burning with numbness, which slightly detracts from its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the input, discussing pre-diabetes, lifestyle changes, and the importance of medication, which are relevant to managing high glucose levels indicated in the glucose tolerance test. However, there is a slight inconsistency in diagnosing pre-diabetes, as the fasting glucose level provided (128 mg/dL) can suggest diabetes, not pre-diabetes.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model‚Äôs response provides a comprehensive overview of managing high blood glucose levels and includes advice on lifestyle modifications and medication. However, it might be incomplete in terms of specific recommendations on immediate action, such as the need for a follow-up HbA1c test or an urgency for medical consultation given the high glucose readings.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is very natural-sounding, using a polite and professional tone consistent with that of a medical professional addressing a patient. The response is fluent and human-like, with appropriate structure and wording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "    - The model's response is coherent with the context provided. It addresses the issue of double vision and provides a possible medical explanation (diplopia) that aligns with the user's description of symptoms. It recognizes the need to see an ophthalmologist for a proper diagnosis, aligning well with the user‚Äôs actions and concerns.\n",
      "\n",
      "- Completeness: 4.0\n",
      "    - The response is fairly complete, as it provides a possible explanation (diplopia) for the symptoms and offers practical advice for the user to manage the situation until they see an ophthalmologist. However, it lacks specific addressing of age-related changes and the possible link to refractive issues as mentioned in the true answer. It could have included more about the possible non-severe nature of symptoms given the actions that relieve them.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "    - The model's response is quite natural and human-like, using polite and considerate language which is appropriate for a medical context. It presents information in a structured manner with numbered points that make it easy to follow, simulating a professional medical response.\n",
      "\n",
      "Overall, the model does a good job in addressing the user's concerns but could improve on acknowledging age-related vision changes and providing reassurance that such symptoms might not indicate a severe issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response is coherent and logically aligns with the context provided. It comprehensively addresses the main issue described by the patient and provides relevant advice and information. However, it doesn't directly address the use of \"Aspoline\", which was mentioned as already being applied without improvement.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - The response sufficiently answers the patient's concerns by providing general advice and steps to alleviate the condition. It offers practical steps for self-care and advice to consult a healthcare professional. However, it lacks a direct mention of Aspoline, and it does not address all potential causes or treatments for the symptoms described.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  - The model's response is very fluent and reads in a human-like, empathetic manner. The response includes a polite and structured format with a logical flow similar to a doctor's consultation. The ending is respectful and aligns with professional medical advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is generally coherent with the input context. It acknowledges the seriousness of the heart-related conditions and recommends seeing a cardiologist, which aligns with the context. However, it only slightly addresses the inquiry about preventive surgery and other specialists needed.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The completeness is moderate. While the model suggests seeing a cardiologist and provides general lifestyle advice, it does not address the full scope of the question regarding preventive surgical options or other specialists, such as a vascular surgeon, who might also be relevant given the input. The mention of continuing statin medication conflicts with the user's preference to avoid them.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response sounds fluent and human-like, maintaining a conversational tone throughout. It effectively presents itself as a caring and professional response from a doctor. However, the phrase \"a lot of heart disease\" could be more professionally phrased.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The response provides general advice on weight loss and diabetes management, which is relevant to the context. However, it does not address the user's concern about unintentional weight loss directly, which could be a sign of a potential issue rather than a desired outcome.\n",
      "  \n",
      "- Completeness: 2.5  \n",
      "  While the response offers valuable lifestyle suggestions for weight management and diabetes control, it misses directly addressing the user's specific concern about unexpected weight loss. The response could benefit from recommending the user to discuss this weight loss with a healthcare provider to rule out underlying issues.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluently constructed and uses friendly, conversational language. It sounds human-like and appropriate for the context, with a supportive and caring tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is generally coherent as it addresses the user's concerns regarding heart health and provides a medication suggestion that fits the context of preventing heart attacks. However, it doesn't incorporate specifics from the CT-angio report or any follow-up on the medical assessment as outlined in the provided context.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the model suggests aspirin to reduce heart attack risk, it doesn't fully engage with the detailed findings or recommendations typically made based on a CT-angiogram. It lacks the nuanced medical advice about lifestyle modifications, potential non-cardiac causes for the chest pain, or consideration of myocardial bridging, which were discussed in the true answer.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and sounds very natural in tone, coming across as caring and professional. It effectively humanizes the interaction, addressing the user by name and offering reassurance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5 - The model's response aligns with the context provided but does not address any specific detail from the patient's symptoms or reports. It acknowledges the patient‚Äôs health issues in a general way but lacks alignment with the specific concerns raised, such as the hormonal imbalance symptoms described by the patient.\n",
      "\n",
      "- Completeness: 2.5 - While the response suggests a comprehensive physical exam and possible referral to a specialist, it does not offer any specific insights or recommendations regarding the hormonal imbalances, or any interpretation of the results from the colonoscopy or other attached reports. It misses delivering actionable steps or insights on managing PCOS, PMDD, or the heavy periods as detailed in the patient's input.\n",
      "\n",
      "- Naturalness: 4.5 - The response is fluent and professional, with a clear, human-like tone. It sounds appropriately respectful and empathetic, using common medical communication practices such as recommending further examinations and consultations. However, the lack of specific guidance slightly detracts from its authenticity in providing a tailored patient response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  - The model's response incorrectly states that Accentrix is used to treat diabetes. Accentrix is actually used in the treatment of diabetic macular edema, a complication related to diabetes, not for regulating blood sugar levels. This misinformation negatively impacts coherence.\n",
      "  \n",
      "- Completeness: 2.5  \n",
      "  - The response provides some general information about the medication and the importance of consulting a professional. However, it fails to address the specifics of the OCT report findings, missing the critical aspect of increased macular thickness due to diabetic macular edema, which is discussed in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  - The response is generally well-written, fluent, and resembles a human-like assistant in conversational tone. However, slight deductions are made due to possible ambiguity in the description of the medication's use. Nonetheless, the model generally achieves good naturalness in its tone and structure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response aligns with the context by addressing the situation with a diagnosis of cellulitis and explaining the condition and treatment options. However, it makes an assumption about the diagnosis without additional context on the brother's medical history, such as diabetes.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides a general explanation of cellulitis and offers some information on treatments like antibiotics and surgery. Nonetheless, it lacks specific details that may be relevant to the patient's condition, such as the absence of questions about underlying conditions like diabetes, which is mentioned in the true answer as pertinent information.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and reads like a human doctor's reply, with clear and well-structured sentences. It adopts a professional yet accessible tone that suits the situation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "   \n",
      "   The model effectively aligns its response with the context provided in the input, offering a comprehensive overview of what anxiety is and why it's important to manage it. It provides logical advice consistent with the user's concerns but could have included a bit more technical reasoning akin to the true answer regarding potential biochemical causes.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "   The response is thorough in terms of general advice on managing anxiety and suggests seeking professional help as a potential next step. However, it lacks a more in-depth discussion about the potential for biochemical causes and doesn't directly address the user's concern that their anxiety might be something more severe, unlike the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "\n",
      "   The model's response is very fluent and human-like. It uses empathetic language and maintains a professional yet approachable tone, akin to how a real doctor might respond, making it sound natural and supportive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Based on the evaluation metrics provided, here are the scores for the model's response:\n",
      "\n",
      "- **Coherence: 4.0**\n",
      "  - The response aligns with the context and addresses potential causes for the symptoms described, such as dry eyes and floaters. However, it slightly misses addressing specific details from the context, like the incomplete eyelid closure while sleeping.\n",
      "\n",
      "- **Completeness: 3.5**\n",
      "  - The response provides a decent explanation for the symptoms and suggests seeing an ophthalmologist. However, it lacks depth and does not explore other potential underlying conditions (like exposure keratopathy or details about the vitrectomy) mentioned in the true answer.\n",
      "\n",
      "- **Naturalness: 4.5**\n",
      "  - The response reads fluently and maintains a professional tone, akin to a human doctor. It engages politely and expresses willingness to help further, which adds to its naturalness. However, some sentences come across as slightly generic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "   - The model's response logically aligns with the information provided in the input. It addresses the query about mild LVH and relates it to the patient's symptoms and medical tests. However, it slightly lacks details about specific diagnoses or assumptions regarding the patient's condition, which you can find in the True Answer.\n",
      "   \n",
      "- Completeness: 4.0\n",
      "   - The response adequately addresses the question about mild LVH and its implications on heart health. It suggests further evaluation and reassures the patient of the likely benign nature of mild LVH. However, it could be more detailed by including potential diagnoses or further explanations that the True Answer provides in terms of lifestyle recommendations and possible scenarios.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "   - The response is fluent and sounds human-like. It offers reassurance in a professional yet approachable manner. The language used is appropriate for a healthcare setting, conveying empathy while remaining informative.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is mostly coherent with the context provided in the input. It addresses the patient's concerns about SGLT2 inhibitors and explains how they work, including their potential side effects. However, it excessively repeats the information about how these medicines function and could have provided a more targeted discussion related to the patient's broader concern about different medication options besides SGLT2 inhibitors. \n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The response focuses primarily on the SGLT2 inhibitors and does not touch upon other potential medication options or strategies given the patient's concerns about weight gain with sulfonylureas and insulin or the ineffectiveness of Acarbose and Voglibose. The response lacks a broader discussion on alternative treatments or lifestyle changes that might be beneficial, thus providing an incomplete answer to the patient's overall request for guidance on changing medications.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is largely fluent and human-like in its explanation of the SGLT2 inhibitors, using language that is easy to understand. However, the repetition in explaining the mode of action of SGLT2 inhibitors slightly detracts from the naturalness, making it seem somewhat mechanical. The inclusion of a reiterative invitation to consult a doctor also feels formulaic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response is coherent in terms of addressing heel pain and potential causes like plantar fasciitis. However, it failed to address the specific condition of flat foot mentioned in the input, which could be a significant source of the pain.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The model provided general information about heel pain and plantar fasciitis, but it did not adequately address the specific issue of flat foot that the user asked about. Important recommendations related to flat foot, such as custom-made shoes or specific types of physical therapy, were not provided.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like. It maintains a professional tone expected from a medical professional and conveys the information in a way that is easy to understand. There are no awkward phrasings or grammatical errors, contributing to a natural-sounding response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response aligns logically with the context, suggesting appropriate tests like MRI or biopsy given the health conditions described. However, it misses certain specificities related to the suggested treatment path and the nature of the SOL as a hemangioma.\n",
      "  \n",
      "- Completeness: 3.0  \n",
      "  While the response provides general guidance on further evaluation (CT, MRI, biopsy) and mentions the importance of specialist consultation, it lacks specific action plans related to the identified hemangioma, like conservative management or the criteria for surgery. It also does not address the need for follow-up imaging or symptom control, which are prominent in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, with a compassionate tone and clear communication. It feels like a typical engagement one would expect from a healthcare professional, although slightly more details about the immediate next steps could enhance the natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model‚Äôs response logically aligns with the input context by directly addressing the concerns about the connection between obstructive sleep apnea and observed cerebral changes. It correctly identifies that untreated sleep apnea can lead to brain changes like stroke and ischemic changes. However, the model fails to consider other potential risk factors such as high blood pressure, dyslipidemia, or age, which are mentioned in the true answer.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - While the model answers the question about the connection between sleep apnea and cerebral changes, and suggests a polysomnogram as a particular investigation along with CPAP treatment, it does not sufficiently cover all relevant aspects found in the true answer. It overlooks the importance of understanding other risk factors, like high blood pressure or atherosclerosis, and does not provide a complete treatment plan that includes regular monitoring of conditions such as dyslipidemia or diabetes.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "  - The model's response is fluent and human-like, using professional but accessible language. It reads as if a medical professional is providing advice to a peer. There is a minor unnatural element in addressing the recipient as \"Mr. Doctor,\" which minimally impacts the overall naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is generally coherent and provides logical information regarding the recall of metformin and potential alternatives. However, it slightly misrepresents the situation by stating that the recall was not due to safety concerns, which could be misleading without context. \n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The response offers a broad range of suggestions, including natural supplements and lifestyle changes, but it fails to directly address the urgency of the high blood sugar level and the need for immediate medical attention or a new prescription. It also doesn't refer to specific alternative prescription medications, which are essential given the input's context of an alternative to metformin due to the recall scare.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The model's response is fluent and human-like, using a conversational and professional tone consistent with that of a healthcare professional. It presents advice and suggestions in a coherent manner, making it easy to follow and understand. However, the introduction and closing with the name place-holders slightly detract from the overall naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0\n",
      "\n",
      "The model's response focuses primarily on migraines, which may not be the most relevant issue based on the context provided. The input mentions a \"burning sensation\" on the head, but the model's response does not address the potential variety of causes, such as vitamin deficiency, diabetes, or sinusitis, mentioned in the true answer. Therefore, the response does not adequately align with the user's provided context.\n",
      "\n",
      "- Completeness: 2.0\n",
      "\n",
      "The model's response fails to cover the range of possible causes for the symptom described by the user. While it gives an extensive guide on managing migraines, it does not address the full range of potential causes, such as vitamin deficiency or other medical issues, as noted in the true answer. Thus, it only partially answers the user's question.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The language used by the model is fluent and human-like. It adopts a professional and instructive tone, which is suitable for a medical advice context. However, the content is not particularly tailored to the user‚Äôs specific question, which detracts slightly from the naturalness in terms of relevance and context-specific dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 5.0\n",
      "  - The model's response aligns well with the input context, discussing ringworm treatments, mentioning both oral and topical antifungals, and providing relevant advice.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - While the model discusses general treatments for ringworm, it does not address the follow-up specifics like potential resistant strains or customized recommendations such as the use of Trfy 250mg (Terbinafine) and DK gel mentioned in the true answer. It also lacks tailored advice based on the patient's current medication state and symptoms.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent, human-like, and provides a reassuring tone typical of a doctor-patient interaction. It maintains a professional and clear tone throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5  \n",
      "  The model's response demonstrates some effort to coherently address the concerns listed by the patient, but it contains inaccuracies and generalizations. For example, it incorrectly suggests that gastric bypass will help quit smoking, which seems irrelevant as the patient quit smoking decades ago. Additionally, the response assumes that gastric bypass could help with achalasia, which is not directly applicable here. These assumptions misalign with the context provided.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  The response attempts to address the patient's concerns by discussing each of the mentioned health issues individually. However, it lacks detailed information on the specific risks associated with anesthesia and surgery for someone with such a complex medical history, making the completeness somewhat superficial.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The tone of the response is polite and conversational, which sounds relatively natural and human-like. However, the repetitive structure of \"I can see that you...\" and \"I can assure you that...\" gives it a somewhat mechanical feel, but overall it maintains a fluent style.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is mostly coherent, aligning well with the user's concerns about managing anxiety and providing appropriate suggestions. However, it doesn't address all aspects of the user's medical profile (e.g., coronary artery disease, diabetes, bloating, constipation) explicitly, which affects overall logical alignment with the complete context.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The response offers practical strategies to manage anxiety, which is part of the user's problem. However, it lacks completeness as it doesn't discuss medication adjustments, potential medication side effects related to bloating and constipation, or how the user's other medical conditions could interplay with the anxiety treatments. It also doesn't provide insights into how to integrate treatment considering the user's coronary artery disease and diabetes.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is quite natural and sounds human-like, with polite and empathetic language. It provides clear and practical suggestions, making it sound conversational and supportive. The slight lack of specificity regarding the other medical conditions and their treatments slightly reduces the perception of expert-level naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  - The model's response is mostly coherent with the input. It addresses the context of the mother's Alzheimer's medication and the symptoms experienced. However, it introduces an unnecessary element about Dr. John Doe being the primary care physician, which doesn't align with the question of whether the jerks will return.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  - The response offers a detailed explanation that the jerks could be related to the Alzheimer's medication or the recent treatment, but it doesn't provide a direct answer to whether the jerks will come back. The suggestion to consult a physician or neurologist is appropriate, yet it might have benefitted from mentioning the unpredictability of such symptoms more explicitly.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  - The response is quite natural and human-like in its tone and structure. It maintains a professional and empathetic tone, which is appropriate for a healthcare context. There are minor issues like overly formal or scripted elements which slightly affect the naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response reasonably aligns with the context of the input. It acknowledges the mother's conditions of diabetes and anemia and offers general advice aligned with these issues. However, it does not directly address some specific context elements, such as the detailed blood work.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides general suggestions for managing diabetes and anemia, including diet, exercise, and stress management. However, it lacks specific medical guidance like adjustments to the medication regimen or addressing the specific findings from the attached reports or conversation with the patient, which the true answer partially suggests.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is fluent and reads like a human-written text. The language used is empathetic and clear, displaying an appropriate tone for a medical consultation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response partially aligns with the context but contains inaccuracies. Specifically, it indicates the TSH level is within the normal range, which is incorrect according to the provided range (0.4-4.0 mIU/L). This misalignment affects coherence.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The response does not fully answer the question as it fails to recognize the elevated TSH level, which can indicate subclinical hypothyroidism. The model does not mention the possibility of subclinical hypothyroidism and skips potential subsequent steps like regular monitoring or additional tests, which are crucial for this situation.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The language used is generally fluent and human-like, with polite and standard phrasing appropriate for communication by a healthcare professional. However, the incorrect interpretation of the TSH range impacts the perceived expertise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0 \n",
      "  - The model's response is mostly coherent with the input context, as it considers the symptoms and suggests steps that align with the situation presented. However, it does not directly address the specific advice given by the family doctor to pursue a Doppler test. Moreover, it doesn‚Äôt specifically mention concerns like fear of hospitalization and potential for amputation.\n",
      "\n",
      "- Completeness: 3.0 \n",
      "  - While the model's response covers the general steps for addressing leg swelling and potential venous issues, it fails to specifically address the question of why the leg gets swollen intermittently and the potential internal problems due to prolonged antibiotic use over 67 days. It also omits discussing the immediate recommendation for hospitalization or more urgent care indicated in the true answer.\n",
      "\n",
      "- Naturalness: 4.5 \n",
      "  - The response reads fluently and is structured in a manner typical of a medical consultation. It gives a clear and human-like explanation of the condition and the possible next steps in medical terms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "  - The model's response addresses the input by acknowledging the concerns of the user, but it introduces a potential diagnosis (melanoma) without considering more common causes related to the given context, such as the user's diabetes. It also fails to acknowledge the user's controlled diabetes and recent HbA1c level, which are relevant details that provide context for assessing the skin condition.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The response highlights the importance of seeing a doctor, which is a prudent suggestion, but it does not sufficiently explore or mention the more likely causes such as frictional hyperkeratosis or acanthosis nigricans, as indicated in the true answer. It also doesn't provide any remedies or interim steps besides moisturizing, missing potential topical treatment options that the true answer provides.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The language used in the model's response is fluent and human-like. The polite and caring tone is appropriate for a healthcare provider. The structure is clear and professional, which contributes to its naturalness. However, there's a slight repetition in the assurance to contact again which reduces its variety slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "The model's response logically aligns with the input context. It acknowledges the user's concern about weakness during sex and suggests lifestyle changes as potential remedies, which is coherent with the presented problem. However, it does not directly address nightfall as part of the user's issue, which is part of the initial context.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "While the model provides a detailed response, it does not sufficiently answer the question regarding the underlying reasons and a detailed remedy for both the weakness during sex and nightfall. The true answer emphasizes checking for diabetes and other endocrine issues, which are significant omissions in the model's response.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "The response sounds fluent and professional, resembling the tone and style of a human-like response a doctor might provide, making it very natural in its communication.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context, accurately acknowledging the seriousness of the condition and emphasizing the importance of immediate medical attention. However, the response contains a slight contradiction by stating it is \"not possible to restore\" while also mentioning a \"chance of recovery,\" which may confuse coherence slightly.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response indicates the seriousness of the condition and recommends immediate medical attention, which is critical. However, it lacks specific information about potential recovery mechanisms and more detailed medical insights, such as the role of the extent of brain damage in recovery, which were present in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds polite and formal, mimicking a professional and human-like response. It is courteous and consistent with what one might expect from a medical professional, although some phrasing could be slightly more coherent for added naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response aligns fairly well with the context provided. It identifies potential causes of chest pain and acknowledges the importance of consulting a doctor for a proper diagnosis, which is relevant to the input concerning the father's health issues.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The model provides a broad overview of possible chest pain causes and general management tips, but does not address specific medications or home remedies for the father's existing conditions (diabetes and blood pressure) or directly respond to the request for medicine or home remedies to overcome these problems. It lacks specific and practical advice tailored to the father's needs as requested in the input.\n",
      "  \n",
      "- Naturalness: 4.5\n",
      "  - The response is generally fluent and human-like, using a conversational style and polite language. It provides structured and logical information like a knowledgeable but non-specialized advisor, noting the limitations of not being a doctor. However, it could slightly improve by focusing more directly on the input's request.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It addresses the parent's concern about the child's blood sugar levels, acknowledging the slightly elevated readings and the potential need for further evaluation by a pediatrician.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  While the model identifies the slightly elevated blood sugar levels as a concern and suggests seeing a pediatrician, it could improve by providing more specific details about what constitutes normal blood sugar levels for a child or mentioning other symptoms to watch for. However, it sufficiently advises on the next steps.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response sounds fluent and human-like, using polite and professional language. It is appropriate for a medical context and conveys concern and readiness to provide further assistance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context of the input. It accurately describes the general steps a doctor might take during an examination for erection problems.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response covers the basic physical examination and questions about symptoms and medical history, it lacks details on specific conditions that might be explored, such as diabetes or nerve issues, which were mentioned in the True Answer. It also omits more specialized tests like a stamp test or penile Doppler.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, with a polite greeting and logical structure that sounds like a typical conversation one might have with a doctor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided. It acknowledges the situation of the user experiencing thoughts of suicide due to depression and emphasizes the importance of seeking help, which is coherent with the original input.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model sufficiently addresses the immediate concern about thoughts of death or suicide by recommending seeking help and mentioning therapy and medication as treatment options, it lacks the depth and detail found in the True Answer. It doesn‚Äôt mention depression as a biological illness, the suggestion of consulting a psychiatrist, or other aspects like tests that might be necessary, which slightly limits its completeness.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like, maintaining a compassionate and professional tone that matches the expectation of a healthcare provider responding to a sensitive situation. It slightly overemphasizes the positive nature of seeking help as \"a sign of strength,\" which may not feel entirely natural in a clinical context, but overall remains highly natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the provided context by identifying and focusing on sciatica, a common cause of nerve pain between the lower back and leg. It provides a reasonable explanation of the condition and potential causes, which fits well with the symptoms described by the user.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response is fairly comprehensive in offering potential causes, treatment options, and self-care tips for sciatica, but it lacks some of the diagnostic exploration present in the true answer, such as suggesting further medical tests or considering additional conditions like lumbar spondylosis or peripheral neuropathy. It also does not inquire about other health conditions like obesity or diabetes which could be relevant.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and human-like. It adopts a conversational tone, offering empathy and practical advice, which is typical of a human healthcare provider. Overall, it reads smoothly and is approachable for someone seeking medical advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "  The model's response is largely coherent with the context of the inquiry, offering possible medical explanations for excessive urination. However, it does not directly address the specific combination of symptoms presented‚Äînamely, the unusual erotic sensation associated with a full bladder, which was mentioned in the user's query. This oversight slightly affects the logical alignment with the inquiry.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "  While the response covers several potential causes of excessive urination and advises seeing a doctor, it misses out on discussing the erotic sensation aspect, which the user explicitly mentioned and was part of their concern. The true answer delves into this by explaining possible reasons for such a sensation, suggesting the model's response could be more complete by incorporating similar insights.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "  The response is professional, polite, and uses appropriate medical terminology, making it sound fluent and human-like. It closely resembles how a medical professional might communicate in written advice. The professional tone and structure contribute positively to its naturalness; however, inserting the user's name without addressing it in the context slightly detracts, as it makes the greeting feel slightly artificial.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is coherent with the input context. It correctly identifies the issue of frequent urination and suggests a possible condition (overactive bladder, OAB) as a cause. However, it does not fully address all symptoms, such as the burning sensation, nor does it reference the provided information about the uroflowmetry test.\n",
      "  \n",
      "- Completeness: 3.0  \n",
      "  The completeness of the response is somewhat lacking. While it offers a potential explanation and some general advice, it does not adequately explore all potential causes mentioned in the true answer, like stress or prostate gland issues. Furthermore, the response misses specific diagnostic recommendations or specific treatment options that have been suggested in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is mostly natural and human-like, featuring a polite and professional tone typical of a medical consultation. The language is fluent and clear, although the inclusion of the phone number for scheduling an appointment might feel somewhat out of place in the context of the specific query, hindering its overall naturalness slightly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is logically aligned with the context provided. It acknowledges the mother's condition and treatment, discusses common steroid side effects, and addresses the bitter taste issue, suggesting potential sources and actions to take.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response sufficiently answers the question by discussing side effects of steroids and potential causes for the bitter taste. However, it does not directly indicate a medication to reduce steroid side effects, which was explicitly asked. \n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent, polite, and human-like. It provides a clear and coherent explanation while maintaining a professional tone expected from a doctor's reply.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5\n",
      "  - The model's response identifies a plausible condition (trigger finger) based on the symptom of pain when gripping or pressing. However, it does not consider other possibilities like neuralgia or vascular issues, which could also be relevant given the input.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The response addresses the pain comprehensively in the context of trigger finger but misses discussing other potential causes that the true answer highlights, such as diabetic neuropathy and cervical spondylosis. Thus, it doesn't fully cover the input's complexities.\n",
      "  \n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent, friendly, and professional, closely resembling communication from a human doctor. The language is clear and easy to understand, with a reassuring tone, making it sound natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response is partially coherent. It acknowledges the difficulty in obtaining quality biopsy samples from MDS patients, which aligns with the provided context. However, it fails to address the key question about the significance of \"fibrino-leukocytic consistency,\" leading to a lower coherence score.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The response does not sufficiently answer the specific question about whether the \"fibrino-leukocytic consistency\" of the biopsy material could prove the suspected condition. Instead, it generalizes the situation without directly addressing this crucial aspect, demonstrating a lack of completeness.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The language used in the model's response is mostly fluent and human-like. The structure is appropriate for a professional medical discussion, but slight repetitiveness and lack of specific details prevent it from being rated higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.5  \n",
      "    The response initially suggests going to the ER, which contradicts the input, as it states that the user's brother has already taken her there. The response does not appropriately align with the scenario described in the context. \n",
      "\n",
      "- Completeness: 3.0  \n",
      "    The response includes general advice on managing a diabetic foot injury and suggests strategies for controlling inflammation and spotting infection. However, it misses discussing what might happen to the foot in the future, which is the core of the user's question.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "    The response is quite fluent and human-like. It provides structured and clear advice in a manner that is typical of a healthcare professional. However, the initial mistake might slightly hinder the perceived naturalness as it feels less attentive to the full context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response acknowledges the issue of a potential fungal infection and suggests continuing the use of the prescribed treatments, which makes sense given the context of a recurring issue. However, it inaccurately attributes symptoms to the side effects of Itraconazole, which doesn't align with the context of recurrent infection post-sexual activity and stopping Oxra.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The response lacks depth and leaves out important details about why the infection might have recurred, such as the possibility of transferring the infection between partners or the need for a longer treatment course. It does not suggest any additional specific medical actions beyond consulting a doctor and applying the cream.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The language used is quite fluent and mostly sounds like it could be from a human. The polite tone and common medical advice language aid in making the response natural, though some parts feel a bit generic and not tailored to the specific situation given.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response partially aligns with the context provided in the input. It discusses the risk of infection from a needle stick and gives general preventive measures, but it doesn't fully grasp the specific scenario where the user did not actually get pricked. The reassurance about the risk is vague, and the information about germs and washing hands is somewhat unrelated to the main concern about HIV risk.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The response does not sufficiently address the user's specific concern about HIV or provide targeted reassurance based on the context (e.g., the type of needle, the fact that the needle didn't pierce the skin, and the subsequent illness). The model fails to address the psychological reassurance aspect or prompt for information about the diabetic person's HIV status, as suggested in the true answer.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The model's response sounds fluent and human-like in terms of language and structure. It gives a professional tone typical of a doctor's response. However, it could have been more concise and directly relevant to the user's specific inquiry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It correctly interprets the test results mentioned and presents them clearly, alongside providing a sensible recommendation to consult a physician.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response addresses the primary concern by suggesting a follow-up with a physician for further management. However, it could have been more complete by advising on specific aspects of lifestyle changes or monitoring until the consultation, which might reflect a more comprehensive interim plan.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is generally fluent and human-like, maintaining a professional and courteous tone expected from a healthcare professional. It is structured and coherent, which adds to the perceived naturalness of the communication.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "    \n",
      "    The model's response is coherent and logically aligns with the input question. It acknowledges the user's HbA1c level and provides suggestions for supplements, which is directly related to the query about reducing HbA1c. However, the model's response could have been enhanced by including some educational context about HbA1c or glucose control for better coherence with the true answer.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  \n",
      "    The model‚Äôs response provides a list of supplements (Chromium, Berberine, Cinnamon, and Magnesium) that could potentially aid in lowering HbA1c levels. However, it misses broader lifestyle and dietary advice, which is crucial for a comprehensive answer to the user's question. The true answer covers a wider range of strategies, including exercise and dietary changes, which are not mentioned by the model.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "    The response sounds fluent and human-like. It opens and closes with polite, conversational language that is typically used in professional consultations, making it sound more natural. The response could have felt even more personal and engaging with a slight adjustment to avoid sounding overly formal in parts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  - The response logically aligns with the context by addressing the symptoms and offering potential diagnoses and treatments. However, the introductory note about educational purposes slightly disconnects it from the context of asking for direct guidance.\n",
      "  \n",
      "- Completeness: 3.5  \n",
      "  - The response covers a general approach to diagnosis and treatment but lacks specific recommendations based on the detailed treatment history provided in the input. It doesn't directly address the ineffectiveness of the past treatments mentioned.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  - The response is fluent and human-like, with polite and professional language typical of medical advice. The tone is formal, which aligns well with the context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context provided, acknowledging the key considerations such as age, diabetes, and previous health history. However, it suggests angioplasty which contradicts the true answer's recommended procedure, indicating a slight logical disconnect given the patient's specific circumstances.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The model provides a general overview of angioplasty without addressing why this decision may be less favorable, as highlighted in the true answer. It lacks specific details about the complexities of the patient's condition that might affect the treatment decision, such as the ejection fraction and the lesion complexity.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response sounds fluent and human-like, with polite and considerate language. It encourages further consultation, reflecting a natural interaction between a healthcare provider and a patient. There is room for a slight improvement in personalizing the response based on the provided information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The response is somewhat coherent but contains an incorrect suggestion. The patient is already taking a calcium channel blocker (Amlodipine), and the suggestion to consider another calcium channel blocker is not appropriate given the history provided. The response does align with the general theme of exploring other non-diuretic options but fails to make new, relevant suggestions.\n",
      "\n",
      "- Completeness: 2.5\n",
      "  - The response partially answers the question by indicating that there are other non-diuretic options available. However, it lacks specificity in additional medication suggestions beyond the calcium channel blockers, which the patient is already using. It also misses discussing other drug classes and lifestyle modifications that could be explored, as noted in the True Answer.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is written fluently and sounds polite and human-like. The tone is professional and caring, as would be expected in communication from a doctor. Nonetheless, better specificity would improve overall satisfaction and perceived expertise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "   The model's response is coherent as it acknowledges the symptoms described and suggests further evaluation by a healthcare provider. However, it lacks specificity in addressing potential causes, as indicated in the true answer with suggestions for specific tests like the head-up tilt test.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "   The model provides general advice to see a specialist and monitor symptoms, which sufficiently covers general guidance. However, it does not delve into specific tests or potential diagnoses, such as orthostatic intolerance or panic attacks, as mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "   The response is fluent and sounds human-like. It is polite and expresses concern, reflecting a caring and considerate tone typical of professional healthcare advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input, acknowledging the severity of conditions like typhoid and a blood clot in the brain. However, it mistakenly ties the blood clot as a complication of typhoid rather than addressing them as separate conditions the patient is experiencing.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response is fairly complete, offering guidance on the urgency of medical intervention for the blood clot and mentioning the need for proper treatment for typhoid. However, it could be improved by addressing specific steps for managing typhoid and more explicitly prioritizing the headache related to the blood clot.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and human-like, using a caring tone and reassurance, which is appropriate for a patient-facing communication, especially in a medical context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is generally coherent with the input context, providing explanation about jock itch and general treatment methods. However, it does not specifically address the persistence of the issue after stopping the medication, which is a significant part of the user's concern.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response gives a general overview on how to treat jock itch but lacks specific advice tailored to the user's situation, such as addressing the recurrence after stopping the medicine or considering other health factors like diabetes. It doesn't offer a new or alternative prescription beyond what's already been tried, missing an opportunity to provide a more comprehensive solution.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is quite natural and fluent, reading much like a human medical professional might respond. It covers basic treatment methods in a clear and informative manner. However, the lack of personalization with respect to the user's ongoing treatment situation slightly detracts from its natural feel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 4.0**  \n",
      "  The model's response is coherent and aligns with the context, providing relevant information about nasal polyps and mentioning the lack of necessity for a biopsy based on typical practice. However, it overlooks the specific context of the patient's age and the potential need for a biopsy due to risk factors associated with polyps after age 40. It doesn't directly address the details related to the diagnosis or the risks mentioned in the true answer.\n",
      "\n",
      "- **Completeness: 3.5**  \n",
      "  The model adequately explains what a polyp is and potential symptoms but falls short in addressing the specific concerns about the necessity of a biopsy and the severity level for someone over 40 with unilateral nasal polyps. The completeness is compromised by not fully addressing the question of whether a biopsy should be conducted based on age-related cancer risks, as highlighted in the true answer.\n",
      "\n",
      "- **Naturalness: 5.0**  \n",
      "  The response is natural-sounding, fluent, and reads like it was written by a human. It provides a clear and professional explanation suitable for a lay audience, which aligns well with typical healthcare communication.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided, discussing the implications of elevated creatinine and triglycerides, and the importance of monitoring diabetes. However, it does not address the specific combination of diabetes and potential kidney issues.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response is somewhat complete, suggesting consultation with a doctor and maintaining a healthy lifestyle. However, it lacks specific advice about revising diabetes medication and the potential need to restart medication, which are important aspects given the user's medical history. It also doesn't inquire about other critical details, such as the duration of diabetes or any ongoing kidney issues.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is quite fluent and human-like, following a polite and structured tone typical of a human doctor's advice. The language used is clear and easily understandable, contributing to its natural tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  *The response partially aligns with the context, reinforcing the importance of controlling blood pressure and sugar levels, but it doesn't address potential medication overlaps or specific concerns about the changes in medication regimen.*\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  *The response lacks detail and does not directly address all aspects of the patient's inquiry, such as the specific concerns about the medication switch from Prolomet XL to Tazloc-H or the suitability of taking Metformin ER twice daily.*\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  *The response is fluently written and sounds human-like, using an appropriate tone for medical advice. However, it lacks some specificity, which affects its credibility as a professional response.*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided and appropriately addresses the symptoms and concerns mentioned in the input. It provides a step-by-step approach to diagnosis, aligning well with the inquiry about lymphadenopathy and associated symptoms.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response includes a comprehensive list of tests and evaluations but does not address some aspects like potential vein pathology, detailed explanations on the causes of low sedimentation rate, or a more in-depth analysis of related symptoms like numbness and stiffness. It could provide a more thorough exploration similar to the true answer.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent, professional, and human-like in tone. It maintains a respectful and reassuring communication style that is typical of a real doctor-patient interaction, although it may slightly lack the empathic tone seen in personal communications.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The model's response is somewhat coherent with the context. It recognizes the blood sugar reading as high, but it's not entirely clear since 125 mg/dL is actually indicative of pre-diabetes when fasting. The response lacks direct reference to whether the fasting period (since 11 PM) was long enough, which is crucial contextual information for accurate assessment.\n",
      "\n",
      "- Completeness: 2.5  \n",
      "  The model doesn‚Äôt directly answer the specific question of whether the patient is diabetic. It provides general advice on managing blood sugar levels and mentions the importance of monitoring over time, but it misses mentioning that a single reading isn't enough to diagnose diabetes. A more complete response would advise the user to consult a healthcare professional for further testing (like an A1C test) to determine diabetic status.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is quite natural and human-like. It starts off with a friendly and supportive tone and flows coherently, resembling how a doctor might express concern and suggest a plan. There are minor repetitive phrases, but overall, it maintains a conversational tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context and provides a coherent explanation and actionable steps for dealing with ingrown nails. It matches the professional tone expected from a medical expert like a podiatrist. However, it does not address the recurrence of the issue, which the input emphasizes.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The response offers a good range of advice on dealing with an ingrown nail, including home care and the option of seeking professional help. However, it lacks specific suggestions relevant to the individual's situation (e.g., the history of nail removal and recurrence). It also does not discuss when to consider medical interventions like medication or related health checks such as diabetes, which are mentioned in the true answer.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response is fluent, human-like, and maintains a professional and empathetic tone, characteristic of a human podiatrist. It is polite and includes a call to action, encouraging further communication, making it sound quite natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "Below is the evaluation of the model's response based on the given metrics:\n",
      "\n",
      "- **Coherence: 3.5**\n",
      "  - The model's response demonstrates some logical coherence with the context, as it addresses the father‚Äôs history of stent placement and symptoms, suggesting angina as a possible cause. However, it overlooks the specific symptoms described, such as the right index finger sensation, which weakens the coherence.\n",
      "\n",
      "- **Completeness: 3.0**\n",
      "  - While the model addresses potential cardiac-related issues, it fails to discuss neurological causes, which are crucial given the symptoms of the right index finger and side chest depression, as highlighted in the true answer. The lack of discussion on these neurological aspects renders the response incomplete.\n",
      "\n",
      "- **Naturalness: 4.5**\n",
      "  - The response is written in a fluent and polite manner, resembling a human-like conversation with reassuring and natural wording. However, slight rigidity in the structured explanation might detract from complete naturalness in a casual, patient-to-doctor dialogue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response logically aligns with the context provided in the input. It acknowledges the elevated C-reactive protein level and discusses possible explanations such as inflammation and autoimmune responses, which are relevant to the medical context provided. However, it could have more directly addressed the specific symptoms described in the input, like shoulder and wrist joint pains in relation to the high CRP and recent diabetes diagnosis.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides some information about possible causes for the elevated CRP level and suggests further tests. However, it falls short of a more thorough explanation or guidance regarding the specific symptoms and the recent diabetes diagnosis, which are crucial parts of the question. More detailed insight into the relationship between these symptoms and his conditions would improve completeness.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluently written and sounds human-like. It includes empathetic language and reassures the user, which contributes to its naturalness. The tone is professional and courteous, typical of a healthcare consultation, though a touch more conciseness might enhance the overall natural flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "  - The model's response generally aligns with the context in acknowledging the symptoms and the need for further evaluation, which is a logical step for addressing the user's concerns. However, it lacks specific references to the mentioned symptoms such as hot flashes or other potential medical conditions mentioned in the input, which affects the coherence.\n",
      "\n",
      "- Completeness: 2.0\n",
      "  - The response fails to provide a specific answer to the symptoms described and does not address potential causes or next steps in terms of specific medical checks, unlike the true answer. It suggests scheduling an appointment and reviewing the medical history, which is a generic recommendation not adequately tailored to the user's detailed input.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent, polite, and human-like, offering a warm and professional tone. It effectively mimics how a doctor might respond to initial contact from a patient. However, the response could be slightly more specific to score higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided in the input. It correctly identifies and discusses the issues related to the patient's medical history, the complications of the suggested AV fistula placement, and the potential impact on mobility. However, it doesn't address the specific mention of alternative placement options, such as near the chest area.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - The response provides a general overview of the considerations involved in placing a fistula and hints at the implications for patient mobility. However, it lacks specific details about alternative sites for fistula placement, such as the possibility of chest area placement or leg options, which were sought in the query. The response also does not provide information about alternative solutions like using a central line temporarily.\n",
      "\n",
      "- Naturalness: 4.7\n",
      "  - The language used in the response is fluent and human-like, with a clear and respectful tone that is appropriate for the context of a medical inquiry. The explanation is well-structured and easy to understand, making it sound natural overall.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided in the input. It acknowledges the patient's condition and offers advice consistent with maintaining heart health, which is relevant to the patient's situation. However, it slightly minimizes the concern about mild concentric left ventricular hypertrophy without considering all aspects mentioned in the input, such as recent lifestyle changes.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model provides a detailed answer regarding lifestyle recommendations and medication adherence. However, it does not directly address the question of whether mild concentric LVH can regress with diet and exercise. Additionally, it does not suggest a specific timeframe for reassessment or provide a plan for monitoring progress.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The model's response is fluent and sounds human-like. The tone is professional and empathetic, and the language used is appropriate for a medical context. The structure of the response is coherent and organized, closely resembling what one might expect from a healthcare professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response displays some coherence as it attempts to address the various health conditions and prescribed treatments. However, it does not directly address the specific concern about potential interactions or the completion of TB treatment. The response seems to diverge into a general discussion on each condition rather than focusing on the immediate questions raised in the query.\n",
      "\n",
      "- Completeness: 2.5\n",
      "\n",
      "The model does not sufficiently answer the specific question about the potential drug interactions and the implications of not completing the TB treatment. While it provides detailed information about each health condition and mentions medications, it fails to directly address whether any medications have poor interactions or are unnecessary.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The tone of the response is formal and relatively natural for a healthcare professional's advice. However, it is lengthy and might overwhelm the reader with information that is not directly requested. The conversational style could be improved by making the response more concise and focused on the specific questions asked.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- **Coherence: 3.0**  \n",
      "  The model's response contains some logically aligned information regarding jaundice and liver disease. However, it incorrectly states that diabetes is directly linked to contracting hepatitis E; this is not coherent with medical knowledge. \n",
      "\n",
      "- **Completeness: 2.5**  \n",
      "  The response covers possible complications of hepatitis E but does not sufficiently address the specific concerns of the user, particularly about whether the condition is life-threatening. It misses key information provided in the true answer about the usual progression and prognosis of hepatitis E, as well as advice on management and the significance of the ANA test result.\n",
      "\n",
      "- **Naturalness: 4.5**  \n",
      "  The model's response is fluent and human-like. It maintains a conversational tone and is easy to understand. However, parts of the explanation might confuse a patient due to their incorrectness, which slightly impacts the naturalness as helpful communication.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is generally coherent‚Äîit acknowledges the MRI reports and describes a sensible plan of action by recommending a consultation with a sports medicine specialist. However, it somewhat overlooks the specific concern expressed by the user regarding the clear MRI and their ongoing pain.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response adequately suggests seeking further evaluation for the knee pain and provides lifestyle suggestions. However, it could be more complete by directly addressing the negative MRI findings or exploring other potential causes of knee pain in diabetics, which might reassess why the pain persists despite normal imaging results.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The language used by the model is fluent and human-like. It incorporates a helpful and reassuring tone commonly found in medical consultations, which makes it sound very natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5 \n",
      "  - The model's response is generally coherent and logically aligned with the context provided. It appropriately addresses the presence of gallstones and suggests general actions related to managing gallstones. However, it lacks the depth and comprehensive understanding shown in the true answer, which discusses the size implications of gallstones and other possible causes of pain.\n",
      "  \n",
      "- Completeness: 3.0 \n",
      "  - The model provides some useful advice regarding gallstones, including pain relief and potential treatments. However, it doesn't fully address the potential causes of abdominal pain as detailed in the true answer, such as other conditions like ulcers or pancreatitis. It also does not acknowledge the lack of detailed symptoms which could lead to different diagnoses and treatments.\n",
      "  \n",
      "- Naturalness: 4.5 \n",
      "  - The response is generally fluent and human-like, using polite language and clear explanations. It correctly uses medical terminology in a manner that would be understandable to a layperson, maintaining a conversational tone appropriate for a doctor's advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is generally coherent and aligns well with the context provided in the input. It explains the difference between early bronchiectatic changes and bronchiectasis, mentions treatment options, and addresses life expectancy with some alignment to general clinical understanding. However, there are some inaccuracies and omissions regarding the inclusion of specific diagnostic elements like atelectasis which were mentioned in the true answer.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response covers the main aspects of the question such as the difference between early bronchiectasis and bronchiectasis, treatment, and life expectancy. However, it doesn't mention certain diagnostic and treatment suggestions like atelectasis and the additional medications or procedures (like Aerodil or postural drainage) that were recommended in the true answer. Therefore, it doesn't fully answer all parts of the input query.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The model's response is fluent and human-like, using a calm and professional tone similar to how a doctor would communicate with a patient. It is well-structured and reassuring while answering the patient's inquiries, which resembles real-life doctor-patient interactions effectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 2.0  \n",
      "  The model's response does not logically align with the specific issues presented in the input. The input mentions specific symptoms (abdominal pain, burning sensations, weakness) and lists the medications being taken, but the response provides general advice rather than addressing these specific concerns or suggesting any particular interventions related to the symptoms described.\n",
      "\n",
      "- Completeness: 1.5  \n",
      "  The response fails to adequately answer the query about the mother's specific symptoms and continuing issues. While general advice on medication management and seeing a doctor is provided, it misses the crucial element of addressing the actual symptoms and potential causes as suggested in the \"True Answer,\" such as stress, medication side effects, or acid reflux.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  Despite the lack of specificity, the response is fluently written and sounds human-like. It offers a supportive tone and uses natural language, indicating good naturalness. However, the repetition of information in \"Response (correct)\" and \"Response (incorrect)\" might slightly detract from its perceived authenticity, but not significantly enough to detract from the overall score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is generally coherent with the input provided. It acknowledges the concern about the lightened area on the MRI, the possible causes of brain atrophy, and mentions consulting a healthcare professional for a proper diagnosis. However, it does not delve into specific details about the conditions mentioned, such as meningioma or the possible association of frontal atrophy with certain symptoms, which slightly impacts coherence.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "The model's response addresses the key questions asked: the nature of the lightened area on the MRI and possible causes of brain atrophy. However, it lacks depth in its explanation and does not provide as many specifics or alternatives as the true answer does. It could have benefitted from discussing specific conditions, potential implications of the findings, and more targeted recommendations.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The language used by the model sounds fluent and human-like. It adopts a reassuring and professional tone, akin to how a real doctor might respond. The phrasing is clear and concise, making it easy to understand. However, it remains somewhat generic and could have been more personalized or detailed to increase its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "  - The model's response aligns with the context provided, addressing the concern about irregular bleeding after initial sexual activity. However, it introduces unrelated advice about post-children bleeding, which was irrelevant to the user's situation.\n",
      "  \n",
      "- Completeness: 3.0\n",
      "  - The model mentions potential causes for irregular bleeding and recommends consulting a doctor, but lacks specific medical advice such as ruling out pregnancy or checking for physical causes (tears, polyps, etc.) mentioned in the true answer.\n",
      "  \n",
      "- Naturalness: 4.5\n",
      "  - The response is fluent, polite, and maintains a professional tone typical of a doctor's advice, which makes it sound human-like. However, it could improve by being more concise and directly related to the specific user scenario.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response aligns with the context provided in the input by addressing the symptoms of redness, pain, and discharge on the penis. However, it lacks specific details tying the symptoms directly to a likely diagnosis, such as candidal balanitis, which is mentioned in the true answer.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response provides general advice and suggestions for managing the condition, but it lacks a thorough analysis of the possible causes. It does not explicitly mention potential conditions like candidal balanitis, chancroid, or herpes, nor does it address the concerns about using Surfaz SN or seek further information through follow-up questions.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is fluent and human-like, using polite language and structured advice. It sounds empathetic and provides a logical series of steps to follow, although it could be slightly more conversational by integrating specific queries about the condition's history or additional symptoms, as seen in the true answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and logically aligns with the context provided. It addresses the patient's concerns and information about diabetes management effectively. However, it could have been more concise, focusing directly on the patient's medication concerns without repeating general advice on diet and exercise.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model's response provides a comprehensive answer, covering various medications and lifestyle suggestions. However, it does not directly address the patient's specific concerns about possible kidney damage from sodium glucose transporter medications. Mentioning consulting a specialist or discussing more deeply with the doctor about this specific concern could enhance completeness.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and sounds human-like, using appropriate medical terminology and conversational language to convey the message clearly. It is polite and empathetic to the patient's situation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response aligns with the context provided, discussing the diet in relation to managing diabetes and high BP. However, it does not fully address the specifics of a low potassium, low urate, and low phosphorus diet.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - While the model provides general advice on maintaining a balanced diet and controlling conditions like diabetes and high blood pressure, it does not detail the specific aspects of the diet plan mentioned in the question. The advice on fish and non-vegetarian foods is somewhat vague and lacks deeper guidance on the full range of dietary restrictions mentioned.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "  - The model's response is fluent and human-like, maintaining a professional yet empathetic tone that is suitable for this context. However, minor improvements could be made in integrating specific dietary details for more tailored advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response aligns well with the context provided. It addresses the issue of prediabetes and suggests practical next steps. However, there could be a more direct connection to the specific test results mentioned in the input to enhance coherence.\n",
      "\n",
      "- Completeness: 4.0\n",
      "  - The response is quite detailed in terms of offering general advice on managing prediabetes and includes lifestyle changes and medication options. However, it does not address the specifics of the HbA1c test result being normal (4.8) and reassuring the user as the True Answer does.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The response is fluently written and maintains a professional, empathetic tone that sounds very human-like. It uses clear language and offers support, mimicking a natural and polite consultation process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "The model's response is generally coherent. It acknowledges the need for medical consultation and suggests a variety of common treatments for blocked arteries, such as medications, lifestyle changes, and surgery. However, it does not specifically address the high degree of blockage (90% and 75%) mentioned in the input, nor does it align with the urgency suggested by such significant blockages.\n",
      "\n",
      "- Completeness: 3.0\n",
      "\n",
      "The response provides a range of general treatments for artery blockage but fails to specifically advise on the necessity of stenting, despite the critical level of blockage described. The input mentions a heart attack and specific percentages of blockage that require immediate and specific treatment. The model response stays broad and generic rather than directly addressing the significant blockage and the advised stenting.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "The response is fluent and natural-sounding, resembling how a healthcare professional might speak. It uses clear language and provides a comforting tone, although a bit more specificity would strengthen the authenticity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "  - The model's response logically aligns with the context provided in the input. It recognizes the symptoms and suggests that they could be indicative of a condition like Peyronie's disease, which is coherent with the symptoms described by the user.\n",
      "\n",
      "- Completeness: 3.5\n",
      "  - While the model provides a reasonable overview of potential conditions and advises consulting with a specialist, it lacks some specific details present in the true answer, such as the mention of frenulum issues, partial phimosis, and specific advice regarding medication like Tadalafil. These would provide a more complete answer to the user's concerns.\n",
      "\n",
      "- Naturalness: 5.0\n",
      "  - The model's response is fluent and sounds human-like. It uses natural language, provides suggestions, and maintains a comforting tone suitable for a medical setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5 \n",
      "  - The model's response generally aligns with the context and makes sense in terms of the symptoms and medication changes discussed. However, there are instances where it inaccurately describes the father's condition as bacterial without proper testing or exploration of other possible causes.\n",
      "\n",
      "- Completeness: 2.5 \n",
      "  - While the model addresses the questions by suggesting alternative antibiotics and changes to diabetic management, it lacks depth and oversight by not recommending clinical tests or consulting a doctor. The true answer emphasizes diagnosis and consultation before prescribing medication, which the model fails to cover adequately.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "  - The language used by the model is fluent and sounds quite natural. The recommendations flow well, framed in a conversational tone, though some parts could be seen as repetitive (like the insulin discussion), which slightly affects the naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response is generally coherent and aligns with the input context. It addresses the symptoms described by the patient and provides a possible explanation (anemia), which is logical given the symptoms. However, it assumes anemia without considering other potential causes like diabetes or thyroid issues, which slightly affects coherence.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model‚Äôs response provides a detailed explanation of anemia and its possible causes, it does not fully cover other potential explanations for the symptoms such as vitamin deficiencies or diabetes, which were mentioned in the true answer. It offers a recommendation to see a doctor but lacks specific advice on which tests might be relevant.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is well-written, fluent, and human-like. It provides a polite and professional tone, appropriate for doctor-patient communication. The only issue affecting naturalness slightly is the lack of adaptation to the specific concerns raised in the input, such as considering a broader range of potential issues beyond anemia.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0  \n",
      "  The model's response aligns fairly well with the context, mentioning the general importance of managing cholesterol levels and potential medications. However, it lacks individualized insight based on the patient's familial medical history and personal details provided in the input. \n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the response provides general information about cholesterol management and potential medications, it doesn't address all specific questions asked. It doesn't delve into the reasons why the cholesterol levels remain high, omit details regarding the familial risk of coronary artery disease, potential medicine side effects, and lifestyle precautions tailored to the patient's profile. \n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is largely fluent and human-like, maintaining a professional and considerate tone. However, the generic approach and repetitive structure slightly detract from its natural presentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.5  \n",
      "  The response generally aligns with the context of the input, addressing the issue of urinary difficulties. However, it fails to directly acknowledge or integrate the specific details mentioned by the user, such as the normal prostate scans and type 2 diabetes. The model does not consider these specifics in its proposed solutions.\n",
      "\n",
      "- Completeness: 3.0  \n",
      "  While the model provides a broad range of potential treatments and considerations, it doesn't sufficiently address the user's specific situation, such as the fact that the prostate is normal and that they are taking insulin. It also doesn't offer a direct opinion or personalized advice about the user's situation, which was requested.\n",
      "\n",
      "- Naturalness: 4.0  \n",
      "  The response is generally fluent and sounds human-like, though a bit formulaic. The enumeration of various treatment options could detract from the natural flow, but the language used is otherwise typical of conversational advice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.0\n",
      "\n",
      "  The model's response is mostly coherent with the context, as it acknowledges the question about menstruation affecting blood glucose levels. It mentions that menstruation does not have a direct effect on blood sugar levels and correctly addresses potential hormonal changes during the menstrual cycle. However, the initial part of the response wrongly assumes the user is showing symptoms of diabetes.\n",
      "\n",
      "- Completeness: 3.5\n",
      "\n",
      "  The model's response provides an explanation about how menstruation and blood sugar might be related through hormonal changes. However, it does not directly answer if the test results could be impacted by the user being on their first day of their menstrual cycle. The advice to consult a healthcare provider is helpful, but a more direct clarification regarding the impact on test results would improve completeness.\n",
      "\n",
      "- Naturalness: 4.5\n",
      "\n",
      "  The response sounds quite natural and generally human-like. The language is polite and the explanation is clear. However, the phrase \"I'm sorry to hear you are experiencing some symptoms of diabetes\" is slightly misplaced because the user did not mention experiencing symptoms, which could affect how natural the response feels in context.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically addresses the increase in WBC count and suggests infection as a possible cause, which is consistent with the medical context provided. However, it assumes an infection due to the stent without additional checks, which may not be the sole reason for leukocytosis.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a plausible explanation for the high WBC count and mentions potential treatments. However, it lacks a recommendation for further medical evaluation or consultation with a specialist, which would have provided a more comprehensive approach to the patient's concern.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent and sounds human-like. It offers a professional tone typical of a healthcare provider, making the interaction feel genuine and attentive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0\n",
      "\n",
      "The model's response is generally coherent in terms of acknowledging the presence of a medical issue and suggesting the importance of consulting a doctor. However, it lacks specific advice related to the frenuloplasty or circumcision, which were explicitly mentioned in the input. This makes the response less logically aligned with the patient's question about deciding between the two surgical options.\n",
      "\n",
      "- Completeness: 1.5\n",
      "\n",
      "The model fails to address the question directly. It does not provide any guidance on whether the patient should opt for frenuloplasty or circumcision. Instead, it gives generic advice about consulting a doctor for more information. The patient's query is not sufficiently answered.\n",
      "\n",
      "- Naturalness: 4.0\n",
      "\n",
      "The response is generally fluent and human-like, using polite language and a friendly tone. However, the model's response feels somewhat generic and might sound too formulaic, reducing a bit of its natural conversational tone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response aligns well with the context provided in the input. It discusses the relevance of glucose readings, potential contributing factors, and advises on confirming the diagnosis through appropriate testing.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The response provides a comprehensive answer by addressing the uncertainty surrounding the glucose readings and suggesting further tests like fasting plasma glucose test or oral glucose tolerance test. However, it doesn't mention HbA1c, FBS, or PPBS, which were highlighted in the true answer, which could be an important omission in providing a complete response.\n",
      "\n",
      "- Naturalness: 5.0  \n",
      "  The response is fluent and human-like, maintaining a professional tone throughout, which is appropriate given the medical context. It reads as though it could have been written by a healthcare professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "\n",
      "The model's response is coherent and logically aligns with the input context. It provides a structured and sensible set of recommendations for improving the chances of getting pregnant. However, it could improve slightly by acknowledging more specific medical advisories mentioned in the true answer, such as checking specific health markers or timing with the woman's cycle.\n",
      "\n",
      "- Completeness: 4.0\n",
      "\n",
      "The response is quite comprehensive and covers key points such as maintaining a healthy lifestyle, managing stress, and when to seek a fertility specialist. However, it omits certain medical advisories mentioned in the true answer, like checking for rubella immunity, thyroid levels, fertility window timing, and folic acid supplementation, as well as specific conditions or age factors that could affect fertility.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "\n",
      "The model's response is very natural and fluent, with a friendly and professional tone that is appropriate for a doctor. It sounds human-like and engaging. The introduction and closing statements make the response feel personable and conversational.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "    - The model's response is coherent and logically aligns with the concern presented by the patient regarding prostate-related pain. It provides information relevant to the patient's situation and explains possible causes such as prostatitis, which aligns well with the symptoms described by the patient.\n",
      "\n",
      "- Completeness: 4.0\n",
      "    - The response sufficiently answers the patient's question by suggesting prostatitis as a possible condition and advising the patient to consult a doctor for further evaluation. However, it could be more complete by asking additional questions to help narrow down the diagnosis, as seen in the true answer, which probes deeper into the patient's medical history and other potential symptoms.\n",
      "\n",
      "- Naturalness: 4.8\n",
      "    - The language used by the model is fluent and human-like, resembling a typical interaction one would expect from a healthcare professional addressing a patient's concerns. The response is polite, empathetic, and informative, maintaining a professional tone throughout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context provided, addressing the concern about miscarriages with potential causes and steps for further investigation. However, it lacks some specific tests recommended in the True Answer which could enhance coherence with detailed medical context.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the model's response provides a general overview of possible causes and diagnostics for miscarriages, it does not specifically mention the tests suggested in the True Answer, such as diabetes, thyroid issues, and TORCH investigations, which makes it less complete.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The response is fluent, using polite and empathetic language, similar to how a human doctor might address the situation. It maintains a supportive tone, and the language is natural and conversational.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response is somewhat coherent with the context provided in the input, as it acknowledges the blood test results and suggests general health advice such as a healthy diet and regular exercise. However, it misses addressing the specific data points like the vitamin D level, which is a critical factor mentioned in the context. \n",
      "\n",
      "- Completeness: 2.0  \n",
      "  The model's response does not sufficiently answer the question in the input. It misses the crucial detail regarding the borderline vitamin D levels and the specific recommendation to take Cholecalciferol granules. The advice given is too generic and fails to address the specific concerns or preventative measures related to the individual's test results. \n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The model's response is quite fluent and human-like, with polite and professional language that aligns with a typical doctor's approach to addressing patient concerns. However, the slightly formulaic nature of the advice makes it feel somewhat generic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5\n",
      "- Completeness: 4.0\n",
      "- Naturalness: 4.8\n",
      "\n",
      "**Explanation**:\n",
      "- **Coherence (4.5)**: The model's response logically aligns with the user's descriptions of high blood sugar levels, providing general advice on managing high blood sugar. However, it could have been improved by directly addressing all specific elements of the user's situation, such as the potential for continuing the current medication or the feasibility of fasting.\n",
      "  \n",
      "- **Completeness (4.0)**: While the response provides several good recommendations for managing blood sugar levels, it does not fully address the user's query regarding fasting and taking the current hypertension medication, Co-Diovan. It could have included information on HBA1c, checking for retinopathy, and specific dietary restrictions mentioned in the true answer.\n",
      "\n",
      "- **Naturalness (4.8)**: The response is fluent and well-structured, sounding professional and human-like. It uses clear language and provides practical advice, making it highly readable. However, a slightly more empathetic tone may improve its naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context. It acknowledges the patient's high blood sugar levels and suggests seeing a doctor, which is coherent with the situation described by the patient.\n",
      "\n",
      "- Completeness: 4.0  \n",
      "  The model addresses the main issue of high blood sugar levels and recommends consulting a doctor, similar to the true answer. However, it lacks some details, such as target blood sugar levels, lifestyle changes, and the link for further consultation, which are present in the true answer.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response is fluent and human-like. The language is polite and professional, which is appropriate for a doctor's response to a patient inquiry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response is coherent and logically aligns with the context provided, mentioning common causes of foot pain and suggesting possible treatments. However, it lacks specifics about potential conditions like plantar fasciitis, which might have been more directly relevant given the symptoms described.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  The response touches on key points such as potential diagnoses and treatment options, but it remains quite general. It does not directly suggest possible specific conditions or medication regimen like the true answer, which limits its completeness in terms of providing a more targeted recommendation.\n",
      "\n",
      "- Naturalness: 4.7  \n",
      "  The response sounds fluent and human-like, presenting information in a clear, professional manner. It encourages further consultation with a healthcare professional, which adds to its natural presentation. However, the lack of detailed suggestions slightly diminishes the overall professional tone compared to what a human specialist might provide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 3.0  \n",
      "  The model's response is somewhat coherent with the input as it considers the complaint of pain near the rib cage, suggesting a rib fracture as a possible cause. However, it jumps to conclusions without sufficient prior investigation or questioning, which is crucial in the medical field.\n",
      "\n",
      "- Completeness: 2.0  \n",
      "  While the model provides a detailed management plan for a rib fracture, it does not adequately address the question of whether the pain is serious. It lacks a thorough diagnostic inquiry, which is evident in the true answer requiring further information before making a conclusion.\n",
      "\n",
      "- Naturalness: 4.5  \n",
      "  The response is mostly natural and polite, resembling a human-like interaction. The language is clear, and the guidance provided is structured in a coherent manner. However, the insertion of \"[Patient Name]\" indicates a placeholder error, slightly detracting from the naturalness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result:\n",
      "- Coherence: 4.5  \n",
      "  The model's response logically aligns with the context of the elevated CRP levels and gives possible reasons for its elevation. However, it does not directly address the specific mention of IBS, anxiety, tension headaches, and allergic rhinitis in the patient's context, which are likely relevant to the patient's condition.\n",
      "\n",
      "- Completeness: 3.5  \n",
      "  While the response provides a thorough explanation of potential general causes of elevated CRP levels, it misses addressing why the patient's ESR could be normal while the CRP is elevated. Additionally, it does not discuss the connection between the patient's existing medical conditions and the elevated CRP.\n",
      "\n",
      "- Naturalness: 4.8  \n",
      "  The language is fluent and professional, typical of how a medical doctor might explain a concept to a patient. The tone is courteous and informative, making it sound human-like and natural.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌèâÍ∑† Ï†êÏàò:\n",
      "Coherence       3.975000\n",
      "Completeness    3.285000\n",
      "Naturalness     4.592000\n",
      "BLEURT          0.564581\n",
      "BERTScore_F1    0.470551\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# generation\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "generation = df[df['task'] == 'generation']\n",
    "results = []\n",
    "\n",
    "for _, row in generation.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    print(f\"Evaluation result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column BLEURT not found in DataFrame. Skipping normalization.\n",
      "Warning: Column BERTScore_F1 not found in DataFrame. Skipping normalization.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Coherence', 'Completeness', 'Naturalness', 'BLEURT', 'BERTScore_F1'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 147\u001b[0m\n\u001b[1;32m    144\u001b[0m evaluation_df \u001b[38;5;241m=\u001b[39m normalize_scores(evaluation_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEURT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m evaluation_df \u001b[38;5;241m=\u001b[39m normalize_scores(evaluation_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore_F1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m average_scores \u001b[38;5;241m=\u001b[39m evaluation_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoherence\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleteness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaturalness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEURT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTScore_F1\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÌèâÍ∑† Ï†êÏàò:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(average_scores)\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Coherence', 'Completeness', 'Naturalness', 'BLEURT', 'BERTScore_F1'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# daily_diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "daily = df[df['task'] == 'daily_diets']\n",
    "results = []\n",
    "\n",
    "for i, row in daily.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_outpu_1024'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Evaluation {i+1} result:\\n{evaluation}\")\n",
    "    \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌèâÍ∑† Ï†êÏàò:\n",
      "Coherence       3.223577\n",
      "Completeness    2.880081\n",
      "Naturalness     3.008130\n",
      "BLEURT          0.488236\n",
      "BERTScore_F1    0.627131\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# alternative_diets\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_score import score as bert_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# BLEURT Î™®Îç∏ Î°úÎìú\n",
    "bleurt_model_name = \"Elron/bleurt-large-512\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bleurt_model_name)\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(bleurt_model_name)\n",
    "bleurt_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bleurt_model = bleurt_model.to(device)\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "\n",
    "# GPT-4 ÌèâÍ∞Ä Ìï®Ïàò\n",
    "def evaluate_with_gpt4(input_text, model_output, true_output):\n",
    "    input_text = str(input_text)[:MAX_CONTEXT_LENGTH]\n",
    "    model_output = str(model_output)[:MAX_CONTEXT_LENGTH]\n",
    "    true_output = str(true_output)[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with evaluating the quality of a QA model's responses based on the following metrics:\n",
    "    1. **Coherence**: Does the model's response logically align with the context provided in the input?\n",
    "    2. **Completeness**: Does the model's response sufficiently answer the question in the input?\n",
    "    3. **Naturalness**: Does the model's response sound fluent and human-like?\n",
    "\n",
    "    **Input**:\n",
    "    {input_text}\n",
    "\n",
    "    **Model's Response**:\n",
    "    {model_output}\n",
    "\n",
    "    **True Answer**:\n",
    "    {true_output}\n",
    "\n",
    "    Please rate each metric on a scale from 1 to 5. \n",
    "    Example response format:\n",
    "    - Coherence: X.X\n",
    "    - Completeness: X.X\n",
    "    - Naturalness: X.X\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator for Summarization models.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error with GPT-4 API:\", e)\n",
    "        return None\n",
    "\n",
    "# GPT-4 Ï†êÏàò Ï∂îÏ∂ú\n",
    "def extract_scores(evaluation):\n",
    "    if evaluation is None:\n",
    "        return {\"Coherence\": 0.0, \"Completeness\": 0.0, \"Naturalness\": 0.0}\n",
    "    coherence = re.search(r\"Coherence: (\\d\\.\\d)\", evaluation)\n",
    "    completeness = re.search(r\"Completeness: (\\d\\.\\d)\", evaluation)\n",
    "    naturalness = re.search(r\"Naturalness: (\\d\\.\\d)\", evaluation)\n",
    "    \n",
    "    return {\n",
    "        \"Coherence\": float(coherence.group(1)) if coherence else 0.0,\n",
    "        \"Completeness\": float(completeness.group(1)) if completeness else 0.0,\n",
    "        \"Naturalness\": float(naturalness.group(1)) if naturalness else 0.0\n",
    "    }\n",
    "\n",
    "# BLEURT Ï†êÏàò Í≥ÑÏÇ∞\n",
    "def calculate_bleurt(y_true, y_pred):\n",
    "    inputs = tokenizer(y_pred, y_true, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = bleurt_model(**inputs).logits\n",
    "\n",
    "    if scores.numel() == 1:\n",
    "        return float(scores.squeeze().item())  \n",
    "    return [float(score) for score in scores.squeeze().tolist()]  \n",
    "\n",
    "# BLEURT Î∞è BERTScore Í≥ÑÏÇ∞\n",
    "def calculate_bleurt_and_bertscore(y_true, y_pred):\n",
    "    bleurt_score_value = calculate_bleurt(y_true, y_pred)\n",
    "    _, _, bert_f1 = bert_score(y_pred, y_true, lang=\"en\", rescale_with_baseline=True)\n",
    "    bert_f1_avg = sum(bert_f1) / len(bert_f1) if len(bert_f1) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"BLEURT\": bleurt_score_value if isinstance(bleurt_score_value, float) else sum(bleurt_score_value) / len(bleurt_score_value),\n",
    "        \"BERTScore_F1\": bert_f1_avg\n",
    "    }\n",
    "\n",
    "# Ï†êÏàò Ï†ïÍ∑úÌôî Ìï®Ïàò\n",
    "def normalize_scores(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Warning: Column {column} not found in DataFrame. Skipping normalization.\")\n",
    "        return df\n",
    "    df[column] = df[column].apply(lambda x: float(x) if isinstance(x, torch.Tensor) else x)\n",
    "    min_val, max_val = df[column].min(), df[column].max()\n",
    "    df[column] = df[column].apply(lambda x: (x - min_val) / (max_val - min_val) if max_val > min_val else 0.5)\n",
    "    return df\n",
    "\n",
    "alternative = df[df['task'] == 'alternative_diet']\n",
    "results = []\n",
    "\n",
    "for _, row in alternative.iterrows():\n",
    "    input_text = str(row['input'])\n",
    "    model_output = str(row['model_output'])\n",
    "    true_output = str(row['output'])\n",
    "    \n",
    "    evaluation = evaluate_with_gpt4(input_text, model_output, true_output)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Evaluation {i+1} result:\\n{evaluation}\")\n",
    "            \n",
    "    scores = extract_scores(evaluation)\n",
    "    metric_scores = calculate_bleurt_and_bertscore([true_output], [model_output])\n",
    "\n",
    "    results.append({\n",
    "        \"input\": input_text,\n",
    "        \"model_output\": model_output,\n",
    "        \"true_output\": true_output,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"Coherence\": scores[\"Coherence\"],\n",
    "        \"Completeness\": scores[\"Completeness\"],\n",
    "        \"Naturalness\": scores[\"Naturalness\"],\n",
    "        \"BLEURT\": metric_scores.get(\"BLEURT\", 0.0),  # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï\n",
    "        \"BERTScore_F1\": metric_scores.get(\"BERTScore_F1\", 0.0)\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "\n",
    "# 'BLEURT' Ïª¨ÎüºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Ï†ïÍ∑úÌôî ÏàòÌñâ\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BLEURT\")\n",
    "evaluation_df = normalize_scores(evaluation_df, \"BERTScore_F1\")\n",
    "\n",
    "average_scores = evaluation_df[[\"Coherence\", \"Completeness\", \"Naturalness\", \"BLEURT\", \"BERTScore_F1\"]].mean()\n",
    "print(\"ÌèâÍ∑† Ï†êÏàò:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>prep_time</th>\n",
       "      <th>cook_time</th>\n",
       "      <th>servings</th>\n",
       "      <th>steps</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition_facts</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark</td>\n",
       "      <td>Raspberry Swirl Frozen Yogurt Bark: Dive into ...</td>\n",
       "      <td>10 min</td>\n",
       "      <td>4 hr</td>\n",
       "      <td>6 Servings</td>\n",
       "      <td>['Cover a freezer-safe tray with parchment pap...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...</td>\n",
       "      <td>{'Servings': '6 Servings', 'Serving Size': '1 ...</td>\n",
       "      <td>[{'label': 'Plain Nonfat Greek yogurt', 'us_me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maple-Pumpkin Spice Oatmeal Cookies</td>\n",
       "      <td>Description not found</td>\n",
       "      <td>10 min</td>\n",
       "      <td>25 min</td>\n",
       "      <td>14 Servings</td>\n",
       "      <td>['Preheat the oven to 350 degrees F. Line two ...</td>\n",
       "      <td>['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...</td>\n",
       "      <td>{'Servings': '14 Servings', 'Serving Size': '1...</td>\n",
       "      <td>[{'label': 'old-fashioned rolled oats', 'us_me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0   Raspberry Swirl Frozen Yogurt Bark   \n",
       "1  Maple-Pumpkin Spice Oatmeal Cookies   \n",
       "\n",
       "                                         description prep_time cook_time  \\\n",
       "0  Raspberry Swirl Frozen Yogurt Bark: Dive into ...    10 min      4 hr   \n",
       "1                              Description not found    10 min    25 min   \n",
       "\n",
       "      servings                                              steps  \\\n",
       "0   6 Servings  ['Cover a freezer-safe tray with parchment pap...   \n",
       "1  14 Servings  ['Preheat the oven to 350 degrees F. Line two ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Kid Friendly', 'Vegetarian', 'Dessert', 'Sna...   \n",
       "1  ['Kid Friendly', 'Vegetarian', 'Snacks', 'Glut...   \n",
       "\n",
       "                                     nutrition_facts  \\\n",
       "0  {'Servings': '6 Servings', 'Serving Size': '1 ...   \n",
       "1  {'Servings': '14 Servings', 'Serving Size': '1...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  [{'label': 'Plain Nonfat Greek yogurt', 'us_me...  \n",
       "1  [{'label': 'old-fashioned rolled oats', 'us_me...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfh = pd.read_csv(\"/data/jaesung/llm_for_diabetes/src/data/data2_daily_diets/diabetes_food_hub_new_nutri_facts.csv\")\n",
    "dfh.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [00:00<00:00, 22063.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results for Each Row ===\n",
      "Row Index: 661\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 662\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 663\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 664\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 665\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 666\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 667\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 668\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 669\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 670\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 671\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 672\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 673\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 674\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 675\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 676\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 677\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 678\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 679\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 680\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 681\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 682\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 683\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 684\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 685\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 686\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 687\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 688\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 689\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 690\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 691\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 692\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 693\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 694\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 695\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 696\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 697\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 698\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 699\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 700\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 701\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 702\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 703\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 704\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 705\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 706\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 707\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 708\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 709\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 710\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 711\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 712\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 713\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 714\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 715\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 716\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 717\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 718\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 719\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 720\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 721\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 722\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 723\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 724\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 725\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 726\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 727\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 728\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 729\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 730\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 731\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 732\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 733\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 734\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 735\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 736\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 737\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 738\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 739\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 740\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 741\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 742\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 743\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 744\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 745\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 746\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 747\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 748\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 749\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 750\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 751\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 752\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 753\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 754\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 755\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 756\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 757\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 758\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 759\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 760\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 761\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 762\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 763\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 764\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 765\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 766\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 767\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 768\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 769\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 770\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 771\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 772\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 773\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 774\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 775\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 776\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 777\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 778\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 779\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 780\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 781\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 782\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 783\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 784\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 785\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 786\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 787\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 788\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 789\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 790\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 791\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 792\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 793\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 794\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 795\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 796\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 797\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 798\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 799\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 800\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 801\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 802\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 803\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 804\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 805\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 806\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 807\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 808\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 809\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 810\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 811\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 812\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 813\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 814\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 815\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 816\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 817\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 818\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 819\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 820\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 821\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 822\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 823\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 824\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 825\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 826\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 827\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 828\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 829\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 830\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 831\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 832\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 833\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 834\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 835\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 836\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 837\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 838\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 839\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 840\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 841\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 842\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 843\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 844\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 845\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 846\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 847\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 848\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 849\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 850\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 851\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 852\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 853\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 854\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 855\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 856\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 857\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 858\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 859\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 860\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 861\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 862\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 863\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 864\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 865\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 866\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 867\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 868\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 869\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 870\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 871\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 872\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 873\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 874\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 875\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 876\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 877\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 878\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 879\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 880\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 881\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 882\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 883\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 884\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 885\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 886\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 887\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 888\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 889\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 890\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 891\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 892\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 893\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 894\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 895\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 896\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 897\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 898\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 899\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 900\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 901\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 902\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 903\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 904\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 905\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 906\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 907\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 908\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 909\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 910\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 911\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 912\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 913\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 914\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 915\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 916\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 917\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 918\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 919\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 920\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 921\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 922\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 923\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 924\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 925\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 926\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 927\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 928\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 929\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 930\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 931\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 932\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 933\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "Row Index: 934\n",
      "Output Scores: {}\n",
      "Model Output Scores: {}\n",
      "\n",
      "=== Overall Averages ===\n",
      "Output Average Nutri-Score: None\n",
      "Model Output Average Nutri-Score: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# daily diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return all(key in data for key in ['Breakfast', 'Lunch', 'Dinner'])\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # Í≥ºÏùº/Ï±ÑÏÜå ÎπÑÏú®ÏùÑ 100g Í∏∞Ï§ÄÏúºÎ°ú Î≥ÄÌôò\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data) if isinstance(data, (int, float, str)) else default\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # Ï†ÑÏ≤¥ Î¨¥Í≤å Í≥ÑÏÇ∞\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g Í∏∞Ï§ÄÏúºÎ°ú ÏÑ±Î∂Ñ Ï†ïÍ∑úÌôî\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_meal_nutri_score(meal_data, dfh):\n",
    "    meal_scores = {}\n",
    "\n",
    "    for meal, title in meal_data.items():\n",
    "        matched_row = find_most_similar_row(title, dfh)\n",
    "        if matched_row is None:\n",
    "            continue\n",
    "\n",
    "        nutrition_facts = matched_row['nutrition_facts']\n",
    "        ingredients = matched_row['ingredients']\n",
    "        score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "\n",
    "        if score is None:\n",
    "            print(f\"Warning: Nutri-Score calculation failed for meal '{meal}' with title '{title}'.\")\n",
    "            grade = \"N/A\"\n",
    "        else:\n",
    "            grade = get_nutri_score_grade(score)\n",
    "\n",
    "        meal_scores[meal] = {'score': score, 'grade': grade}\n",
    "\n",
    "    return meal_scores\n",
    "\n",
    "def calculate_scores_with_comparison(df, dfh):\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        output_scores = {}\n",
    "        model_scores = {}\n",
    "        if is_valid_meal_structure(row.get('output', '')):\n",
    "            output_data = json.loads(row['output'])\n",
    "            output_scores = calculate_meal_nutri_score(output_data, dfh)\n",
    "        if is_valid_meal_structure(row.get('model_output_512', '')):\n",
    "            model_data = json.loads(row['model_output_512'])\n",
    "            model_scores = calculate_meal_nutri_score(model_data, dfh)\n",
    "        results.append({'row_index': idx, 'output_scores': output_scores, 'model_scores': model_scores})\n",
    "    return results\n",
    "\n",
    "def calculate_average_scores(results):\n",
    "    \"\"\"\n",
    "    Calculate the average Nutri-Scores for outputs and model outputs.\n",
    "    \"\"\"\n",
    "    output_total_score = 0\n",
    "    model_total_score = 0\n",
    "    output_count = 0\n",
    "    model_count = 0\n",
    "\n",
    "    for result in results:\n",
    "        # Extract output scores\n",
    "        for meal, score_data in result['output_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                output_total_score += score_data['score']\n",
    "                output_count += 1\n",
    "\n",
    "        # Extract model scores\n",
    "        for meal, score_data in result['model_scores'].items():\n",
    "            if score_data['score'] is not None:\n",
    "                model_total_score += score_data['score']\n",
    "                model_count += 1\n",
    "\n",
    "    # Calculate averages\n",
    "    output_avg = output_total_score / output_count if output_count > 0 else None\n",
    "    model_avg = model_total_score / model_count if model_count > 0 else None\n",
    "\n",
    "    return output_avg, model_avg\n",
    "\n",
    "\n",
    "# 'daily_diets' task Nutri-Score calculation\n",
    "filtered_df = df[df['task'] == 'daily_diets']\n",
    "results = calculate_scores_with_comparison(filtered_df, dfh)\n",
    "\n",
    "# Calculate overall averages\n",
    "output_avg, model_avg = calculate_average_scores(results)\n",
    "\n",
    "# Print results\n",
    "print(\"=== Results for Each Row ===\")\n",
    "for result in results:\n",
    "    print(f\"Row Index: {result['row_index']}\")\n",
    "    print(f\"Output Scores: {result['output_scores']}\")\n",
    "    print(f\"Model Output Scores: {result['model_scores']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== Overall Averages ===\")\n",
    "print(f\"Output Average Nutri-Score: {output_avg}\")\n",
    "print(f\"Model Output Average Nutri-Score: {model_avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/246 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 158/246 [03:34<01:46,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error identifying fruits and vegetables: unterminated string literal (detected at line 1) (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 207/246 [04:37<00:40,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Total weight is zero. Skipping calculation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 246/246 [05:27<00:00,  1.33s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 216\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# Execution\u001b[39;00m\n\u001b[1;32m    215\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malternative_diet\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 216\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_scores_with_comparison_no_meals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Cell \u001b[0;32mIn[32], line 207\u001b[0m, in \u001b[0;36mcalculate_scores_with_comparison_no_meals\u001b[0;34m(df, dfh)\u001b[0m\n\u001b[1;32m    200\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    201\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_index\u001b[39m\u001b[38;5;124m'\u001b[39m: idx,\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         })\n\u001b[1;32m    206\u001b[0m final_output_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(output_scores_list) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(output_scores_list) \u001b[38;5;28;01mif\u001b[39;00m output_scores_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m final_model_output_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_output_scores_list\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(model_output_scores_list) \u001b[38;5;28;01mif\u001b[39;00m model_output_scores_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Average Nutri-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_output_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Output Average Nutri-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_model_output_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# alternative diet - nutri score\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            match = re.search(r\"(\\d+(\\.\\d+)?)\", value)\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_numeric_value: {e}, value: {value}\")\n",
    "    return 0.0\n",
    "\n",
    "def is_valid_meal_structure(json_string):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return isinstance(data, dict)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return False\n",
    "\n",
    "def find_most_similar_row(title, dfh):\n",
    "    try:\n",
    "        dfh['title'] = dfh['title'].fillna('')  # Handle NaN values\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(dfh['title'])\n",
    "        input_vector = vectorizer.transform([title])\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        return dfh.iloc[most_similar_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_most_similar_row: {e}, title: {title}\")\n",
    "        return None\n",
    "\n",
    "def identify_fruit_veg(ingredients_list):\n",
    "    try:\n",
    "        prompt = f\"Identify which items in the following ingredient list are fruits or vegetables:\\n\\n{ingredients_list}\\n\\nReturn only the names of items that are fruits or vegetables in a Python list format.\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant identifying fruits and vegetables.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0\n",
    "        )\n",
    "        fruits_vegetables = response['choices'][0]['message']['content']\n",
    "        return ast.literal_eval(fruits_vegetables)\n",
    "    except Exception as e:\n",
    "        print(f\"Error identifying fruits and vegetables: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_fruit_veg_points(ingredients, total_weight):\n",
    "    try:\n",
    "        ingredients_list = ast.literal_eval(ingredients)\n",
    "        fruit_veg_labels = identify_fruit_veg(ingredients_list)\n",
    "\n",
    "        fruit_veg_weight = 0\n",
    "        for ingredient in ingredients_list:\n",
    "            label = ingredient.get('label', '')\n",
    "            weight = extract_numeric_value(ingredient.get('metric_measure', 0))\n",
    "            if label in fruit_veg_labels:\n",
    "                fruit_veg_weight += weight\n",
    "\n",
    "        # Í≥ºÏùº/Ï±ÑÏÜå ÎπÑÏú®ÏùÑ 100g Í∏∞Ï§ÄÏúºÎ°ú Î≥ÄÌôò\n",
    "        fruit_veg_ratio = (fruit_veg_weight / total_weight) * 100 if total_weight > 0 else 0\n",
    "\n",
    "        if fruit_veg_ratio > 80:\n",
    "            return 5\n",
    "        elif fruit_veg_ratio > 60:\n",
    "            return 2\n",
    "        elif fruit_veg_ratio > 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating fruit_veg_points: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_nested_value(data, keys, default=0):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, {})\n",
    "            else:\n",
    "                return default\n",
    "        return extract_numeric_value(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_nested_value: {e}, keys: {keys}, data: {data}\")\n",
    "        return default\n",
    "\n",
    "def calculate_nutri_score(nutrition_facts, ingredients):\n",
    "    try:\n",
    "        if isinstance(nutrition_facts, str):\n",
    "            nutrition_facts = ast.literal_eval(nutrition_facts)\n",
    "\n",
    "        # Ï†ÑÏ≤¥ Î¨¥Í≤å Í≥ÑÏÇ∞\n",
    "        total_weight = sum(\n",
    "            extract_numeric_value(ingredient.get('metric_measure', 0)) \n",
    "            for ingredient in ast.literal_eval(ingredients)\n",
    "        )\n",
    "        if total_weight == 0:\n",
    "            print(\"Warning: Total weight is zero. Skipping calculation.\")\n",
    "            return None\n",
    "\n",
    "        # 100g Í∏∞Ï§ÄÏúºÎ°ú ÏÑ±Î∂Ñ Ï†ïÍ∑úÌôî\n",
    "        energy = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Calories']) / total_weight * 100\n",
    "        saturated_fat = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Fat', 'Amount']) / total_weight * 100\n",
    "        sugar = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Total Sugars']) / total_weight * 100\n",
    "        sodium = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Sodium']) / total_weight * 100\n",
    "        fiber = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Total Carbohydrates', 'Dietary Fiber']) / total_weight * 100\n",
    "        protein = extract_nested_value(nutrition_facts, ['Amount per Serving', 'Protein']) / total_weight * 100\n",
    "\n",
    "        # Unfavorable points calculation\n",
    "        energy_points = min(energy / 80, 800)\n",
    "        saturated_fat_points = min(saturated_fat / 1, 10)\n",
    "        sugar_points = min(sugar / 4.5, 45)\n",
    "        sodium_points = min(sodium / 90, 900)\n",
    "\n",
    "        unfavorable_points = energy_points + saturated_fat_points + sugar_points + sodium_points\n",
    "\n",
    "        # Favorable points calculation\n",
    "        fiber_points = min(fiber / 0.7, 3.5)\n",
    "        protein_points = min(protein / 1.6, 8.0)\n",
    "        fruit_veg_points = calculate_fruit_veg_points(ingredients, total_weight)\n",
    "\n",
    "        favorable_points = fiber_points + protein_points + fruit_veg_points\n",
    "\n",
    "        # Final Nutri-Score calculation\n",
    "        total_score = unfavorable_points - favorable_points\n",
    "        return total_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_nutri_score: {e}, nutrition_facts: {nutrition_facts}\")\n",
    "        return None\n",
    "\n",
    "def get_nutri_score_grade(score):\n",
    "    if score <= -1:\n",
    "        return \"A\"\n",
    "    elif score <= 2:\n",
    "        return \"B\"\n",
    "    elif score <= 10:\n",
    "        return \"C\"\n",
    "    elif score <= 18:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "\n",
    "def calculate_scores_with_comparison_no_meals(df, dfh):\n",
    "    results = []\n",
    "    output_scores_list = []\n",
    "    model_output_scores_list = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            output_text = row.get('output', '')\n",
    "            if output_text:\n",
    "                matched_row = find_most_similar_row(output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    output_scores_list.append(output_score)\n",
    "                else:\n",
    "                    output_score = None\n",
    "\n",
    "            model_output_text = row.get('model_output_512', '')\n",
    "            if model_output_text:\n",
    "                matched_row = find_most_similar_row(model_output_text, dfh)\n",
    "                if matched_row is not None:\n",
    "                    nutrition_facts = matched_row['nutrition_facts']\n",
    "                    ingredients = matched_row['ingredients']\n",
    "                    model_output_score = calculate_nutri_score(nutrition_facts, ingredients)\n",
    "                    model_output_scores_list.append(model_output_score)\n",
    "                else:\n",
    "                    model_output_score = None\n",
    "\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': output_score,\n",
    "                'model_output_score': model_output_score\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            results.append({\n",
    "                'row_index': idx,\n",
    "                'output_score': None,\n",
    "                'model_output_score': None\n",
    "            })\n",
    "\n",
    "    final_output_avg = sum(output_scores_list) / len(output_scores_list) if output_scores_list else None\n",
    "    final_model_output_avg = sum(model_output_scores_list) / len(model_output_scores_list) if model_output_scores_list else None\n",
    "\n",
    "    print(f\"Output Average Nutri-Score: {final_output_avg}\")\n",
    "    print(f\"Model Output Average Nutri-Score: {final_model_output_avg}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Execution\n",
    "filtered_df = df[df['task'] == 'alternative_diet']\n",
    "results = calculate_scores_with_comparison_no_meals(filtered_df, dfh)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env_kernel",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
